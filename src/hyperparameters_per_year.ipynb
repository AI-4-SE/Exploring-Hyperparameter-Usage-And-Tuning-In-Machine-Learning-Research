{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "statistic_dir = \"../data/statistics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_latex(df: pd.DataFrame) -> None:\n",
    "    print(df.to_latex(index=False))\n",
    "\n",
    "def get_module(name, data):\n",
    "    module = next(filter(lambda x: name == x[\"name\"], data))\n",
    "    return module\n",
    "\n",
    "with open(\"../data/statistic_files_per_year.json\", \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "    #print(len(data))\n",
    "    #data = data[8:]\n",
    "\n",
    "    #for item in data:\n",
    "    #    print(item[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ml_method_params(library_name: str, library_dir: str, files: str, year: int) -> pd.DataFrame:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [module[\"name\"] for module in library_data]\n",
    "\n",
    "    total_params_set = 0\n",
    "    total_params_available = 0\n",
    "    default_params = 0\n",
    "    customized_params = 0\n",
    "\n",
    "    for project in files:\n",
    "        with open(statistic_dir + project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "                                \n",
    "                                if class_name not in class_names:\n",
    "                                    continue\n",
    "\n",
    "                                library_module_data = get_module(class_name, library_data)\n",
    "                                library_module_params = library_module_data[\"params\"]\n",
    "                                total_params_available += len(library_module_params)\n",
    "\n",
    "                                for name, value in data.items():\n",
    "                                    if name in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        total_params_set += 1\n",
    "                                        if name in library_module_params.keys():\n",
    "\n",
    "                                            if str(library_module_params[name]).replace(\"'\", \"\") == value[\"value\"]:\n",
    "                                                default_params += 1\n",
    "                                            else:\n",
    "                                                customized_params += 1\n",
    "                                        else:\n",
    "                                            customized_params += 1\n",
    "\n",
    "\n",
    "    assert total_params_set == default_params + customized_params\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"Year\"] = [year]\n",
    "    df[\"Paper Count\"] = [len(files)]\n",
    "    df[\"Available\"] = [total_params_available]\n",
    "    df[\"Set\"] = [total_params_set]\n",
    "    df[\"Default\"] = [default_params]\n",
    "    df[\"Custom\"] = [customized_params]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Count params of ML methods across the code repositories for which the respective paper reported hyperparameter tuning\n",
    "with open(\"../data/repos_hyperparameter_tuning.json\", \"r\", encoding=\"utf-8\") as src:\n",
    "    repos_files = json.load(src)\n",
    "\n",
    "#df_sklearn = count_ml_method_params(\"sklearn\", \"../data/library_data/sklearn_estimators.json\" , repos_files)#\n",
    "#df_tf = count_ml_method_params(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\" , repos_files)\n",
    "#df_pytorch = count_ml_method_params(\"torch\", \"../data/library_data/torch_optimizer.json\" , repos_files)\n",
    "#df_all = pd.concat([df_sklearn, df_tf, df_pytorch])\n",
    "\n",
    "#df_to_latex(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &         90 &    6 &        0 &       6 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2014 &            7 &          0 &    0 &        0 &       0 \\\\\n",
      " 2015 &           10 &          0 &    0 &        0 &       0 \\\\\n",
      " 2016 &           20 &         12 &    2 &        2 &       0 \\\\\n",
      " 2017 &           27 &         25 &   14 &        0 &      14 \\\\\n",
      " 2018 &           79 &        599 &  189 &       50 &     139 \\\\\n",
      " 2019 &          103 &        566 &   72 &        6 &      66 \\\\\n",
      " 2020 &          162 &        725 &  118 &       26 &      92 \\\\\n",
      " 2021 &          104 &       1541 &  221 &       36 &     185 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &         14 &    1 &        0 &       1 \\\\\n",
      " 2014 &            7 &         91 &   21 &        0 &      21 \\\\\n",
      " 2015 &           10 &          6 &    1 &        0 &       1 \\\\\n",
      " 2016 &           20 &        132 &   12 &        0 &      12 \\\\\n",
      " 2017 &           27 &        252 &   45 &        1 &      44 \\\\\n",
      " 2018 &           79 &        592 &  178 &        8 &     170 \\\\\n",
      " 2019 &          103 &       1761 &  533 &      200 &     333 \\\\\n",
      " 2020 &          162 &       1355 &  212 &       15 &     197 \\\\\n",
      " 2021 &          104 &        460 &   70 &       11 &      59 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2014 &            7 &         84 &   24 &        0 &      24 \\\\\n",
      " 2015 &           10 &         90 &   25 &        3 &      22 \\\\\n",
      " 2016 &           20 &         21 &    7 &        0 &       7 \\\\\n",
      " 2017 &           27 &        250 &   56 &        1 &      55 \\\\\n",
      " 2018 &           79 &        834 &  171 &       16 &     155 \\\\\n",
      " 2019 &          103 &       1179 &  288 &        7 &     281 \\\\\n",
      " 2020 &          162 &       2545 &  744 &       17 &     727 \\\\\n",
      " 2021 &          104 &       1798 &  438 &       28 &     410 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_hp_tuning_stats_per_year(data: List, library_name: str, library_dir: str):\n",
    "    dfs = []\n",
    "\n",
    "    for item in data:\n",
    "        files = item[\"hp_yes\"]\n",
    "\n",
    "        if not files:\n",
    "            df = pd.DataFrame()\n",
    "            df[\"Year\"] = [item[\"year\"]]\n",
    "            df[\"Paper Count\"] = [len(files)]\n",
    "            df[\"Available\"] = [0]\n",
    "            df[\"Set\"] = [0]\n",
    "            df[\"Default\"] = [0]\n",
    "            df[\"Custom\"] = [0]\n",
    "            dfs.append(df)\n",
    "            continue\n",
    "\n",
    "        df = count_ml_method_params(library_name=library_name, library_dir=library_dir, files=files, year=item[\"year\"])\n",
    "        dfs.append(df)\n",
    "    \n",
    "    df_all = pd.concat(dfs)\n",
    "    return df_all\n",
    "\n",
    "df_sklearn = get_hp_tuning_stats_per_year(data, \"sklearn\", \"../data/library_data/sklearn_estimators.json\")\n",
    "df_tf = get_hp_tuning_stats_per_year(data, \"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\")\n",
    "df_torch = get_hp_tuning_stats_per_year(data, \"torch\", \"../data/library_data/torch_optimizer.json\")\n",
    "            \n",
    "df_to_latex(df_sklearn)\n",
    "df_to_latex(df_tf)\n",
    "df_to_latex(df_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &         90 &    6 &        0 &       6 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2014 &            7 &          0 &    0 &        0 &       0 \\\\\n",
      " 2015 &           10 &          0 &    0 &        0 &       0 \\\\\n",
      " 2016 &           20 &         12 &    2 &        2 &       0 \\\\\n",
      " 2017 &           27 &         25 &   14 &        0 &      14 \\\\\n",
      " 2018 &           79 &        599 &  189 &       50 &     139 \\\\\n",
      " 2019 &          103 &        566 &   72 &        6 &      66 \\\\\n",
      " 2020 &          162 &        725 &  118 &       26 &      92 \\\\\n",
      " 2021 &          104 &       1541 &  221 &       36 &     185 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &         14 &    1 &        0 &       1 \\\\\n",
      " 2014 &            7 &         91 &   21 &        0 &      21 \\\\\n",
      " 2015 &           10 &          6 &    1 &        0 &       1 \\\\\n",
      " 2016 &           20 &        132 &   12 &        0 &      12 \\\\\n",
      " 2017 &           27 &        252 &   45 &        1 &      44 \\\\\n",
      " 2018 &           79 &        592 &  178 &        8 &     170 \\\\\n",
      " 2019 &          103 &       1761 &  533 &      200 &     333 \\\\\n",
      " 2020 &          162 &       1355 &  212 &       15 &     197 \\\\\n",
      " 2021 &          104 &        460 &   70 &       11 &      59 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &          0 &    0 &        0 &       0 \\\\\n",
      " 2014 &            7 &         84 &   24 &        0 &      24 \\\\\n",
      " 2015 &           10 &         90 &   25 &        3 &      22 \\\\\n",
      " 2016 &           20 &         21 &    7 &        0 &       7 \\\\\n",
      " 2017 &           27 &        250 &   56 &        1 &      55 \\\\\n",
      " 2018 &           79 &        834 &  171 &       16 &     155 \\\\\n",
      " 2019 &          103 &       1179 &  288 &        7 &     281 \\\\\n",
      " 2020 &          162 &       2545 &  744 &       17 &     727 \\\\\n",
      " 2021 &          104 &       1798 &  438 &       28 &     410 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_final_hp_values_stats_per_year(data: List, library_name: str, library_dir: str):\n",
    "    dfs = []\n",
    "\n",
    "    for item in data:\n",
    "        files = item[\"fv_yes\"]\n",
    "\n",
    "        if not files:\n",
    "            df = pd.DataFrame()\n",
    "            df[\"Year\"] = [item[\"year\"]]\n",
    "            df[\"Paper Count\"] = [len(files)]\n",
    "            df[\"Available\"] = [0]\n",
    "            df[\"Set\"] = [0]\n",
    "            df[\"Default\"] = [0]\n",
    "            df[\"Custom\"] = [0]\n",
    "            dfs.append(df)\n",
    "            continue\n",
    "\n",
    "        df = count_ml_method_params(library_name=library_name, library_dir=library_dir, files=files, year=item[\"year\"])\n",
    "        dfs.append(df)\n",
    "    \n",
    "    df_all = pd.concat(dfs)\n",
    "    return df_all\n",
    "\n",
    "df_sklearn = get_hp_tuning_stats_per_year(data, \"sklearn\", \"../data/library_data/sklearn_estimators.json\")\n",
    "df_tf = get_hp_tuning_stats_per_year(data, \"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\")\n",
    "df_torch = get_hp_tuning_stats_per_year(data, \"torch\", \"../data/library_data/torch_optimizer.json\")\n",
    "            \n",
    "df_to_latex(df_sklearn)\n",
    "df_to_latex(df_tf)\n",
    "df_to_latex(df_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ml_method_params(library_name: str, library_dir: str, files: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [module[\"name\"] for module in library_data]\n",
    "\n",
    "    total_params_set = 0\n",
    "    total_params_available = 0\n",
    "    default_params = 0\n",
    "    customized_params = 0\n",
    "\n",
    "    for project in files:\n",
    "        with open(statistic_dir + project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "                                \n",
    "                                if class_name not in class_names:\n",
    "                                    continue\n",
    "\n",
    "                                library_module_data = get_module(class_name, library_data)\n",
    "                                library_module_params = library_module_data[\"params\"]\n",
    "                                total_params_available += len(library_module_params)\n",
    "\n",
    "                                for name, value in data.items():\n",
    "                                    if name in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        total_params_set += 1\n",
    "                                        if name in library_module_params.keys():\n",
    "\n",
    "                                            if str(library_module_params[name]).replace(\"'\", \"\") == value[\"value\"]:\n",
    "                                                default_params += 1\n",
    "                                            else:\n",
    "                                                customized_params += 1\n",
    "                                        else:\n",
    "                                            customized_params += 1\n",
    "\n",
    "\n",
    "    assert total_params_set == default_params + customized_params\n",
    "\n",
    "    return total_params_available, total_params_set, default_params, customized_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      " Year &  Paper Count &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      " 1994 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2002 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2009 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2010 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2011 &            1 &         90 &    6 &        0 &       6 \\\\\n",
      " 2012 &            0 &          0 &    0 &        0 &       0 \\\\\n",
      " 2013 &            1 &         14 &    1 &        0 &       1 \\\\\n",
      " 2014 &            7 &        175 &   45 &        0 &      45 \\\\\n",
      " 2015 &           10 &         96 &   26 &        3 &      23 \\\\\n",
      " 2016 &           20 &        165 &   21 &        2 &      19 \\\\\n",
      " 2017 &           27 &        527 &  115 &        2 &     113 \\\\\n",
      " 2018 &           79 &       2025 &  538 &       74 &     464 \\\\\n",
      " 2019 &          103 &       3506 &  893 &      213 &     680 \\\\\n",
      " 2020 &          162 &       4625 & 1074 &       58 &    1016 \\\\\n",
      " 2021 &          104 &       3799 &  729 &       75 &     654 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_hp_tuning_stats_per_year(data):\n",
    "    dfs = []\n",
    "    for item in data:\n",
    "        total_parameter = 0\n",
    "        actually_set = 0\n",
    "        default = 0\n",
    "        customized = 0\n",
    "        files = item[\"hp_yes\"]\n",
    "        year = item[\"year\"]\n",
    "\n",
    "\n",
    "        if not files:\n",
    "            total_parameter += 0\n",
    "            actually_set += 0 \n",
    "            default += 0\n",
    "            customized += 0\n",
    "        else:\n",
    "            sklearn_total, sklearn_set, sklearn_def, sklearn_cus = count_ml_method_params(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", files=files)\n",
    "            tf_total, tf_set, tf_def, tf_cus = count_ml_method_params(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", files=files)\n",
    "            torch_total, torch_set, torch_def, torch_cus = count_ml_method_params(\"torch\", \"../data/library_data/torch_optimizer.json\", files=files)\n",
    "\n",
    "            total_parameter += sklearn_total + tf_total + torch_total\n",
    "            actually_set += sklearn_set + tf_set + torch_set\n",
    "            default += sklearn_def + tf_def + torch_def\n",
    "            customized += sklearn_cus + tf_cus + torch_cus\n",
    "\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Year\"] = [item[\"year\"]]\n",
    "        df[\"Paper Count\"] = [len(files)]\n",
    "        df[\"Available\"] = [total_parameter]\n",
    "        df[\"Set\"] = [actually_set]\n",
    "        df[\"Default\"] = [default]\n",
    "        df[\"Custom\"] = [customized]    \n",
    "        dfs.append(df)\n",
    "\n",
    "    df_all = pd.concat(dfs)\n",
    "    return df_all\n",
    "\n",
    "df_all = get_hp_tuning_stats_per_year(data)\n",
    "\n",
    "#df_sklearn = get_hp_tuning_stats_per_year(data, \"sklearn\", \"../data/library_data/sklearn_estimators.json\")\n",
    "#df_tf = get_hp_tuning_stats_per_year(data, \"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\")\n",
    "#df_torch = get_hp_tuning_stats_per_year(data, \"torch\", \"../data/library_data/torch_optimizer.json\")\n",
    "            \n",
    "df_to_latex(df_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
