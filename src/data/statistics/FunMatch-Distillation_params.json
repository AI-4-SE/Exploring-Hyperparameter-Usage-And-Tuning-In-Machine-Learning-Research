{
    "crop_resize.py": {
        "tensorflow": {
            "sample_distorted_bounding_box_51": {
                "variable": {
                    "value": "sample_distorted_bounding_box",
                    "type": "Variable",
                    "possible_values": []
                },
                "image_size": {
                    "value": "tf.shape(image)",
                    "type": "Call",
                    "possible_values": []
                },
                "bounding_boxes": {
                    "value": "bbox",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "min_object_covered": {
                    "value": "min_object_covered",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                },
                "aspect_ratio_range": {
                    "value": "aspect_ratio_range",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(3.0 / 4.0",
                            "MethodArgument"
                        ]
                    ]
                },
                "area_range": {
                    "value": "area_range",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(0.05",
                            "MethodArgument"
                        ]
                    ]
                },
                "max_attempts": {
                    "value": "max_attempts",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "100",
                            "MethodArgument"
                        ]
                    ]
                },
                "use_image_if_no_bounding_boxes": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "slice_63": {
                "variable": {
                    "value": "cropped_image",
                    "type": "Variable",
                    "possible_values": []
                },
                "input_": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "begin": {
                    "value": "bbox_begin",
                    "type": "Variable",
                    "possible_values": []
                },
                "size": {
                    "value": "bbox_size",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "resize_94": {
                "variable": {
                    "value": "distorted_image",
                    "type": "Variable",
                    "possible_values": []
                },
                "images": {
                    "value": "distorted_image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.resize(distorted_image, (height, width))",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(height, width)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "constant_83": {
                "variable": {
                    "value": "bbox",
                    "type": "Variable",
                    "possible_values": []
                },
                "value": {
                    "value": "[0.0, 0.0, 1.0, 1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shape": {
                    "value": "[1, 1, 4]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "convert_image_dtype_86": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "shape_52": {
                "input": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.float32)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    }
}