{
    "eval_lm.py": {
        "torch": {
            "is_available_55": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/bleu.py": {
        "torch": {}
    },
    "fairseq/checkpoint_utils.py": {
        "torch": {
            "load_132": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "path",
                            "Method Argument"
                        ],
                        [
                            "path",
                            "Method Argument"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "save_192": {
                "obj": {
                    "value": "*args",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "is_tensor_206": {
                "obj": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'args': args, 'model': model_state_dict if model_state_dict else {}, 'optimizer_history': optim_history + [{'criterion_name': criterion.__class__.__name__, 'optimizer_name': optimizer.__class__.__name__, 'lr_scheduler_state': lr_scheduler.state_dict(), 'num_updates': num_updates}], 'last_optimizer_state': convert_state_dict_type(optimizer.state_dict()), 'extra_state': extra_state}",
                            "Dict"
                        ],
                        [
                            "state_dict",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/criterions/adaptive_loss.py": {
        "torch": {
            "cross_entropy_60": {
                "input": {
                    "value": "logits[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "target": {
                    "value": "target[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum if reduce else none",
                    "type": "IfExp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/criterions/composite_loss.py": {
        "torch": {}
    },
    "fairseq/criterions/cross_entropy.py": {
        "torch": {
            "nll_loss_45": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_normalized_probs(net_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "lprobs.view(-1, lprobs.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, net_output).view(-1)",
                            "Call"
                        ]
                    ]
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum if reduce else none",
                    "type": "IfExp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/criterions/fairseq_criterion.py": {
        "torch": {}
    },
    "fairseq/criterions/label_smoothed_cross_entropy.py": {
        "torch": {
            "bernoulli_92": {
                "variable": {
                    "value": "drop_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "drop_p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_drop * torch.ones_like(loss_weight)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "tensor_28": {
                "variable": {
                    "value": "freq",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "freq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(freq)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_38": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.tensor([1.0, 1.0, 1.0, 1.0]), self.weight]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ones_like_91": {
                "input": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight[target]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "exp_31": {
                "input": {
                    "value": "-1 * args.adaptive_T * item / mid",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "tensor_38": {
                "data": {
                    "value": "[1.0, 1.0, 1.0, 1.0]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "pow_35": {
                "input": {
                    "value": "item / mid",
                    "type": "BinOp",
                    "possible_values": []
                },
                "exponent": {
                    "value": "torch.tensor(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "exp_35": {
                "input": {
                    "value": "-1 * args.adaptive_T * item / mid",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "tensor_35": {
                "data": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/criterions/masked_lm_loss.py": {
        "torch": {
            "nll_loss_26": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.log_softmax(logits, -1, dtype=torch.float32)",
                    "type": "Call",
                    "possible_values": []
                },
                "target": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "targets",
                            "Method Argument"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "ignore_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-100",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_27": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "logits",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/backtranslation_dataset.py": {
        "torch": {
            "is_available_94": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/block_pair_dataset.py": {
        "torch": {
            "cat_287": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.dataset[idx] for idx in range(start_ds_idx, end_ds_idx + 1)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/dictionary.py": {
        "torch": {
            "Tensor_220": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "is_tensor_56": {
                "obj": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/fairseq_dataset.py": {
        "torch": {}
    },
    "fairseq/data/indexed_dataset.py": {
        "torch": {
            "from_numpy_129": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "a",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "from_numpy_195": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "a",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "from_numpy_432": {
                "variable": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.frombuffer(self._bin_buffer, dtype=self._index.dtype, count=size, offset=ptr)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/iterators.py": {
        "torch": {
            "DataLoader_191": {
                "dataset": {
                    "value": "self.dataset",
                    "type": "Attribute",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "self.collate_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_sampler": {
                    "value": "batches[offset:]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(list(batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "list(ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[]))",
                            "Call"
                        ],
                        [
                            "shuffle_batches(list(self.frozen_batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(batches, self.seed + epoch + self.shard_id)",
                            "Call"
                        ],
                        [
                            "list(ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[]))",
                            "Call"
                        ],
                        [
                            "batches",
                            "Method Argument"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "self.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/language_pair_dataset.py": {
        "torch": {
            "cat_135": {
                "variable": {
                    "value": "tgt_item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.tgt[index], torch.LongTensor([eos])]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/lm_context_window_dataset.py": {
        "torch": {
            "from_numpy_59": {
                "variable": {
                    "value": "sample[net_input][src_tokens]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_toks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty([bsz, tsz + self.context_window], dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_60": {
                "variable": {
                    "value": "sample[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_tgt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.full([bsz, tsz + self.context_window], pad, dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/masked_lm_dataset.py": {
        "torch": {}
    },
    "fairseq/data/monolingual_dataset.py": {
        "torch": {
            "cat_136": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[source.new([self.vocab.bos()]), source]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_108": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[source, source.new([self.vocab.eos()])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_138": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[target.new([self.tgt_vocab.bos()]), target]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_111": {
                "variable": {
                    "value": "future_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[future_target, future_target.new([self.vocab.pad()])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_115": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[past_target.new([self.vocab.pad()]), past_target[1:], source[-2, None]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/noising.py": {
        "torch": {
            "t_65": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.t(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "t_295": {
                "variable": {
                    "value": "src_tokens_t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.src_dataset[index]",
                            "Subscript"
                        ],
                        [
                            "src_tokens.unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "t_302": {
                "variable": {
                    "value": "noisy_src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "noisy_src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.word_shuffle.noising(x=x, lengths=lengths, max_shuffle_distance=self.max_word_shuffle_distance)",
                            "Call"
                        ],
                        [
                            "self.word_dropout.noising(x=noisy_src_tokens, lengths=noisy_src_lengths, dropout_prob=self.word_dropout_prob)",
                            "Call"
                        ],
                        [
                            "self.word_dropout.noising(x=noisy_src_tokens, lengths=noisy_src_lengths, dropout_prob=self.word_blanking_prob, blank_idx=self.dictionary.unk())",
                            "Call"
                        ],
                        [
                            "self.noiser.noising(src_tokens_t, src_lengths)",
                            "Call"
                        ],
                        [
                            "torch.t(noisy_src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_184": {
                "ndarray": {
                    "value": "permutation",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.argsort()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/token_block_dataset.py": {
        "torch": {
            "cat_119": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.dataset[idx] for idx in range(start_ds_idx, end_ds_idx + 1)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "cat_132": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.eos]), buffer[0:e - 1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_133": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.pad, self.eos]), buffer[0:e - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cumsum_73": {
                "variable": {
                    "value": "cumsum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "sizes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.array(sizes, dtype=int)",
                            "Call"
                        ],
                        [
                            "torch.tensor(sizes)",
                            "Call"
                        ],
                        [
                            "sizes",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_137": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.eos]), buffer[0:e - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_72": {
                "variable": {
                    "value": "sizes",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "sizes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.array(sizes, dtype=int)",
                            "Call"
                        ],
                        [
                            "torch.tensor(sizes)",
                            "Call"
                        ],
                        [
                            "sizes",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "is_tensor_71": {
                "obj": {
                    "value": "sizes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.array(sizes, dtype=int)",
                            "Call"
                        ],
                        [
                            "torch.tensor(sizes)",
                            "Call"
                        ],
                        [
                            "sizes",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/transform_eos_dataset.py": {
        "torch": {
            "cat_84": {
                "variable": {
                    "value": "item[source]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item['source'], self.eos]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_90": {
                "variable": {
                    "value": "item[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item['target'], self.eos]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/distributed_utils.py": {
        "torch": {
            "is_initialized_70": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "rand_85": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/file_utils.py": {
        "torch": {}
    },
    "fairseq/legacy_distributed_data_parallel.py": {
        "torch": {
            "zeros_like_144": {
                "variable": {
                    "value": "param.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "param",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_111": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ],
                        [
                            "params[0]",
                            "Subscript"
                        ],
                        [
                            "params",
                            "variable"
                        ],
                        [
                            "params",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/models/distributed_fairseq_model.py": {
        "torch": {}
    },
    "fairseq/models/fairseq_decoder.py": {
        "torch": {}
    },
    "fairseq/models/fairseq_encoder.py": {
        "torch": {}
    },
    "fairseq/models/fairseq_model.py": {
        "torch": {
            "ModuleDict_271": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "{key: FairseqModel(encoders[key], decoders[key]) for key in self.keys}",
                    "type": "DictComp",
                    "possible_values": []
                }
            },
            "is_tensor_425": {
                "obj": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)",
                            "Call"
                        ],
                        [
                            "self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)",
                            "Call"
                        ],
                        [
                            "self.models[key].encoder(src_tokens, src_lengths, **kwargs)",
                            "Call"
                        ],
                        [
                            "net_output['encoder_out']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "is_tensor_48": {
                "obj": {
                    "value": "net_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output",
                            "Method Argument"
                        ],
                        [
                            "net_output",
                            "Method Argument"
                        ],
                        [
                            "net_output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "remove_weight_norm_110": {
                "module": {
                    "value": "module",
                    "type": "variable",
                    "possible_values": [
                        [
                            "module",
                            "Method Argument"
                        ],
                        [
                            "module",
                            "Method Argument"
                        ],
                        [
                            "module",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_428": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_430": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_51": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_53": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/fconv.py": {
        "torch": {
            "Embedding_556": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_571": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_157": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_158": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_202": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_306": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x.view(sz[0] * sz[1], sz[2])",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_368": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_369": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_370": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_428": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "weight_norm_574": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_583": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "weight_norm_593": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_228": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_237": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_449": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_451": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_479": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_235": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, padding_r)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Linear_404": {
                "variable": {
                    "value": "self.fc3",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "out_embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "weight_norm_501": {
                "variable": {
                    "value": "self.convolutions[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "module": {
                    "value": "conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "zip(self.projections, self.convolutions, self.residuals)",
                            "Call"
                        ],
                        [
                            "zip(self.projections, self.convolutions, self.attention, self.residuals)",
                            "Call"
                        ],
                        [
                            "conv in enumerate(self.convolutions)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "remove_weight_norm_500": {
                "module": {
                    "value": "conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "zip(self.projections, self.convolutions, self.residuals)",
                            "Call"
                        ],
                        [
                            "zip(self.projections, self.convolutions, self.attention, self.residuals)",
                            "Call"
                        ],
                        [
                            "conv in enumerate(self.convolutions)",
                            "Call"
                        ]
                    ]
                }
            },
            "Tensor_496": {}
        }
    },
    "fairseq/models/fconv_self_att.py": {
        "torch": {
            "Embedding_485": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_498": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_172": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_173": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_174": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_175": {
                "variable": {
                    "value": "self.attproj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_194": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_308": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_309": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_310": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_311": {
                "variable": {
                    "value": "self.selfattention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_312": {
                "variable": {
                    "value": "self.attproj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_385": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_426": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_214": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_217": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, padding_r)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "glu_219": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_349": {
                "variable": {
                    "value": "self.gate1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_350": {
                "variable": {
                    "value": "self.gate2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_352": {
                "variable": {
                    "value": "self.joining",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim * 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_401": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_403": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_433": {
                "variable": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x, self.pretrained_outputs['out']]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_438": {
                "variable": {
                    "value": "fusion",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[gated_x1, gated_x2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Sigmoid_349": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sigmoid_350": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_355": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_358": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/lightconv.py": {
        "torch": {
            "Embedding_653": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_660": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_205": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_232": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_315": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_380": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_471": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for _ in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_485": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_493": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_499": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_500": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_502": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_594": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_600": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_629": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_630": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_632": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "triu_425": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_427": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "GLU_447": {
                "variable": {
                    "value": "self.act",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_535": {
                "variable": {
                    "value": "self.act",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_623": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_337": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_410": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_412": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/lstm.py": {
        "torch": {
            "Embedding_473": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(task.source_dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "LSTM_480": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LSTMCell_488": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "input_size": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size",
                            "Method Argument"
                        ],
                        [
                            "input_size",
                            "Method Argument"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hidden_size",
                            "Method Argument"
                        ],
                        [
                            "hidden_size",
                            "Method Argument"
                        ],
                        [
                            "512",
                            "Method Argument"
                        ],
                        [
                            "512",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_497": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_223": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_in",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_229": {
                "variable": {
                    "value": "packed_x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "src_lengths.data.tolist()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_241": {
                "variable": {
                    "value": "(x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "sequence": {
                    "value": "packed_outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.lstm(packed_x, (h0, c0))",
                            "Call"
                        ]
                    ]
                },
                "padding_value": {
                    "value": "self.padding_value",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_242": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_300": {
                "variable": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(source_hids * x.unsqueeze(0)).sum(dim=2)",
                            "Call"
                        ],
                        [
                            "attn_scores.float().masked_fill_(encoder_padding_mask, float('-inf')).type_as(attn_scores)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_scores, dim=0)",
                            "Call"
                        ],
                        [
                            "x.new_zeros(srclen, seqlen, bsz)",
                            "Call"
                        ],
                        [
                            "attn_scores.transpose(0, 2)",
                            "Call"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tanh_305": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.output_proj(torch.cat((x, input), dim=1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_338": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LSTMCell(input_size=hidden_size + embed_dim if layer == 0 else hidden_size, hidden_size=hidden_size) for layer in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_373": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_in",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_428": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "outs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_395": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x[j, :, :], input_feed)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_413": {
                "variable": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()",
                            "Call"
                        ],
                        [
                            "self.attention(hidden, encoder_outs, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "hidden",
                            "variable"
                        ],
                        [
                            "F.dropout(out, p=self.dropout_out, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_402": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "rnn(input, (prev_hiddens[i], prev_cells[i]))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_443": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_445": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_305": {
                "tensors": {
                    "value": "(x, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/masked_lm.py": {
        "torch": {
            "Linear_168": {
                "variable": {
                    "value": "self.masked_lm_pooler",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_173": {
                "variable": {
                    "value": "self.lm_head_transform_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_179": {
                "variable": {
                    "value": "self.lm_output_learned_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(self.vocab_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_229": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "inner_states[-1].transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(self.activation_fn(self.lm_head_transform_weight(x)))",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.sentence_encoder.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.embed_out(x)",
                            "Call"
                        ],
                        [
                            "x + self.lm_output_learned_bias",
                            "BinOp"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.sentence_encoder.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_182": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_189": {
                "variable": {
                    "value": "self.sentence_projection_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.sentence_out_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_179": {
                "*size": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/transformer.py": {
        "torch": {
            "Embedding_730": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_737": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_189": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_219": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_323": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_400": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_555": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_562": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.activation_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_564": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_678": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_707": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.activation_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_709": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "triu_450": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_452": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_700": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_345": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), self.output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_435": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_437": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_278": {},
            "Tensor_478": {}
        }
    },
    "fairseq/modules/adaptive_input.py": {
        "torch": {
            "ModuleList_38": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_43": {
                "variable": {
                    "value": "seq",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Embedding(size, dim, padding_idx)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_44": {
                "num_embeddings": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.cutoff[i] - prev",
                            "BinOp"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_45": {
                "in_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/adaptive_softmax.py": {
        "torch": {
            "Linear_39": {
                "variable": {
                    "value": "self.class_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_classes",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "LogSoftmax_76": {
                "variable": {
                    "value": "self.lsm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_94": {
                "variable": {
                    "value": "self.tail",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_159": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_23": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight.t() if self.transpose else self.weight",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Sequential_34": {
                "variable": {
                    "value": "self.word_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(input_dim, emb_dim, bias=False)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_81": {
                "variable": {
                    "value": "self.head",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cutoff[0] + len(cutoff) - 1",
                            "BinOp"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Sequential_109": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_107": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + 1))",
                            "Call"
                        ],
                        [
                            "input.size()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_35": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "emb_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tied_emb.size()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_105": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "tied_proj.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "tied_proj.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_111": {
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_112": {
                "in_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + 1))",
                            "Call"
                        ],
                        [
                            "input.size()",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.cutoff[i + 1] - self.cutoff[i]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/beamable_mm.py": {
        "torch": {
            "mm_41": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mat2": {
                    "value": "input2[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/character_token_embedder.py": {
        "torch": {
            "Embedding_38": {
                "variable": {
                    "value": "self.char_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "257",
                    "type": "int",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "char_embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "variable": {
                    "value": "self.symbol_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(2, word_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_43": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_53": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "last_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sum((f[1] for f in filters))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "word_embed_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_154": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "conv_result",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "max_150": {
                "variable": {
                    "value": "(x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv(char_embs)",
                            "Call"
                        ],
                        [
                            "torch.max(x, -1)",
                            "Call"
                        ],
                        [
                            "F.relu(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(conv_result, dim=-1)",
                            "Call"
                        ],
                        [
                            "self.highway(x)",
                            "Call"
                        ],
                        [
                            "self.projection(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_151": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv(char_embs)",
                            "Call"
                        ],
                        [
                            "torch.max(x, -1)",
                            "Call"
                        ],
                        [
                            "F.relu(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(conv_result, dim=-1)",
                            "Call"
                        ],
                        [
                            "self.highway(x)",
                            "Call"
                        ],
                        [
                            "self.projection(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_124": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "pads.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "word_embs.new_zeros(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_126": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "eos.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "self.symbol_embeddings[self.eos_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_128": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "unk.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "self.symbol_embeddings[self.unk_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "Conv1d_46": {
                "in_channels": {
                    "value": "char_embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_c",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filters",
                            "variable"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "width",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filters",
                            "variable"
                        ]
                    ]
                }
            },
            "where_109": {
                "variable": {
                    "value": "chars",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "eos.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "chars.new_zeros(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "chars",
                    "type": "variable",
                    "possible_values": [
                        [
                            "vocab[i].encode()",
                            "Call"
                        ],
                        [
                            "input.view(-1, self.max_char_len)",
                            "Call"
                        ],
                        [
                            "self.word_to_char[flat_words.type_as(self.word_to_char)].type_as(input)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), chars.new_zeros(1), chars)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/conv_tbc.py": {
        "torch": {
            "Parameter_25": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.kernel_size[0], in_channels, out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_27": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/downsampled_multihead_attention.py": {
        "torch": {
            "Linear_244": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ],
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ],
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Sequential_54": {
                "variable": {
                    "value": "self.in_proj_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*k_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Sequential_55": {
                "variable": {
                    "value": "self.in_proj_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*v_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "bmm_108": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query",
                            "variable"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "q.view(tgt_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "q.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_138": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_139": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_141": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "value",
                            "variable"
                        ],
                        [
                            "self.in_proj_v(v)",
                            "Call"
                        ],
                        [
                            "v.view(src_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "v.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "scalar_bias(v, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_247": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Linear(in_features, out_features, bias=bias)",
                            "Call"
                        ]
                    ]
                }
            },
            "Sequential_252": {
                "*args": {
                    "value": "Linear(in_features, out_features * 4, dropout, bias)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_214": {
                "variable": {
                    "value": "full_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_223": {
                "variable": {
                    "value": "full_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_224": {
                "variable": {
                    "value": "full_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "GLU_254": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_256": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "unsqueeze_112": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_116": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tril_112": {
                "input": {
                    "value": "attn_weights.data.new([1]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "triu_116": {
                "input": {
                    "value": "attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/dynamic_convolution.py": {
        "torch": {
            "Linear_17": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_151": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "bmm_153": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "unfold1d(x, K, padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight.unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_200": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, 0, self.input_size).contiguous()",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, 0, self.input_size).contiguous()",
                            "Call"
                        ],
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_67": {
                "variable": {
                    "value": "self.conv_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_127": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_141": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_149": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_176": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_187": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_188": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_175": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/gelu.py": {
        "torch": {
            "tanh_20": {
                "input": {
                    "value": "gelu_accurate._a * (x + 0.044715 * torch.pow(x, 3))",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "erf_24": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "pow_20": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "exponent": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/grad_multiply.py": {
        "torch": {}
    },
    "fairseq/modules/highway.py": {
        "torch": {
            "ModuleList_26": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ReLU_28": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sigmoid_52": {
                "variable": {
                    "value": "gate",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "gate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "projection.chunk(2, dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.sigmoid(gate)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_26": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/layer_norm.py": {
        "torch": {
            "LayerNorm_18": {
                "normalized_shape": {
                    "value": "normalized_shape",
                    "type": "variable",
                    "possible_values": [
                        [
                            "normalized_shape",
                            "Method Argument"
                        ]
                    ]
                },
                "eps": {
                    "value": "eps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1e-05",
                            "Method Argument"
                        ]
                    ]
                },
                "elementwise_affine": {
                    "value": "elementwise_affine",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "is_available_12": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/learned_positional_embedding.py": {
        "torch": {}
    },
    "fairseq/modules/lightweight_convolution.py": {
        "torch": {
            "Parameter_47": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, 1, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_73": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "conv1d_79": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.view(-1, H, T)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "groups": {
                    "value": "self.num_heads",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_117": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, 1, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_184": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_185": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "unfold1d(x, self.kernel_size, self.padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                }
            },
            "dropout_214": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_216": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_50": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_71": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Parameter_119": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/linearized_convolution.py": {
        "torch": {
            "linear_65": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._get_linearized_weight()",
                            "Call"
                        ],
                        [
                            "self.weight.transpose(2, 1).transpose(1, 0).contiguous()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_64": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/logsumexp_moe.py": {
        "torch": {
            "logsumexp_22": {
                "input": {
                    "value": "logp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "logp",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-1",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/mean_pool_gating_network.py": {
        "torch": {
            "Linear_25": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_27": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_experts",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_experts",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "tanh_49": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "sum_44": {
                "variable": {
                    "value": "ntokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1 - encoder_padding_mask",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "mean_47": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out['encoder_out'].transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "encoder_out.clone()",
                            "Call"
                        ],
                        [
                            "encoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_53": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(encoder_out, dim=1) / ntokens.type_as(encoder_out)",
                            "BinOp"
                        ],
                        [
                            "torch.mean(encoder_out, dim=1)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "self.dropout(x)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_26": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "sum_45": {
                "input": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out['encoder_out'].transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "encoder_out.clone()",
                            "Call"
                        ],
                        [
                            "encoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/multihead_attention.py": {
        "torch": {
            "Linear_47": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_185": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_qkv(query)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_213": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), attn_weights.float()).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_215": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), attn_weights.float()).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_qkv(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_v(value)",
                            "Call"
                        ],
                        [
                            "self.in_proj_v(key)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, self.bias_v.repeat(1, bsz, 1)])",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(-1, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "prev_value",
                            "variable"
                        ],
                        [
                            "torch.cat((prev_value, v), dim=1)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_36": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_38": {
                "variable": {
                    "value": "self.k_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(embed_dim, self.kdim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "variable": {
                    "value": "self.v_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(embed_dim, self.vdim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_40": {
                "variable": {
                    "value": "self.q_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_43": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_50": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_51": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_131": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_132": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_177": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, k.new_zeros((k.size(0), 1) + k.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_178": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, v.new_zeros((v.size(0), 1) + v.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "linear_272": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.k_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.v_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_134": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_136": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_180": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_182": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, torch.zeros(key_padding_mask.size(0), 1).type_as(key_padding_mask)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "where_198": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "key_padding_mask.unsqueeze(1).unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "torch.Tensor([float('-Inf')])",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_244": {
                "input": {
                    "value": "query",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query",
                            "Method Argument"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.q_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "linear_254": {
                "input": {
                    "value": "key",
                    "type": "variable",
                    "possible_values": [
                        [
                            "key",
                            "Method Argument"
                        ],
                        [
                            "key",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.k_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.v_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "linear_264": {
                "input": {
                    "value": "value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "value",
                            "Method Argument"
                        ],
                        [
                            "value",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.k_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.v_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_152": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_key, k)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_158": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_value, v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_183": {
                "*size": {
                    "value": "key_padding_mask.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/positional_embedding.py": {
        "torch": {}
    },
    "fairseq/modules/scalar_bias.py": {
        "torch": {}
    },
    "fairseq/modules/sinusoidal_positional_embedding.py": {
        "torch": {
            "exp_47": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(half_dim, dtype=torch.float) * -emb",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_49": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.sin(emb), torch.cos(emb)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_52": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[emb, torch.zeros(num_embeddings, 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_80": {
                "variable": {
                    "value": "embedding_shape",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(bsz.view(1), seq_len.view(1), torch.LongTensor([-1]))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "arange_48": {
                "start": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_48": {
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_47": {
                "start": {
                    "value": "half_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim // 2",
                            "BinOp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_52": {
                "*size": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sin_49": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cos_49": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/transformer_sentence_encoder.py": {
        "torch": {
            "Embedding_106": {
                "variable": {
                    "value": "self.embed_tokens",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_131": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[TransformerSentenceEncoderLayer(embedding_dim=self.embedding_dim, ffn_embedding_dim=ffn_embedding_dim, num_attention_heads=num_attention_heads, dropout=self.dropout, attention_dropout=attention_dropout, activation_dropout=activation_dropout, activation_fn=activation_fn, add_bias_kv=add_bias_kv, add_zero_attn=add_zero_attn, export=export) for _ in range(num_encoder_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_185": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(tokens)",
                            "Call"
                        ],
                        [
                            "x * (1 - padding_mask.unsqueeze(-1).type_as(x))",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=padding_mask)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_112": {
                "num_embeddings": {
                    "value": "self.num_segments",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/transformer_sentence_encoder_layer.py": {
        "torch": {
            "Linear_57": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_58": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_82": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_88": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.activation_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_90": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/unfold.py": {
        "torch": {
            "pad_15": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, kernel_size - 1 - padding_l), value=pad_value)",
                            "Call"
                        ],
                        [
                            "x.as_strided((T, B, C, kernel_size), (B * C, C, 1, B * C))",
                            "Call"
                        ],
                        [
                            "x.unsqueeze(3)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, kernel_size - 1 - padding_l)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "pad_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/adadelta.py": {
        "torch": {}
    },
    "fairseq/optim/adafactor.py": {
        "torch": {
            "mul_128": {
                "input": {
                    "value": "r_factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(exp_avg_sq_row / exp_avg_sq_row.mean(dim=-1)).rsqrt_().unsqueeze(-1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "c_factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "exp_avg_sq_col.unsqueeze(-2).rsqrt()",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_like_159": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "grad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_161": {
                "variable": {
                    "value": "state[exp_avg_sq_row]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "*size": {
                    "value": "grad_shape[:-1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_162": {
                "variable": {
                    "value": "state[exp_avg_sq_col]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "*size": {
                    "value": "grad_shape[:-2] + grad_shape[-1:]",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_164": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "grad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "rsqrt_197": {
                "input": {
                    "value": "exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "update",
                    "type": "variable",
                    "possible_values": [
                        [
                            "grad ** 2 + group['eps'][0]",
                            "BinOp"
                        ],
                        [
                            "exp_avg",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/adagrad.py": {
        "torch": {}
    },
    "fairseq/optim/adam.py": {
        "torch": {
            "is_available_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_like_124": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ],
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_126": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ],
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_283": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ],
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_285": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ],
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_129": {
                "variable": {
                    "value": "state[max_exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ],
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "max_148": {
                "input": {
                    "value": "max_exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "max_exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/fairseq_optimizer.py": {
        "torch": {
            "clip_grad_norm__85": {
                "parameters": {
                    "value": "self.params",
                    "type": "Attribute",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "max_norm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_norm",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/fp16_optimizer.py": {
        "torch": {
            "Parameter_99": {
                "variable": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params[0].new(0).float().new(total_param_size)",
                            "Call"
                        ],
                        [
                            "torch.nn.Parameter(fp32_params)",
                            "Call"
                        ],
                        [
                            "fp32_params",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/lamb.py": {
        "torch": {
            "zeros_like_111": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_113": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py": {
        "torch": {}
    },
    "fairseq/optim/nag.py": {
        "torch": {
            "zeros_like_81": {
                "variable": {
                    "value": "param_state[momentum_buffer]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "d_p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data.float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/sgd.py": {
        "torch": {}
    },
    "fairseq/options.py": {
        "torch": {
            "device_count_263": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/search.py": {
        "torch": {
            "stack_163": {
                "variable": {
                    "value": "self.scores_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "scores_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.scores_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_164": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "indices_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_165": {
                "variable": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "beams_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "topk_73": {
                "input": {
                    "value": "lprobs.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "k": {
                    "value": "min(beam_size * 2, lprobs.view(bsz, -1).size(1) - 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "(self.scores_buf, self.indices_buf)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "div_83": {
                "input": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "other": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_135": {
                "*size": {
                    "value": "lprobs[:, 0, :].size()",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "self.diversity_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "multinomial_195": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_nopad.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "beam_size",
                            "Method Argument"
                        ]
                    ]
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "multinomial_202": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_nopad.view(bsz * beam_size, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "gather_214": {
                "input": {
                    "value": "probs_nopad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs_nopad.exp_()",
                            "Call"
                        ],
                        [
                            "probs_nopad.expand(bsz, beam_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "self.indices_buf.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "self.scores_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "gather_224": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "topk_indices.expand(bsz, beam_size, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "self.indices_buf.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "squeeze_224": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_236": {
                "variable": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "beam_size",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "add_144": {
                "variable": {
                    "value": "lprobs_g",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs_g",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs[:, g::self.num_groups, :]",
                            "Subscript"
                        ],
                        [
                            "torch.add(lprobs_g, self.diversity_strength, self.diversity_buf.unsqueeze(1))",
                            "Call"
                        ],
                        [
                            "lprobs_g.contiguous()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.diversity_strength",
                    "type": "Attribute",
                    "possible_values": []
                },
                "alpha": {
                    "value": "self.diversity_buf.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_239": {
                "input": {
                    "value": "scores[:, :, step - 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/sequence_generator.py": {
        "torch": {
            "arange_149": {
                "variable": {
                    "value": "new_order",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size[0]",
                            "Subscript"
                        ],
                        [
                            "new_bsz",
                            "variable"
                        ]
                    ]
                }
            },
            "arange_173": {
                "variable": {
                    "value": "cand_offsets",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "cand_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2 * beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "no_grad_102": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_536": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "models",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_547": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_553": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "gather_481": {
                "variable": {
                    "value": "active_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1)).view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores[:, step].view(bsz, beam_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "add_462": {
                "input": {
                    "value": "eos_mask.type_as(cand_offsets) * cand_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "cand_offsets[:eos_mask.size(1)]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                }
            },
            "topk_471": {
                "input": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.beam_size",
                            "Attribute"
                        ],
                        [
                            "1",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "largest": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(_ignore, active_hypos)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "gather_477": {
                "input": {
                    "value": "cand_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ],
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_490": {
                "input": {
                    "value": "tokens[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "tokens.clone()",
                            "Call"
                        ],
                        [
                            "tokens",
                            "variable"
                        ]
                    ]
                }
            },
            "gather_494": {
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf.view(bsz, beam_size, -1)[:, :, step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "gather_503": {
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1)).view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf.view(bsz, beam_size, -1)[:, :, step]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "logsumexp_582": {
                "input": {
                    "value": "torch.stack(log_probs, dim=0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "gather_357": {
                "variable": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_slice",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.view(bsz, -1, lprobs.size(-1))[:, 0, :]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "prefix_tokens[:, step].view(-1, 1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_like_365": {
                "variable": {
                    "value": "cand_beams",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "sort_390": {
                "input": {
                    "value": "lprobs[:, self.eos]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(eos_scores, eos_bbsz_idx)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "masked_select_410": {
                "input": {
                    "value": "cand_bbsz_idx[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "cand_indices.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_bbsz_idx')",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_499": {
                "input": {
                    "value": "scores[:, :step]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf[:, :step]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "scores.clone()",
                            "Call"
                        ],
                        [
                            "scores_buf.type_as(lprobs)",
                            "Call"
                        ],
                        [
                            "scores",
                            "variable"
                        ]
                    ]
                }
            },
            "index_select_510": {
                "input": {
                    "value": "attn[:, :, :step + 2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "attn_buf[:, :, :step + 2]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "attn.clone()",
                            "Call"
                        ],
                        [
                            "attn",
                            "variable"
                        ]
                    ]
                }
            },
            "stack_582": {
                "tensors": {
                    "value": "log_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "log_probs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "masked_select_416": {
                "input": {
                    "value": "cand_scores[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "cand_indices.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "eos_scores / (step + 1) ** self.len_penalty",
                            "BinOp"
                        ],
                        [
                            "eos_scores",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_304": {
                "start": {
                    "value": "batch_idxs.numel()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_172": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size[0]",
                            "Subscript"
                        ],
                        [
                            "new_bsz",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/sequence_scorer.py": {
        "torch": {
            "no_grad_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_tensor_82": {
                "obj": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out[1]",
                            "Subscript"
                        ],
                        [
                            "attn.data",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/tasks/fairseq_task.py": {
        "torch": {
            "no_grad_239": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_244": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/tasks/language_modeling.py": {
        "torch": {
            "no_grad_227": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/tasks/multilingual_translation.py": {
        "torch": {
            "no_grad_271": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_284": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/tasks/translation_moe.py": {
        "torch": {
            "cat_150": {
                "variable": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "get_lprob_y(encoder_out, prev_output_tokens_k)",
                            "Call"
                        ],
                        [
                            "torch.cat(lprob_y, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_170": {
                "variable": {
                    "value": "prob_z_xy",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprob_yz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "get_lprob_yz()",
                            "Call"
                        ],
                        [
                            "get_lprob_yz()",
                            "Call"
                        ],
                        [
                            "lprob_y",
                            "variable"
                        ],
                        [
                            "lprob_y + lprob_z.type_as(lprob_y)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_201": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_207": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_168": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/trainer.py": {
        "torch": {
            "manual_seed_495": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "is_available_42": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_373": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_497": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "get_device_capability_105": {
                "device": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "get_device_capability_113": {
                "device": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_cache_395": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/utils.py": {
        "torch": {
            "remainder_199": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range - num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "remainder_201": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range + num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_39": {
                "obj": {
                    "value": "maybe_tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "maybe_tensor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Tensor_124": {
                "variable": {
                    "value": "embed_dict[pieces[0]]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_179": {
                "start": {
                    "value": "max",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "buffered_arange.buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "norm_214": {
                "input": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ],
                        [
                            "tensor",
                            "Method Argument"
                        ],
                        [
                            "tensor",
                            "Method Argument"
                        ],
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "softmax_278": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "softmax_280": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "log_softmax_285": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_287": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cumsum_168": {
                "input": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor.ne(padding_idx).long()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq_cli/eval_lm.py": {
        "torch": {
            "is_available_55": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq_cli/generate.py": {
        "torch": {
            "is_available_31": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq_cli/interactive.py": {
        "torch": {
            "is_available_71": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq_cli/train.py": {
        "torch": {
            "manual_seed_34": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "set_device_33": {
                "device": {
                    "value": "args.device_id",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_count_277": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_289": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_283": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "generate.py": {
        "torch": {
            "is_available_31": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "generator.py": {
        "torch": {
            "is_available_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "interactive.py": {
        "torch": {
            "is_available_71": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "scripts/average_checkpoints.py": {
        "torch": {
            "load_33": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "inputs",
                            "variable"
                        ],
                        [
                            "files",
                            "variable"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, _: torch.serialization.default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "save_137": {
                "obj": {
                    "value": "new_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "state",
                            "variable"
                        ],
                        [
                            "average_checkpoints(args.inputs)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "args.output",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_average_checkpoints.py": {
        "torch": {
            "Embedding_26": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "1000",
                    "type": "int",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_27": {
                "variable": {
                    "value": "self.FC1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_28": {
                "variable": {
                    "value": "self.FC2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_30": {
                "variable": {
                    "value": "self.FC2.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.FC1.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_31": {
                "variable": {
                    "value": "self.FC2.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.FC1.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReLU_33": {
                "variable": {
                    "value": "self.relu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_66": {
                "obj": {
                    "value": "collections.OrderedDict([('model', params_0)])",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "path_0",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tempfile.mkstemp()",
                            "Call"
                        ]
                    ]
                }
            },
            "save_67": {
                "obj": {
                    "value": "collections.OrderedDict([('model', params_1)])",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "path_1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tempfile.mkstemp()",
                            "Call"
                        ]
                    ]
                }
            },
            "save_95": {
                "obj": {
                    "value": "{'model': m.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(tmpdir, 'm1.pt')",
                            "Call"
                        ],
                        [
                            "os.path.join(tmpdir, 'm2.pt')",
                            "Call"
                        ],
                        [
                            "os.path.join(tmpdir, 'm3.pt')",
                            "Call"
                        ],
                        [
                            "path",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "equal_117": {
                "input": {
                    "value": "new_model['model']['embedding.weight']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "(m1.embedding.weight + m2.embedding.weight + m3.embedding.weight) / 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "equal_126": {
                "input": {
                    "value": "new_model['model']['FC1.weight']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "(m1.FC1.weight + m2.FC1.weight + m3.FC1.weight) / 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "equal_135": {
                "input": {
                    "value": "new_model['model']['FC2.weight']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "(m1.FC2.weight + m2.FC2.weight + m3.FC2.weight) / 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_backtranslation_dataset.py": {
        "torch": {
            "is_available_32": {
                "variable": {
                    "value": "self.cuda",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_76": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "backtranslation_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "BacktranslationDataset(tgt_dataset=TransformEosDataset(dataset=tgt_dataset, eos=self.tgt_dict.eos(), remove_eos_from_src=remove_eos_from_input_src), src_dict=self.tgt_dict, backtranslation_fn=lambda sample: generator.generate([self.model], sample), output_collater=TransformEosDataset(dataset=tgt_dataset, eos=self.tgt_dict.eos(), append_eos_to_tgt=remove_eos_from_input_src, remove_eos_from_src=remove_eos_from_output_src).collater, cuda=self.cuda)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "backtranslation_dataset.collater",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_binaries.py": {
        "torch": {
            "rand_453": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_examples * maxlen",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "floor_454": {
                "input": {
                    "value": "26 * data",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_character_token_embedder.py": {
        "torch": {}
    },
    "tests/test_concat_dataset.py": {
        "torch": {}
    },
    "tests/test_convtbc.py": {
        "torch": {
            "Conv1d_20": {
                "variable": {
                    "value": "conv1d",
                    "type": "variable",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_25": {
                "variable": {
                    "value": "input_tbc",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "7",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "randn_34": {
                "variable": {
                    "value": "grad_tbc",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "output_tbc.size()",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_dictionary.py": {
        "torch": {}
    },
    "tests/test_label_smoothing.py": {
        "torch": {
            "unsqueeze_43": {
                "variable": {
                    "value": "self.args.probs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_multi_corpus_sampled_dataset.py": {
        "torch": {}
    },
    "tests/test_noising.py": {
        "torch": {
            "DataLoader_442": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "language_pair_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "LanguagePairDataset(src=noising_dataset, tgt=tgt, src_sizes=None, src_dict=src_dict)",
                            "Call"
                        ],
                        [
                            "TransformEosDataset(language_pair_dataset, src_dict.eos(), append_eos_to_tgt=append_eos_to_tgt)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "language_pair_dataset.collater",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "t_456": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[['he@@', 'llo', 'n@@', 'ew', 'y@@', 'or@@', 'k'], ['how', 'are', 'y@@', 'ou']]",
                            "List"
                        ],
                        [
                            "[['he', 'llo_EOW', 'n', 'ew_EOW', 'y', 'or', 'k_EOW'], ['how_EOW', 'are_EOW', 'y', 'ou_EOW']]",
                            "List"
                        ],
                        [
                            "[['hello', 'new', 'york', 'you'], ['how', 'are', 'you', 'new', 'york']]",
                            "List"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=True)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=False)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "t_493": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[['he@@', 'llo', 'n@@', 'ew', 'y@@', 'or@@', 'k'], ['how', 'are', 'y@@', 'ou']]",
                            "List"
                        ],
                        [
                            "[['he', 'llo_EOW', 'n', 'ew_EOW', 'y', 'or', 'k_EOW'], ['how_EOW', 'are_EOW', 'y', 'ou_EOW']]",
                            "List"
                        ],
                        [
                            "[['hello', 'new', 'york', 'you'], ['how', 'are', 'you', 'new', 'york']]",
                            "List"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=True)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=False)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "tests/test_sequence_generator.py": {
        "torch": {
            "log_140": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_239": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_sequence_scorer.py": {
        "torch": {
            "log_99": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_token_block_dataset.py": {
        "torch": {
            "tensor_26": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_27": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_28": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_36": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_37": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_38": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_47": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_48": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_49": {
                "data": {
                    "value": "[9, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_59": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_60": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_61": {
                "data": {
                    "value": "[9, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_68": {
                "data": {
                    "value": "[4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_69": {
                "data": {
                    "value": "[5, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_70": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_71": {
                "data": {
                    "value": "[6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_train.py": {
        "torch": {}
    },
    "tests/test_utils.py": {
        "torch": {}
    },
    "tests/utils.py": {
        "torch": {
            "DataLoader_47": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TestDataset(samples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(samples)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda samples: collate(samples, padding_idx, eos_idx)",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "rand_222": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bbsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "prev_output_tokens.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tgt_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "prev_output_tokens.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "src_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out.size(1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    }
}