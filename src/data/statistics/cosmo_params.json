{
    "src/bert_dictionary.py": {
        "torch": {}
    },
    "src/learned_positional_embedding.py": {
        "torch": {}
    },
    "src/ngram_criterions.py": {
        "torch": {
            "cat_62": {
                "variable": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "logits_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(**sample['net_input'], return_all_hiddens=False)[0]",
                            "Subscript"
                        ],
                        [
                            "model(**sample['net_input'], return_all_hiddens=False)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_64": {
                "variable": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits.view(-1, logits.size(-1))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "nll_loss_71": {
                "variable": {
                    "value": "my_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets.view(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "nll_loss_77": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets.view(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_126": {
                "variable": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "logits_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(**sample['net_input'], return_all_hiddens=False)[0]",
                            "Subscript"
                        ],
                        [
                            "model(**sample['net_input'], return_all_hiddens=False)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_128": {
                "variable": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits.view(-1, logits.size(-1))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "nll_loss_136": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets.view(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_55": {
                "variable": {
                    "value": "padding_targets",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ],
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ]
                    ]
                }
            },
            "zeros_like_119": {
                "variable": {
                    "value": "padding_targets",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ],
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ]
                    ]
                }
            },
            "where_57": {
                "variable": {
                    "value": "expend_targets[i, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "condition": {
                    "value": "sample['target_idx'] >= i",
                    "type": "Compare",
                    "possible_values": []
                },
                "x": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ],
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ]
                    ]
                },
                "y": {
                    "value": "padding_targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros_like(targets).fill_(self.padding_idx)",
                            "Call"
                        ],
                        [
                            "torch.zeros_like(targets).fill_(self.padding_idx)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_121": {
                "variable": {
                    "value": "expend_targets[i, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "condition": {
                    "value": "sample['target_idx'] >= i",
                    "type": "Compare",
                    "possible_values": []
                },
                "x": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ],
                        [
                            "model.get_targets(sample, [logits_list[0]])",
                            "Call"
                        ],
                        [
                            "expend_targets",
                            "variable"
                        ]
                    ]
                },
                "y": {
                    "value": "padding_targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros_like(targets).fill_(self.padding_idx)",
                            "Call"
                        ],
                        [
                            "torch.zeros_like(targets).fill_(self.padding_idx)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "src/ngram_multihead_attention.py": {
        "torch": {
            "from_numpy_29": {
                "ndarray": {
                    "value": "np.array(bias_result, dtype=np.float32)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_63": {
                "variable": {
                    "value": "self.relative_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_buckets * num_heads",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_76": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "lt_122": {
                "variable": {
                    "value": "is_small",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "max_exact",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_buckets // 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "min_125": {
                "variable": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_exact + torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)",
                            "BinOp"
                        ],
                        [
                            "torch.min(val_if_large, torch.ones_like(val_if_large) * (num_buckets - 1))",
                            "Call"
                        ],
                        [
                            "val_if_large.int()",
                            "Call"
                        ]
                    ]
                }
            },
            "gather_171": {
                "variable": {
                    "value": "result",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "values",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.relative_linear(query)",
                            "Call"
                        ],
                        [
                            "values.view(values.size(0), values.size(1), self.num_buckets, self.num_heads)",
                            "Call"
                        ],
                        [
                            "values.transpose(1, 3)",
                            "Call"
                        ],
                        [
                            "values.transpose(2, 3)",
                            "Call"
                        ],
                        [
                            "values.reshape(attn_weights.size(0), attn_weights.size(1), -1)",
                            "Call"
                        ],
                        [
                            "values.reshape(-1, values.size(-1))",
                            "Call"
                        ],
                        [
                            "self.relative_linear(query)",
                            "Call"
                        ],
                        [
                            "values.view(*values.size()[:-1], self.num_buckets, self.num_heads)",
                            "Call"
                        ],
                        [
                            "values.permute(0, 1, 4, 2, 3)",
                            "Call"
                        ],
                        [
                            "values.reshape(N * BH, T, -1)",
                            "Call"
                        ],
                        [
                            "values.reshape(-1, values.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "i_buckets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "i_bucket_main_stream",
                            "variable"
                        ],
                        [
                            "self._relative_positions_bucket(relative_positions, False)",
                            "Call"
                        ],
                        [
                            "i_buckets.repeat(1, self.num_heads, 1).view(attn_weights.size(0), attn_weights.size(1), -1)",
                            "Call"
                        ],
                        [
                            "i_buckets.view(-1, i_buckets.size(-1)).long()",
                            "Call"
                        ],
                        [
                            "i_bucket_relative_stream",
                            "variable"
                        ],
                        [
                            "self._relative_positions_bucket(relative_positions, False)",
                            "Call"
                        ],
                        [
                            "i_buckets.unsqueeze(0).repeat(N, 1, self.num_heads, 1)",
                            "Call"
                        ],
                        [
                            "i_buckets.view(-1, i_buckets.size(-1)).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "gather_217": {
                "variable": {
                    "value": "result",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "values",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.relative_linear(query)",
                            "Call"
                        ],
                        [
                            "values.view(values.size(0), values.size(1), self.num_buckets, self.num_heads)",
                            "Call"
                        ],
                        [
                            "values.transpose(1, 3)",
                            "Call"
                        ],
                        [
                            "values.transpose(2, 3)",
                            "Call"
                        ],
                        [
                            "values.reshape(attn_weights.size(0), attn_weights.size(1), -1)",
                            "Call"
                        ],
                        [
                            "values.reshape(-1, values.size(-1))",
                            "Call"
                        ],
                        [
                            "self.relative_linear(query)",
                            "Call"
                        ],
                        [
                            "values.view(*values.size()[:-1], self.num_buckets, self.num_heads)",
                            "Call"
                        ],
                        [
                            "values.permute(0, 1, 4, 2, 3)",
                            "Call"
                        ],
                        [
                            "values.reshape(N * BH, T, -1)",
                            "Call"
                        ],
                        [
                            "values.reshape(-1, values.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "i_buckets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "i_bucket_main_stream",
                            "variable"
                        ],
                        [
                            "self._relative_positions_bucket(relative_positions, False)",
                            "Call"
                        ],
                        [
                            "i_buckets.repeat(1, self.num_heads, 1).view(attn_weights.size(0), attn_weights.size(1), -1)",
                            "Call"
                        ],
                        [
                            "i_buckets.view(-1, i_buckets.size(-1)).long()",
                            "Call"
                        ],
                        [
                            "i_bucket_relative_stream",
                            "variable"
                        ],
                        [
                            "self._relative_positions_bucket(relative_positions, False)",
                            "Call"
                        ],
                        [
                            "i_buckets.unsqueeze(0).repeat(N, 1, self.num_heads, 1)",
                            "Call"
                        ],
                        [
                            "i_buckets.view(-1, i_buckets.size(-1)).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "bmm_301": {
                "variable": {
                    "value": "attn_weights_main",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q_main",
                    "type": "variable",
                    "possible_values": [
                        [
                            "q_list[0]",
                            "Subscript"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k_main.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_313": {
                "variable": {
                    "value": "attn_weights_main",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights_main",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q_main, k_main.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights_main + main_relative_logits",
                            "BinOp"
                        ],
                        [
                            "attn_weights_main + self_attn_mask",
                            "BinOp"
                        ],
                        [
                            "utils.softmax(attn_weights_main, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights_main)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights_main, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_315": {
                "variable": {
                    "value": "attn_main",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights_main",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q_main, k_main.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights_main + main_relative_logits",
                            "BinOp"
                        ],
                        [
                            "attn_weights_main + self_attn_mask",
                            "BinOp"
                        ],
                        [
                            "utils.softmax(attn_weights_main, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights_main)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights_main, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v_main",
                    "type": "variable",
                    "possible_values": [
                        [
                            "v_list[0]",
                            "Subscript"
                        ],
                        [
                            "torch.cat((prev_value, v_main), dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_321": {
                "variable": {
                    "value": "q_ngram",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "q_predict_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "q_list[1:]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_323": {
                "tensors": {
                    "value": "[k_main, k_p]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_328": {
                "variable": {
                    "value": "h_ngram",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "h_predict_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "h_list[1:]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_331": {
                "tensors": {
                    "value": "[v_main, v_p]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "einsum_336": {
                "variable": {
                    "value": "attn_weights_ngram",
                    "type": "variable",
                    "possible_values": []
                },
                "equation": {
                    "value": "nbtc,nbsc->nbts",
                    "type": "str",
                    "possible_values": []
                },
                "*operands": {
                    "value": "(q_ngram, k_ngram)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "dropout_350": {
                "variable": {
                    "value": "attn_weights_ngram",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights_ngram",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.einsum('nbtc,nbsc->nbts', (q_ngram, k_ngram))",
                            "Call"
                        ],
                        [
                            "attn_weights_ngram + predict_relative_logits",
                            "BinOp"
                        ],
                        [
                            "attn_weights_ngram + ngram_mask_matrix",
                            "BinOp"
                        ],
                        [
                            "utils.softmax(attn_weights_ngram, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights_ngram)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights_ngram, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "einsum_353": {
                "variable": {
                    "value": "attn_ngram",
                    "type": "variable",
                    "possible_values": []
                },
                "equation": {
                    "value": "nbts,nbsc->nbtc",
                    "type": "str",
                    "possible_values": []
                },
                "*operands": {
                    "value": "(attn_weights_ngram, v_ngram)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_363": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn_result",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_65": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_67": {
                "variable": {
                    "value": "self.k_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(embed_dim, self.kdim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_68": {
                "variable": {
                    "value": "self.v_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(embed_dim, self.vdim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_69": {
                "variable": {
                    "value": "self.q_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_72": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_79": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_80": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "abs_118": {
                "variable": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            },
            "max_120": {
                "variable": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            },
            "arange_143": {
                "variable": {
                    "value": "relative_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "S + 1",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "unsqueeze_143": {
                "variable": {
                    "value": "relative_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_191": {
                "variable": {
                    "value": "relative_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "S",
                    "type": "variable",
                    "possible_values": [
                        [
                            "attn_weights.size(-1)",
                            "Call"
                        ],
                        [
                            "attn_weights.size()",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_191": {
                "variable": {
                    "value": "relative_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_259": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_260": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "linear_404": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.k_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.v_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "where_127": {
                "condition": {
                    "value": "is_small",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.lt(n, max_exact)",
                            "Call"
                        ]
                    ]
                },
                "x": {
                    "value": "n.int()",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_exact + torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)",
                            "BinOp"
                        ],
                        [
                            "torch.min(val_if_large, torch.ones_like(val_if_large) * (num_buckets - 1))",
                            "Call"
                        ],
                        [
                            "val_if_large.int()",
                            "Call"
                        ]
                    ]
                }
            },
            "linear_376": {
                "input": {
                    "value": "query",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "query.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ],
                        [
                            "query",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.q_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "linear_386": {
                "input": {
                    "value": "key",
                    "type": "variable",
                    "possible_values": [
                        [
                            "key",
                            "Method Argument"
                        ],
                        [
                            "key",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.k_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.v_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "linear_396": {
                "input": {
                    "value": "value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "value",
                            "Method Argument"
                        ],
                        [
                            "value",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.k_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.v_proj_weight",
                            "Attribute"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[self.embed_dim:2 * self.embed_dim]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[2 * self.embed_dim:]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_like_120": {
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_125": {
                "input": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_exact + torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)",
                            "BinOp"
                        ],
                        [
                            "torch.min(val_if_large, torch.ones_like(val_if_large) * (num_buckets - 1))",
                            "Call"
                        ],
                        [
                            "val_if_large.int()",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_287": {
                "variable": {
                    "value": "k_main",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_key, k_main)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_293": {
                "variable": {
                    "value": "v_main",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_value, v_main)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_323": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_331": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "lt_117": {
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "torch.zeros_like(n)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_123": {
                "input": {
                    "value": "n.float() / max_exact",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_117": {
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "src/ngram_s2s_model.py": {
        "torch": {
            "Embedding_828": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_835": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_240": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_241": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_265": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_271": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.activation_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_273": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_327": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_328": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_371": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_391": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_397": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.activation_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_399": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_433": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_483": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_561": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "lt_615": {
                "variable": {
                    "value": "is_small",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "max_exact",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_buckets // 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "min_618": {
                "variable": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_exact + torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)",
                            "BinOp"
                        ],
                        [
                            "torch.min(val_if_large, torch.ones_like(val_if_large) * (num_buckets - 1))",
                            "Call"
                        ],
                        [
                            "val_if_large.int()",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_636": {
                "variable": {
                    "value": "predicting_stream_relative_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(real_positions_shift_predicting_stream, real_positions)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_636": {
                "variable": {
                    "value": "predicting_stream_relative_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_663": {
                "variable": {
                    "value": "finetune_i_bucket_predicting_stream",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self._finetune_i_bucket_predicting_stream[:, :n_tokens, :n_tokens], self._finetune_i_bucket_predicting_stream[:, :n_tokens, self.max_target_positions:self.max_target_positions + n_tokens]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_736": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x] + ngram_masks",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_741": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.ngram_self_attn(query=x, key=x, value=x, incremental_state=incremental_state, need_weights=False, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "x + main_stream_pos_embed",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([x] + ngram_masks, 0)",
                            "Call"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, ngram_mask_matrix=ngram_mask_matrix, i_buckets_main_stream=i_buckets_main_stream, i_bucket_relative_stream=i_bucket_relative_stream, real_positions=real_positions)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_820": {
                "variable": {
                    "value": "ngram_future_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self._ngram_future_mask[:, :dim, :dim], self._ngram_future_mask[:, :dim, self.max_target_positions:self.max_target_positions + dim]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "load_150": {
                "variable": {
                    "value": "states",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.load_from_pretrained_model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Parameter_579": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), self.embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "abs_611": {
                "variable": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            },
            "max_613": {
                "variable": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            },
            "arange_656": {
                "variable": {
                    "value": "fake_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "self.max_target_positions + 1",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "triu_811": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_tensor_95": {
                "obj": {
                    "value": "net_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output",
                            "Method Argument"
                        ],
                        [
                            "net_output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "where_620": {
                "condition": {
                    "value": "is_small",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.lt(n, max_exact)",
                            "Call"
                        ]
                    ]
                },
                "x": {
                    "value": "n.int()",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_exact + torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)",
                            "BinOp"
                        ],
                        [
                            "torch.min(val_if_large, torch.ones_like(val_if_large) * (num_buckets - 1))",
                            "Call"
                        ],
                        [
                            "val_if_large.int()",
                            "Call"
                        ]
                    ]
                }
            },
            "linear_796": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_798": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_163": {
                "variable": {
                    "value": "_index",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "states[position_name].size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_like_613": {
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_618": {
                "input": {
                    "value": "val_if_large",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_exact + torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)",
                            "BinOp"
                        ],
                        [
                            "torch.min(val_if_large, torch.ones_like(val_if_large) * (num_buckets - 1))",
                            "Call"
                        ],
                        [
                            "val_if_large.int()",
                            "Call"
                        ]
                    ]
                }
            },
            "log_softmax_98": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "net_output[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_100": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "net_output[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "_index",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(_index[1:], _index[:1])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_167": {
                "variable": {
                    "value": "states[position_name]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[states[position_name], expend_position_states[:, _index]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "lt_610": {
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "torch.zeros_like(n)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_616": {
                "input": {
                    "value": "n.float() / max_exact",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_610": {
                "input": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-relative_positions",
                            "UnaryOp"
                        ],
                        [
                            "torch.abs(n)",
                            "Call"
                        ],
                        [
                            "torch.max(n, torch.zeros_like(n))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "src/prophetnet_cosmo.py": {
        "torch": {
            "cat_99": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(target)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_100": {
                "variable": {
                    "value": "prev_output_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "prev_output_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(prev_output_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_101": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_131": {
                "variable": {
                    "value": "mod_sam[net_input][src_tokens]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[src_tokens_first, tmp, src_tokens_second]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_206": {
                "variable": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(lprob_y)",
                            "Call"
                        ]
                    ]
                }
            },
            "sort_208": {
                "variable": {
                    "value": "(_, sorted_indices)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(lprob_y)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_259": {
                "variable": {
                    "value": "mod_sam[net_input][src_tokens]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[src_tokens_first, tmp, src_tokens_second]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_244": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_267": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_102": {
                "tensors": {
                    "value": "src_lengths",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(src_lengths, dim=1)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_103": {
                "tensors": {
                    "value": "src_id",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(src_id, dim=1)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_216": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_34": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_34": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "pad_76": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samp['target'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['target'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1), samp['target'][i][-1].reshape(1, 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['net_input']['prev_output_tokens'][i][0].reshape(1, 1), samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j] + 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_79": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(samp['target'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1), samp['target'][i][-1].reshape(1, 1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pad_81": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samp['target'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['target'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1), samp['target'][i][-1].reshape(1, 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['net_input']['prev_output_tokens'][i][0].reshape(1, 1), samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pad_91": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samp['target'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['target'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1), samp['target'][i][-1].reshape(1, 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['net_input']['prev_output_tokens'][i][0].reshape(1, 1), samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j] + 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_94": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(samp['net_input']['prev_output_tokens'][i][0].reshape(1, 1), samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pad_96": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samp['target'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['target'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1), samp['target'][i][-1].reshape(1, 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['target'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].view(1, splits[j + 1] - splits[j] - 1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j] + 1), mode='constant', value=0)",
                            "Call"
                        ],
                        [
                            "torch.cat((samp['net_input']['prev_output_tokens'][i][0].reshape(1, 1), samp['net_input']['prev_output_tokens'][i][splits[j]:splits[j + 1] - 1].reshape(1, splits[j + 1] - splits[j] - 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "F.pad(t, pad=(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j]), mode='constant', value=0)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, samp['net_input']['prev_output_tokens'][i].shape[0] - splits[j + 1] + splits[j])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    }
}