{
    "datasets/waymo2coco.py": {
        "tensorflow": {
            "enable_eager_execution_10": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "TFRecordDataset_70": {
                "variable": {
                    "value": "dataset",
                    "possible_values": []
                },
                "filenames": {
                    "value": "tf_records_filenames",
                    "possible_values": [
                        [
                            "[os.path.join(raw_dir, phase, p) for p in os.listdir(os.path.join(raw_dir, phase)) if p.endswith('.tfrecord')]",
                            "ListComp"
                        ]
                    ]
                },
                "compression_type": {
                    "value": "",
                    "possible_values": []
                }
            },
            "decode_jpeg_97": {
                "variable": {
                    "value": "img_array",
                    "possible_values": []
                },
                "contents": {
                    "value": "i.image",
                    "possible_values": []
                }
            }
        }
    },
    "src/data/build.py": {
        "torch": {}
    },
    "src/data/pair_sampler.py": {
        "torch": {
            "Generator_94": {
                "variable": {
                    "value": "g",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "randperm_97": {
                "n": {
                    "value": "self._total_size",
                    "possible_values": []
                },
                "generator": {
                    "value": "g",
                    "possible_values": [
                        [
                            "torch.Generator()",
                            "Call"
                        ]
                    ]
                }
            },
            "arange_99": {
                "start": {
                    "value": "self._total_size",
                    "possible_values": []
                }
            },
            "flip_123": {
                "variable": {
                    "value": "d[image]",
                    "possible_values": []
                },
                "input": {
                    "value": "d['image']",
                    "possible_values": []
                },
                "dims": {
                    "value": "[2]",
                    "possible_values": []
                }
            }
        }
    },
    "src/engine/defaults.py": {
        "torch": {
            "as_tensor_216": {
                "variable": {
                    "value": "image",
                    "possible_values": []
                },
                "data": {
                    "value": "image.astype('float32').transpose(2, 0, 1)",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_285": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "self.build_model(cfg)",
                            "Call"
                        ],
                        [
                            "DistributedDataParallel(model, device_ids=[comm.get_local_rank()], broadcast_buffers=False)",
                            "Call"
                        ],
                        [
                            "build_model(cfg)",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[comm.get_local_rank()]",
                    "possible_values": []
                },
                "broadcast_buffers": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "no_grad_207": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "src/engine/evaluate.py": {
        "torch": {
            "no_grad_49": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_57": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "synchronize_58": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "src/engine/train_loop.py": {
        "torch": {
            "isfinite_256": {
                "input": {
                    "value": "losses",
                    "possible_values": [
                        [
                            "sum(loss_dict.values())",
                            "Call"
                        ]
                    ]
                }
            },
            "all_256": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Stream_240": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "src/modeling/meta_arch/rcnn_ss.py": {
        "torch": {
            "device_33": {
                "variable": {
                    "value": "self.device",
                    "possible_values": []
                },
                "type": {
                    "value": "cfg.MODEL.DEVICE",
                    "possible_values": []
                }
            },
            "Tensor_57": {
                "variable": {
                    "value": "pixel_mean",
                    "possible_values": []
                }
            },
            "Tensor_62": {
                "variable": {
                    "value": "pixel_std",
                    "possible_values": []
                }
            }
        }
    },
    "src/modeling/roi_heads/fast_rcnn.py": {
        "torch": {
            "softmax_363": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.pred_class_logits",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "isfinite_98": {
                "input": {
                    "value": "scores",
                    "possible_values": [
                        [
                            "scores[valid_mask]",
                            "Subscript"
                        ],
                        [
                            "scores[:, :-1]",
                            "Subscript"
                        ],
                        [
                            "scores[filter_mask]",
                            "Subscript"
                        ],
                        [
                            "self.predict_probs()",
                            "Call"
                        ]
                    ]
                }
            },
            "all_98": {
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "arange_279": {
                "variable": {
                    "value": "gt_class_cols",
                    "possible_values": []
                },
                "start": {
                    "value": "box_dim",
                    "possible_values": [
                        [
                            "self.gt_boxes.tensor.size(1)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "self.pred_proposal_deltas.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "cross_entropy_248": {
                "input": {
                    "value": "self.pred_class_logits",
                    "possible_values": []
                },
                "target": {
                    "value": "self.gt_classes",
                    "possible_values": []
                },
                "reduction": {
                    "value": "mean",
                    "possible_values": []
                }
            },
            "zeros_202": {
                "*size": {
                    "value": "0",
                    "possible_values": []
                },
                "out": {
                    "value": "4",
                    "possible_values": []
                },
                "device": {
                    "value": "self.pred_proposal_deltas.device",
                    "possible_values": []
                }
            },
            "arange_286": {
                "start": {
                    "value": "box_dim",
                    "possible_values": [
                        [
                            "self.gt_boxes.tensor.size(1)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "self.pred_proposal_deltas.device",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "src/modeling/roi_heads/roi_heads.py": {
        "torch": {
            "zeros_369": {
                "variable": {
                    "value": "idxs",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(proposals)",
                    "possible_values": []
                }
            },
            "cat_383": {
                "variable": {
                    "value": "boxes",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[gt_boxes, boxes]",
                    "possible_values": []
                }
            },
            "cat_384": {
                "variable": {
                    "value": "scores",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[gt_scores, scores]",
                    "possible_values": []
                }
            },
            "nonzero_388": {
                "variable": {
                    "value": "keep_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "scores > self.box_roi_thr_logits",
                    "possible_values": []
                }
            },
            "squeeze_388": {
                "variable": {
                    "value": "keep_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "isnan_300": {
                "input": {
                    "value": "features_list[i]",
                    "possible_values": []
                }
            },
            "sum_300": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ones_380": {
                "*size": {
                    "value": "len(gt_boxes)",
                    "possible_values": []
                }
            },
            "no_grad_447": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "src/modeling/self_supervised/cycle.py": {
        "torch": {
            "device_18": {
                "variable": {
                    "value": "self.device",
                    "possible_values": []
                },
                "type": {
                    "value": "cfg.MODEL.DEVICE",
                    "possible_values": []
                }
            },
            "Sequential_21": {
                "variable": {
                    "value": "self.enc1",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(cin, 256, kernel_size=3, padding=0, bias=True)",
                    "possible_values": []
                }
            },
            "softmax_59": {
                "variable": {
                    "value": "score",
                    "possible_values": []
                },
                "input": {
                    "value": "dist",
                    "possible_values": [
                        [
                            "(diff * diff).sum(dim=1).view(us, vs) * self.coef",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "matmul_67": {
                "variable": {
                    "value": "soft_v",
                    "possible_values": []
                },
                "input": {
                    "value": "sim_score",
                    "possible_values": []
                },
                "other": {
                    "value": "feat_v",
                    "possible_values": [
                        [
                            "self.enc1(prev_boxes)",
                            "Call"
                        ],
                        [
                            "feat_v.view(feat_v.size(0), feat_v.size(1))",
                            "Call"
                        ],
                        [
                            "self.enc1(v)",
                            "Call"
                        ],
                        [
                            "feat_v.view(feat_v.size(0), feat_v.size(1))",
                            "Call"
                        ]
                    ]
                }
            },
            "arange_71": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "start": {
                    "value": "len(feat_u)",
                    "possible_values": []
                }
            },
            "Conv2d_22": {
                "in_channels": {
                    "value": "cin",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "256",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "ReLU_24": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Conv2d_25": {
                "in_channels": {
                    "value": "256",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "256",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "ReLU_27": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_28": {
                "output_size": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_72": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "src/modeling/self_supervised/jigsaw.py": {
        "torch": {
            "device_21": {
                "variable": {
                    "value": "self.device",
                    "possible_values": []
                },
                "type": {
                    "value": "cfg.MODEL.DEVICE",
                    "possible_values": []
                }
            },
            "Sequential_44": {
                "variable": {
                    "value": "self.fusion",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(cin * 4, cin * 2, kernel_size=3, stride=1, padding=1, bias=False)",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_68": {
                "variable": {
                    "value": "self.avgpool",
                    "possible_values": []
                },
                "output_size": {
                    "value": "(1, 1)",
                    "possible_values": []
                }
            },
            "Sequential_69": {
                "variable": {
                    "value": "self.classifier",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(out_channels, num_classes)",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_71": {
                "variable": {
                    "value": "self.criterion",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tensor_75": {
                "variable": {
                    "value": "pixel_mean",
                    "possible_values": []
                }
            },
            "Tensor_76": {
                "variable": {
                    "value": "pixel_std",
                    "possible_values": []
                }
            },
            "cat_123": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "tensors": {
                    "value": "x_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_171": {
                "variable": {
                    "value": "data",
                    "possible_values": []
                },
                "tensors": {
                    "value": "data",
                    "possible_values": [
                        [
                            "[tiles[self.permutations[order][t]] for t in range(self.step * self.step)]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(data, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_179": {
                "variable": {
                    "value": "targets",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(tensors)",
                    "possible_values": []
                }
            },
            "stack_187": {
                "variable": {
                    "value": "stacked_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "tiles",
                    "possible_values": [
                        [
                            "[None] * self.step ** 2",
                            "BinOp"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Sequential_95": {
                "variable": {
                    "value": "downsample",
                    "possible_values": []
                },
                "*args": {
                    "value": "conv1x1(self.inplanes, planes * block.expansion, stride)",
                    "possible_values": []
                }
            },
            "Sequential_110": {
                "*args": {
                    "value": "*layers",
                    "possible_values": []
                }
            },
            "Conv2d_45": {
                "in_channels": {
                    "value": "cin * 4",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "cin * 2",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_47": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Conv2d_48": {
                "in_channels": {
                    "value": "cin * 2",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "cin",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_50": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Linear_70": {
                "in_features": {
                    "value": "out_channels",
                    "possible_values": [
                        [
                            "self.inplanes",
                            "Attribute"
                        ],
                        [
                            "out_channels * 2",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "24",
                            "Constant"
                        ]
                    ]
                }
            }
        }
    },
    "src/modeling/self_supervised/leftright.py": {
        "torch": {
            "device_22": {
                "variable": {
                    "value": "self.device",
                    "possible_values": []
                },
                "type": {
                    "value": "cfg.MODEL.DEVICE",
                    "possible_values": []
                }
            },
            "Sequential_42": {
                "variable": {
                    "value": "self.fusion",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(cin * 2, cin, kernel_size=3, stride=1, padding=1, bias=False)",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_58": {
                "variable": {
                    "value": "self.avgpool",
                    "possible_values": []
                },
                "output_size": {
                    "value": "(1, 1)",
                    "possible_values": []
                }
            },
            "Sequential_59": {
                "variable": {
                    "value": "self.classifier",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(out_channels, num_classes)",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_61": {
                "variable": {
                    "value": "self.criterion",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tensor_65": {
                "variable": {
                    "value": "pixel_mean",
                    "possible_values": []
                }
            },
            "Tensor_66": {
                "variable": {
                    "value": "pixel_std",
                    "possible_values": []
                }
            },
            "cat_113": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "tensors": {
                    "value": "x_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_160": {
                "variable": {
                    "value": "data",
                    "possible_values": []
                },
                "tensors": {
                    "value": "data",
                    "possible_values": [
                        [
                            "[tiles[self.permutations[order][t]] for t in range(2)]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(data, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_168": {
                "variable": {
                    "value": "targets",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(tensors)",
                    "possible_values": []
                }
            },
            "stack_176": {
                "variable": {
                    "value": "stacked_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "tiles",
                    "possible_values": [
                        [
                            "[None] * 2",
                            "BinOp"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Sequential_85": {
                "variable": {
                    "value": "downsample",
                    "possible_values": []
                },
                "*args": {
                    "value": "conv1x1(self.inplanes, planes * block.expansion, stride)",
                    "possible_values": []
                }
            },
            "Sequential_101": {
                "*args": {
                    "value": "*layers",
                    "possible_values": []
                }
            },
            "Conv2d_43": {
                "in_channels": {
                    "value": "cin * 2",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "cin",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_45": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Linear_60": {
                "in_features": {
                    "value": "out_channels",
                    "possible_values": [
                        [
                            "self.inplanes",
                            "Attribute"
                        ],
                        [
                            "out_channels * 2",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "cfg.MODEL.SS.NUM_CLASSES",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "src/modeling/self_supervised/rotation.py": {
        "torch": {
            "device_18": {
                "variable": {
                    "value": "self.device",
                    "possible_values": []
                },
                "type": {
                    "value": "cfg.MODEL.DEVICE",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_49": {
                "variable": {
                    "value": "self.avgpool",
                    "possible_values": []
                },
                "output_size": {
                    "value": "(1, 1)",
                    "possible_values": []
                }
            },
            "Linear_50": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "in_features": {
                    "value": "out_channels",
                    "possible_values": [
                        [
                            "self.inplanes",
                            "Attribute"
                        ],
                        [
                            "out_channels * 2",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "4",
                            "Constant"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_51": {
                "variable": {
                    "value": "self.criterion",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tensor_55": {
                "variable": {
                    "value": "pixel_mean",
                    "possible_values": []
                }
            },
            "Tensor_56": {
                "variable": {
                    "value": "pixel_std",
                    "possible_values": []
                }
            },
            "zeros_121": {
                "variable": {
                    "value": "targets",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(tensors)",
                    "possible_values": []
                }
            },
            "Sequential_75": {
                "variable": {
                    "value": "downsample",
                    "possible_values": []
                },
                "*args": {
                    "value": "conv1x1(self.inplanes, planes * block.expansion, stride)",
                    "possible_values": []
                }
            },
            "Sequential_91": {
                "*args": {
                    "value": "*layers",
                    "possible_values": []
                }
            }
        }
    },
    "src/modeling/self_supervised/ss_layers.py": {
        "torch": {
            "Conv2d_7": {
                "in_channels": {
                    "value": "in_planes",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_planes",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "dilation",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "groups": {
                    "value": "groups",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                },
                "dilation": {
                    "value": "dilation",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Conv2d_13": {
                "in_channels": {
                    "value": "in_planes",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_planes",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_33": {
                "variable": {
                    "value": "self.relu",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "src/modeling/utils/image_list.py": {
        "torch": {
            "rand_126": {
                "variable": {
                    "value": "croped_tensors",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(tensors)",
                    "possible_values": []
                },
                "out": {
                    "value": "tensors[0].size(0)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "crop_size",
                    "possible_values": []
                },
                "layout": {
                    "value": "crop_size",
                    "possible_values": []
                }
            },
            "pad_84": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "input": {
                    "value": "tensors[0]",
                    "possible_values": []
                },
                "pad": {
                    "value": "[0, max_size[-1] - image_size[1], 0, max_size[-2] - image_size[0]]",
                    "possible_values": []
                },
                "value": {
                    "value": "pad_value",
                    "possible_values": []
                }
            },
            "interpolate_133": {
                "variable": {
                    "value": "resized_image",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor",
                    "possible_values": [
                        [
                            "tensor.unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "scale_factor": {
                    "value": "ratio",
                    "possible_values": []
                }
            },
            "squeeze_133": {
                "variable": {
                    "value": "resized_image",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "tools/ckpt_surgery.py": {
        "torch": {
            "load_6": {
                "variable": {
                    "value": "ckpt",
                    "possible_values": []
                },
                "f": {
                    "value": "ckpt_path",
                    "possible_values": []
                }
            },
            "save_19": {
                "obj": {
                    "value": "ckpt",
                    "possible_values": [
                        [
                            "torch.load(ckpt_path)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "save_path",
                    "possible_values": []
                }
            }
        }
    },
    "tools/train_net.py": {
        "torch": {}
    }
}