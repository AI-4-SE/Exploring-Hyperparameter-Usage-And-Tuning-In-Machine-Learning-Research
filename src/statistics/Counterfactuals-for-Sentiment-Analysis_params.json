{
    "cfsa.py": {
        "torch": {}
    },
    "cfsa/cfsa.py": {
        "torch": {
            "tensor_31": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.tokenizer.encode(tokenized, add_special_tokens=True)]",
                    "possible_values": []
                }
            },
            "no_grad_32": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_41": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "tensor_50": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.tokenizer.encode(after_remove, add_special_tokens=True)]",
                    "possible_values": []
                }
            },
            "tensor_42": {
                "data": {
                    "value": "[self.tokenizer.encode(tokens, add_special_tokens=True)]",
                    "possible_values": []
                }
            },
            "no_grad_51": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "cfsa/cfsarep.py": {
        "torch": {}
    },
    "cfsa/cfsarm.py": {
        "torch": {
            "tensor_25": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.tokenizer.encode(input_text, add_special_tokens=True)]",
                    "possible_values": []
                }
            },
            "tensor_36": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.tokenizer.encode(text, add_special_tokens=True)]",
                    "possible_values": []
                }
            },
            "no_grad_27": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_37": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    }
}