{
    "baselines.py": {
        "torch": {
            "DropoutBottleneck_135": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv2d_141": {
                    "variable": {
                        "value": "self.conv1",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "inplanes",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "planes",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "BatchNorm2d_145": {
                    "variable": {
                        "value": "self.bn1",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "planes",
                        "possible_values": []
                    }
                },
                "Conv2d_146": {
                    "variable": {
                        "value": "self.conv2",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "planes",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "planes",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "stride",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ],
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "BatchNorm2d_148": {
                    "variable": {
                        "value": "self.bn2",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "planes",
                        "possible_values": []
                    }
                },
                "Conv2d_149": {
                    "variable": {
                        "value": "self.conv3",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "planes",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "planes * 4",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "BatchNorm2d_150": {
                    "variable": {
                        "value": "self.bn3",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "planes * 4",
                        "possible_values": []
                    }
                },
                "ReLU_151": {
                    "variable": {
                        "value": "self.relu",
                        "possible_values": []
                    },
                    "inplace": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "self.downsample": {
                    "value": "downsample",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.pre_dropout": {
                    "value": "pre_dropout",
                    "possible_values": [
                        [
                            "False",
                            "MethodArgument"
                        ],
                        [
                            "False",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "BWtoRGB_186": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BasicDropoutBlock_200": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "BatchNorm2d_210": {
                    "variable": {
                        "value": "self.bn1",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "planes",
                        "possible_values": []
                    }
                },
                "ReLU_211": {
                    "variable": {
                        "value": "self.relu",
                        "possible_values": []
                    },
                    "inplace": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "BatchNorm2d_213": {
                    "variable": {
                        "value": "self.bn2",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "planes",
                        "possible_values": []
                    }
                },
                "self.downsample": {
                    "value": "downsample",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.pre_dropout": {
                    "value": "pre_dropout",
                    "possible_values": [
                        [
                            "False",
                            "MethodArgument"
                        ],
                        [
                            "False",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "MultiBatchModule_636": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.output_size": {
                    "value": "output_size",
                    "possible_values": []
                },
                "self.latent_size": {
                    "value": "latent_size",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.checkpoint": {
                    "value": "checkpoint",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "interpolate_406": {
                "variable": {
                    "value": "x_downsampled",
                    "possible_values": []
                },
                "input": {
                    "value": "F.interpolate(data, ds_img_size, mode='bilinear', align_corners=True)",
                    "possible_values": []
                },
                "size": {
                    "value": "original_img_size",
                    "possible_values": [
                        [
                            "tuple(data.size()[-2:])",
                            "Call"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "interpolate_409": {
                "variable": {
                    "value": "x_upsampled",
                    "possible_values": []
                },
                "input": {
                    "value": "data",
                    "possible_values": []
                },
                "size": {
                    "value": "(args.synthetic_upsample_size, args.synthetic_upsample_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "is_available_111": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "manual_seed_120": {
                "seed": {
                    "value": "args.seed",
                    "possible_values": []
                }
            },
            "Sequential_705": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "*args": {
                    "value": "BWtoRGB()",
                    "possible_values": []
                }
            },
            "Sequential_712": {
                "variable": {
                    "value": "proj",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.BatchNorm1d(self.latent_size)",
                    "possible_values": []
                }
            },
            "load_763": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "f": {
                    "value": "args.restore",
                    "possible_values": []
                }
            },
            "manual_seed_all_122": {
                "seed": {
                    "value": "args.seed",
                    "possible_values": []
                }
            },
            "Dropout2d_143": {
                "variable": {
                    "value": "self.do1",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ],
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Dropout2d_208": {
                "variable": {
                    "value": "self.do1",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ],
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "interpolate_407": {
                "input": {
                    "value": "data",
                    "possible_values": []
                },
                "size": {
                    "value": "ds_img_size",
                    "possible_values": [
                        [
                            "tuple((int(i) for i in np.asarray(original_img_size) // args.downsample_scale))",
                            "Call"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "DataParallel_620": {
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "MultiBatchModule(loader.output_size, checkpoint=args.checkpoint)",
                            "Call"
                        ],
                        [
                            "model.half() if args.half is True else model",
                            "IfExp"
                        ],
                        [
                            "model.cuda() if args.cuda is True else model",
                            "IfExp"
                        ],
                        [
                            "nn.DataParallel(model) if args.ngpu > 1 else model",
                            "IfExp"
                        ],
                        [
                            "torch.load(args.restore)",
                            "Call"
                        ],
                        [
                            "nn.Sequential(BWtoRGB(), nn.Upsample(size=[224, 224], mode='bilinear', align_corners=True), model_map[args.baseline](num_classes=self.latent_size))",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_194": {
                "tensors": {
                    "value": "[x, x, x]",
                    "possible_values": []
                },
                "dim": {
                    "value": "chan_dim",
                    "possible_values": [
                        [
                            "1 if len(x.shape) == 4 else 2",
                            "IfExp"
                        ]
                    ]
                }
            },
            "SGD_317": {
                "params": {
                    "value": "params",
                    "possible_values": []
                },
                "lr": {
                    "value": "lr",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "0.0001",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.9",
                    "possible_values": []
                }
            },
            "memory_allocated_511": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "interpolate_519": {
                "input": {
                    "value": "img",
                    "possible_values": []
                },
                "size": {
                    "value": "(32, 32)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_585": {
                "variable": {
                    "value": "patches_fold_H",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(patches_fold_H, img[:, :, -patch_H:].permute(0, 1, 3, 2).unsqueeze(2))",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_592": {
                "variable": {
                    "value": "patches_fold_HW",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(patches_fold_HW, patches_fold_H[:, :, :, -patch_W:, :].permute(0, 1, 2, 4, 3).unsqueeze(3))",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "possible_values": []
                }
            },
            "Upsample_707": {
                "size": {
                    "value": "[224, 224]",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "BatchNorm1d_713": {
                "num_features": {
                    "value": "self.latent_size",
                    "possible_values": []
                }
            },
            "ReLU_714": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Linear_715": {
                "in_features": {
                    "value": "self.latent_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.latent_size",
                    "possible_values": []
                }
            },
            "BatchNorm1d_716": {
                "num_features": {
                    "value": "self.latent_size",
                    "possible_values": []
                }
            },
            "ReLU_717": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Linear_718": {
                "in_features": {
                    "value": "self.latent_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.output_size",
                    "possible_values": []
                }
            },
            "no_grad_462": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_523": {
                "tensors": {
                    "value": "[F.interpolate(img[:, i, :, :, :], (32, 32), mode='bilinear', align_corners=True) for i in range(img.shape[1])]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "detect_anomaly_463": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cross_entropy_470": {
                "input": {
                    "value": "loss_logits_t",
                    "possible_values": [
                        [
                            "model(data_to_infer)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "labels",
                    "possible_values": []
                }
            },
            "softmax_475": {
                "input": {
                    "value": "loss_logits_t",
                    "possible_values": [
                        [
                            "model(data_to_infer)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "clip_grad_norm__493": {
                "parameters": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "args.clip",
                    "possible_values": []
                }
            },
            "interpolate_523": {
                "input": {
                    "value": "img[:, i, :, :, :]",
                    "possible_values": []
                },
                "size": {
                    "value": "(32, 32)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "main.py": {
        "torch": {
            "interpolate_285": {
                "variable": {
                    "value": "x_downsampled",
                    "possible_values": []
                },
                "input": {
                    "value": "F.interpolate(data, ds_img_size, mode='bilinear', align_corners=True)",
                    "possible_values": []
                },
                "size": {
                    "value": "original_img_size",
                    "possible_values": [
                        [
                            "tuple(data.size()[-2:])",
                            "Call"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "interpolate_288": {
                "variable": {
                    "value": "x_upsampled",
                    "possible_values": []
                },
                "input": {
                    "value": "data",
                    "possible_values": []
                },
                "size": {
                    "value": "(args.synthetic_upsample_size, args.synthetic_upsample_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "is_available_161": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "manual_seed_170": {
                "seed": {
                    "value": "args.seed",
                    "possible_values": []
                }
            },
            "manual_seed_all_172": {
                "seed": {
                    "value": "args.seed",
                    "possible_values": []
                }
            },
            "interpolate_286": {
                "input": {
                    "value": "data",
                    "possible_values": []
                },
                "size": {
                    "value": "ds_img_size",
                    "possible_values": [
                        [
                            "tuple((int(i) for i in np.asarray(original_img_size) // args.downsample_scale))",
                            "Call"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "interpolate_526": {
                "variable": {
                    "value": "gen_map[samples{}_imgs.format(i)]",
                    "possible_values": []
                },
                "input": {
                    "value": "sample",
                    "possible_values": []
                },
                "size": {
                    "value": "(32, 32)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "SGD_193": {
                "params": {
                    "value": "params",
                    "possible_values": []
                },
                "lr": {
                    "value": "lr",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "0.0001",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.9",
                    "possible_values": []
                }
            },
            "memory_allocated_396": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "interpolate_443": {
                "input": {
                    "value": "torchvision.transforms.ToTensor()(x).unsqueeze(0)",
                    "possible_values": []
                },
                "size": {
                    "value": "(args.synthetic_upsample_size, args.synthetic_upsample_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "squeeze_443": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "no_grad_497": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_340": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "detect_anomaly_341": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "softmax_352": {
                "input": {
                    "value": "output_map['preds']",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "clip_grad_value__371": {
                "parameters": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "clip_value": {
                    "value": "args.clip",
                    "possible_values": []
                }
            }
        }
    },
    "models/image_state_projector.py": {
        "torch": {
            "ImageStateProjector_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": [
                        [
                            "deepcopy(self.config)",
                            "Call"
                        ]
                    ]
                },
                "self.output_size": {
                    "value": "output_size",
                    "possible_values": []
                }
            },
            "DataParallel_33": {
                "variable": {
                    "value": "self.conv",
                    "possible_values": []
                },
                "module": {
                    "value": "self.conv",
                    "possible_values": []
                }
            },
            "DataParallel_34": {
                "variable": {
                    "value": "self.state_proj",
                    "possible_values": []
                },
                "module": {
                    "value": "self.state_proj",
                    "possible_values": []
                }
            },
            "DataParallel_35": {
                "variable": {
                    "value": "self.out_proj",
                    "possible_values": []
                },
                "module": {
                    "value": "self.out_proj",
                    "possible_values": []
                }
            },
            "Sequential_74": {
                "variable": {
                    "value": "state_projector",
                    "possible_values": []
                },
                "*args": {
                    "value": "self._get_dense(name='state_proj')(state_input_size, state_output_size, normalization_str=self.config['dense_normalization'], activation_fn=str_to_activ_module(self.config['activation']))",
                    "possible_values": []
                }
            },
            "cat_22": {
                "variable": {
                    "value": "combined",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[state, conv_features]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/localized_spatial_transformer.py": {
        "torch": {
            "LocalizedSpatialTransformerFn_91": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "LocalizedSpatialTransformer_245": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.chans": {
                    "value": "chans",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                }
            },
            "cat_81": {
                "variable": {
                    "value": "crops",
                    "possible_values": []
                },
                "tensors": {
                    "value": "pool_tabulated",
                    "possible_values": [
                        [
                            "pool(crop_lambdas, theta_np, override=override)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "max_129": {
                "variable": {
                    "value": "m_x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(base_grid[0])",
                    "possible_values": []
                }
            },
            "unsqueeze_129": {
                "variable": {
                    "value": "m_x",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "max_131": {
                "variable": {
                    "value": "m_y",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(base_grid[1])",
                    "possible_values": []
                }
            },
            "unsqueeze_131": {
                "variable": {
                    "value": "m_y",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_191": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "base_grid_x",
                    "possible_values": []
                }
            },
            "zeros_like_194": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "base_grid_y",
                    "possible_values": []
                }
            },
            "bmm_204": {
                "variable": {
                    "value": "grad_x_small",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x",
                    "possible_values": [
                        [
                            "torch.zeros_like(base_grid_x)",
                            "Call"
                        ],
                        [
                            "grad_x.unsqueeze(2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "m_y",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(base_grid[1]), 1 - torch.abs(theta[:, 2].unsqueeze(1) - base_grid[1])).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "bmm_205": {
                "variable": {
                    "value": "grad_y_small",
                    "possible_values": []
                },
                "input": {
                    "value": "m_x",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(base_grid[0]), 1 - torch.abs(theta[:, 1].unsqueeze(1) - base_grid[0])).unsqueeze(2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "grad_y",
                    "possible_values": [
                        [
                            "torch.zeros_like(base_grid_y)",
                            "Call"
                        ],
                        [
                            "grad_y.unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_235": {
                "variable": {
                    "value": "grad_y_final",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_y_final",
                    "possible_values": [
                        [
                            "grad_grid * (crops * grad_y_upsampled)",
                            "BinOp"
                        ],
                        [
                            "torch.sum(grad_y_final, (1, 2, 3)).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "(1, 2, 3)",
                    "possible_values": []
                }
            },
            "unsqueeze_235": {
                "variable": {
                    "value": "grad_y_final",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_236": {
                "variable": {
                    "value": "grad_x_final",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x_final",
                    "possible_values": [
                        [
                            "grad_grid * (crops * grad_x_upsampled)",
                            "BinOp"
                        ],
                        [
                            "torch.sum(grad_x_final, (1, 2, 3)).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "(1, 2, 3)",
                    "possible_values": []
                }
            },
            "unsqueeze_236": {
                "variable": {
                    "value": "grad_x_final",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ones_like_237": {
                "variable": {
                    "value": "grad_s_final",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x_final",
                    "possible_values": [
                        [
                            "grad_grid * (crops * grad_x_upsampled)",
                            "BinOp"
                        ],
                        [
                            "torch.sum(grad_x_final, (1, 2, 3)).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_240": {
                "variable": {
                    "value": "grad_theta",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grad_s_final, grad_x_final, grad_y_final]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "clamp_268": {
                "input": {
                    "value": "clamp_map[self.config['reparam_type']](theta)",
                    "possible_values": []
                },
                "min": {
                    "value": "-1.0",
                    "possible_values": []
                },
                "max": {
                    "value": "1.0",
                    "possible_values": []
                }
            },
            "linspace_125": {
                "start": {
                    "value": "-1",
                    "possible_values": []
                },
                "end": {
                    "value": "1",
                    "possible_values": []
                },
                "steps": {
                    "value": "W",
                    "possible_values": []
                }
            },
            "linspace_126": {
                "start": {
                    "value": "-1",
                    "possible_values": []
                },
                "end": {
                    "value": "1",
                    "possible_values": []
                },
                "steps": {
                    "value": "H",
                    "possible_values": []
                }
            },
            "unsqueeze_177": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_like_129": {
                "input": {
                    "value": "base_grid[0]",
                    "possible_values": []
                }
            },
            "zeros_like_131": {
                "input": {
                    "value": "base_grid[1]",
                    "possible_values": []
                }
            },
            "abs_130": {
                "input": {
                    "value": "theta[:, 1].unsqueeze(1) - base_grid[0]",
                    "possible_values": []
                }
            },
            "abs_132": {
                "input": {
                    "value": "theta[:, 2].unsqueeze(1) - base_grid[1]",
                    "possible_values": []
                }
            },
            "pad_177": {
                "input": {
                    "value": "tensor[i]",
                    "possible_values": []
                },
                "pad": {
                    "value": "(padding, padding)",
                    "possible_values": []
                }
            }
        }
    },
    "models/localized_spatial_transformer2.py": {
        "torch": {
            "LocalizedSpatialTransformerFn_91": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "LocalizedSpatialTransformer_338": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.chans": {
                    "value": "chans",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                }
            },
            "cat_81": {
                "variable": {
                    "value": "crops",
                    "possible_values": []
                },
                "tensors": {
                    "value": "pool_tabulated",
                    "possible_values": [
                        [
                            "pool(crop_lambdas, theta_np, override=override)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_135": {
                "variable": {
                    "value": "grid_concat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[base_grid[0].unsqueeze(2), base_grid[1].unsqueeze(2), torch.ones_like(base_grid[1]).unsqueeze(2)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "bmm_141": {
                "variable": {
                    "value": "grid",
                    "possible_values": []
                },
                "input": {
                    "value": "grid_concat",
                    "possible_values": [
                        [
                            "torch.cat([base_grid[0].unsqueeze(2), base_grid[1].unsqueeze(2), torch.ones_like(base_grid[1]).unsqueeze(2)], 2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "theta_inv.transpose(1, 2)",
                    "possible_values": []
                }
            },
            "max_143": {
                "variable": {
                    "value": "m_x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(grid[:, :, 0])",
                    "possible_values": []
                }
            },
            "unsqueeze_143": {
                "variable": {
                    "value": "m_x",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "max_145": {
                "variable": {
                    "value": "m_y",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(grid[:, :, 1])",
                    "possible_values": []
                }
            },
            "unsqueeze_145": {
                "variable": {
                    "value": "m_y",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_194": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "grid[:, :, 0]",
                    "possible_values": []
                }
            },
            "zeros_like_197": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "grid[:, :, 1]",
                    "possible_values": []
                }
            },
            "bmm_207": {
                "variable": {
                    "value": "grad_x_small",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x",
                    "possible_values": [
                        [
                            "torch.zeros_like(grid[:, :, 0])",
                            "Call"
                        ],
                        [
                            "grad_x.unsqueeze(2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "m_y",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(grid[:, :, 1]), 1 - torch.abs(theta[:, 2].unsqueeze(1) - grid[:, :, 1])).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_207": {
                "variable": {
                    "value": "grad_x_small",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_208": {
                "variable": {
                    "value": "grad_y_small",
                    "possible_values": []
                },
                "input": {
                    "value": "m_x",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(grid[:, :, 0]), 1 - torch.abs(theta[:, 1].unsqueeze(1) - grid[:, :, 0])).unsqueeze(2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "grad_y",
                    "possible_values": [
                        [
                            "torch.zeros_like(grid[:, :, 1])",
                            "Call"
                        ],
                        [
                            "grad_y.unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_208": {
                "variable": {
                    "value": "grad_y_small",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_237": {
                "variable": {
                    "value": "grad_y_final",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_y_final",
                    "possible_values": [
                        [
                            "grad_grid * (crops * grad_y_upsampled)",
                            "BinOp"
                        ],
                        [
                            "torch.sum(grad_y_final, (1, 2, 3)).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "(1, 2, 3)",
                    "possible_values": []
                }
            },
            "unsqueeze_237": {
                "variable": {
                    "value": "grad_y_final",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_238": {
                "variable": {
                    "value": "grad_x_final",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x_final",
                    "possible_values": [
                        [
                            "grad_grid * (crops * grad_x_upsampled)",
                            "BinOp"
                        ],
                        [
                            "torch.sum(grad_x_final, (1, 2, 3)).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "(1, 2, 3)",
                    "possible_values": []
                }
            },
            "unsqueeze_238": {
                "variable": {
                    "value": "grad_x_final",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ones_like_239": {
                "variable": {
                    "value": "grad_s_final",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x_final",
                    "possible_values": [
                        [
                            "grad_grid * (crops * grad_x_upsampled)",
                            "BinOp"
                        ],
                        [
                            "torch.sum(grad_x_final, (1, 2, 3)).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_242": {
                "variable": {
                    "value": "grad_theta",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grad_s_final, grad_x_final, grad_y_final]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ones_254": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "zeros_265": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "cat_277": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(LocalizedSpatialTransformerFn.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_281": {
                "variable": {
                    "value": "scale",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.abs(z_where[:, 0:1])",
                    "possible_values": []
                }
            },
            "cat_300": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(LocalizedSpatialTransformerFn.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "index_select_306": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "possible_values": [
                        [
                            "torch.cat((LocalizedSpatialTransformerFn.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:]), 1)",
                            "Call"
                        ],
                        [
                            "out / scale",
                            "BinOp"
                        ],
                        [
                            "torch.cat((LocalizedSpatialTransformerFn.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where), 1)",
                            "Call"
                        ],
                        [
                            "torch.index_select(out, 1, ix)",
                            "Call"
                        ],
                        [
                            "out.view(n, 2, 3)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "ix",
                    "possible_values": [
                        [
                            "Variable(expansion_indices)",
                            "Call"
                        ],
                        [
                            "ix.cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "clamp_361": {
                "input": {
                    "value": "clamp_map[self.config['reparam_type']](theta)",
                    "possible_values": []
                },
                "min": {
                    "value": "-1.0",
                    "possible_values": []
                },
                "max": {
                    "value": "1.0",
                    "possible_values": []
                }
            },
            "linspace_127": {
                "start": {
                    "value": "-1",
                    "possible_values": []
                },
                "end": {
                    "value": "1",
                    "possible_values": []
                },
                "steps": {
                    "value": "W",
                    "possible_values": []
                }
            },
            "linspace_128": {
                "start": {
                    "value": "-1",
                    "possible_values": []
                },
                "end": {
                    "value": "1",
                    "possible_values": []
                },
                "steps": {
                    "value": "H",
                    "possible_values": []
                }
            },
            "abs_281": {
                "input": {
                    "value": "z_where[:, 0:1]",
                    "possible_values": []
                }
            },
            "sum_283": {
                "input": {
                    "value": "scale == 0",
                    "possible_values": []
                }
            },
            "unsqueeze_333": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "ones_like_137": {
                "input": {
                    "value": "base_grid[1]",
                    "possible_values": []
                }
            },
            "unsqueeze_137": {
                "input": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "zeros_like_143": {
                "input": {
                    "value": "grid[:, :, 0]",
                    "possible_values": []
                }
            },
            "zeros_like_145": {
                "input": {
                    "value": "grid[:, :, 1]",
                    "possible_values": []
                }
            },
            "abs_144": {
                "input": {
                    "value": "theta[:, 1].unsqueeze(1) - grid[:, :, 0]",
                    "possible_values": []
                }
            },
            "abs_146": {
                "input": {
                    "value": "theta[:, 2].unsqueeze(1) - grid[:, :, 1]",
                    "possible_values": []
                }
            },
            "pad_333": {
                "input": {
                    "value": "tensor[i]",
                    "possible_values": []
                },
                "pad": {
                    "value": "(padding, padding)",
                    "possible_values": []
                }
            }
        }
    },
    "models/localized_spatial_transformer3.py": {
        "torch": {
            "LocalizedSpatialTransformerFn_46": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "LocalizedSpatialTransformer_238": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.chans": {
                    "value": "chans",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                }
            },
            "affine_grid_21": {
                "variable": {
                    "value": "grid",
                    "possible_values": []
                },
                "theta": {
                    "value": "theta_inv",
                    "possible_values": [
                        [
                            "LocalizedSpatialTransformerFn.expand_z_where(LocalizedSpatialTransformerFn.z_where_inv(theta, clip_scale=max_scale))",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "torch.Size(window_shape)",
                    "possible_values": []
                }
            },
            "cat_27": {
                "variable": {
                    "value": "top_left",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grid[:, 0, 0, 0].unsqueeze(1), grid[:, 0, 0, 1].unsqueeze(1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_29": {
                "variable": {
                    "value": "bottom_right",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grid[:, -1, -1, 0].unsqueeze(1), grid[:, -1, -1, 1].unsqueeze(1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_36": {
                "variable": {
                    "value": "crops",
                    "possible_values": []
                },
                "tensors": {
                    "value": "pool_tabulated",
                    "possible_values": [
                        [
                            "pool(crop_lambdas, top_left, bottom_right, override=override)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_like_115": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "grid[:, :, :, 0]",
                    "possible_values": []
                }
            },
            "zeros_like_118": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "grid[:, :, :, 1]",
                    "possible_values": []
                }
            },
            "max_123": {
                "variable": {
                    "value": "m_x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(base_grid[:, :, :, 0])",
                    "possible_values": []
                }
            },
            "max_125": {
                "variable": {
                    "value": "m_y",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(base_grid[:, :, :, 1])",
                    "possible_values": []
                }
            },
            "bmm_130": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x",
                    "possible_values": [
                        [
                            "torch.zeros_like(grid[:, :, :, 0])",
                            "Call"
                        ],
                        [
                            "torch.bmm(grad_x, m_y).unsqueeze(1)",
                            "Call"
                        ],
                        [
                            "grad_grid * (crops * grad_x)",
                            "BinOp"
                        ],
                        [
                            "grad_x.squeeze(1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "m_y",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(base_grid[:, :, :, 1]), 1 - torch.abs(grid[:, :, :, 1] - base_grid[:, :, :, 1]))",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_130": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_132": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_y",
                    "possible_values": [
                        [
                            "torch.zeros_like(grid[:, :, :, 1])",
                            "Call"
                        ],
                        [
                            "torch.bmm(grad_y, m_x).unsqueeze(1)",
                            "Call"
                        ],
                        [
                            "grad_grid * (crops * grad_y)",
                            "BinOp"
                        ],
                        [
                            "grad_y.squeeze(1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "m_x",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(base_grid[:, :, :, 0]), 1 - torch.abs(grid[:, :, :, 0] - base_grid[:, :, :, 0]))",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_132": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_141": {
                "variable": {
                    "value": "final_grads",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grad_x.unsqueeze(-1), grad_y.unsqueeze(-1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ones_154": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "zeros_165": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "cat_177": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(LocalizedSpatialTransformerFn.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_181": {
                "variable": {
                    "value": "scale",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.abs(z_where[:, 0:1])",
                    "possible_values": []
                }
            },
            "cat_200": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(LocalizedSpatialTransformerFn.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "index_select_206": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "possible_values": [
                        [
                            "torch.cat((LocalizedSpatialTransformerFn.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:]), 1)",
                            "Call"
                        ],
                        [
                            "out / scale",
                            "BinOp"
                        ],
                        [
                            "torch.cat((LocalizedSpatialTransformerFn.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where), 1)",
                            "Call"
                        ],
                        [
                            "torch.index_select(out, 1, ix)",
                            "Call"
                        ],
                        [
                            "out.view(n, 2, 3)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "ix",
                    "possible_values": [
                        [
                            "Variable(expansion_indices)",
                            "Call"
                        ],
                        [
                            "ix.cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "clamp_261": {
                "input": {
                    "value": "clamp_map[self.config['reparam_type']](theta)",
                    "possible_values": []
                },
                "min": {
                    "value": "-1.0",
                    "possible_values": []
                },
                "max": {
                    "value": "1.0",
                    "possible_values": []
                }
            },
            "cat_87": {
                "tensors": {
                    "value": "[gx.unsqueeze(-1), gy.unsqueeze(-1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "linspace_110": {
                "start": {
                    "value": "-1",
                    "possible_values": []
                },
                "end": {
                    "value": "1",
                    "possible_values": []
                },
                "steps": {
                    "value": "W",
                    "possible_values": []
                }
            },
            "zeros_like_123": {
                "input": {
                    "value": "base_grid[:, :, :, 0]",
                    "possible_values": []
                }
            },
            "zeros_like_125": {
                "input": {
                    "value": "base_grid[:, :, :, 1]",
                    "possible_values": []
                }
            },
            "abs_181": {
                "input": {
                    "value": "z_where[:, 0:1]",
                    "possible_values": []
                }
            },
            "sum_183": {
                "input": {
                    "value": "scale == 0",
                    "possible_values": []
                }
            },
            "unsqueeze_233": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "abs_124": {
                "input": {
                    "value": "grid[:, :, :, 0] - base_grid[:, :, :, 0]",
                    "possible_values": []
                }
            },
            "abs_126": {
                "input": {
                    "value": "grid[:, :, :, 1] - base_grid[:, :, :, 1]",
                    "possible_values": []
                }
            },
            "linspace_111": {
                "start": {
                    "value": "-1",
                    "possible_values": []
                },
                "end": {
                    "value": "1",
                    "possible_values": []
                },
                "steps": {
                    "value": "H",
                    "possible_values": []
                }
            },
            "pad_233": {
                "input": {
                    "value": "tensor[i]",
                    "possible_values": []
                },
                "pad": {
                    "value": "(padding, padding)",
                    "possible_values": []
                }
            }
        }
    },
    "models/localized_spatial_transformer4.py": {
        "torch": {
            "LocalizedSpatialTransformerFn_49": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "LocalizedSpatialTransformer_284": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.chans": {
                    "value": "chans",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                }
            },
            "affine_grid_24": {
                "variable": {
                    "value": "grid",
                    "possible_values": []
                },
                "theta": {
                    "value": "theta_inv",
                    "possible_values": [
                        [
                            "LocalizedSpatialTransformerFn.expand_z_where(LocalizedSpatialTransformerFn.z_where_inv(theta, clip_scale=max_scale))",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "torch.Size(window_shape)",
                    "possible_values": []
                }
            },
            "cat_30": {
                "variable": {
                    "value": "top_left",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grid[:, 0, 0, 0].unsqueeze(1), grid[:, 0, 0, 1].unsqueeze(1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_32": {
                "variable": {
                    "value": "bottom_right",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grid[:, -1, -1, 0].unsqueeze(1), grid[:, -1, -1, 1].unsqueeze(1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_39": {
                "variable": {
                    "value": "crops",
                    "possible_values": []
                },
                "tensors": {
                    "value": "pool_tabulated",
                    "possible_values": [
                        [
                            "pool(crop_lambdas, top_left_np, bottom_right_np, override=override)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_like_157": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "grid[:, :, :, 0]",
                    "possible_values": []
                }
            },
            "zeros_like_160": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "grid[:, :, :, 1]",
                    "possible_values": []
                }
            },
            "max_165": {
                "variable": {
                    "value": "m_x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(base_grid[:, :, :, 0])",
                    "possible_values": []
                }
            },
            "max_167": {
                "variable": {
                    "value": "m_y",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.zeros_like(base_grid[:, :, :, 1])",
                    "possible_values": []
                }
            },
            "bmm_172": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_x",
                    "possible_values": [
                        [
                            "torch.zeros_like(grid[:, :, :, 0])",
                            "Call"
                        ],
                        [
                            "torch.bmm(grad_x, m_y).unsqueeze(1)",
                            "Call"
                        ],
                        [
                            "LocalizedSpatialTransformerFn._crop_resize(grad_x, top_left, bottom_right, W, H)",
                            "Call"
                        ],
                        [
                            "grad_grid * (crops * grad_x)",
                            "BinOp"
                        ],
                        [
                            "grad_x.squeeze(1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "m_y",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(base_grid[:, :, :, 1]), 1 - torch.abs(grid[:, :, :, 1] - base_grid[:, :, :, 1]))",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_172": {
                "variable": {
                    "value": "grad_x",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_173": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "m_x",
                    "possible_values": [
                        [
                            "torch.max(torch.zeros_like(base_grid[:, :, :, 0]), 1 - torch.abs(grid[:, :, :, 0] - base_grid[:, :, :, 0]))",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "grad_y",
                    "possible_values": [
                        [
                            "torch.zeros_like(grid[:, :, :, 1])",
                            "Call"
                        ],
                        [
                            "torch.bmm(m_x, grad_y).unsqueeze(1)",
                            "Call"
                        ],
                        [
                            "LocalizedSpatialTransformerFn._crop_resize(grad_y, top_left, bottom_right, W, H)",
                            "Call"
                        ],
                        [
                            "grad_grid * (crops * grad_y)",
                            "BinOp"
                        ],
                        [
                            "grad_y.squeeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_173": {
                "variable": {
                    "value": "grad_y",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_187": {
                "variable": {
                    "value": "final_grads",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[grad_x.unsqueeze(-1), grad_y.unsqueeze(-1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ones_200": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "zeros_211": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "cat_223": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(LocalizedSpatialTransformerFn.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_227": {
                "variable": {
                    "value": "scale",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.abs(z_where[:, 0:1])",
                    "possible_values": []
                }
            },
            "cat_246": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(LocalizedSpatialTransformerFn.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "index_select_252": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "possible_values": [
                        [
                            "torch.cat((LocalizedSpatialTransformerFn.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:]), 1)",
                            "Call"
                        ],
                        [
                            "out / scale",
                            "BinOp"
                        ],
                        [
                            "torch.cat((LocalizedSpatialTransformerFn.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where), 1)",
                            "Call"
                        ],
                        [
                            "torch.index_select(out, 1, ix)",
                            "Call"
                        ],
                        [
                            "out.view(n, 2, 3)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "ix",
                    "possible_values": [
                        [
                            "Variable(expansion_indices)",
                            "Call"
                        ],
                        [
                            "ix.cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "linspace_119": {
                "variable": {
                    "value": "base_grid[i, :, :, 0]",
                    "possible_values": []
                },
                "start": {
                    "value": "nw_x",
                    "possible_values": [
                        [
                            "int(scale(nw[0].item(), 0, W - 1, -1, 1))",
                            "Call"
                        ]
                    ]
                },
                "end": {
                    "value": "se_x",
                    "possible_values": [
                        [
                            "int(scale(se[0].item(), 0, W - 1, -1, 1))",
                            "Call"
                        ]
                    ]
                },
                "steps": {
                    "value": "W",
                    "possible_values": []
                }
            },
            "linspace_120": {
                "variable": {
                    "value": "base_grid[i, :, :, 1]",
                    "possible_values": []
                },
                "start": {
                    "value": "nw_y",
                    "possible_values": [
                        [
                            "int(scale(nw[1].item(), 0, H - 1, -1, 1))",
                            "Call"
                        ]
                    ]
                },
                "end": {
                    "value": "se_y",
                    "possible_values": [
                        [
                            "int(scale(se[1].item(), 0, H - 1, -1, 1))",
                            "Call"
                        ]
                    ]
                },
                "steps": {
                    "value": "H",
                    "possible_values": []
                }
            },
            "cat_127": {
                "tensors": {
                    "value": "[F.interpolate(mv.unsqueeze(0), size=(W, H), mode='bilinear') for mv in matrix]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "clamp_307": {
                "input": {
                    "value": "clamp_map[self.config['reparam_type']](theta)",
                    "possible_values": []
                },
                "min": {
                    "value": "-1.0",
                    "possible_values": []
                },
                "max": {
                    "value": "1.0",
                    "possible_values": []
                }
            },
            "cat_89": {
                "tensors": {
                    "value": "[gx.unsqueeze(-1), gy.unsqueeze(-1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_like_165": {
                "input": {
                    "value": "base_grid[:, :, :, 0]",
                    "possible_values": []
                }
            },
            "zeros_like_167": {
                "input": {
                    "value": "base_grid[:, :, :, 1]",
                    "possible_values": []
                }
            },
            "abs_227": {
                "input": {
                    "value": "z_where[:, 0:1]",
                    "possible_values": []
                }
            },
            "sum_229": {
                "input": {
                    "value": "scale == 0",
                    "possible_values": []
                }
            },
            "unsqueeze_279": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "interpolate_127": {
                "input": {
                    "value": "mv.unsqueeze(0)",
                    "possible_values": []
                },
                "size": {
                    "value": "(W, H)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "abs_166": {
                "input": {
                    "value": "grid[:, :, :, 0] - base_grid[:, :, :, 0]",
                    "possible_values": []
                }
            },
            "abs_168": {
                "input": {
                    "value": "grid[:, :, :, 1] - base_grid[:, :, :, 1]",
                    "possible_values": []
                }
            },
            "pad_279": {
                "input": {
                    "value": "tensor[i]",
                    "possible_values": []
                },
                "pad": {
                    "value": "(padding, padding)",
                    "possible_values": []
                }
            }
        }
    },
    "models/numerical_diff_autograd.py": {
        "torch": {
            "NumDiffAutoGradFn_9": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "interpolate_102": {
                "variable": {
                    "value": "fs_m_h",
                    "possible_values": []
                },
                "input": {
                    "value": "fs_m_h",
                    "possible_values": [
                        [
                            "crops[:, :, cw_b + delta:cw_e - delta, ch_b + delta:ch_e - delta]",
                            "Subscript"
                        ],
                        [
                            "F.interpolate(fs_m_h, size=(window_size, window_size), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(window_size, window_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "interpolate_103": {
                "variable": {
                    "value": "fs_p_h",
                    "possible_values": []
                },
                "input": {
                    "value": "fs_p_h",
                    "possible_values": [
                        [
                            "crops[:, :, cw_b - delta:cw_e + delta, ch_b - delta:ch_e + delta]",
                            "Subscript"
                        ],
                        [
                            "F.interpolate(fs_p_h, size=(window_size, window_size), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(window_size, window_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "cat_109": {
                "variable": {
                    "value": "grads",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[dfs.unsqueeze(1), dfx.unsqueeze(1), dfy.unsqueeze(1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_132": {
                "variable": {
                    "value": "z_grad",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[NumDiffAutoGradFn._numerical_grads(crops_perturbed, window_size, k + 1).unsqueeze(0) for k in range(0, delta)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "mean_134": {
                "variable": {
                    "value": "z_grad",
                    "possible_values": []
                },
                "input": {
                    "value": "z_grad",
                    "possible_values": [
                        [
                            "torch.cat([NumDiffAutoGradFn._numerical_grads(crops_perturbed, window_size, k + 1).unsqueeze(0) for k in range(0, delta)], 0)",
                            "Call"
                        ],
                        [
                            "torch.mean(z_grad, 0)",
                            "Call"
                        ],
                        [
                            "torch.matmul(grad_output.unsqueeze(1), z_grad)",
                            "Call"
                        ],
                        [
                            "torch.mean(torch.mean(torch.mean(z_grad, -1), -1), -1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "matmul_136": {
                "variable": {
                    "value": "z_grad",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_output.unsqueeze(1)",
                    "possible_values": []
                },
                "other": {
                    "value": "z_grad",
                    "possible_values": [
                        [
                            "torch.cat([NumDiffAutoGradFn._numerical_grads(crops_perturbed, window_size, k + 1).unsqueeze(0) for k in range(0, delta)], 0)",
                            "Call"
                        ],
                        [
                            "torch.mean(z_grad, 0)",
                            "Call"
                        ],
                        [
                            "torch.matmul(grad_output.unsqueeze(1), z_grad)",
                            "Call"
                        ],
                        [
                            "torch.mean(torch.mean(torch.mean(z_grad, -1), -1), -1)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_137": {
                "input": {
                    "value": "z_grad",
                    "possible_values": [
                        [
                            "torch.cat([NumDiffAutoGradFn._numerical_grads(crops_perturbed, window_size, k + 1).unsqueeze(0) for k in range(0, delta)], 0)",
                            "Call"
                        ],
                        [
                            "torch.mean(z_grad, 0)",
                            "Call"
                        ],
                        [
                            "torch.matmul(grad_output.unsqueeze(1), z_grad)",
                            "Call"
                        ],
                        [
                            "torch.mean(torch.mean(torch.mean(z_grad, -1), -1), -1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/numerical_diff_autograd_v2.py": {
        "torch": {
            "NumDiffAutoGradFn_6": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "cat_56": {
                "variable": {
                    "value": "dfx",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[F.conv2d(crops[:, i, :, :].unsqueeze(1), weight=sobel_x, stride=1, padding=1) for i in range(crops.size(1))]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_58": {
                "variable": {
                    "value": "dfy",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[F.conv2d(crops[:, i, :, :].unsqueeze(1), weight=sobel_y, stride=1, padding=1) for i in range(crops.size(1))]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "interpolate_66": {
                "variable": {
                    "value": "fs_m_h",
                    "possible_values": []
                },
                "input": {
                    "value": "fs_m_h",
                    "possible_values": [
                        [
                            "crops[:, :, cw_b + delta:cw_e - delta, ch_b + delta:ch_e - delta]",
                            "Subscript"
                        ],
                        [
                            "F.interpolate(fs_m_h, size=(window_size, window_size), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(window_size, window_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "interpolate_68": {
                "variable": {
                    "value": "fs_p_h",
                    "possible_values": []
                },
                "input": {
                    "value": "fs_p_h",
                    "possible_values": [
                        [
                            "crops[:, :, cw_b - delta:cw_e + delta, ch_b - delta:ch_e + delta]",
                            "Subscript"
                        ],
                        [
                            "F.interpolate(fs_p_h, size=(window_size, window_size), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(window_size, window_size)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "cat_75": {
                "variable": {
                    "value": "grads",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[dfs.unsqueeze(1), dfx.unsqueeze(1), dfy.unsqueeze(1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_95": {
                "variable": {
                    "value": "z_grad",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[NumDiffAutoGradFn._numerical_grads(crops_perturbed, sobel_x, sobel_y, window_size, k + 1).unsqueeze(0) for k in range(0, delta)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "mean_98": {
                "variable": {
                    "value": "z_grad",
                    "possible_values": []
                },
                "input": {
                    "value": "z_grad",
                    "possible_values": [
                        [
                            "torch.cat([NumDiffAutoGradFn._numerical_grads(crops_perturbed, sobel_x, sobel_y, window_size, k + 1).unsqueeze(0) for k in range(0, delta)], 0)",
                            "Call"
                        ],
                        [
                            "torch.mean(z_grad, 0)",
                            "Call"
                        ],
                        [
                            "torch.matmul(grad_output.unsqueeze(1), z_grad)",
                            "Call"
                        ],
                        [
                            "torch.mean(torch.mean(torch.mean(z_grad, -1), -1), -1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "matmul_99": {
                "variable": {
                    "value": "z_grad",
                    "possible_values": []
                },
                "input": {
                    "value": "grad_output.unsqueeze(1)",
                    "possible_values": []
                },
                "other": {
                    "value": "z_grad",
                    "possible_values": [
                        [
                            "torch.cat([NumDiffAutoGradFn._numerical_grads(crops_perturbed, sobel_x, sobel_y, window_size, k + 1).unsqueeze(0) for k in range(0, delta)], 0)",
                            "Call"
                        ],
                        [
                            "torch.mean(z_grad, 0)",
                            "Call"
                        ],
                        [
                            "torch.matmul(grad_output.unsqueeze(1), z_grad)",
                            "Call"
                        ],
                        [
                            "torch.mean(torch.mean(torch.mean(z_grad, -1), -1), -1)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_100": {
                "input": {
                    "value": "z_grad",
                    "possible_values": [
                        [
                            "torch.cat([NumDiffAutoGradFn._numerical_grads(crops_perturbed, sobel_x, sobel_y, window_size, k + 1).unsqueeze(0) for k in range(0, delta)], 0)",
                            "Call"
                        ],
                        [
                            "torch.mean(z_grad, 0)",
                            "Call"
                        ],
                        [
                            "torch.matmul(grad_output.unsqueeze(1), z_grad)",
                            "Call"
                        ],
                        [
                            "torch.mean(torch.mean(torch.mean(z_grad, -1), -1), -1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "conv2d_56": {
                "input": {
                    "value": "crops[:, i, :, :].unsqueeze(1)",
                    "possible_values": []
                },
                "weight": {
                    "value": "sobel_x",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "conv2d_58": {
                "input": {
                    "value": "crops[:, i, :, :].unsqueeze(1)",
                    "possible_values": []
                },
                "weight": {
                    "value": "sobel_y",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "models/numerical_diff_module.py": {
        "torch": {
            "NumericalDifferentiator_16": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "from_numpy_21": {
                    "variable": {
                        "value": "self.sobel_x",
                        "possible_values": []
                    },
                    "ndarray": {
                        "value": "np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=np.float32)",
                        "possible_values": []
                    }
                },
                "unsqueeze_21": {
                    "variable": {
                        "value": "self.sobel_x",
                        "possible_values": []
                    },
                    "input": {
                        "value": "0",
                        "possible_values": []
                    }
                },
                "from_numpy_23": {
                    "variable": {
                        "value": "self.sobel_y",
                        "possible_values": []
                    },
                    "ndarray": {
                        "value": "np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)",
                        "possible_values": []
                    }
                },
                "unsqueeze_23": {
                    "variable": {
                        "value": "self.sobel_y",
                        "possible_values": []
                    },
                    "input": {
                        "value": "0",
                        "possible_values": []
                    }
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                }
            }
        }
    },
    "models/pool.py": {
        "torch": {
            "ModelPool_155": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.input_shape": {
                    "value": "input_shape",
                    "possible_values": []
                },
                "self.output_size": {
                    "value": "output_size",
                    "possible_values": []
                },
                "self.num_models": {
                    "value": "num_models",
                    "possible_values": []
                },
                "self.activation_fn": {
                    "value": "activation_fn",
                    "possible_values": [
                        [
                            "F.elu",
                            "MethodArgument"
                        ]
                    ]
                },
                "ModuleList_177": {
                    "variable": {
                        "value": "self.models",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "self.models",
                        "possible_values": []
                    }
                },
                "ModuleList_178": {
                    "variable": {
                        "value": "self.project_to_class_models",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "self.project_to_class_models",
                        "possible_values": []
                    }
                }
            },
            "ModuleList_184": {
                "variable": {
                    "value": "base_model",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(input_size, input_size), nn.Linear(input_size, input_size)]",
                    "possible_values": []
                }
            },
            "Sequential_190": {
                "variable": {
                    "value": "linear",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(input_size, self.output_size)",
                    "possible_values": []
                }
            },
            "squeeze_48": {
                "variable": {
                    "value": "target",
                    "possible_values": []
                },
                "input": {
                    "value": "target",
                    "possible_values": [
                        [
                            "torch.squeeze(target)",
                            "Call"
                        ],
                        [
                            "target == i",
                            "Compare"
                        ],
                        [
                            "target.type(long_type(args.cuda))",
                            "Call"
                        ],
                        [
                            "torch.squeeze(target)",
                            "Call"
                        ],
                        [
                            "target == i",
                            "Compare"
                        ],
                        [
                            "target.type(long_type(args.cuda))",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_195": {
                "variable": {
                    "value": "base_model",
                    "possible_values": []
                },
                "module": {
                    "value": "base_model",
                    "possible_values": [
                        [
                            "nn.ModuleList([nn.Linear(input_size, input_size), nn.Linear(input_size, input_size)])",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(base_model)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_196": {
                "variable": {
                    "value": "linear",
                    "possible_values": []
                },
                "module": {
                    "value": "linear",
                    "possible_values": [
                        [
                            "nn.Sequential(nn.Linear(input_size, self.output_size))",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(linear)",
                            "Call"
                        ]
                    ]
                }
            },
            "cross_entropy_250": {
                "input": {
                    "value": "pred",
                    "possible_values": []
                },
                "target": {
                    "value": "target",
                    "possible_values": [
                        [
                            "torch.squeeze(target)",
                            "Call"
                        ],
                        [
                            "target == i",
                            "Compare"
                        ],
                        [
                            "target.type(long_type(args.cuda))",
                            "Call"
                        ],
                        [
                            "torch.squeeze(target)",
                            "Call"
                        ],
                        [
                            "target == i",
                            "Compare"
                        ],
                        [
                            "target.type(long_type(args.cuda))",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_260": {
                "modules": {
                    "value": "single_model",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "vector_to_parameters_265": {
                "vec": {
                    "value": "nn.utils.parameters_to_vector(single_model.parameters()) * 0",
                    "possible_values": []
                },
                "parameters": {
                    "value": "single_model.parameters()",
                    "possible_values": []
                }
            },
            "no_grad_89": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "squeeze_92": {
                "variable": {
                    "value": "target",
                    "possible_values": []
                },
                "input": {
                    "value": "target",
                    "possible_values": [
                        [
                            "torch.squeeze(target)",
                            "Call"
                        ],
                        [
                            "target == i",
                            "Compare"
                        ],
                        [
                            "target.type(long_type(args.cuda))",
                            "Call"
                        ],
                        [
                            "torch.squeeze(target)",
                            "Call"
                        ],
                        [
                            "target == i",
                            "Compare"
                        ],
                        [
                            "target.type(long_type(args.cuda))",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_191": {
                "in_features": {
                    "value": "input_size",
                    "possible_values": [
                        [
                            "int(np.prod(self.input_shape))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.output_size",
                    "possible_values": []
                }
            },
            "save_221": {
                "obj": {
                    "value": "self.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "model_filename",
                    "possible_values": [
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ],
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ]
                    ]
                }
            },
            "parameters_to_vector_272": {
                "variable": {
                    "value": "single_model_single_layer_params",
                    "possible_values": []
                },
                "parameters": {
                    "value": "single_model[j].parameters()",
                    "possible_values": []
                }
            },
            "parameters_to_vector_273": {
                "variable": {
                    "value": "layer_params",
                    "possible_values": []
                },
                "parameters": {
                    "value": "layer.parameters()",
                    "possible_values": []
                }
            },
            "Linear_185": {
                "in_features": {
                    "value": "input_size",
                    "possible_values": [
                        [
                            "int(np.prod(self.input_shape))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "input_size",
                    "possible_values": [
                        [
                            "int(np.prod(self.input_shape))",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_186": {
                "in_features": {
                    "value": "input_size",
                    "possible_values": [
                        [
                            "int(np.prod(self.input_shape))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "input_size",
                    "possible_values": [
                        [
                            "int(np.prod(self.input_shape))",
                            "Call"
                        ]
                    ]
                }
            },
            "parameters_to_vector_265": {
                "parameters": {
                    "value": "single_model.parameters()",
                    "possible_values": []
                }
            },
            "vector_to_parameters_275": {
                "vec": {
                    "value": "update",
                    "possible_values": [
                        [
                            "single_model_single_layer_params + single_soft_cat[j, i] * layer_params",
                            "BinOp"
                        ]
                    ]
                },
                "parameters": {
                    "value": "single_model[j].parameters()",
                    "possible_values": []
                }
            },
            "load_210": {
                "f": {
                    "value": "model_filename",
                    "possible_values": [
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ],
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models/relational_network.py": {
        "torch": {
            "RelationalNetwork_13": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                },
                "self.hidden_size": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "self.output_size": {
                    "value": "output_size",
                    "possible_values": []
                }
            },
            "mean_64": {
                "variable": {
                    "value": "rn_buffer",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.cat(rn_buffer, 0)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Sequential_37": {
                "variable": {
                    "value": "self.img_model",
                    "possible_values": []
                },
                "*args": {
                    "value": "builder_fn(input_size, self.hidden_size, normalization_str=self.config['normalization'])",
                    "possible_values": []
                }
            },
            "Sequential_48": {
                "*args": {
                    "value": "build_dense_encoder(self.hidden_size * 2, self.hidden_size, normalization_str='batchnorm')",
                    "possible_values": []
                }
            },
            "SELU_51": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_64": {
                "tensors": {
                    "value": "rn_buffer",
                    "possible_values": [
                        [
                            "[self.rn(torch.cat([img_r, img_l], -1)).unsqueeze(0) for img_r in conv_output for img_l in conv_output]",
                            "ListComp"
                        ],
                        [
                            "torch.mean(torch.cat(rn_buffer, 0), 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "SELU_40": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_61": {
                "tensors": {
                    "value": "[img_r, img_l]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/saccade.py": {
        "torch": {
            "Saccader_20": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.vae": {
                    "value": "vae",
                    "possible_values": []
                },
                "self.output_size": {
                    "value": "output_size",
                    "possible_values": []
                }
            },
            "DataParallel_64": {
                "variable": {
                    "value": "self.spatial_transformer",
                    "possible_values": []
                },
                "module": {
                    "value": "self.spatial_transformer",
                    "possible_values": []
                }
            },
            "zeros_like_170": {
                "variable": {
                    "value": "act_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "pred_loss",
                    "possible_values": [
                        [
                            "loss_fn(input=output_map['preds'], target=labels, reduction='none')",
                            "Call"
                        ],
                        [
                            "torch.sum(pred_loss, -1) if len(pred_loss.shape) > 1 else pred_loss",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_182": {
                "variable": {
                    "value": "vae_loss_map[act_loss_mean]",
                    "possible_values": []
                },
                "input": {
                    "value": "act_loss",
                    "possible_values": [
                        [
                            "torch.zeros_like(pred_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_183": {
                "variable": {
                    "value": "vae_loss_map[pred_loss_mean]",
                    "possible_values": []
                },
                "input": {
                    "value": "pred_loss",
                    "possible_values": [
                        [
                            "loss_fn(input=output_map['preds'], target=labels, reduction='none')",
                            "Call"
                        ],
                        [
                            "torch.sum(pred_loss, -1) if len(pred_loss.shape) > 1 else pred_loss",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_184": {
                "variable": {
                    "value": "vae_loss_map[loss_mean]",
                    "possible_values": []
                },
                "input": {
                    "value": "vae_loss_map['loss']",
                    "possible_values": []
                }
            },
            "interpolate_129": {
                "variable": {
                    "value": "imgs_map[softcrop{}_imgs.format(i)]",
                    "possible_values": []
                },
                "input": {
                    "value": "crop",
                    "possible_values": []
                },
                "size": {
                    "value": "crop_resize",
                    "possible_values": [
                        [
                            "(64",
                            "MethodArgument"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "interpolate_131": {
                "variable": {
                    "value": "imgs_map[decoded{}_imgs.format(i)]",
                    "possible_values": []
                },
                "input": {
                    "value": "self.vae.nll_activation(decoded)",
                    "possible_values": []
                },
                "size": {
                    "value": "decode_resize",
                    "possible_values": [
                        [
                            "(32",
                            "MethodArgument"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "interpolate_139": {
                "variable": {
                    "value": "imgs_map[hardcrop{}_imgs.format(i)]",
                    "possible_values": []
                },
                "input": {
                    "value": "crop_true",
                    "possible_values": []
                },
                "size": {
                    "value": "crop_resize",
                    "possible_values": [
                        [
                            "(64",
                            "MethodArgument"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "interpolate_141": {
                "variable": {
                    "value": "imgs_map[inlay{}_imgs.format(i)]",
                    "possible_values": []
                },
                "input": {
                    "value": "inlay",
                    "possible_values": []
                },
                "size": {
                    "value": "decode_resize",
                    "possible_values": [
                        [
                            "(32",
                            "MethodArgument"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "clamp_204": {
                "input": {
                    "value": "clamp_map[self.config['reparam_type']](z)",
                    "possible_values": []
                },
                "min": {
                    "value": "0.0",
                    "possible_values": []
                },
                "max": {
                    "value": "1.0",
                    "possible_values": []
                }
            },
            "Sequential_40": {
                "*args": {
                    "value": "self._get_dense('posterior_to_st_proj')(self.vae.reparameterizer.output_size, 3, normalization_str=self.config['dense_normalization'], activation_fn=str_to_activ_module(self.config['activation']))",
                    "possible_values": []
                }
            },
            "load_82": {
                "variable": {
                    "value": "self",
                    "possible_values": []
                },
                "f": {
                    "value": "model_filename",
                    "possible_values": [
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ],
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_100": {
                "obj": {
                    "value": "self",
                    "possible_values": [
                        [
                            "torch.load(model_filename)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "model_filename",
                    "possible_values": [
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ],
                        [
                            "os.path.join('.models', self.get_name() + '.th')",
                            "Call"
                        ]
                    ]
                }
            },
            "interpolate_107": {
                "variable": {
                    "value": "return_map[name]",
                    "possible_values": []
                },
                "input": {
                    "value": "img",
                    "possible_values": []
                },
                "size": {
                    "value": "resize",
                    "possible_values": [
                        [
                            "(128",
                            "MethodArgument"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "from_numpy_109": {
                "variable": {
                    "value": "theta",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.tile(np.array([[1.0, 0.0, 0.0]]), (batch_size, 1))",
                    "possible_values": []
                }
            },
            "interpolate_118": {
                "variable": {
                    "value": "return_map[name]",
                    "possible_values": []
                },
                "input": {
                    "value": "original_full_img",
                    "possible_values": []
                },
                "size": {
                    "value": "resize",
                    "possible_values": [
                        [
                            "(128",
                            "MethodArgument"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "sum_165": {
                "input": {
                    "value": "pred_loss",
                    "possible_values": [
                        [
                            "loss_fn(input=output_map['preds'], target=labels, reduction='none')",
                            "Call"
                        ],
                        [
                            "torch.sum(pred_loss, -1) if len(pred_loss.shape) > 1 else pred_loss",
                            "IfExp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "no_grad_231": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "mean_276": {
                "variable": {
                    "value": "state",
                    "possible_values": []
                },
                "input": {
                    "value": "self.vae.memory.get_state()[0]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_308": {
                "tensors": {
                    "value": "x_preds",
                    "possible_values": [
                        [
                            "zeros((batch_size, self.config['latent_size']), cuda=x_related.is_cuda, dtype=get_dtype(x_related)).requires_grad_()",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(x_preds, -1) if self.config['concat_prediction_size'] > 0 else x_preds",
                            "IfExp"
                        ],
                        [
                            "x_preds + state_proj[:, 0:-1]",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/spatial_transformer.py": {
        "torch": {
            "SpatialTransformer_10": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": []
                }
            },
            "ones_29": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "zeros_40": {
                "variable": {
                    "value": "p_tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "cat_50": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(SpatialTransformer.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "index_select_56": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "possible_values": [
                        [
                            "torch.cat((SpatialTransformer.ng_zeros([1, 1]).type_as(z_where).expand(n, 1), z_where), 1)",
                            "Call"
                        ],
                        [
                            "torch.index_select(out, 1, ix)",
                            "Call"
                        ],
                        [
                            "out.view(n, 2, 3)",
                            "Call"
                        ],
                        [
                            "torch.cat((SpatialTransformer.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:]), 1)",
                            "Call"
                        ],
                        [
                            "out / scale",
                            "BinOp"
                        ],
                        [
                            "F.grid_sample(windows.view(n, 1, window_size, window_size), grid)",
                            "Call"
                        ],
                        [
                            "F.grid_sample(images_trunc.view(n, *image_size), grid)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "ix",
                    "possible_values": [
                        [
                            "Variable(expansion_indices)",
                            "Call"
                        ],
                        [
                            "ix.cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_68": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(SpatialTransformer.ng_ones([1, 1]).type_as(z_where).expand(n, 1), -z_where[:, 1:])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_72": {
                "variable": {
                    "value": "scale",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.abs(z_where[:, 0:1])",
                    "possible_values": []
                }
            },
            "affine_grid_89": {
                "variable": {
                    "value": "grid",
                    "possible_values": []
                },
                "theta": {
                    "value": "theta",
                    "possible_values": [
                        [
                            "SpatialTransformer.expand_z_where(z_where)",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "torch.Size((n, 1, image_size, image_size))",
                    "possible_values": []
                }
            },
            "grid_sample_90": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "windows.view(n, 1, window_size, window_size)",
                    "possible_values": []
                },
                "grid": {
                    "value": "grid",
                    "possible_values": [
                        [
                            "F.affine_grid(theta, torch.Size((n, 1, image_size, image_size)))",
                            "Call"
                        ],
                        [
                            "F.affine_grid(theta_inv_trunc, torch.Size((n, chans, window_size, window_size)))",
                            "Call"
                        ]
                    ]
                }
            },
            "affine_grid_116": {
                "variable": {
                    "value": "grid",
                    "possible_values": []
                },
                "theta": {
                    "value": "theta_inv_trunc",
                    "possible_values": [
                        [
                            "theta_inv.half()",
                            "Call"
                        ],
                        [
                            "theta_inv",
                            "Name"
                        ]
                    ]
                },
                "size": {
                    "value": "torch.Size((n, chans, window_size, window_size))",
                    "possible_values": []
                }
            },
            "grid_sample_117": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "images_trunc.view(n, *image_size)",
                    "possible_values": []
                },
                "grid": {
                    "value": "grid",
                    "possible_values": [
                        [
                            "F.affine_grid(theta, torch.Size((n, 1, image_size, image_size)))",
                            "Call"
                        ],
                        [
                            "F.affine_grid(theta_inv_trunc, torch.Size((n, chans, window_size, window_size)))",
                            "Call"
                        ]
                    ]
                }
            },
            "abs_72": {
                "input": {
                    "value": "z_where[:, 0:1]",
                    "possible_values": []
                }
            },
            "sum_74": {
                "input": {
                    "value": "scale == 0",
                    "possible_values": []
                }
            }
        }
    },
    "optimizers/adamnormgrad.py": {
        "torch": {
            "AdamNormGrad_10": {
                "base_class_0": {
                    "value": "torch.optim.Optimizer",
                    "possible_values": []
                }
            },
            "norm_53": {
                "input": {
                    "value": "grad",
                    "possible_values": [
                        [
                            "p.grad.data",
                            "Attribute"
                        ],
                        [
                            "grad / (torch.norm(grad, 2) + 1e-07)",
                            "BinOp"
                        ],
                        [
                            "grad.add(group['weight_decay'], p.data)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "possible_values": []
                }
            }
        }
    },
    "optimizers/adamw.py": {
        "torch": {
            "AdamW_6": {
                "base_class_0": {
                    "value": "torch.optim.Optimizer",
                    "possible_values": []
                }
            },
            "zeros_like_56": {
                "variable": {
                    "value": "state[exp_avg]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "zeros_like_58": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            }
        }
    }
}