{
    "main_linear_classification.py": {
        "torch": {
            "device_count_236": {
                "variable": {
                    "value": "ngpus_per_node",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_362": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_182": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model)",
                            "Call"
                        ],
                        [
                            "model.cuda(args.gpu)",
                            "Call"
                        ],
                        [
                            "obow.classification.FrozenFeaturesLinearClassifier(feature_extractor=feature_extractor, linear_classifier_opts=linear_classifier_opts)",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.gpu]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_188": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model)",
                            "Call"
                        ],
                        [
                            "model.cuda(args.gpu)",
                            "Call"
                        ],
                        [
                            "obow.classification.FrozenFeaturesLinearClassifier(feature_extractor=feature_extractor, linear_classifier_opts=linear_classifier_opts)",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_219": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_172": {
                "device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_201": {
                "device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_325": {
                "type": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "main_obow.py": {
        "torch": {
            "device_316": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_264": {
                "device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_152": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], output_device=args.gpu, find_unused_parameters=True)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], output_device=args.gpu, find_unused_parameters=True)",
                            "Call"
                        ],
                        [
                            "model.cuda(args.gpu)",
                            "Call"
                        ],
                        [
                            "obow.builder_obow.OBoW(feature_extractor=feature_extractor, num_channels=num_channels, bow_levels=model_opts['bow_levels'], bow_extractor_opts_list=model_opts['bow_extractor_opts_list'], bow_predictor_opts=model_opts['bow_predictor_opts'], alpha=model_opts['alpha'], num_classes=model_opts.get('num_classes', None))",
                            "Call"
                        ],
                        [
                            "solver.model.module if args.distributed else solver.model",
                            "IfExp"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.gpu]",
                    "type": "List",
                    "possible_values": []
                },
                "output_device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "find_unused_parameters": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_159": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], output_device=args.gpu, find_unused_parameters=True)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], output_device=args.gpu, find_unused_parameters=True)",
                            "Call"
                        ],
                        [
                            "model.cuda(args.gpu)",
                            "Call"
                        ],
                        [
                            "obow.builder_obow.OBoW(feature_extractor=feature_extractor, num_channels=num_channels, bow_levels=model_opts['bow_levels'], bow_extractor_opts_list=model_opts['bow_extractor_opts_list'], bow_predictor_opts=model_opts['bow_predictor_opts'], alpha=model_opts['alpha'], num_classes=model_opts.get('num_classes', None))",
                            "Call"
                        ],
                        [
                            "solver.model.module if args.distributed else solver.model",
                            "IfExp"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.gpu]",
                    "type": "List",
                    "possible_values": []
                },
                "output_device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "find_unused_parameters": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "manual_seed_173": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "main_semisupervised.py": {
        "torch": {
            "device_count_190": {
                "variable": {
                    "value": "ngpus_per_node",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_281": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_147": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model)",
                            "Call"
                        ],
                        [
                            "model.cuda(args.gpu)",
                            "Call"
                        ],
                        [
                            "obow.classification.SupervisedClassification(feature_extractor=feature_extractor, linear_classifier_opts=linear_classifier_opts)",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.gpu]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_153": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model)",
                            "Call"
                        ],
                        [
                            "model.cuda(args.gpu)",
                            "Call"
                        ],
                        [
                            "obow.classification.SupervisedClassification(feature_extractor=feature_extractor, linear_classifier_opts=linear_classifier_opts)",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_173": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_138": {
                "device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_157": {
                "device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "obow/builder_obow.py": {
        "torch": {
            "stack_42": {
                "variable": {
                    "value": "perplexity_batch",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "perplexity_batch",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.stack(perplexity_batch, dim=0).view(-1).tolist()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_43": {
                "variable": {
                    "value": "perplexity_img",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "perplexity_img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.stack(perplexity_img, dim=0).view(-1).tolist()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_17": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "normalize_27": {
                "variable": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "bow_target_level",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bow_target",
                            "variable"
                        ]
                    ]
                },
                "p": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_28": {
                "variable": {
                    "value": "perplexity_img_level",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-torch.sum(probs * torch.log(probs + 1e-05), dim=1)",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "mean_28": {
                "variable": {
                    "value": "perplexity_img_level",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "normalize_35": {
                "variable": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "bow_target_sum_all",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bow_target_level.sum(dim=0)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_36": {
                "variable": {
                    "value": "perplexity_batch_level",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-torch.sum(probs * torch.log(probs + 1e-05), dim=0)",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "no_grad_160": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_170": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cross_entropy_212": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.linear_classifier(features)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels.cuda(self.device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "labels.cuda(self.device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "stack_287": {
                "variable": {
                    "value": "losses",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "losses + [loss_cls]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_349": {
                "variable": {
                    "value": "embedding",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "num_channels",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "clamp_349": {
                "variable": {
                    "value": "embedding",
                    "type": "variable",
                    "possible_values": []
                },
                "min": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_355": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_387": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_392": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "min_412": {
                "variable": {
                    "value": "(min_dist, enc_indices)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "dist",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features.pow(2).sum(1, keepdim=True) + F.conv2d(features, weight=embeddings_w, bias=embeddings_b)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_434": {
                "variable": {
                    "value": "bow",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "bow",
                    "type": "variable",
                    "possible_values": [
                        [
                            "utils.global_pooling(codes, type=self._bow_pool).flatten(1)",
                            "Call"
                        ],
                        [
                            "F.normalize(bow, p=1, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_452": {
                "variable": {
                    "value": "self.bow_extractor",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[BoWExtractor(**opts) for opts in opts_list]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "no_grad_455": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_515": {
                "variable": {
                    "value": "self.layers_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "generators",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "Parameter_517": {
                "variable": {
                    "value": "self.scale",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(num_bow_levels).fill_(kappa)",
                    "type": "Call",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "learn_kappa",
                    "type": "variable",
                    "possible_values": [
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "split_560": {
                "variable": {
                    "value": "kappa",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "self.scale",
                    "type": "Attribute",
                    "possible_values": []
                },
                "split_size_or_sections": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "chunk_692": {
                "variable": {
                    "value": "scale",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "model.bow_predictor.scale",
                    "type": "Attribute",
                    "possible_values": []
                },
                "chunks": {
                    "value": "len(dictionary)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_199": {
                "tensors": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[F.kl_div(F.log_softmax(p, dim=1), expand_target(t, p), reduction='batchmean') for (p, t) in zip(bow_prediction, bow_target)]",
                            "ListComp"
                        ],
                        [
                            "F.cross_entropy(scores, labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_199": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "randint_364": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "num_locs",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "(batch_size,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "features.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "broadcast_398": {
                "tensor": {
                    "value": "embedding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.randn(num_words, num_channels).clamp(min=0)",
                            "Call"
                        ],
                        [
                            "self._embedding.data.clone()",
                            "Call"
                        ]
                    ]
                },
                "src": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_430": {
                "variable": {
                    "value": "codes",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-inv_delta_adaptive * dist",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "kl_div_197": {
                "input": {
                    "value": "F.log_softmax(p, dim=1)",
                    "type": "Call",
                    "possible_values": []
                },
                "target": {
                    "value": "expand_target(t, p)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "batchmean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "no_grad_213": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_226": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_273": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_351": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_352": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "avg_pool2d_361": {
                "variable": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features.detach()",
                            "Call"
                        ],
                        [
                            "self.feature_extractor_teacher(image, self._bow_levels)",
                            "Call"
                        ],
                        [
                            "[features]",
                            "List"
                        ],
                        [
                            "self.feature_extractor_teacher(img_orig, self._bow_levels)",
                            "Call"
                        ],
                        [
                            "features if isinstance(features, torch.Tensor) else features[-1]",
                            "IfExp"
                        ],
                        [
                            "features.detach()",
                            "Call"
                        ],
                        [
                            "[self.feature_extractor(x) for x in img_crops]",
                            "ListComp"
                        ],
                        [
                            "F.avg_pool2d(features, kernel_size=3, stride=1, padding=0)",
                            "Call"
                        ],
                        [
                            "features.flatten(2)",
                            "Call"
                        ],
                        [
                            "features[:, :, 1:-1, 1:-1].contiguous()",
                            "Call"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "conv2d_410": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features.detach()",
                            "Call"
                        ],
                        [
                            "self.feature_extractor_teacher(image, self._bow_levels)",
                            "Call"
                        ],
                        [
                            "[features]",
                            "List"
                        ],
                        [
                            "self.feature_extractor_teacher(img_orig, self._bow_levels)",
                            "Call"
                        ],
                        [
                            "features if isinstance(features, torch.Tensor) else features[-1]",
                            "IfExp"
                        ],
                        [
                            "features.detach()",
                            "Call"
                        ],
                        [
                            "[self.feature_extractor(x) for x in img_crops]",
                            "ListComp"
                        ],
                        [
                            "F.avg_pool2d(features, kernel_size=3, stride=1, padding=0)",
                            "Call"
                        ],
                        [
                            "features.flatten(2)",
                            "Call"
                        ],
                        [
                            "features[:, :, 1:-1, 1:-1].contiguous()",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "embeddings_w",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-2 * self._embedding.unsqueeze(2).unsqueeze(3)",
                            "BinOp"
                        ]
                    ]
                },
                "bias": {
                    "value": "embeddings_b",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._embedding.pow(2).sum(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_618": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_680": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'network': model.feature_extractor.state_dict(), 'meters': None}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "f'feature_extractor_net_checkpoint_{epoch}.pth.tar'",
                            "JoinedStr"
                        ],
                        [
                            "str(self.exp_dir / filename)",
                            "Call"
                        ],
                        [
                            "f'tochvision_{arch}_student_K{num_words}_epoch{epoch}.pth.tar'",
                            "JoinedStr"
                        ],
                        [
                            "str(self.exp_dir / filename)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_725": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_735": {
                "obj": {
                    "value": "{'network': torchvision_resnet.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "f'feature_extractor_net_checkpoint_{epoch}.pth.tar'",
                            "JoinedStr"
                        ],
                        [
                            "str(self.exp_dir / filename)",
                            "Call"
                        ],
                        [
                            "f'tochvision_{arch}_student_K{num_words}_epoch{epoch}.pth.tar'",
                            "JoinedStr"
                        ],
                        [
                            "str(self.exp_dir / filename)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_758": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sum_37": {
                "input": {
                    "value": "probs * torch.log(probs + 1e-05)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_128": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_197": {
                "input": {
                    "value": "p",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_353": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_365": {
                "start": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "target.size(0)",
                            "Call"
                        ],
                        [
                            "selected_features.shape[0]",
                            "Subscript"
                        ],
                        [
                            "img_orig.size(0)",
                            "Call"
                        ],
                        [
                            "img_orig.size(0)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "features.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Sequential_508": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_510": {
                "in_features": {
                    "value": "num_channels_in[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_channels_hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "4096",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm1d_511": {
                "num_features": {
                    "value": "num_channels_hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "4096",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ReLU_512": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_513": {
                "in_features": {
                    "value": "num_channels_hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "4096",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_channels_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "mm_562": {
                "input": {
                    "value": "f.flatten(1) * k",
                    "type": "BinOp",
                    "possible_values": []
                },
                "mat2": {
                    "value": "w",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sum_29": {
                "input": {
                    "value": "probs * torch.log(probs + 1e-05)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_37": {
                "input": {
                    "value": "probs + 1e-05",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "log_29": {
                "input": {
                    "value": "probs + 1e-05",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "obow/classification.py": {
        "torch": {
            "Sequential_32": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_70": {
                "variable": {
                    "value": "prediction_layer",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "total_num_channels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_channels",
                            "variable"
                        ],
                        [
                            "total_num_channels * (output_size * output_size)",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cross_entropy_93": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.linear_classifier(features)",
                            "Call"
                        ],
                        [
                            "self.linear_classifier(features)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels.cuda(self.device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "Sequential_121": {
                "variable": {
                    "value": "self.feature_extractor",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_116": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cross_entropy_139": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.linear_classifier(features)",
                            "Call"
                        ],
                        [
                            "self.linear_classifier(features)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels.cuda(self.device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "Flatten_68": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_94": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_134": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_140": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_197": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'network': model.feature_extractor.state_dict(), 'meters': None}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "f'feature_extractor_net_checkpoint_{epoch}.pth.tar'",
                            "JoinedStr"
                        ],
                        [
                            "str(self.exp_dir / filename)",
                            "Call"
                        ]
                    ]
                }
            },
            "set_grad_enabled_220": {
                "mode": {
                    "value": "training",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "BatchNorm2d_67": {
                "num_features": {
                    "value": "num_channels",
                    "type": "variable",
                    "possible_values": []
                },
                "affine": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "AvgPool2d_46": {
                "kernel_size": {
                    "value": "kernel_size",
                    "type": "variable",
                    "possible_values": []
                },
                "stride": {
                    "value": "stride",
                    "type": "variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "padding",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_52": {
                "output_size": {
                    "value": "output_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pool_params",
                            "variable"
                        ],
                        [
                            "pool_params",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "obow/dataset_cityscapes.py": {
        "torch": {
            "DataLoader_156": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Cityscapes(root='./CityScapes', transform=transforms.ToTensor())",
                            "Call"
                        ],
                        [
                            "json.load(file)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "obow/datasets.py": {
        "torch": {
            "DataLoader_374": {
                "variable": {
                    "value": "loader_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "sampler_train is None",
                    "type": "Compare",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_383": {
                "variable": {
                    "value": "loader_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_545": {
                "variable": {
                    "value": "loader_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "sampler_train is None",
                    "type": "Compare",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_554": {
                "variable": {
                    "value": "loader_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_604": {
                "variable": {
                    "value": "loader_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "sampler_train is None",
                    "type": "Compare",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_613": {
                "variable": {
                    "value": "loader_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "SubsetRandomSampler_1026": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "indices": {
                    "value": "list(range(epoch_size))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "DataLoader_1112": {
                "variable": {
                    "value": "loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)",
                            "Call"
                        ],
                        [
                            "ImageNetLowShot(dataset, phase=split)",
                            "Call"
                        ],
                        [
                            "get_ImageNet_fewshot_data(data_dir, split=split)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, split), transform=transform)",
                            "Call"
                        ],
                        [
                            "get_ImageNet_data_for_visualization(data_dir, split=split, subset=subset)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "torch.utils.data.SequentialSampler(dataset)",
                    "type": "Call",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_1245": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)",
                            "Call"
                        ],
                        [
                            "ImageNetLowShot(dataset, phase=split)",
                            "Call"
                        ],
                        [
                            "get_ImageNet_fewshot_data(data_dir, split=split)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, split), transform=transform)",
                            "Call"
                        ],
                        [
                            "get_ImageNet_data_for_visualization(data_dir, split=split, subset=subset)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "RandomSampler_1430": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_1431": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_1433": {
                "variable": {
                    "value": "loader_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "sampler_train is None",
                    "type": "Compare",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset_train)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_1442": {
                "variable": {
                    "value": "loader_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.SequentialSampler(dataset_test)",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Subset_364": {
                "variable": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "elem_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "list(range(dataset_size)) * num_times",
                            "BinOp"
                        ],
                        [
                            "elem_list + np.random.choice(dataset_size, residual, replace=False).tolist()",
                            "BinOp"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(data))",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_368": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_369": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "RandomSampler_371": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_372": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "Subset_533": {
                "variable": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "elem_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "list(range(dataset_size)) * num_times",
                            "BinOp"
                        ],
                        [
                            "elem_list + np.random.choice(dataset_size, residual, replace=False).tolist()",
                            "BinOp"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(data))",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_537": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_539": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "RandomSampler_542": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_543": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "Subset_592": {
                "variable": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "elem_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "list(range(dataset_size)) * num_times",
                            "BinOp"
                        ],
                        [
                            "elem_list + np.random.choice(dataset_size, residual, replace=False).tolist()",
                            "BinOp"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(data))",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_596": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_598": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "RandomSampler_601": {
                "variable": {
                    "value": "sampler_train",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='train_ssl', transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(train_data_path, transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform_train)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.Subset(dataset_train, elem_list)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=None)",
                            "Call"
                        ],
                        [
                            "subset_of_ImageNet_train_split(dataset_train, subset)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_train, labels=dataset_train.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / train_split_str, random_view=True, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size_train, epoch_size=epoch_size, five_crop=five_crop)",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_602": {
                "variable": {
                    "value": "sampler_test",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "Cityscapes(root=data_dir, split='test', transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform_test)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=None)",
                            "Call"
                        ],
                        [
                            "PrecacheFeaturesDataset(data=dataset_test, labels=dataset_test.targets, feature_extractor=feature_extractor, cache_dir=cache_dir / dataset_name / 'val', random_view=False, device=device, init_size=256, crop_size=224, mean=_MEAN_PIXEL_IMAGENET, std=_STD_PIXEL_IMAGENET, precache_num_workers=workers, precache_batch_size=precache_batch_size, epoch_size=None, five_crop=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_960": {
                "variable": {
                    "value": "images",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.dataset[img_idx][0] for (img_idx, _) in examples]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "DataLoader_1043": {
                "variable": {
                    "value": "loader_fewshot_this",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_fewshot_this",
                    "type": "variable",
                    "possible_values": [
                        [
                            "FewShotDataset(dataset=dataset, nKnovel=num_novel, nKbase=0, nExemplars=num_train_this, nTestNovel=num_test, nTestBase=0, epoch_size=epoch_size)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "workers",
                    "type": "variable",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.SubsetRandomSampler(list(range(epoch_size)))",
                            "Call"
                        ]
                    ]
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "from_numpy_1358": {
                "variable": {
                    "value": "feature",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "self.all_features[total_index]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "stack_140": {
                "tensors": {
                    "value": "patches",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[patches[i] for i in indices.tolist()]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_1215": {
                "variable": {
                    "value": "crops",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.normalize(x) for x in crops]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_1260": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_1265": {
                "variable": {
                    "value": "crops",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[crops, torch.flip(crops, dims=(4,))]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Subset_1322": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.Subset(data, elem_list)",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "elem_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "list(range(dataset_size)) * num_times",
                            "BinOp"
                        ],
                        [
                            "elem_list + np.random.choice(dataset_size, residual, replace=False).tolist()",
                            "BinOp"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(dataset_train))",
                            "Call"
                        ],
                        [
                            "generate_element_list(epoch_size, len(data))",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_81": {
                "tensors": {
                    "value": "x_views",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[self.transform(x) for _ in range(self.num_views)]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "SequentialSampler_1118": {
                "data_source": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)",
                            "Call"
                        ],
                        [
                            "ImageNetLowShot(dataset, phase=split)",
                            "Call"
                        ],
                        [
                            "get_ImageNet_fewshot_data(data_dir, split=split)",
                            "Call"
                        ],
                        [
                            "torchvision.datasets.ImageFolder(os.path.join(data_dir, split), transform=transform)",
                            "Call"
                        ],
                        [
                            "get_ImageNet_data_for_visualization(data_dir, split=split, subset=subset)",
                            "Call"
                        ]
                    ]
                }
            },
            "randperm_137": {
                "n": {
                    "value": "len(patches)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "flip_1265": {
                "input": {
                    "value": "crops",
                    "type": "variable",
                    "possible_values": [
                        [
                            "crops.cuda(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "torch.cat([crops, torch.flip(crops, dims=(4,))], dim=1)",
                            "Call"
                        ],
                        [
                            "crops.view([batch_size_x_num_views] + list(crops.size()[2:]))",
                            "Call"
                        ],
                        [
                            "self.crop(img)",
                            "Call"
                        ],
                        [
                            "torch.stack([self.normalize(x) for x in crops], dim=0)",
                            "Call"
                        ],
                        [
                            "self.normalize(crops).unsqueeze(0)",
                            "Call"
                        ]
                    ]
                },
                "dims": {
                    "value": "(4,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "obow/feature_extractor.py": {
        "torch": {
            "ModuleList_19": {
                "variable": {
                    "value": "self._feature_blocks",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "feature_blocks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "Sequential_50": {
                "variable": {
                    "value": "subnetwork",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_112": {
                "variable": {
                    "value": "self.convResidual",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_189": {
                "variable": {
                    "value": "conv1",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_199": {
                "variable": {
                    "value": "block1",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_211": {
                "variable": {
                    "value": "block2",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_223": {
                "variable": {
                    "value": "block3",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_258": {
                "variable": {
                    "value": "conv1",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_136": {
                "variable": {
                    "value": "self.convShortcut",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_138": {
                "variable": {
                    "value": "self.convShortcut",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "in_planes",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_planes",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "stride",
                    "type": "variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Sequential_164": {
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Conv2d_120": {
                "in_channels": {
                    "value": "in_planes",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_planes",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel_size1",
                    "type": "variable",
                    "possible_values": []
                },
                "stride": {
                    "value": "stride",
                    "type": "variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "padding1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1 if kernel_size1 == 3 else 0",
                            "IfExp"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm2d_124": {
                "num_features": {
                    "value": "out_planes",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ReLU_125": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Conv2d_128": {
                "in_channels": {
                    "value": "out_planes",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_planes",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel_size2",
                    "type": "variable",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "padding2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1 if kernel_size2 == 3 else 0",
                            "IfExp"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Conv2d_192": {
                "in_channels": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "num_channels[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm2d_193": {
                "num_features": {
                    "value": "num_channels[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "ReLU_194": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm2d_205": {
                "num_features": {
                    "value": "num_channels[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "ReLU_206": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm2d_217": {
                "num_features": {
                    "value": "num_channels[2]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "ReLU_218": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm2d_229": {
                "num_features": {
                    "value": "num_channels[3]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "ReLU_230": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm2d_115": {
                "num_features": {
                    "value": "in_planes",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ReLU_116": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_133": {
                "p": {
                    "value": "drop_rate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.0",
                            "Method Argument"
                        ],
                        [
                            "0.0",
                            "Method Argument"
                        ],
                        [
                            "0.0",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "obow/fewshot.py": {
        "torch": {
            "bmm_23": {
                "variable": {
                    "value": "weight_novel",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "labels_train_transposed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels_train.transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "features_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "preprocess_5D_features(features_train, global_pooling)",
                            "Call"
                        ],
                        [
                            "F.normalize(features_train, p=2, dim=2)",
                            "Call"
                        ],
                        [
                            "features_i[:batch_size_train]",
                            "Subscript"
                        ],
                        [
                            "utils.add_dimension(features_train, meta_batch_size)",
                            "Call"
                        ]
                    ]
                }
            },
            "normalize_45": {
                "variable": {
                    "value": "features_train",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features_train",
                    "type": "variable",
                    "possible_values": [
                        [
                            "preprocess_5D_features(features_train, global_pooling)",
                            "Call"
                        ],
                        [
                            "F.normalize(features_train, p=2, dim=2)",
                            "Call"
                        ],
                        [
                            "features_i[:batch_size_train]",
                            "Subscript"
                        ],
                        [
                            "utils.add_dimension(features_train, meta_batch_size)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_49": {
                "variable": {
                    "value": "features_test",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "preprocess_5D_features(features_test, global_pooling)",
                            "Call"
                        ],
                        [
                            "F.normalize(features_test, p=2, dim=2)",
                            "Call"
                        ],
                        [
                            "features_i[batch_size_train:]",
                            "Subscript"
                        ],
                        [
                            "utils.add_dimension(features_test, meta_batch_size)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_50": {
                "variable": {
                    "value": "prototypes",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "prototypes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "average_train_features(features_train, labels_train)",
                            "Call"
                        ],
                        [
                            "prototypes.view(meta_batch_size, num_novel, -1)",
                            "Call"
                        ],
                        [
                            "F.normalize(prototypes, p=2, dim=2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cross_entropy_70": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scale_cls * torch.bmm(features_test, prototypes.transpose(1, 2))",
                            "BinOp"
                        ],
                        [
                            "few_shot_classifier_with_prototypes(features_test=features_test, features_train=features_train, labels_train=labels_train_1hot)",
                            "Call"
                        ],
                        [
                            "scores.view(scores.size(0) * scores.size(1), -1)",
                            "Call"
                        ],
                        [
                            "few_shot_classifier_with_prototypes(features_test, features_train, labels_train_1hot, scale_cls=10.0, global_pooling=True)",
                            "Call"
                        ],
                        [
                            "scores.view(scores.size(0) * scores.size(1), -1)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "labels_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels_test.view(-1)",
                            "Call"
                        ],
                        [
                            "labels_test.view(-1)",
                            "Call"
                        ],
                        [
                            "labels_test.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_104": {
                "variable": {
                    "value": "images",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[images_train, images_test]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_130": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.cross_entropy(scores, labels_test)",
                            "Call"
                        ],
                        [
                            "torch.stack(loss, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_131": {
                "variable": {
                    "value": "accuracy",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "accuracy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "utils.accuracy(scores, labels_test, topk=(1,))",
                            "Call"
                        ],
                        [
                            "torch.stack(accuracy, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_78": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "bmm_51": {
                "input": {
                    "value": "features_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "preprocess_5D_features(features_test, global_pooling)",
                            "Call"
                        ],
                        [
                            "F.normalize(features_test, p=2, dim=2)",
                            "Call"
                        ],
                        [
                            "features_i[batch_size_train:]",
                            "Subscript"
                        ],
                        [
                            "utils.add_dimension(features_test, meta_batch_size)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "prototypes.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_72": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cross_entropy_126": {
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scale_cls * torch.bmm(features_test, prototypes.transpose(1, 2))",
                            "BinOp"
                        ],
                        [
                            "few_shot_classifier_with_prototypes(features_test=features_test, features_train=features_train, labels_train=labels_train_1hot)",
                            "Call"
                        ],
                        [
                            "scores.view(scores.size(0) * scores.size(1), -1)",
                            "Call"
                        ],
                        [
                            "few_shot_classifier_with_prototypes(features_test, features_train, labels_train_1hot, scale_cls=10.0, global_pooling=True)",
                            "Call"
                        ],
                        [
                            "scores.view(scores.size(0) * scores.size(1), -1)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "labels_test",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels_test.view(-1)",
                            "Call"
                        ],
                        [
                            "labels_test.view(-1)",
                            "Call"
                        ],
                        [
                            "labels_test.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_127": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "obow/solver.py": {
        "torch": {
            "Adam_28": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filter(lambda p: p.requires_grad, self.model.parameters())",
                            "Call"
                        ]
                    ]
                },
                "lr": {
                    "value": "learning_rate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "opts['lr']",
                            "Subscript"
                        ],
                        [
                            "compute_cosine_learning_rate(epoch, start_lr, end_lr, self.num_epochs, self.warmup_epochs)",
                            "Call"
                        ],
                        [
                            "param_group.get('start_lr', self.start_lr)",
                            "Call"
                        ],
                        [
                            "learning_rate * (self.lr_decay if epoch >= milestone else 1.0)",
                            "BinOp"
                        ],
                        [
                            "start_lr * (float(total_iter) / (self.warmup_epochs * num_batches))",
                            "BinOp"
                        ]
                    ]
                },
                "betas": {
                    "value": "opts['beta']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "opts['weight_decay']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "load_211": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "self.net_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "self.optim_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(last, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_220": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "self.net_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "self.optim_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(last, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_231": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "self.net_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "self.optim_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(last, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "SGD_34": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filter(lambda p: p.requires_grad, self.model.parameters())",
                            "Call"
                        ]
                    ]
                },
                "lr": {
                    "value": "learning_rate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "opts['lr']",
                            "Subscript"
                        ],
                        [
                            "compute_cosine_learning_rate(epoch, start_lr, end_lr, self.num_epochs, self.warmup_epochs)",
                            "Call"
                        ],
                        [
                            "param_group.get('start_lr', self.start_lr)",
                            "Call"
                        ],
                        [
                            "learning_rate * (self.lr_decay if epoch >= milestone else 1.0)",
                            "BinOp"
                        ],
                        [
                            "start_lr * (float(total_iter) / (self.warmup_epochs * num_batches))",
                            "BinOp"
                        ]
                    ]
                },
                "momentum": {
                    "value": "opts['momentum']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "opts['weight_decay']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "nesterov": {
                    "value": "opts['nesterov']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "save_186": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'network': self.model.state_dict(), 'meters': meters}",
                            "Dict"
                        ],
                        [
                            "{'epoch': epoch, 'optimizer': self.optimizer.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "self.net_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "self.optim_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(last, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_196": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'network': self.model.state_dict(), 'meters': meters}",
                            "Dict"
                        ],
                        [
                            "{'epoch': epoch, 'optimizer': self.optimizer.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "self.net_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "self.optim_checkpoint_filename(epoch, suffix)",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(last, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.net_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ],
                        [
                            "pathlib.Path(self.optim_checkpoint_filename(epoch, suffix))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "obow/utils.py": {
        "torch": {
            "no_grad_87": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_94": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_105": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_114": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_391": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(filename)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "tensor_219": {
                "variable": {
                    "value": "values",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.count, self.sum]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "is_available_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_initialized_34": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_100": {
                "tensors": {
                    "value": "tensors_gather",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "allclose_129": {
                "variable": {
                    "value": "is_close",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.data.detach()",
                            "Call"
                        ],
                        [
                            "state.data.detach().float()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "rtol": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                },
                "atol": {
                    "value": "1e-08",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_130": {
                "variable": {
                    "value": "is_close_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[is_close]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "allclose_153": {
                "variable": {
                    "value": "is_close",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.data.detach()",
                            "Call"
                        ],
                        [
                            "state.data.detach().float()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "rtol": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                },
                "atol": {
                    "value": "1e-08",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_154": {
                "variable": {
                    "value": "is_close_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[is_close]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "no_grad_177": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_283": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_pool2d_316": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(x.size(2), x.size(3))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "normalize_344": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "self.dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_like_97": {
                "input": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "broadcast_127": {
                "tensor": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "src": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "broadcast_151": {
                "tensor": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "src": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "avg_pool2d_318": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(x.size(2), x.size(3))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "is_available_299": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_memory_allocated_301": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "obow/visualization.py": {
        "torch": {
            "Tensor_91": {
                "variable": {
                    "value": "mean_pixel",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Tensor_92": {
                "variable": {
                    "value": "std_pixel",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "pad_133": {
                "variable": {
                    "value": "image_pad",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "image",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dataset_images[img][0]",
                            "Subscript"
                        ],
                        [
                            "torch.flip(image, dims=(2,))",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(halfp, halfp, halfp, halfp)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "stack_29": {
                "variable": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[img, torch.flip(img, dims=(3,))]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "flip_131": {
                "variable": {
                    "value": "image",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "image",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dataset_images[img][0]",
                            "Subscript"
                        ],
                        [
                            "torch.flip(image, dims=(2,))",
                            "Call"
                        ]
                    ]
                },
                "dims": {
                    "value": "(2,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_169": {
                "variable": {
                    "value": "patches_k",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_patches",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "patch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "layout": {
                    "value": "patch_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "flip_29": {
                "input": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "batch[0] if isinstance(batch, (list, tuple)) else batch",
                            "IfExp"
                        ],
                        [
                            "img[0] if isinstance(img, (list, tuple)) else img",
                            "IfExp"
                        ],
                        [
                            "img.cuda()",
                            "Call"
                        ],
                        [
                            "torch.stack([img, torch.flip(img, dims=(3,))], dim=1)",
                            "Call"
                        ],
                        [
                            "img.view(2 * img.size(0), 3, img.size(3), img.size(4))",
                            "Call"
                        ],
                        [
                            "index // num_locs_flip",
                            "BinOp"
                        ]
                    ]
                },
                "dims": {
                    "value": "(3,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "test.py": {
        "torch": {
            "no_grad_87": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_94": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_105": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_114": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_391": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pathlib.Path(filename)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "tensor_219": {
                "variable": {
                    "value": "values",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.count, self.sum]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "is_available_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_initialized_34": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_100": {
                "tensors": {
                    "value": "tensors_gather",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "allclose_129": {
                "variable": {
                    "value": "is_close",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.data.detach()",
                            "Call"
                        ],
                        [
                            "state.data.detach().float()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "rtol": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                },
                "atol": {
                    "value": "1e-08",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_130": {
                "variable": {
                    "value": "is_close_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[is_close]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "allclose_153": {
                "variable": {
                    "value": "is_close",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.data.detach()",
                            "Call"
                        ],
                        [
                            "state.data.detach().float()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "rtol": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                },
                "atol": {
                    "value": "1e-08",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_154": {
                "variable": {
                    "value": "is_close_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[is_close]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "no_grad_177": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_283": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_pool2d_316": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(x.size(2), x.size(3))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "normalize_344": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "self.dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_like_97": {
                "input": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "broadcast_127": {
                "tensor": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "src": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "broadcast_151": {
                "tensor": {
                    "value": "state_src",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state.clone()",
                            "Call"
                        ],
                        [
                            "state.clone()",
                            "Call"
                        ]
                    ]
                },
                "src": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "avg_pool2d_318": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(x.size(2), x.size(3))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randn_401": {
                "*size": {
                    "value": "(2, 3)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "is_available_299": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_memory_allocated_301": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "utils/convert_pytorch_to_caffe2.py": {
        "torch": {
            "load_78": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "file_path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "from_numpy_94": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "weight_np",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.detach().numpy()",
                            "Call"
                        ],
                        [
                            "weight_np[:, ::-1, :, :].copy()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    }
}