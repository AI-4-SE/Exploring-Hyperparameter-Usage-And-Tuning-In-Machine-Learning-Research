{
    "baselines/multimodal_transformer/build_vocab.py": {
        "torch": {
            "save_81": {
                "obj": {
                    "value": "glove_matrix",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.zeros([len(word2idx), glove_dim])",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "vocab_glove_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(opt.cache, '{}_vocab_glove.pt'.format(opt.dset_name))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "baselines/multimodal_transformer/train.py": {
        "torch": {
            "device_307": {
                "variable": {
                    "value": "opt.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if opt.device >= 0 else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "DataLoader_354": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TVCaptionDataset(ctx_mode=opt.ctx_mode, data_ratio=opt.data_ratio, data_path=opt.train_path, sub_meta_path=opt.sub_meta_path, vid_h5_path_or_handler=opt.vid_feat_path, word2idx_path=opt.word2idx_path, max_cap_len=opt.max_cap_len, max_sub_len=opt.max_sub_len, max_v_len=opt.max_v_len, h5driver=opt.h5driver, clip_length=1.5, normalize_vfeat=not opt.no_norm_vfeat, is_eval=False)",
                            "Call"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "caption_collate",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "opt.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "opt.pin_memory",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_360": {
                "variable": {
                    "value": "eval_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TVCaptionDataset(ctx_mode=opt.ctx_mode, data_ratio=1.0, data_path=opt.eval_path, sub_meta_path=opt.sub_meta_path, vid_h5_path_or_handler=train_dataset.vid_h5 if 'video' in opt.ctx_mode else None, word2idx_path=opt.word2idx_path, max_cap_len=opt.max_cap_len, max_sub_len=opt.max_sub_len, max_v_len=opt.max_v_len, h5driver=opt.h5driver, clip_length=1.5, normalize_vfeat=not opt.no_norm_vfeat, is_eval=True)",
                            "Call"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "caption_collate",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "opt.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "opt.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "opt.pin_memory",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_detect_anomaly_48": {
                "mode": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "set_detect_anomaly_82": {
                "mode": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "manual_seed_320": {
                "seed": {
                    "value": "opt.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__64": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "opt.grad_clip",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_176": {
                "obj": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'model': model.state_dict(), 'model_cfg': model.config, 'opt': opt, 'epoch': epoch_i}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "model_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "opt.save_model + '_acc_{c}.chkpt'.format(c=cider * 100)",
                            "BinOp"
                        ],
                        [
                            "opt.save_model + '.chkpt'",
                            "BinOp"
                        ]
                    ]
                }
            },
            "from_numpy_393": {
                "ndarray": {
                    "value": "torch.load(opt.glove_path)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "save_182": {
                "obj": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'model': model.state_dict(), 'model_cfg': model.config, 'opt': opt, 'epoch': epoch_i}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "model_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "opt.save_model + '_acc_{c}.chkpt'.format(c=cider * 100)",
                            "BinOp"
                        ],
                        [
                            "opt.save_model + '.chkpt'",
                            "BinOp"
                        ]
                    ]
                }
            },
            "load_393": {
                "f": {
                    "value": "opt.glove_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "baselines/multimodal_transformer/transformer/beam_search.py": {
        "torch": {
            "zeros_73": {
                "variable": {
                    "value": "self.top_beam_finished",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "[batch_size]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "full_74": {
                "variable": {
                    "value": "self.best_scores",
                    "type": "Attribute",
                    "possible_values": []
                },
                "size": {
                    "value": "[batch_size]",
                    "type": "List",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "-10000000000.0",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "mb_device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "arange_77": {
                "variable": {
                    "value": "self._batch_offset",
                    "type": "Attribute",
                    "possible_values": []
                },
                "start": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_78": {
                "variable": {
                    "value": "self._beam_offset",
                    "type": "Attribute",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "batch_size * beam_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "step": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "mb_device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_81": {
                "variable": {
                    "value": "self.topk_log_probs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[0.0] + [float('-inf')] * (beam_size - 1)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "device": {
                    "value": "mb_device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "empty_87": {
                "variable": {
                    "value": "self.topk_scores",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, beam_size)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "mb_device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "empty_89": {
                "variable": {
                    "value": "self.topk_ids",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, beam_size)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "mb_device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "empty_91": {
                "variable": {
                    "value": "self._batch_index",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "[batch_size, beam_size]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "mb_device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_158": {
                "variable": {
                    "value": "self.alive_seq",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.alive_seq.index_select(0, self.select_indices), self.topk_ids.view(_B * self.beam_size, 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_196": {
                "variable": {
                    "value": "non_finished",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "non_finished_batch",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "topk_142": {
                "input": {
                    "value": "curr_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "log_probs / length_penalty",
                            "BinOp"
                        ],
                        [
                            "curr_scores.reshape(_B, self.beam_size * vocab_size)",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "self.beam_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "out": {
                    "value": "(self.topk_scores, self.topk_ids)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "mul_148": {
                "input": {
                    "value": "self.topk_scores",
                    "type": "Attribute",
                    "possible_values": []
                },
                "other": {
                    "value": "length_penalty",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.length_penalty_func(step + 1, self.length_penalty_alpha)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "self.topk_log_probs",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "div_151": {
                "input": {
                    "value": "self.topk_ids",
                    "type": "Attribute",
                    "possible_values": []
                },
                "other": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "log_probs.size(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "self._batch_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "baselines/multimodal_transformer/transformer/decode_strategy.py": {
        "torch": {
            "full_69": {
                "variable": {
                    "value": "self.alive_seq",
                    "type": "Attribute",
                    "possible_values": []
                },
                "size": {
                    "value": "[batch_size * parallel_paths, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "self.bos",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_72": {
                "variable": {
                    "value": "self.is_finished",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "[batch_size, parallel_paths]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "baselines/multimodal_transformer/transformer/model.py": {
        "torch": {
            "LogSoftmax_21": {
                "variable": {
                    "value": "self.log_softmax",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "full_24": {
                "variable": {
                    "value": "one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "(tgt_vocab_size,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "smoothing_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "label_smoothing / (tgt_vocab_size - 1)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "zeros_73": {
                "variable": {
                    "value": "pe",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hidden_states.size(1)",
                            "Call"
                        ],
                        [
                            "dec_mask.size(1)",
                            "Call"
                        ],
                        [
                            "500",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "n_filters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "128",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_74": {
                "variable": {
                    "value": "position",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hidden_states.size(1)",
                            "Call"
                        ],
                        [
                            "dec_mask.size(1)",
                            "Call"
                        ],
                        [
                            "500",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "unsqueeze_74": {
                "variable": {
                    "value": "position",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_75": {
                "variable": {
                    "value": "div_term",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(0, n_filters, 2).float() * -(math.log(10000.0) / n_filters)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sin_76": {
                "variable": {
                    "value": "pe[:, 0::2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "position * div_term",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cos_77": {
                "variable": {
                    "value": "pe[:, 1::2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "position * div_term",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Parameter_98": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_99": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_120": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_121": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_122": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_124": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_154": {
                "variable": {
                    "value": "attention_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_166": {
                "variable": {
                    "value": "context_layer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_176": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_178": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_210": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_222": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_224": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_244": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.word_vec_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_245": {
                "variable": {
                    "value": "self.word_fc",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "BertLayerNorm(config.word_vec_size, eps=config.layer_norm_eps)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_252": {
                "variable": {
                    "value": "self.video_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "BertLayerNorm(config.video_feature_size, eps=config.layer_norm_eps)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_262": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_267": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_335": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[BertLayerNoMemoryUntied(config) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_407": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[BertDecoderLayerNoMemoryUntied(config) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_438": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_471": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(config.vocab_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "kl_div_41": {
                "input": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.log_softmax(output[valid_indices])",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "model_prob",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.one_hot.repeat(target.size(0), 1)",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Linear_464": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_469": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "erf_50": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_98": {
                "*size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_99": {
                "*size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sqrt_105": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Softmax_160": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Dropout_247": {
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_248": {
                "in_features": {
                    "value": "config.word_vec_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReLU_249": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_254": {
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_255": {
                "in_features": {
                    "value": "config.video_feature_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReLU_256": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_471": {
                "*size": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_491": {
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "arange_75": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "n_filters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "128",
                            "Method Argument"
                        ]
                    ]
                },
                "step": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tril_325": {
                "input": {
                    "value": "self_attention_mask.new_ones(max_len, max_len)",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tril_383": {
                "input": {
                    "value": "self_attention_mask.new_ones(max_len, max_len)",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "baselines/multimodal_transformer/transformer/optimization.py": {
        "torch": {
            "zeros_like_302": {
                "variable": {
                    "value": "state[next_m]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_304": {
                "variable": {
                    "value": "state[next_v]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__311": {
                "parameters": {
                    "value": "p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "baselines/multimodal_transformer/transformer/tvc_dataset.py": {
        "torch": {}
    },
    "baselines/multimodal_transformer/translate.py": {
        "torch": {
            "DataLoader_72": {
                "variable": {
                    "value": "eval_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TVCaptionDataset(ctx_mode=opt.ctx_mode, data_path=opt.eval_path, sub_meta_path=opt.sub_meta_path, vid_h5_path_or_handler=opt.vid_feat_path, word2idx_path=opt.word2idx_path, max_cap_len=opt.max_cap_len, max_sub_len=opt.max_sub_len, max_v_len=opt.max_v_len, h5driver=opt.h5driver, clip_length=1.5, normalize_vfeat=not opt.no_norm_vfeat, is_eval=True)",
                            "Call"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "caption_collate",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "opt.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "opt.pin_memory",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_114": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(opt.res_dir, 'model.chkpt')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "manual_seed_112": {
                "seed": {
                    "value": "opt.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "baselines/multimodal_transformer/translator.py": {
        "torch": {
            "log_112": {
                "variable": {
                    "value": "logprobs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.softmax(pred_scores[:, dec_idx], dim=1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_112": {
                "input": {
                    "value": "pred_scores[:, dec_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    }
}