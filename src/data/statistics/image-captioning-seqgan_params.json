{
    "datasets.py": {
        "torch": {
            "from_numpy_53": {
                "variable": {
                    "value": "img_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "img_feats",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.load(self.processed_data_path + '/' + self.dataset + '/' + self.split_type + '/image_features/' + self.cnn_architecture + '/' + img_name.split('/')[-1] + '.npy')",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(img_feats)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_68": {
                "variable": {
                    "value": "mismatched_img_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "mismatched_img_feats",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.load(self.processed_data_path + '/' + self.dataset + '/' + self.split_type + '/image_features/' + self.cnn_architecture + '/' + mismatched_img_name.split('/')[-1] + '.npy')",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(mismatched_img_feats)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models.py": {
        "torch": {
            "device_8": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Linear_43": {
                "variable": {
                    "value": "self.W1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "encoder_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "attention_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_44": {
                "variable": {
                    "value": "self.W2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "decoder_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "attention_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_45": {
                "variable": {
                    "value": "self.V",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "attention_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_46": {
                "variable": {
                    "value": "self.tanh",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Softmax_47": {
                "variable": {
                    "value": "self.softmax",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Embedding_79": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab_size",
                            "Attribute"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_80": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "GRUCell_81": {
                "variable": {
                    "value": "self.gru",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_size": {
                    "value": "embedding_dim + encoder_dim",
                    "type": "BinOp",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "gru_units",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_82": {
                "variable": {
                    "value": "self.init_h",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "encoder_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "gru_units",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_83": {
                "variable": {
                    "value": "self.f_beta",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "gru_units",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "encoder_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Sigmoid_84": {
                "variable": {
                    "value": "self.sigmoid",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_85": {
                "variable": {
                    "value": "self.fc",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "gru_units",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Softmax_86": {
                "variable": {
                    "value": "self.softmax",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_87": {
                "variable": {
                    "value": "self.relu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_113": {
                "variable": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "img_feats.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "caps.shape[1] - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_114": {
                "variable": {
                    "value": "alphas",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "img_feats.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "caps.shape[1] - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "num_pixels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "img_feats.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_141": {
                "variable": {
                    "value": "samples",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_word.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "col_shape",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Embedding_183": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab_size",
                            "Attribute"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "GRU_184": {
                "variable": {
                    "value": "self.gru",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_size": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "gru_units",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_186": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "encoder_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_187": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "gru_units",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sigmoid_188": {
                "variable": {
                    "value": "self.sigmoid",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "avg_pool1d_192": {
                "variable": {
                    "value": "img_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "img_feats",
                    "type": "variable",
                    "possible_values": [
                        [
                            "img_feats[indices]",
                            "Subscript"
                        ],
                        [
                            "img_feats.permute(0, 2, 1)",
                            "Call"
                        ],
                        [
                            "F.avg_pool1d(img_feats, img_feats.shape[-1]).squeeze(-1)",
                            "Call"
                        ],
                        [
                            "self.fc1(img_feats)",
                            "Call"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "img_feats.shape[-1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "squeeze_192": {
                "variable": {
                    "value": "img_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_195": {
                "variable": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(img_feats.unsqueeze(1), embeddings)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_196": {
                "variable": {
                    "value": "inputs_packed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat((img_feats.unsqueeze(1), embeddings), 1)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "cap_lens + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "enforce_sorted": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "arange_203": {
                "variable": {
                    "value": "row_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "caps.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_available_8": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_17": {
                "variable": {
                    "value": "self.net",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*list(self.net.children())[:-2]",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Sequential_21": {
                "variable": {
                    "value": "self.net",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*list(self.net.children())[:-2]",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "zeros_143": {
                "variable": {
                    "value": "hidden_states",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_word.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "col_shape",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.gru_units",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_134": {
                "tensors": {
                    "value": "[embeddings, context_vec]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_120": {
                "tensors": {
                    "value": "[embeddings[:, t], context_vec]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "multinomial_150": {
                "variable": {
                    "value": "input_word",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros(batch_size, caps.shape[1] - 1, vocab_size).to(device)",
                            "Call"
                        ],
                        [
                            "self.softmax(self.fc(hidden_state))",
                            "Call"
                        ]
                    ]
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_153": {
                "variable": {
                    "value": "input_word",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros(batch_size, caps.shape[1] - 1, vocab_size).to(device)",
                            "Call"
                        ],
                        [
                            "self.softmax(self.fc(hidden_state))",
                            "Call"
                        ]
                    ]
                }
            },
            "multinomial_163": {
                "variable": {
                    "value": "input_word",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros(batch_size, caps.shape[1] - 1, vocab_size).to(device)",
                            "Call"
                        ],
                        [
                            "self.softmax(self.fc(hidden_state))",
                            "Call"
                        ]
                    ]
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_166": {
                "variable": {
                    "value": "input_word",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros(batch_size, caps.shape[1] - 1, vocab_size).to(device)",
                            "Call"
                        ],
                        [
                            "self.softmax(self.fc(hidden_state))",
                            "Call"
                        ]
                    ]
                }
            },
            "pad_packed_sequence_199": {
                "sequence": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pad_packed_sequence(outputs, batch_first=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "preprocess.py": {
        "torch": {
            "device_21": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_21": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_138": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageDataset(split_type='train', dataset=args.dataset, transform=data_transforms, img_src_path=args.storage + '/' + args.image_path, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "DataLoader_158": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageDataset(split_type='val', dataset=args.dataset, transform=data_transforms, img_src_path=args.storage + '/images', processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "pretrain_discriminator.py": {
        "torch": {
            "device_18": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Adam_51": {
                "variable": {
                    "value": "dis_optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "discriminator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "args.lr",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "StepLR_52": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "dis_optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "optim.Adam(discriminator.parameters(), lr=args.lr)",
                            "Call"
                        ]
                    ]
                },
                "step_size": {
                    "value": "args.step_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.5",
                    "type": "float",
                    "possible_values": []
                }
            },
            "BCELoss_53": {
                "variable": {
                    "value": "dis_criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_59": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "gen_checkpoint_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.storage + '/ckpts/' + args.dataset + '/gen/' + args.gen_checkpoint_filename",
                            "BinOp"
                        ]
                    ]
                }
            },
            "load_65": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "dis_checkpoint_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.storage + '/ckpts/' + args.dataset + '/dis/' + args.dis_checkpoint_filename",
                            "BinOp"
                        ]
                    ]
                }
            },
            "DataLoader_72": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='discriminator', split_type='train', use_img_feats=True, transform=None, img_src_path=None, cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_82": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='discriminator', split_type='train', use_img_feats=False, transform=data_transforms, img_src_path=args.storage + '/images', cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_143": {
                "variable": {
                    "value": "ones",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "caps.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_144": {
                "variable": {
                    "value": "zeros",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "caps.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "is_available_18": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_109": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_97": {
                "obj": {
                    "value": "{'dis_state_dict': discriminator.state_dict(), 'optimizer_state_dict': dis_optimizer.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "args.storage + '/ckpts/' + args.dataset + '/dis/{}_{}_{}_{}.pth'.format('PRETRAIN_DIS', e, args.sampling_method, args.cnn_architecture)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "max_110": {
                "input": {
                    "value": "cap_lens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cap_lens.squeeze(-1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "rollout.py": {
        "torch": {
            "device_7": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_7": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_26": {
                "variable": {
                    "value": "cap_len",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "sample_cap_lens",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_25": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_28": {
                "variable": {
                    "value": "rewards",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "samples.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "col_shape",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_38": {
                "variable": {
                    "value": "fake_caps",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[samples[:, :j + 1], incomplete_fake_caps]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "from_numpy_40": {
                "variable": {
                    "value": "fake_caps",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "fake_caps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([samples[:, :j + 1], incomplete_fake_caps], dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(fake_caps)",
                            "Call"
                        ],
                        [
                            "fake_caps.to(device)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "train_mle.py": {
        "torch": {
            "device_30": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Adam_54": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "generator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "args.lr",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "StepLR_55": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "optim.Adam(generator.parameters(), lr=args.lr)",
                            "Call"
                        ]
                    ]
                },
                "step_size": {
                    "value": "args.step_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.5",
                    "type": "float",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_56": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "word_index['<pad>']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "is_available_31": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_59": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.storage + '/ckpts/' + args.dataset + '/gen/' + args.checkpoint_filename",
                            "BinOp"
                        ]
                    ]
                }
            },
            "DataLoader_68": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='train', use_img_feats=True, transform=None, img_src_path=None, cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_75": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='val', use_img_feats=True, transform=None, img_src_path=None, cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_85": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='train', use_img_feats=False, transform=data_transforms, img_src_path=args.storage + '/images', cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "DataLoader_93": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='val', use_img_feats=False, transform=data_transforms, img_src_path=args.storage + '/images', cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clip_grad_norm__150": {
                "parameters": {
                    "value": "generator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "args.clip",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_188": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_111": {
                "obj": {
                    "value": "{'gen_state_dict': generator.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "args.storage + '/ckpts/' + args.dataset + '/gen/{}_{}_{}.pth'.format('MLE_GEN', args.cnn_architecture, e)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_147": {
                "input": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pack_padded_sequence(preds, output_lens, batch_first=True)[0]",
                            "Subscript"
                        ],
                        [
                            "pack_padded_sequence(preds, output_lens, batch_first=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "lengths": {
                    "value": "output_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_148": {
                "input": {
                    "value": "caps[:, 1:]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "lengths": {
                    "value": "output_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_205": {
                "input": {
                    "value": "preds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pack_padded_sequence(preds, output_lens, batch_first=True)[0]",
                            "Subscript"
                        ],
                        [
                            "pack_padded_sequence(preds, output_lens, batch_first=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "lengths": {
                    "value": "output_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_206": {
                "input": {
                    "value": "caps[:, 1:]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "lengths": {
                    "value": "output_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "max_229": {
                "input": {
                    "value": "preds_clone",
                    "type": "variable",
                    "possible_values": [
                        [
                            "preds.clone()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "train_pg.py": {
        "torch": {
            "Adam_42": {
                "variable": {
                    "value": "gen_optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "generator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "args.gen_lr",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Adam_43": {
                "variable": {
                    "value": "dis_optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "discriminator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "args.dis_lr",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_51": {
                "variable": {
                    "value": "gen_train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='train', use_img_feats=True, transform=None, img_src_path=None, cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_57": {
                "variable": {
                    "value": "dis_train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='discriminator', split_type='train', use_img_feats=True, transform=None, img_src_path=None, cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_63": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='val', use_img_feats=True, transform=None, img_src_path=None, cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_73": {
                "variable": {
                    "value": "gen_train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='train', use_img_feats=False, transform=data_transforms, img_src_path=args.storage + '/images', cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_80": {
                "variable": {
                    "value": "dis_train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='discriminator', split_type='train', use_img_feats=False, transform=data_transforms, img_src_path=args.storage + '/images', cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_87": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ImageCaptionDataset(dataset=args.dataset, model='generator', split_type='val', use_img_feats=False, transform=data_transforms, img_src_path=args.storage + '/images', cnn_architecture=args.cnn_architecture, processed_data_path=args.storage + '/processed_data')",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "utils.py": {
        "torch": {
            "device_5": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_5": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}