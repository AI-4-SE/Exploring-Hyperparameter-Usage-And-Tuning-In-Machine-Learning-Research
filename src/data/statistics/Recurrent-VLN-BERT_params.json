{
    "r2r_src/agent.py": {
        "torch": {
            "CrossEntropyLoss_116": {
                "variable": {
                    "value": "self.criterion",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "args.ignoreid",
                    "type": "Attribute",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "from_numpy_128": {
                "variable": {
                    "value": "seq_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "seq_tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.array([ob['instr_encoding'] for ob in obs])",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(seq_tensor)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_129": {
                "variable": {
                    "value": "seq_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "seq_lengths",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.argmax(seq_tensor == padding_idx, axis=1)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(seq_lengths)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_136": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sorted_tensor != padding_idx",
                            "Compare"
                        ],
                        [
                            "np.ones(batch_size, np.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_164": {
                "variable": {
                    "value": "input_a_t",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "input_a_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.zeros((len(obs), args.angle_feat_size), np.float32)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(input_a_t).cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "load_568": {
                "variable": {
                    "value": "states",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "from_numpy_189": {
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.zeros(len(obs), dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_298": {
                "variable": {
                    "value": "visual_attention_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(language_attention_mask, visual_temp_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_405": {
                "variable": {
                    "value": "language_features",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(h_t.unsqueeze(1), language_features[:, 1:, :])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_408": {
                "variable": {
                    "value": "visual_attention_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(language_attention_mask, visual_temp_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "save_564": {
                "obj": {
                    "value": "states",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ],
                        [
                            "torch.load(path)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "from_numpy_158": {
                "ndarray": {
                    "value": "candidate_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.zeros((len(obs), max(candidate_leng), self.feature_size + args.angle_feat_size), dtype=np.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_295": {
                "variable": {
                    "value": "language_features",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(h_t.unsqueeze(1), language_features[:, 1:, :])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_329": {
                "variable": {
                    "value": "log_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "from_numpy_147": {
                "ndarray": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty((len(obs), args.views, self.feature_size + args.angle_feat_size), dtype=np.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_332": {
                "variable": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Categorical_333": {
                "variable": {
                    "value": "c",
                    "type": "variable",
                    "possible_values": []
                },
                "probs": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.softmax(logit, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_437": {
                "ndarray": {
                    "value": "masks[t]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "from_numpy_439": {
                "ndarray": {
                    "value": "clip_reward",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discount_reward.copy()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "r2r_src/model_OSCAR.py": {
        "torch": {
            "Sequential_20": {
                "variable": {
                    "value": "self.action_state_project",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(hidden_size + args.angle_feat_size, hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Dropout_24": {
                "variable": {
                    "value": "self.drop_env",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "args.featdropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_25": {
                "variable": {
                    "value": "self.img_projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "feature_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048 + 128",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Parameter_65": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_66": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_79": {
                "variable": {
                    "value": "self.state2value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(768, 512)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_21": {
                "in_features": {
                    "value": "hidden_size + args.angle_feat_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Tanh_21": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_40": {
                "variable": {
                    "value": "state_action_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(sentence[:, 0, :], action_feats)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_43": {
                "variable": {
                    "value": "state_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(state_with_action.unsqueeze(1), sentence[:, 1:, :])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_65": {
                "*size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_66": {
                "*size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "sqrt_72": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_80": {
                "in_features": {
                    "value": "768",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_81": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_82": {
                "p": {
                    "value": "args.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_83": {
                "in_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "r2r_src/model_PREVALENT.py": {
        "torch": {
            "Sequential_23": {
                "variable": {
                    "value": "self.action_state_project",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(hidden_size + args.angle_feat_size, hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Dropout_27": {
                "variable": {
                    "value": "self.drop_env",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "args.featdropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_28": {
                "variable": {
                    "value": "self.img_projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "feature_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2048 + 128",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_32": {
                "variable": {
                    "value": "self.state_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Parameter_74": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_75": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_88": {
                "variable": {
                    "value": "self.state2value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(768, 512)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_24": {
                "in_features": {
                    "value": "hidden_size + args.angle_feat_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Tanh_24": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_46": {
                "variable": {
                    "value": "state_action_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(sentence[:, 0, :], action_feats)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_49": {
                "variable": {
                    "value": "state_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(state_with_action.unsqueeze(1), sentence[:, 1:, :])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_59": {
                "variable": {
                    "value": "state_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(h_t, vis_lang_feat)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ones_74": {
                "*size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_75": {
                "*size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vln_bert.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                }
            },
            "sqrt_81": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_89": {
                "in_features": {
                    "value": "768",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_90": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_91": {
                "p": {
                    "value": "args.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_92": {
                "in_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "r2r_src/param.py": {
        "torch": {}
    },
    "r2r_src/train.py": {
        "torch": {
            "manual_seed_179": {
                "seed": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "manual_seed_180": {
                "seed": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "r2r_src/utils.py": {
        "torch": {
            "manual_seed_493": {
                "seed": {
                    "value": "local_seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hash(viewpoint) ^ seed",
                            "BinOp"
                        ]
                    ]
                }
            },
            "ones_494": {
                "*size": {
                    "value": "2048",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_474": {
                "start": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(max(length)) if size is None else size",
                            "IfExp"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_474": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "r2r_src/vlnbert/vlnbert_OSCAR.py": {
        "torch": {
            "matmul_48": {
                "variable": {
                    "value": "attention_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_64": {
                "variable": {
                    "value": "context_layer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "attention_probs * head_mask",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_135": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[CaptionBertLayer(config) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_236": {
                "variable": {
                    "value": "self.state_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_239": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_31": {
                "variable": {
                    "value": "x_states",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[history_state, hidden_states]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_207": {
                "variable": {
                    "value": "concat_embedding_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(language_features, img_feats)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Softmax_54": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_149": {
                "variable": {
                    "value": "concat_layer_outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(layer_outputs[0][:, 0:1, :], hidden_states[:, 1:-self.config.directions, :], layer_outputs[0][:, 1:self.config.directions + 1, :])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_265": {
                "variable": {
                    "value": "language_attention_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_266": {
                "variable": {
                    "value": "visual_attention_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_277": {
                "variable": {
                    "value": "state_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(pooled_output, vis_lang_feat)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_265": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_266": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "r2r_src/vlnbert/vlnbert_PREVALENT.py": {
        "torch": {
            "Embedding_49": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Embedding_50": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_51": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_56": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_89": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_90": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_91": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_93": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_110": {
                "variable": {
                    "value": "attention_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_126": {
                "variable": {
                    "value": "context_layer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "attention_probs * head_mask",
                            "BinOp"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_139": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_141": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_166": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_181": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_183": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_211": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tanh_212": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_249": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_250": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ctx_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "config.hidden_size",
                            "Attribute"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_251": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ctx_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "config.hidden_size",
                            "Attribute"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_253": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_270": {
                "variable": {
                    "value": "attention_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_284": {
                "variable": {
                    "value": "context_layer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "attention_probs * head_mask",
                            "BinOp"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_326": {
                "variable": {
                    "value": "visn_att_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(lang_feats[:, 0:1, :], visn_feats)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_327": {
                "variable": {
                    "value": "state_vis_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(lang_attention_mask[:, :, :, 0:1], visn_attention_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_338": {
                "variable": {
                    "value": "lang_att_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(state_visn_output[:, 0:1, :], lang_feats[:, 1:, :])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_351": {
                "variable": {
                    "value": "self.visn_fc",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "feat_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "vision_size",
                            "variable"
                        ]
                    ]
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_354": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_377": {
                "variable": {
                    "value": "self.lalayer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[BertLayer(config) for _ in range(self.la_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_379": {
                "variable": {
                    "value": "self.addlayer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LXRTXLayer(config) for _ in range(self.vl_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "sigmoid_32": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "self.visn_fc(feats)",
                            "Call"
                        ],
                        [
                            "self.visn_layer_norm(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "arange_61": {
                "variable": {
                    "value": "position_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_64": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_like_390": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "erf_28": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Softmax_116": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_278": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_443": {
                "variable": {
                    "value": "language_attention_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_444": {
                "variable": {
                    "value": "visual_attention_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_443": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_444": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    }
}