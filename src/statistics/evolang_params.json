{
    "bots.py": {
        "torch": {
            "Tensor_62": {
                "variable": {
                    "value": "self.h_state",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tensor_63": {
                "variable": {
                    "value": "self.c_state",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Embedding_71": {
                "variable": {
                    "value": "self.listen_net",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.opt['in_vocab_size']",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.opt['embed_size']",
                    "possible_values": []
                }
            },
            "Linear_72": {
                "variable": {
                    "value": "self.speak_net",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.opt['out_vocab_size']",
                    "possible_values": []
                }
            },
            "Softmax_80": {
                "variable": {
                    "value": "self.softmax",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Categorical_159": {
                "variable": {
                    "value": "out_distr",
                    "possible_values": []
                },
                "probs": {
                    "value": "self.softmax(self.speak_net(self.h_state))",
                    "possible_values": []
                }
            },
            "zeros_178": {
                "variable": {
                    "value": "self.h_state",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "self.opt['batch_size']",
                            "Subscript"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "zeros_179": {
                "variable": {
                    "value": "self.c_state",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "self.opt['batch_size']",
                            "Subscript"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "LSTMCell_225": {
                "variable": {
                    "value": "self.rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self.opt['embed_size']",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "LSTMCell_230": {
                "variable": {
                    "value": "self.predict_rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self.opt['embed_size']",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "Linear_231": {
                "variable": {
                    "value": "self.predict_net",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_preds",
                    "possible_values": [
                        [
                            "sum([len(ii) for ii in self.opt['props'].values()])",
                            "Call"
                        ],
                        [
                            "num_attrs",
                            "Name"
                        ]
                    ]
                }
            },
            "Embedding_311": {
                "variable": {
                    "value": "self.img_net",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_attrs",
                    "possible_values": [
                        [
                            "sum([len(ii) for ii in self.opt['props'].values()])",
                            "Call"
                        ],
                        [
                            "sum([len(ii) for ii in self.opt['props'].values()])",
                            "Call"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.opt['img_feat_size']",
                    "possible_values": []
                }
            },
            "LSTMCell_312": {
                "variable": {
                    "value": "self.rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "rnn_input_size",
                    "possible_values": [
                        [
                            "num_unique_attrs * self.opt['img_feat_size'] + self.opt['embed_size']",
                            "BinOp"
                        ],
                        [
                            "num_unique_attrs * self.opt['img_feat_size'] + self.opt['embed_size']",
                            "BinOp"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "cat_326": {
                "variable": {
                    "value": "features",
                    "possible_values": []
                },
                "tensors": {
                    "value": "list(embeds.transpose(0, 1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "LSTMCell_361": {
                "variable": {
                    "value": "self.rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "rnn_input_size",
                    "possible_values": [
                        [
                            "num_unique_attrs * self.opt['img_feat_size'] + self.opt['embed_size']",
                            "BinOp"
                        ],
                        [
                            "num_unique_attrs * self.opt['img_feat_size'] + self.opt['embed_size']",
                            "BinOp"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "Embedding_364": {
                "variable": {
                    "value": "self.img_net",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_attrs",
                    "possible_values": [
                        [
                            "sum([len(ii) for ii in self.opt['props'].values()])",
                            "Call"
                        ],
                        [
                            "sum([len(ii) for ii in self.opt['props'].values()])",
                            "Call"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.opt['img_feat_size']",
                    "possible_values": []
                }
            },
            "zeros_368": {
                "variable": {
                    "value": "dummy_image",
                    "possible_values": []
                },
                "*size": {
                    "value": "[num_unique_attrs * self.opt['img_feat_size']]",
                    "possible_values": []
                }
            },
            "LSTMCell_374": {
                "variable": {
                    "value": "self.predict_rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self.opt['embed_size']",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                }
            },
            "Linear_375": {
                "variable": {
                    "value": "self.predict_net",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_preds",
                    "possible_values": [
                        [
                            "sum([len(ii) for ii in self.opt['props'].values()])",
                            "Call"
                        ],
                        [
                            "num_attrs",
                            "Name"
                        ]
                    ]
                }
            },
            "Linear_78": {
                "variable": {
                    "value": "self.value_net",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_233": {
                "variable": {
                    "value": "self.predict_value_net",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.opt['hidden_size']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Categorical_255": {
                "variable": {
                    "value": "out_distr",
                    "possible_values": []
                },
                "probs": {
                    "value": "self.softmax(self.predict_net(self.h_state))",
                    "possible_values": []
                }
            },
            "cat_99": {
                "variable": {
                    "value": "token_embeds",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(token_embeds, observation['image'])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "no_grad_75": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_106": {
                "variable": {
                    "value": "token_embeds",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(token_embeds, dummy_image)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "arange_74": {
                "start": {
                    "value": "self.opt['out_vocab_size']",
                    "possible_values": []
                }
            },
            "log_139": {
                "input": {
                    "value": "act_dist.probs",
                    "possible_values": []
                }
            }
        }
    },
    "dataloader.py": {
        "torch": {
            "Tensor_92": {
                "variable": {
                    "value": "tasks",
                    "possible_values": []
                }
            },
            "arange_106": {
                "variable": {
                    "value": "tasks",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "len(self.task_defn)",
                    "possible_values": []
                }
            },
            "arange_81": {
                "variable": {
                    "value": "neg_indices",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "len(self.data[dtype])",
                    "possible_values": []
                }
            },
            "masked_select_81": {
                "variable": {
                    "value": "neg_indices",
                    "possible_values": []
                },
                "input": {
                    "value": "neg_indices",
                    "possible_values": [
                        [
                            "current_pred.view(-1, len(self.task_defn)).sum(1) < len(self.task_defn)",
                            "Compare"
                        ],
                        [
                            "torch.arange(0, len(self.data[dtype])).masked_select(neg_indices).long()",
                            "Call"
                        ],
                        [
                            "neg_indices[neg_samples]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_85": {
                "variable": {
                    "value": "neg_samples",
                    "possible_values": []
                },
                "*size": {
                    "value": "neg_batch_size",
                    "possible_values": [
                        [
                            "int(self.opt['batch_size'] * self.opt['neg_fraction'])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "evaluate.py": {
        "torch": {
            "load_36": {
                "variable": {
                    "value": "world_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "find_model(model_dir, None, map_location=map_location)",
                            "Call"
                        ],
                        [
                            "find_model(model_dir, None, map_location=map_location)",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'initial_world.pth')",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'world_epoch_{:0>5d}.pth'.format(epoch))",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'best_world.pth')",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'best_train_world.pth')",
                            "Call"
                        ],
                        [
                            "find_model(model_dir, epoch)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "map_location",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "load_41": {
                "variable": {
                    "value": "world_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "find_model(model_dir, None, map_location=map_location)",
                            "Call"
                        ],
                        [
                            "find_model(model_dir, None, map_location=map_location)",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'initial_world.pth')",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'world_epoch_{:0>5d}.pth'.format(epoch))",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'best_world.pth')",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'best_train_world.pth')",
                            "Call"
                        ],
                        [
                            "find_model(model_dir, epoch)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "map_location",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "load_67": {
                "variable": {
                    "value": "world_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "find_model(model_dir, None, map_location=map_location)",
                            "Call"
                        ],
                        [
                            "find_model(model_dir, None, map_location=map_location)",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'initial_world.pth')",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'world_epoch_{:0>5d}.pth'.format(epoch))",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'best_world.pth')",
                            "Call"
                        ],
                        [
                            "pth.join(model_dir, 'best_train_world.pth')",
                            "Call"
                        ],
                        [
                            "find_model(model_dir, epoch)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "map_location",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_213": {
                "variable": {
                    "value": "qbot_age",
                    "possible_values": []
                },
                "data": {
                    "value": "results['ages']['qbot']",
                    "possible_values": []
                }
            },
            "tensor_214": {
                "variable": {
                    "value": "abot_age",
                    "possible_values": []
                },
                "data": {
                    "value": "results['ages']['abot']",
                    "possible_values": []
                }
            },
            "manual_seed_all_313": {
                "seed": {
                    "value": "new_opt['seed']",
                    "possible_values": []
                }
            },
            "manual_seed_314": {
                "seed": {
                    "value": "new_opt['seed']",
                    "possible_values": []
                }
            },
            "zeros_133": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_134": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_135": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_136": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_137": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_138": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_139": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_140": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_141": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_142": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_143": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_144": {
                "*size": {
                    "value": "Nq",
                    "possible_values": [
                        [
                            "len(world.qbots)",
                            "Call"
                        ],
                        [
                            "len(world.qbots)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "Na",
                    "possible_values": [
                        [
                            "len(world.abots)",
                            "Call"
                        ],
                        [
                            "len(world.abots)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_172": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "mean_184": {
                "input": {
                    "value": "first_match.float()",
                    "possible_values": []
                }
            },
            "mean_185": {
                "input": {
                    "value": "second_match.float()",
                    "possible_values": []
                }
            },
            "mean_186": {
                "input": {
                    "value": "atleast_match.float()",
                    "possible_values": []
                }
            },
            "mean_187": {
                "input": {
                    "value": "both_matches.float()",
                    "possible_values": []
                }
            }
        }
    },
    "exp9.py": {
        "torch": {
            "device_11": {
                "variable": {
                    "value": "cpu",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            }
        }
    },
    "train.py": {
        "torch": {
            "tensor_22": {
                "variable": {
                    "value": "val_accs",
                    "possible_values": []
                },
                "data": {
                    "value": "results['val']['both']",
                    "possible_values": []
                }
            },
            "tensor_59": {
                "variable": {
                    "value": "val_accs",
                    "possible_values": []
                },
                "data": {
                    "value": "results['val']['both']",
                    "possible_values": []
                }
            },
            "Tensor_142": {
                "variable": {
                    "value": "reward",
                    "possible_values": []
                }
            },
            "softmax_29": {
                "variable": {
                    "value": "qbot_merit_dist",
                    "possible_values": []
                },
                "input": {
                    "value": "qbot_merit_score / temp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "softmax_68": {
                "variable": {
                    "value": "qbot_merit_dist",
                    "possible_values": []
                },
                "input": {
                    "value": "-qbot_merit_score / temp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "softmax_72": {
                "variable": {
                    "value": "abot_merit_dist",
                    "possible_values": []
                },
                "input": {
                    "value": "-abot_merit_score / temp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Adam_109": {
                "variable": {
                    "value": "a_optimizers[i]",
                    "possible_values": []
                },
                "params": {
                    "value": "abot.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "OPT['learning_rate']",
                    "possible_values": [
                        [
                            "options.read()",
                            "Call"
                        ],
                        [
                            "world.opt",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Adam_115": {
                "variable": {
                    "value": "q_optimizers[i]",
                    "possible_values": []
                },
                "params": {
                    "value": "qbot.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "OPT['learning_rate']",
                    "possible_values": [
                        [
                            "options.read()",
                            "Call"
                        ],
                        [
                            "world.opt",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Adam_123": {
                "variable": {
                    "value": "q_optimizers[i]",
                    "possible_values": []
                },
                "params": {
                    "value": "bot.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "OPT['learning_rate']",
                    "possible_values": [
                        [
                            "options.read()",
                            "Call"
                        ],
                        [
                            "world.opt",
                            "Attribute"
                        ]
                    ]
                }
            },
            "manual_seed_all_426": {
                "seed": {
                    "value": "OPT['seed']",
                    "possible_values": []
                }
            },
            "manual_seed_427": {
                "seed": {
                    "value": "OPT['seed']",
                    "possible_values": []
                }
            },
            "tensor_78": {
                "variable": {
                    "value": "kill_worstq",
                    "possible_values": []
                },
                "data": {
                    "value": "[eps, 1 - eps]",
                    "possible_values": []
                }
            },
            "multinomial_78": {
                "variable": {
                    "value": "kill_worstq",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "tensor_85": {
                "variable": {
                    "value": "kill_worsta",
                    "possible_values": []
                },
                "data": {
                    "value": "[eps, 1 - eps]",
                    "possible_values": []
                }
            },
            "multinomial_85": {
                "variable": {
                    "value": "kill_worsta",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Adam_97": {
                "params": {
                    "value": "qbot.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "OPT['learning_rate']",
                    "possible_values": [
                        [
                            "options.read()",
                            "Call"
                        ],
                        [
                            "world.opt",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Adam_102": {
                "params": {
                    "value": "abot.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "OPT['learning_rate']",
                    "possible_values": [
                        [
                            "options.read()",
                            "Call"
                        ],
                        [
                            "world.opt",
                            "Attribute"
                        ]
                    ]
                }
            },
            "ones_154": {
                "*size": {
                    "value": "OPT['q_out_vocab']",
                    "possible_values": []
                }
            },
            "ones_155": {
                "*size": {
                    "value": "OPT['a_out_vocab']",
                    "possible_values": []
                }
            },
            "log_238": {
                "variable": {
                    "value": "q_word_logprobs",
                    "possible_values": []
                },
                "input": {
                    "value": "word_prior['q'] / q_denom",
                    "possible_values": []
                }
            },
            "log_248": {
                "variable": {
                    "value": "a_word_logprobs",
                    "possible_values": []
                },
                "input": {
                    "value": "word_prior['a'] / a_denom",
                    "possible_values": []
                }
            },
            "mean_287": {
                "input": {
                    "value": "reward",
                    "possible_values": [
                        [
                            "torch.Tensor(OPT['batch_size']).fill_(-10 * OPT['rl_scale'])",
                            "Call"
                        ],
                        [
                            "reward.cuda()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "utils.py": {
        "torch": {
            "log_5": {
                "input": {
                    "value": "D",
                    "possible_values": []
                }
            }
        }
    },
    "world.py": {
        "torch": {
            "save_134": {
                "obj": {
                    "value": "d",
                    "possible_values": [
                        [
                            "{} if extra is None else dict(extra)",
                            "IfExp"
                        ]
                    ]
                },
                "f": {
                    "value": "save_path",
                    "possible_values": []
                }
            }
        }
    }
}