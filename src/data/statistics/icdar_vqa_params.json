{
    "data_loader.py": {
        "torch": {
            "SubsetRandomSampler_86": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "indices": {
                    "value": "train_indices",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "SubsetRandomSampler_87": {
                "variable": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "indices": {
                    "value": "val_indices",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_89": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_vqa",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VqaDataset(root=args.data_root)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SubsetRandomSampler(train_indices)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.n_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "args.pin_mem",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_96": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_vqa",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VqaDataset(root=args.data_root)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SubsetRandomSampler(val_indices)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.n_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "args.pin_mem",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "main.py": {
        "torch": {
            "CrossEntropyLoss_23": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_45": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_104": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Model(vocab_size, args.word_embed_dim, args.hidden_size, args.resnet_out, num_answers)",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(model).to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "Adam_108": {
                "variable": {
                    "value": "optim",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "0.0002",
                    "type": "float",
                    "possible_values": []
                }
            },
            "manual_seed_86": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_88": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_count_93": {
                "variable": {
                    "value": "args.devices",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_96": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_116": {
                "variable": {
                    "value": "ckpt",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.resume",
                    "type": "Attribute",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda')",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__63": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "0.25",
                    "type": "float",
                    "possible_values": []
                }
            },
            "manual_seed_97": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_90": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "model.py": {
        "torch": {
            "Linear_12": {
                "variable": {
                    "value": "self.i2t",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "inp_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_13": {
                "variable": {
                    "value": "self.i2g",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "inp_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tanh_17": {
                "variable": {
                    "value": "inp2transform",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.i2t(data)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "sigmoid_18": {
                "variable": {
                    "value": "inp2gate",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.i2g(data)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mul_19": {
                "variable": {
                    "value": "gated_transform",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "inp2transform",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tanh(self.i2t(data))",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "inp2gate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sigmoid(self.i2g(data))",
                            "Call"
                        ]
                    ]
                }
            },
            "Embedding_28": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "GRU_33": {
                "variable": {
                    "value": "self.encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_34": {
                "variable": {
                    "value": "self.enc_mlp",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "3 * gru_hidden_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "gru_hidden_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_35": {
                "variable": {
                    "value": "self.do",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                }
            },
            "adaptive_max_pool1d_41": {
                "variable": {
                    "value": "max_pool_out",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "outputs.permute(1, 2, 0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "squeeze_41": {
                "variable": {
                    "value": "max_pool_out",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "adaptive_avg_pool1d_42": {
                "variable": {
                    "value": "avg_pool_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs.permute(1, 2, 0)",
                    "type": "Call",
                    "possible_values": []
                },
                "output_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "squeeze_42": {
                "variable": {
                    "value": "avg_pool_out",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_43": {
                "variable": {
                    "value": "cat_out",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(outputs[-1], max_pool_out, avg_pool_out)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Embedding_54": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_59": {
                "variable": {
                    "value": "self.MLP1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2048",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_60": {
                "variable": {
                    "value": "self.MLP2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "2048",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_61": {
                "variable": {
                    "value": "self.do",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                }
            },
            "mean_65": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embeddings(data)",
                            "Call"
                        ],
                        [
                            "self.embeddings(data)",
                            "Call"
                        ],
                        [
                            "torch.mean(data, dim=2)",
                            "Call"
                        ],
                        [
                            "self.MLP1(data)",
                            "Call"
                        ],
                        [
                            "self.MLP2(data)",
                            "Call"
                        ],
                        [
                            "self.do(data)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_78": {
                "variable": {
                    "value": "self.attn_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_84": {
                "variable": {
                    "value": "attn_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.attn_layer(gated_transform)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_98": {
                "variable": {
                    "value": "concat_features",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(ques_features, img_features)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_100": {
                "variable": {
                    "value": "img_encode",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.mul(img_features, attn_probs)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Dropout_111": {
                "variable": {
                    "value": "self.do",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "0.3",
                    "type": "float",
                    "possible_values": []
                }
            },
            "mul_117": {
                "variable": {
                    "value": "joint_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "ques_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ques_features.unsqueeze(1).expand(-1, 36, -1)",
                            "Call"
                        ],
                        [
                            "self.ques_nonlinear(ques_features)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "img_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.img_nonlinear(img_features)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_129": {
                "variable": {
                    "value": "self.ques_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "text_embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_answers",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_130": {
                "variable": {
                    "value": "self.img_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "img_embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_answers",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sigmoid_138": {
                "variable": {
                    "value": "joint_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.add(ques_out, img_out)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_149": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "text_embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_answers",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sigmoid_153": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.classifier(self.nonlinear(joint_embed))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_167": {
                "variable": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "answer_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.answer_encoder(answers)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "joint_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.mul(ques_features, img_features)",
                            "Call"
                        ],
                        [
                            "self.do(joint_embed)",
                            "Call"
                        ],
                        [
                            "joint_embed.unsqueeze(2)",
                            "Call"
                        ],
                        [
                            "self.joint_embed(ques_enc, img_enc)",
                            "Call"
                        ]
                    ]
                }
            },
            "squeeze_167": {
                "variable": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "from_numpy_31": {
                "ndarray": {
                    "value": "pretrained_wemb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.zeros((vocab_size + 1, embed_dim), dtype=np.float32)",
                            "Call"
                        ],
                        [
                            "np.zeros((vocab_size + 1, embed_dim), dtype=np.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_57": {
                "ndarray": {
                    "value": "pretrained_wemb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.zeros((vocab_size + 1, embed_dim), dtype=np.float32)",
                            "Call"
                        ],
                        [
                            "np.zeros((vocab_size + 1, embed_dim), dtype=np.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "mul_100": {
                "input": {
                    "value": "img_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.img_nonlinear(img_features)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "attn_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.softmax(attn_scores, dim=1)",
                            "Call"
                        ],
                        [
                            "self.attention(concat_features)",
                            "Call"
                        ]
                    ]
                }
            },
            "add_138": {
                "input": {
                    "value": "ques_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.ques_linear(ques_embed)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "img_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.img_linear(img_embed)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "utils.py": {
        "torch": {
            "save_108": {
                "obj": {
                    "value": "{'epoch': epoch + 1, 'state_dict': model.state_dict(), 'optim_state_dict': optim.state_dict(), 'score': score}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(save, 'ckpts', 'model_{}.pth.tar'.format(epoch))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "max_100": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    }
}