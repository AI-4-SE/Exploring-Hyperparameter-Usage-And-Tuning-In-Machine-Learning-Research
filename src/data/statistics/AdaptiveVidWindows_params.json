{
    "pyzmq-vidwin/pub/microbatchresizing.py": {
        "tensorflow": {
            "img_to_array_22": {
                "variable": {
                    "value": "img_array",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "im_resized",
                    "type": "Name",
                    "possible_values": [
                        [
                            "im_pil.resize(resolution)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_model_179": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "filepath": {
                    "value": "mobilenet_model_voc_20class_ep_40_sgd_layer_83.h5",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "preprocess_input_24": {
                "x": {
                    "value": "image_array_expanded",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.expand_dims(img_array, axis=0)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pyzmq-vidwin/sub/dnnmodel.py": {
        "tensorflow": {
            "load_model_45": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "filepath": {
                    "value": "mobilenet_model.h5",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ResNet50_50": {
                "variable": {
                    "value": "model_resnet",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_model_54": {
                "variable": {
                    "value": "model_resnet",
                    "type": "Variable",
                    "possible_values": []
                },
                "filepath": {
                    "value": "resnet101_model_voc_20class_ep_50_sgd_layer_351.h5",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "VGG16_60": {
                "variable": {
                    "value": "model_VGG",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "InceptionResNetV2_65": {
                "variable": {
                    "value": "model_resnet",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "MobileNet_70": {
                "variable": {
                    "value": "model_mobilenet",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_model_80": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "filepath": {
                    "value": "densenet121_model_voc_20class_ep_100_sgd_layer_433.h5",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/sub/faster_rcnn.py": {
        "tensorflow": {
            "get_file_34": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_41": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "convert_to_tensor_120": {
                "value": {
                    "value": "frame",
                    "type": "Name",
                    "possible_values": [
                        [
                            "frame_list",
                            "Name"
                        ],
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_121": {
                "values": {
                    "value": "input_tensor",
                    "type": "ListComp",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ],
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch[:idx]]",
                            "ListComp"
                        ],
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch[idx:]]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "stack_101": {
                "values": {
                    "value": "input_tensor",
                    "type": "ListComp",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ],
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch[:idx]]",
                            "ListComp"
                        ],
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch[idx:]]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "convert_to_tensor_98": {
                "value": {
                    "value": "frame",
                    "type": "Name",
                    "possible_values": [
                        [
                            "frame_list",
                            "Name"
                        ],
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "convert_to_tensor_100": {
                "value": {
                    "value": "frame",
                    "type": "Name",
                    "possible_values": [
                        [
                            "frame_list",
                            "Name"
                        ],
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            }
        },
        "torch": {}
    },
    "pyzmq-vidwin/utils/FasterRCNN_BKP2.py": {
        "tensorflow": {
            "get_file_35": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_42": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "global_variables_initializer_48": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "convert_to_tensor_67": {
                "value": {
                    "value": "frame",
                    "type": "Call",
                    "possible_values": [
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_70": {
                "values": {
                    "value": "input_tensor",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ]
                    ]
                }
            }
        },
        "torch": {}
    },
    "pyzmq-vidwin/utils/FasterRCNN_PyTorch.py": {
        "tensorflow": {
            "get_file_17": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_24": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "convert_to_tensor_62": {
                "variable": {
                    "value": "input_tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "value": {
                    "value": "img_batch[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        },
        "torch": {}
    },
    "pyzmq-vidwin/utils/FasterRCNN_TF.py": {
        "tensorflow": {
            "get_file_36": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_43": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "convert_to_tensor_69": {
                "value": {
                    "value": "frame",
                    "type": "Call",
                    "possible_values": [
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_70": {
                "values": {
                    "value": "input_tensor",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ]
                    ]
                }
            }
        },
        "torch": {}
    },
    "pyzmq-vidwin/utils/FasterRCNN_TF_test.py": {
        "tensorflow": {
            "get_file_31": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_38": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "convert_to_tensor_64": {
                "value": {
                    "value": "frame",
                    "type": "Call",
                    "possible_values": [
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_65": {
                "values": {
                    "value": "input_tensor",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ]
                    ]
                }
            }
        }
    },
    "pyzmq-vidwin/utils/dnn_model_latency.py": {
        "tensorflow": {
            "MobileNet_216": {
                "variable": {
                    "value": "model_mobilenet",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/utils/dnn_model_throughput.py": {
        "tensorflow": {
            "ResNet50_197": {
                "variable": {
                    "value": "model_resnet",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "VGG16_200": {
                "variable": {
                    "value": "model_VGG",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "MobileNet_203": {
                "variable": {
                    "value": "model_mobilenet",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "MobileNetV2_206": {
                "variable": {
                    "value": "model_mobilenetv2",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "DenseNet121_209": {
                "variable": {
                    "value": "model_densenet121",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/utils/dnnnmodel_batch_accuracy.py": {
        "tensorflow": {
            "get_file_21": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_28": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "global_variables_initializer_34": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "convert_to_tensor_55": {
                "value": {
                    "value": "frame",
                    "type": "Call",
                    "possible_values": [
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_58": {
                "values": {
                    "value": "input_tensor",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ]
                    ]
                }
            }
        },
        "torch": {}
    },
    "pyzmq-vidwin/utils/faster_rcnn_resolution.py": {
        "tensorflow": {
            "get_file_13": {
                "variable": {
                    "value": "model_dir",
                    "type": "Variable",
                    "possible_values": []
                },
                "fname": {
                    "value": "model_name",
                    "type": "Variable",
                    "possible_values": []
                },
                "origin": {
                    "value": "base_url + model_file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "untar": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_20": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "export_dir": {
                    "value": "str(model_dir)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "convert_to_tensor_46": {
                "value": {
                    "value": "frame",
                    "type": "Call",
                    "possible_values": [
                        [
                            "cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "cv2.resize(frame, res)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_47": {
                "values": {
                    "value": "input_tensor",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[tf.convert_to_tensor(frame) for frame in img_batch]",
                            "ListComp"
                        ]
                    ]
                }
            }
        }
    },
    "pyzmq-vidwin/utils/frameresolution.py": {
        "tensorflow": {
            "load_model_343": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "filepath": {
                    "value": "mobilenet_model_voc_20class_ep_50_sgd.h5",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_img_49": {
                "variable": {
                    "value": "img",
                    "type": "Variable",
                    "possible_values": []
                },
                "path": {
                    "value": "img",
                    "type": "Call",
                    "possible_values": [
                        [
                            "image.load_img(img, target_size=resolution)",
                            "Call"
                        ],
                        [
                            "image_files",
                            "Name"
                        ],
                        [
                            "cv2.imread(image_directory + img)",
                            "Call"
                        ],
                        [
                            "prepare_cv_image_2_keras_image(img, resolution)",
                            "Call"
                        ],
                        [
                            "prepare_cv_image_2_keras_image(frame, resolution)",
                            "Call"
                        ]
                    ]
                },
                "target_size": {
                    "value": "resolution",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "resolution_list",
                            "Name"
                        ],
                        [
                            "resolution_list",
                            "Name"
                        ]
                    ]
                }
            },
            "img_to_array_50": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "img",
                    "type": "Call",
                    "possible_values": [
                        [
                            "image.load_img(img, target_size=resolution)",
                            "Call"
                        ],
                        [
                            "image_files",
                            "Name"
                        ],
                        [
                            "cv2.imread(image_directory + img)",
                            "Call"
                        ],
                        [
                            "prepare_cv_image_2_keras_image(img, resolution)",
                            "Call"
                        ],
                        [
                            "prepare_cv_image_2_keras_image(frame, resolution)",
                            "Call"
                        ]
                    ]
                }
            },
            "preprocess_input_52": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "x",
                    "type": "Call",
                    "possible_values": [
                        [
                            "image.img_to_array(img)",
                            "Call"
                        ],
                        [
                            "np.expand_dims(x, axis=0)",
                            "Call"
                        ],
                        [
                            "preprocess_input(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "img_to_array_63": {
                "variable": {
                    "value": "img_array",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "im_resized",
                    "type": "Name",
                    "possible_values": [
                        [
                            "im_pil.resize(resolution)",
                            "Call"
                        ]
                    ]
                }
            },
            "preprocess_input_65": {
                "x": {
                    "value": "image_array_expanded",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.expand_dims(img_array, axis=0)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pyzmq-vidwin/utils/lightweight_densenet.py": {
        "tensorflow": {
            "load_img_30": {
                "variable": {
                    "value": "img",
                    "type": "Variable",
                    "possible_values": []
                },
                "path": {
                    "value": "img_path + file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "target_size": {
                    "value": "(224, 224)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "img_to_array_31": {
                "variable": {
                    "value": "img_array",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "img",
                    "type": "Name",
                    "possible_values": [
                        [
                            "image.load_img(img_path + file, target_size=(224, 224))",
                            "Call"
                        ]
                    ]
                }
            },
            "DenseNet121_42": {
                "variable": {
                    "value": "base_model",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                },
                "include_top": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Model_64": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "inputs": {
                    "value": "base_model.input",
                    "type": "Attribute",
                    "possible_values": []
                },
                "outputs": {
                    "value": "preds",
                    "type": "Name",
                    "possible_values": [
                        [
                            "Dense(20, activation='softmax')(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "ImageDataGenerator_93": {
                "variable": {
                    "value": "train_datagen",
                    "type": "Variable",
                    "possible_values": []
                },
                "preprocessing_function": {
                    "value": "preprocess_input",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "TensorBoard_112": {
                "variable": {
                    "value": "tensorboard",
                    "type": "Variable",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "'logs/{}'.format(time())",
                    "type": "Call",
                    "possible_values": []
                },
                "update_freq": {
                    "value": "epoch",
                    "type": "Constant",
                    "possible_values": []
                },
                "profile_batch": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "preprocess_input_33": {
                "x": {
                    "value": "img_array_expanded_dims",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.expand_dims(img_array, axis=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "GlobalAveragePooling2D_55": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dense_57": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_58": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_59": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_60": {
                "units": {
                    "value": "512",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_62": {
                "units": {
                    "value": "20",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "softmax",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "SGD_86": {
                "learning_rate": {
                    "value": "0.01",
                    "type": "Constant",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.0",
                    "type": "Constant",
                    "possible_values": []
                },
                "nesterov": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "name": {
                    "value": "SGD",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/utils/lightweight_mobilenet.py": {
        "tensorflow": {
            "load_img_27": {
                "variable": {
                    "value": "img",
                    "type": "Variable",
                    "possible_values": []
                },
                "path": {
                    "value": "img_path + file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "target_size": {
                    "value": "(224, 224)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "img_to_array_28": {
                "variable": {
                    "value": "img_array",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "img",
                    "type": "Name",
                    "possible_values": [
                        [
                            "image.load_img(img_path + file, target_size=(224, 224))",
                            "Call"
                        ]
                    ]
                }
            },
            "MobileNet_39": {
                "variable": {
                    "value": "base_model",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                },
                "include_top": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Model_57": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "inputs": {
                    "value": "base_model.input",
                    "type": "Attribute",
                    "possible_values": []
                },
                "outputs": {
                    "value": "preds",
                    "type": "Name",
                    "possible_values": [
                        [
                            "Dense(20, activation='softmax')(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "ImageDataGenerator_87": {
                "variable": {
                    "value": "train_datagen",
                    "type": "Variable",
                    "possible_values": []
                },
                "preprocessing_function": {
                    "value": "preprocess_input",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "TensorBoard_106": {
                "variable": {
                    "value": "tensorboard",
                    "type": "Variable",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "'logs/{}'.format(time())",
                    "type": "Call",
                    "possible_values": []
                },
                "update_freq": {
                    "value": "epoch",
                    "type": "Constant",
                    "possible_values": []
                },
                "profile_batch": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "preprocess_input_30": {
                "x": {
                    "value": "img_array_expanded_dims",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.expand_dims(img_array, axis=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "GlobalAveragePooling2D_48": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dense_50": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_51": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_52": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_53": {
                "units": {
                    "value": "512",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_55": {
                "units": {
                    "value": "20",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "softmax",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "SGD_80": {
                "learning_rate": {
                    "value": "0.01",
                    "type": "Constant",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.0",
                    "type": "Constant",
                    "possible_values": []
                },
                "nesterov": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "name": {
                    "value": "SGD",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/utils/mobilenet_retraining.py": {
        "tensorflow": {
            "MobileNet_38": {
                "variable": {
                    "value": "base_model",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                },
                "include_top": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Model_50": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "inputs": {
                    "value": "base_model.input",
                    "type": "Attribute",
                    "possible_values": []
                },
                "outputs": {
                    "value": "preds",
                    "type": "Name",
                    "possible_values": [
                        [
                            "Dense(20, activation='softmax')(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "ImageDataGenerator_73": {
                "variable": {
                    "value": "train_datagen",
                    "type": "Variable",
                    "possible_values": []
                },
                "preprocessing_function": {
                    "value": "preprocess_input",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "TensorBoard_92": {
                "variable": {
                    "value": "tensorboard",
                    "type": "Variable",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "'logs/{}'.format(time())",
                    "type": "Call",
                    "possible_values": []
                },
                "update_freq": {
                    "value": "epoch",
                    "type": "Constant",
                    "possible_values": []
                },
                "profile_batch": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_img_27": {
                "variable": {
                    "value": "img",
                    "type": "Variable",
                    "possible_values": []
                },
                "path": {
                    "value": "img_path + file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "target_size": {
                    "value": "(224, 224)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "img_to_array_28": {
                "variable": {
                    "value": "img_array",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "img",
                    "type": "Name",
                    "possible_values": [
                        [
                            "image.load_img(img_path + file, target_size=(224, 224))",
                            "Call"
                        ]
                    ]
                }
            },
            "preprocess_input_30": {
                "x": {
                    "value": "img_array_expanded_dims",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.expand_dims(img_array, axis=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "GlobalAveragePooling2D_42": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dense_44": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_45": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_46": {
                "units": {
                    "value": "512",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_48": {
                "units": {
                    "value": "20",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "softmax",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "SGD_65": {
                "learning_rate": {
                    "value": "0.01",
                    "type": "Constant",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.0",
                    "type": "Constant",
                    "possible_values": []
                },
                "nesterov": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "name": {
                    "value": "SGD",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/utils/resnet101voc.py": {
        "tensorflow": {
            "load_img_30": {
                "variable": {
                    "value": "img",
                    "type": "Variable",
                    "possible_values": []
                },
                "path": {
                    "value": "img_path + file",
                    "type": "BinOp",
                    "possible_values": []
                },
                "target_size": {
                    "value": "(224, 224)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "img_to_array_31": {
                "variable": {
                    "value": "img_array",
                    "type": "Variable",
                    "possible_values": []
                },
                "img": {
                    "value": "img",
                    "type": "Name",
                    "possible_values": [
                        [
                            "image.load_img(img_path + file, target_size=(224, 224))",
                            "Call"
                        ]
                    ]
                }
            },
            "ResNet101_42": {
                "variable": {
                    "value": "base_model",
                    "type": "Variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "Constant",
                    "possible_values": []
                },
                "include_top": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Model_64": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "inputs": {
                    "value": "base_model.input",
                    "type": "Attribute",
                    "possible_values": []
                },
                "outputs": {
                    "value": "preds",
                    "type": "Name",
                    "possible_values": [
                        [
                            "Dense(20, activation='softmax')(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "ImageDataGenerator_93": {
                "variable": {
                    "value": "train_datagen",
                    "type": "Variable",
                    "possible_values": []
                },
                "preprocessing_function": {
                    "value": "preprocess_input",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "TensorBoard_112": {
                "variable": {
                    "value": "tensorboard",
                    "type": "Variable",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "'logs/{}'.format(time())",
                    "type": "Call",
                    "possible_values": []
                },
                "update_freq": {
                    "value": "epoch",
                    "type": "Constant",
                    "possible_values": []
                },
                "profile_batch": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "preprocess_input_33": {
                "x": {
                    "value": "img_array_expanded_dims",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.expand_dims(img_array, axis=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "GlobalAveragePooling2D_55": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dense_57": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_58": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_59": {
                "units": {
                    "value": "1024",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_60": {
                "units": {
                    "value": "512",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dense_62": {
                "units": {
                    "value": "20",
                    "type": "Constant",
                    "possible_values": []
                },
                "activation": {
                    "value": "softmax",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "SGD_86": {
                "learning_rate": {
                    "value": "0.01",
                    "type": "Constant",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.0",
                    "type": "Constant",
                    "possible_values": []
                },
                "nesterov": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "name": {
                    "value": "SGD",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/sub/cloudseg/dataset.py": {
        "torch": {}
    },
    "pyzmq-vidwin/sub/cloudseg/model/carn.py": {
        "torch": {
            "cat_21": {
                "variable": {
                    "value": "c1",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c0, b1]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_25": {
                "variable": {
                    "value": "c2",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c1, b2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_29": {
                "variable": {
                    "value": "c3",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c2, b3]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_46": {
                "variable": {
                    "value": "self.entry",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "64",
                    "type": "Constant",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_58": {
                "variable": {
                    "value": "self.exit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "64",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_66": {
                "variable": {
                    "value": "c1",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c0, b1]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_70": {
                "variable": {
                    "value": "c2",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c1, b2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_74": {
                "variable": {
                    "value": "c3",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c2, b3]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/sub/cloudseg/model/carn_m.py": {
        "torch": {
            "cat_21": {
                "variable": {
                    "value": "c1",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c0, b1]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_25": {
                "variable": {
                    "value": "c2",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c1, b2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_29": {
                "variable": {
                    "value": "c3",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c2, b3]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_46": {
                "variable": {
                    "value": "self.entry",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "64",
                    "type": "Constant",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_58": {
                "variable": {
                    "value": "self.exit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "64",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_66": {
                "variable": {
                    "value": "c1",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c0, b1]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_70": {
                "variable": {
                    "value": "c2",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c1, b2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_74": {
                "variable": {
                    "value": "c3",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c2, b3]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/sub/cloudseg/model/ops.py": {
        "torch": {
            "Conv2d_21": {
                "variable": {
                    "value": "self.shifter",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "eye_22": {
                "variable": {
                    "value": "self.shifter.weight.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "n": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Tensor_23": {
                "variable": {
                    "value": "self.shifter.bias.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Sequential_40": {
                "variable": {
                    "value": "self.body",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(in_channels, out_channels, ksize, stride, pad)",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_57": {
                "variable": {
                    "value": "self.body",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(in_channels, out_channels, 3, 1, 1)",
                    "type": null,
                    "possible_values": []
                }
            },
            "relu_67": {
                "variable": {
                    "value": "out",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "out + x",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Sequential_77": {
                "variable": {
                    "value": "self.body",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(in_channels, out_channels, 3, 1, 1, groups=group)",
                    "type": null,
                    "possible_values": []
                }
            },
            "relu_89": {
                "variable": {
                    "value": "out",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "out + x",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Sequential_135": {
                "variable": {
                    "value": "self.body",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*modules",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_41": {
                "in_channels": {
                    "value": "in_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "ksize",
                    "type": "Name",
                    "possible_values": [
                        [
                            "3",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "type": "Name",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_42": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_58": {
                "in_channels": {
                    "value": "in_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ReLU_59": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_60": {
                "in_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_78": {
                "in_channels": {
                    "value": "in_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "groups": {
                    "value": "group",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_79": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_80": {
                "in_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "groups": {
                    "value": "group",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_81": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_82": {
                "in_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_129": {
                "in_channels": {
                    "value": "n_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "4 * n_channels",
                    "type": "BinOp",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "groups": {
                    "value": "group",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_129": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "PixelShuffle_130": {
                "upscale_factor": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_132": {
                "in_channels": {
                    "value": "n_channels",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "9 * n_channels",
                    "type": "BinOp",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "groups": {
                    "value": "group",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_132": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "PixelShuffle_133": {
                "upscale_factor": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/sub/cloudseg/sample.py": {
        "torch": {
            "load_103": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "ckpt_path",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "device_111": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "cat_70": {
                "variable": {
                    "value": "lrs",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[get_tensor(frame_batch).unsqueeze(0)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "set_grad_enabled_109": {
                "mode": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "is_available_111": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/sub/cloudseg/solver.py": {
        "torch": {
            "Adam_29": {
                "variable": {
                    "value": "self.optim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "filter(lambda p: p.requires_grad, self.refiner.parameters())",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "cfg.lr",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_36": {
                "variable": {
                    "value": "self.train_loader",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dataset": {
                    "value": "self.train_data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "cfg.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "device_41": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "DataParallel_59": {
                "variable": {
                    "value": "refiner",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "self.refiner",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device_ids": {
                    "value": "range(cfg.num_gpu)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "DataLoader_110": {
                "variable": {
                    "value": "test_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TestDataset(test_data_dir, scale=scale)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "MSELoss_23": {
                "variable": {
                    "value": "self.loss_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_171": {
                "obj": {
                    "value": "self.refiner.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "save_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(ckpt_dir, '{}_{}.pth'.format(ckpt_name, self.step))",
                            "Call"
                        ]
                    ]
                }
            },
            "L1Loss_25": {
                "variable": {
                    "value": "self.loss_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_160": {
                "f": {
                    "value": "path",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "SmoothL1Loss_27": {
                "variable": {
                    "value": "self.loss_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_41": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pyzmq-vidwin/utils/FasterRCNN_Test.py": {
        "torch": {}
    }
}