{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_category(type_name: str) -> str:\n",
    "\n",
    "    if type_name.lower() in (\"str\", \"joinedstr\"):\n",
    "        return \"String\"\n",
    "\n",
    "    if type_name.lower() in (\"int\", \"float\", \"complex\"):\n",
    "        return \"Numeric\"\n",
    "\n",
    "    if type_name.lower() in (\"list\", \"tuple\", \"listcomp\", \"generatorexp\"):\n",
    "        return \"Sequence\"\n",
    "\n",
    "    if type_name.lower() in (\"dict\", \"dictcomp\", \"kwargs\"):\n",
    "        return \"Mapping\"\n",
    "    \n",
    "    if type_name.lower() in (\"set\", \"setcomp\"):\n",
    "        return \"Set\"\n",
    "\n",
    "    if type_name.lower() in (\"lambda\", \"subscript\"):\n",
    "        return \"Call\"\n",
    "\n",
    "    if type_name.lower() in (\"binop\", \"boolop\", \"unaryop\", \"compare\", \"ifexp\"):\n",
    "        return \"Operation\"\n",
    "\n",
    "    if type_name.lower() == \"none\":\n",
    "        return \"None Type\"\n",
    "\n",
    "    if type_name.lower() in (\"method argument\", \"starred\", \"variable\", \"attribute\", \"yield\"):\n",
    "        return \"Variable\"\n",
    "    \n",
    "    if type_name.lower() in (\"bool\"):\n",
    "        return \"Bool\"\n",
    "\n",
    "    return type_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &   1518 &   33.6\\% \\\\\n",
      "1 &    Numeric &   1417 &   31.3\\% \\\\\n",
      "2 &       Text &    574 &   12.7\\% \\\\\n",
      "5 &       Bool &    399 &    8.8\\% \\\\\n",
      "3 &       Call &    237 &    5.2\\% \\\\\n",
      "4 &  Operation &    134 &    3.0\\% \\\\\n",
      "6 &   Sequence &    121 &    2.7\\% \\\\\n",
      "7 &   NoneType &     68 &    1.5\\% \\\\\n",
      "8 &    Mapping &     53 &    1.2\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &  13271 &   34.9\\% \\\\\n",
      "2 &       Text &   9304 &   24.5\\% \\\\\n",
      "1 &    Numeric &   4598 &   12.1\\% \\\\\n",
      "4 &       Call &   4010 &   10.5\\% \\\\\n",
      "5 &   Sequence &   3133 &    8.2\\% \\\\\n",
      "3 &       Bool &   2216 &    5.8\\% \\\\\n",
      "7 &  Operation &    778 &    2.0\\% \\\\\n",
      "8 &   NoneType &    539 &    1.4\\% \\\\\n",
      "6 &    Mapping &    190 &    0.5\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "1 &   Variable &  82644 &   38.6\\% \\\\\n",
      "2 &    Numeric &  70712 &   33.0\\% \\\\\n",
      "3 &       Bool &  24344 &   11.4\\% \\\\\n",
      "5 &       Call &  17920 &    8.4\\% \\\\\n",
      "4 &  Operation &  10470 &    4.9\\% \\\\\n",
      "0 &   Sequence &   6855 &    3.2\\% \\\\\n",
      "6 &       Text &   1020 &    0.5\\% \\\\\n",
      "8 &   NoneType &    125 &    0.1\\% \\\\\n",
      "7 &    Mapping &     68 &    0.0\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_value_types_all_methods(library_name: str, project_dir: str) -> pd.DataFrame:\n",
    "    value_types = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                for param, param_data in data.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        #if str(param_data[\"type\"]) == \"Subscript\":\n",
    "                                        #    for item in param_data[\"possible_values\"]:\n",
    "                                        #        if \"parse_args\" in item[0] or \"sys.argv\" in item[0]:\n",
    "                                        #            print(project, file)\n",
    "                                        #           print(param_data[\"value\"], param_data[\"possible_values\"])\n",
    "\n",
    "                                        value_type = assign_category(str(param_data[\"type\"]))\n",
    "                                        value_types.append(value_type)\n",
    "\n",
    "\n",
    "    type_data = Counter(value_types)\n",
    "    type_data_portion = OrderedDict([(i, str(round(count / sum(type_data.values()) * 100.0, 1)) + '%') for i, count in type_data.most_common()])\n",
    "    portion = [y for _, y in type_data_portion.items()]\n",
    "    df = pd.DataFrame.from_dict(type_data, orient=\"index\").reset_index()\n",
    "    df = df.rename(columns={'index':'Type', 0:'Count'})\n",
    "    df = df.sort_values(by=['Count'], ascending=False)\n",
    "    df[\"portion\"] = portion\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sklearn = get_value_types_all_methods(\"sklearn\", \"../data/statistics/*\")\n",
    "df_tf = get_value_types_all_methods(\"tensorflow\", \"../data/statistics/*\")\n",
    "df_torch = get_value_types_all_methods(\"torch\", \"../data/statistics/*\")\n",
    "        \n",
    "print(df_sklearn.to_latex())\n",
    "print(df_tf.to_latex())\n",
    "print(df_torch.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "2 &    Numeric &    681 &  33.97\\% \\\\\n",
      "0 &   Variable &    609 &  30.37\\% \\\\\n",
      "1 &       Text &    335 &  16.71\\% \\\\\n",
      "4 &       Bool &    136 &   6.78\\% \\\\\n",
      "3 &       Call &     79 &   3.94\\% \\\\\n",
      "5 &  Operation &     64 &   3.19\\% \\\\\n",
      "6 &   NoneType &     52 &   2.59\\% \\\\\n",
      "8 &    Mapping &     34 &    1.7\\% \\\\\n",
      "7 &   Sequence &     15 &   0.75\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &   1466 &  63.08\\% \\\\\n",
      "1 &    Numeric &    680 &  29.26\\% \\\\\n",
      "3 &       Call &     96 &   4.13\\% \\\\\n",
      "5 &       Bool &     40 &   1.72\\% \\\\\n",
      "4 &  Operation &     23 &   0.99\\% \\\\\n",
      "2 &       Text &     17 &   0.73\\% \\\\\n",
      "6 &   NoneType &      2 &   0.09\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &   3896 &  57.46\\% \\\\\n",
      "2 &    Numeric &   1476 &  21.77\\% \\\\\n",
      "5 &   Sequence &    641 &   9.45\\% \\\\\n",
      "4 &       Call &    470 &   6.93\\% \\\\\n",
      "1 &       Bool &    221 &   3.26\\% \\\\\n",
      "3 &  Operation &     67 &   0.99\\% \\\\\n",
      "6 &   NoneType &      7 &    0.1\\% \\\\\n",
      "7 &       Text &      1 &   0.01\\% \\\\\n",
      "8 &    Mapping &      1 &   0.01\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_value_types_ml_methods(library_name: str, library_dir: str ,project_dir: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [x[\"name\"] for x in library_data]\n",
    "    \n",
    "    value_types = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "\n",
    "                                if class_name not in class_names:\n",
    "                                    continue    \n",
    "\n",
    "                                for param, param_data in data.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        #if str(param_data[\"type\"]) == \"Subscript\":\n",
    "                                        #    for item in param_data[\"possible_values\"]:\n",
    "                                        #        if \"parse_args\" in item[0] or \"sys.argv\" in item[0]:\n",
    "                                        #            print(project, file)\n",
    "                                        #           print(param_data[\"value\"], param_data[\"possible_values\"])\n",
    "\n",
    "                                        value_type = assign_category(str(param_data[\"type\"]))\n",
    "                                        value_types.append(value_type)\n",
    "\n",
    "\n",
    "    type_data = Counter(value_types)\n",
    "    type_data_portion = OrderedDict([(i, str(round(count / sum(type_data.values()) * 100.0, 2)) + '%') for i, count in type_data.most_common()])\n",
    "    portion = [y for _, y in type_data_portion.items()]\n",
    "    df = pd.DataFrame.from_dict(type_data, orient=\"index\").reset_index()\n",
    "    df = df.rename(columns={'index':'Type', 0:'Count'})\n",
    "    df = df.sort_values(by=['Count'], ascending=False)\n",
    "    df[\"portion\"] = portion\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sklearn = get_value_types_ml_methods(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", \"../data/statistics/*\")\n",
    "df_tf = get_value_types_ml_methods(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", \"../data/statistics/*\")\n",
    "df_torch = get_value_types_ml_methods(\"torch\", \"../data/library_data/torch_optimizer.json\", \"../data/statistics/*\")\n",
    "        \n",
    "print(df_sklearn.to_latex())\n",
    "print(df_tf.to_latex())\n",
    "print(df_torch.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_type(values: List) -> str:\n",
    "    value_types = []\n",
    "\n",
    "    for item in values:\n",
    "        value_types.append(item[-1])\n",
    "\n",
    "    count_data = Counter(value_types)\n",
    "    most_common = count_data.most_common(1)\n",
    "    counter = 0\n",
    "    for value in count_data:\n",
    "        if count_data[value] == most_common[0][1]:\n",
    "            counter +=1\n",
    "\n",
    "    if counter > 1:\n",
    "        return \"Multiple Types\"\n",
    "    else:\n",
    "        return count_data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &            Type &  Count &  portion \\\\\n",
      "\\midrule\n",
      "0 &        Variable &    165 &  38.551\\% \\\\\n",
      "4 &            Call &     86 &  20.093\\% \\\\\n",
      "1 &         Numeric &     62 &  14.486\\% \\\\\n",
      "3 &  Multiple Types &     39 &   9.112\\% \\\\\n",
      "2 &       Operation &     35 &   8.178\\% \\\\\n",
      "5 &         Unknown &     29 &   6.776\\% \\\\\n",
      "6 &        Sequence &     10 &   2.336\\% \\\\\n",
      "7 &            Text &      2 &   0.467\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &            Type &  Count &  portion \\\\\n",
      "\\midrule\n",
      "2 &        Variable &    241 &  30.353\\% \\\\\n",
      "0 &  Multiple Types &    239 &  30.101\\% \\\\\n",
      "1 &            Call &    183 &  23.048\\% \\\\\n",
      "3 &         Numeric &     92 &  11.587\\% \\\\\n",
      "4 &         Unknown &     27 &   3.401\\% \\\\\n",
      "5 &       Operation &     11 &   1.385\\% \\\\\n",
      "6 &        Sequence &      1 &   0.126\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &            Type &  Count &  portion \\\\\n",
      "\\midrule\n",
      "2 &        Variable &    546 &  42.857\\% \\\\\n",
      "3 &         Numeric &    246 &  19.309\\% \\\\\n",
      "4 &            Call &    158 &  12.402\\% \\\\\n",
      "5 &       Operation &    132 &  10.361\\% \\\\\n",
      "0 &  Multiple Types &    127 &   9.969\\% \\\\\n",
      "1 &         Unknown &     52 &   4.082\\% \\\\\n",
      "6 &        Sequence &     13 &    1.02\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict \n",
    "\n",
    "def get_types_of_variables_ml_methods(library_name: str, library_dir: str ,project_dir: str):\n",
    "    variable_types = []\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [x[\"name\"] for x in library_data]\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "\n",
    "                                if class_name not in class_names:\n",
    "                                    continue    \n",
    "                                \n",
    "                                for param, param_data in data.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    \n",
    "                                    value_type = param_data[\"type\"]\n",
    "                                    if value_type == \"variable\":\n",
    "                                        if param_data[\"possible_values\"]:\n",
    "                                            most_common_type = get_most_common_type(param_data[\"possible_values\"])\n",
    "                                            variable_types.append(assign_category(most_common_type))\n",
    "                                        else:\n",
    "                                            variable_types.append(\"Unknown\")\n",
    "\n",
    "\n",
    "    type_data = Counter(variable_types)\n",
    "    type_data_portion = OrderedDict([(i, str(round(count / sum(type_data.values()) * 100.0, 3)) + '%') for i, count in type_data.most_common()])\n",
    "    portion = [y for _, y in type_data_portion.items()]\n",
    "    df = pd.DataFrame.from_dict(type_data, orient=\"index\").reset_index()\n",
    "    df = df.rename(columns={'index':'Type', 0:'Count'})\n",
    "    df = df.sort_values(by=['Count'], ascending=False)\n",
    "    df[\"portion\"] = portion\n",
    "\n",
    "    return df\n",
    "\n",
    "df_sklearn_variables = get_types_of_variables_ml_methods(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", \"../data/statistics/*\")\n",
    "df_tf_variables = get_types_of_variables_ml_methods(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", \"../data/statistics/*\")\n",
    "df_torch_variables = get_types_of_variables_ml_methods(\"torch\", \"../data/library_data/torch_optimizer.json\", \"../data/statistics/*\")\n",
    "\n",
    "print(df_sklearn_variables.to_latex())\n",
    "print(df_tf_variables.to_latex())\n",
    "print(df_torch_variables.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
