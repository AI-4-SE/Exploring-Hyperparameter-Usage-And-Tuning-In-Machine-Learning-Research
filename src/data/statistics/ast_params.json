{
    "src/utilities/stats.py": {
        "sklearn": {
            "accuracy_score_26": {
                "variable": {
                    "value": "acc",
                    "type": "variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "np.argmax(target, 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "np.argmax(output, 1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "average_precision_score_32": {
                "variable": {
                    "value": "avg_precision",
                    "type": "variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "target[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y_score": {
                    "value": "output[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "average": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                }
            },
            "roc_auc_score_36": {
                "variable": {
                    "value": "auc",
                    "type": "variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "target[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y_score": {
                    "value": "output[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "average": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                }
            },
            "precision_recall_curve_39": {
                "variable": {
                    "value": "(precisions, recalls, thresholds)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "y_true": {
                    "value": "target[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "probas_pred": {
                    "value": "output[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "roc_curve_43": {
                "variable": {
                    "value": "(fpr, tpr, thresholds)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "y_true": {
                    "value": "target[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y_score": {
                    "value": "output[:, k]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        },
        "torch": {}
    },
    "egs/audioset/ensemble.py": {
        "torch": {
            "BCEWithLogitsLoss_86": {
                "variable": {
                    "value": "args.loss_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_93": {
                "variable": {
                    "value": "eval_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataloader.AudiosetDataset(args.data_eval, label_csv=args.label_csv, audio_conf=val_audio_conf)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "100",
                    "type": "int",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "device_29": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "load_36": {
                "variable": {
                    "value": "sd",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "mdl",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_40": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models.ASTModel(fstride=fstride, tstride=tstride)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(audio_model)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_29": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "egs/audioset/inference.py": {
        "torch": {
            "load_85": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.model_path",
                            "Attribute"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "DataParallel_86": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "ast_mdl",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ASTModel(label_dim=527, input_tdim=input_tdim, imagenet_pretrain=False, audioset_pretrain=False)",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "ZeroPad2d_35": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "(0, 0, 0, p)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "sigmoid_97": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "audio_model.forward(feats_data)",
                            "Call"
                        ],
                        [
                            "torch.sigmoid(output)",
                            "Call"
                        ]
                    ]
                }
            },
            "device_89": {
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "no_grad_95": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pretrained_models/load_pretrained_model.py": {
        "torch": {
            "device_25": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "load_26": {
                "variable": {
                    "value": "sd",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "pretrained_mdl_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../../pretrained_models/audioset_10_10_0.4593.pth'",
                            "Constant"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_28": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models.ASTModel(input_tdim=input_tdim, fstride=fstride, tstride=tstride)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(audio_model)",
                            "Call"
                        ]
                    ]
                }
            },
            "rand_33": {
                "variable": {
                    "value": "test_input",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "[10, input_tdim, 128]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "is_available_25": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/dataloader.py": {
        "torch": {
            "transpose_189": {
                "variable": {
                    "value": "fbank",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "fbank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchaudio.compliance.kaldi.fbank(waveform, htk_compat=True, sample_frequency=sr, use_energy=False, window_type='hanning', num_mel_bins=self.melbins, dither=0.0, frame_shift=10)",
                            "Call"
                        ],
                        [
                            "m(fbank)",
                            "Call"
                        ],
                        [
                            "fbank[0:target_length, :]",
                            "Subscript"
                        ],
                        [
                            "torch.transpose(fbank, 0, 1)",
                            "Call"
                        ],
                        [
                            "fbank.unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "freqm(fbank)",
                            "Call"
                        ],
                        [
                            "timem(fbank)",
                            "Call"
                        ],
                        [
                            "fbank.squeeze(0)",
                            "Call"
                        ],
                        [
                            "torch.transpose(fbank, 0, 1)",
                            "Call"
                        ],
                        [
                            "(fbank - self.norm_mean) / (self.norm_std * 2)",
                            "BinOp"
                        ],
                        [
                            "fbank + torch.rand(fbank.shape[0], fbank.shape[1]) * np.random.rand() / 10",
                            "BinOp"
                        ],
                        [
                            "torch.roll(fbank, np.random.randint(-10, 10), 0)",
                            "Call"
                        ]
                    ]
                },
                "dim0": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim1": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "transpose_198": {
                "variable": {
                    "value": "fbank",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "fbank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchaudio.compliance.kaldi.fbank(waveform, htk_compat=True, sample_frequency=sr, use_energy=False, window_type='hanning', num_mel_bins=self.melbins, dither=0.0, frame_shift=10)",
                            "Call"
                        ],
                        [
                            "m(fbank)",
                            "Call"
                        ],
                        [
                            "fbank[0:target_length, :]",
                            "Subscript"
                        ],
                        [
                            "torch.transpose(fbank, 0, 1)",
                            "Call"
                        ],
                        [
                            "fbank.unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "freqm(fbank)",
                            "Call"
                        ],
                        [
                            "timem(fbank)",
                            "Call"
                        ],
                        [
                            "fbank.squeeze(0)",
                            "Call"
                        ],
                        [
                            "torch.transpose(fbank, 0, 1)",
                            "Call"
                        ],
                        [
                            "(fbank - self.norm_mean) / (self.norm_std * 2)",
                            "BinOp"
                        ],
                        [
                            "fbank + torch.rand(fbank.shape[0], fbank.shape[1]) * np.random.rand() / 10",
                            "BinOp"
                        ],
                        [
                            "torch.roll(fbank, np.random.randint(-10, 10), 0)",
                            "Call"
                        ]
                    ]
                },
                "dim0": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim1": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ZeroPad2d_139": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "(0, 0, 0, p)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "roll_209": {
                "variable": {
                    "value": "fbank",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "fbank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torchaudio.compliance.kaldi.fbank(waveform, htk_compat=True, sample_frequency=sr, use_energy=False, window_type='hanning', num_mel_bins=self.melbins, dither=0.0, frame_shift=10)",
                            "Call"
                        ],
                        [
                            "m(fbank)",
                            "Call"
                        ],
                        [
                            "fbank[0:target_length, :]",
                            "Subscript"
                        ],
                        [
                            "torch.transpose(fbank, 0, 1)",
                            "Call"
                        ],
                        [
                            "fbank.unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "freqm(fbank)",
                            "Call"
                        ],
                        [
                            "timem(fbank)",
                            "Call"
                        ],
                        [
                            "fbank.squeeze(0)",
                            "Call"
                        ],
                        [
                            "torch.transpose(fbank, 0, 1)",
                            "Call"
                        ],
                        [
                            "(fbank - self.norm_mean) / (self.norm_std * 2)",
                            "BinOp"
                        ],
                        [
                            "fbank + torch.rand(fbank.shape[0], fbank.shape[1]) * np.random.rand() / 10",
                            "BinOp"
                        ],
                        [
                            "torch.roll(fbank, np.random.randint(-10, 10), 0)",
                            "Call"
                        ]
                    ]
                },
                "shifts": {
                    "value": "np.random.randint(-10, 10)",
                    "type": "Call",
                    "possible_values": []
                },
                "dims": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_114": {
                "variable": {
                    "value": "temp_wav",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "waveform1.shape[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "rand_208": {
                "*size": {
                    "value": "fbank.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "fbank.shape[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "src/demo.py": {
        "torch": {
            "rand_18": {
                "variable": {
                    "value": "test_input",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "[10, input_tdim, 128]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "src/get_norm_stats.py": {
        "torch": {
            "DataLoader_18": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataloader.AudiosetDataset('/data/sls/scratch/yuangong/audioset/datafiles/balanced_train_data.json', label_csv='/data/sls/scratch/yuangong/audioset/utilities/class_labels_indices.csv', audio_conf=audio_conf)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1000",
                    "type": "int",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "8",
                    "type": "int",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "mean_24": {
                "variable": {
                    "value": "cur_mean",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "audio_input",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "std_25": {
                "variable": {
                    "value": "cur_std",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "audio_input",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "src/models/ast_models.py": {
        "torch": {
            "rand_193": {
                "variable": {
                    "value": "test_input",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "[10, input_tdim, 128]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "rand_201": {
                "variable": {
                    "value": "test_input",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "[10, input_tdim, 128]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "Conv2d_29": {
                "variable": {
                    "value": "self.proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "in_chans",
                    "type": "variable",
                    "possible_values": [
                        [
                            "3",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "patch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "to_2tuple(patch_size)",
                            "Call"
                        ],
                        [
                            "16",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "patch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "to_2tuple(patch_size)",
                            "Call"
                        ],
                        [
                            "16",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "randn_157": {
                "variable": {
                    "value": "test_input",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "input_fdim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ],
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "layout": {
                    "value": "input_tdim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "Constant"
                        ],
                        [
                            "256",
                            "Constant"
                        ],
                        [
                            "1024",
                            "MethodArgument"
                        ],
                        [
                            "1024",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Conv2d_158": {
                "variable": {
                    "value": "test_proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(16, 16)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "stride": {
                    "value": "(fstride, tstride)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_178": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(cls_tokens, dist_token, x)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "autocast_164": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_73": {
                "variable": {
                    "value": "self.mlp_head",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.LayerNorm(self.original_embedding_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Conv2d_84": {
                "variable": {
                    "value": "new_proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(16, 16)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "stride": {
                    "value": "(fstride, tstride)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Parameter_86": {
                "variable": {
                    "value": "new_proj.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_107": {
                "variable": {
                    "value": "self.v.pos_embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_111": {
                "variable": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "device_121": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "load_126": {
                "variable": {
                    "value": "sd",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "../../pretrained_models/audioset_10_10_0.4593.pth",
                    "type": "str",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_128": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ASTModel(label_dim=527, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(audio_model)",
                            "Call"
                        ]
                    ]
                }
            },
            "Sequential_132": {
                "variable": {
                    "value": "self.mlp_head",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.LayerNorm(self.original_embedding_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_154": {
                "variable": {
                    "value": "self.v.pos_embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "LayerNorm_73": {
                "normalized_shape": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_73": {
                "in_features": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "label_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "527",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "interpolate_98": {
                "variable": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)",
                            "Call"
                        ],
                        [
                            "nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))",
                            "Call"
                        ],
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2):int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, 50 - int(t_dim / 2):50 - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2):int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, 6 - int(f_dim / 2):6 - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(self.oringal_hw, t_dim)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "type": "str",
                    "possible_values": []
                }
            },
            "interpolate_103": {
                "variable": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)",
                            "Call"
                        ],
                        [
                            "nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))",
                            "Call"
                        ],
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2):int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, 50 - int(t_dim / 2):50 - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2):int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, 6 - int(f_dim / 2):6 - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(f_dim, t_dim)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "type": "str",
                    "possible_values": []
                }
            },
            "interpolate_147": {
                "variable": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)",
                            "Call"
                        ],
                        [
                            "nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))",
                            "Call"
                        ],
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2):int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, 50 - int(t_dim / 2):50 - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2):int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, 6 - int(f_dim / 2):6 - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(12, t_dim)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "type": "str",
                    "possible_values": []
                }
            },
            "sum_86": {
                "input": {
                    "value": "self.v.patch_embed.proj.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_86": {
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_107": {
                "tensors": {
                    "value": "[self.v.pos_embed[:, :2, :].detach(), new_pos_embed]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_111": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.v.patch_embed.num_patches + 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LayerNorm_132": {
                "normalized_shape": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_132": {
                "in_features": {
                    "value": "self.original_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "label_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "527",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "interpolate_152": {
                "variable": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "new_pos_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)",
                            "Call"
                        ],
                        [
                            "nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))",
                            "Call"
                        ],
                        [
                            "self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2):int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, :, 50 - int(t_dim / 2):50 - int(t_dim / 2) + t_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2):int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ],
                        [
                            "new_pos_embed[:, :, 6 - int(f_dim / 2):6 - int(f_dim / 2) + f_dim, :]",
                            "Subscript"
                        ],
                        [
                            "new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(f_dim, t_dim)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "type": "str",
                    "possible_values": []
                }
            },
            "cat_154": {
                "tensors": {
                    "value": "[self.v.pos_embed[:, :2, :].detach(), new_pos_embed]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_121": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/run.py": {
        "torch": {
            "DataLoader_85": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataloader.AudiosetDataset(args.data_val, label_csv=args.label_csv, audio_conf=val_audio_conf)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "device_103": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "load_104": {
                "variable": {
                    "value": "sd",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.exp_dir + '/models/best_audio_model.pth'",
                    "type": "BinOp",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_105": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models.ASTModel(label_dim=args.n_class, fstride=args.fstride, tstride=args.tstride, input_fdim=128, input_tdim=target_length[args.dataset], imagenet_pretrain=args.imagenet_pretrain, audioset_pretrain=args.audioset_pretrain, model_size='base384')",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(audio_model)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_118": {
                "variable": {
                    "value": "eval_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataloader.AudiosetDataset(args.data_eval, label_csv=args.label_csv, audio_conf=val_audio_conf)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "WeightedRandomSampler_74": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "samples_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.loadtxt(args.data_train[:-5] + '_weight.csv', delimiter=',')",
                            "Call"
                        ]
                    ]
                },
                "num_samples": {
                    "value": "len(samples_weight)",
                    "type": "Call",
                    "possible_values": []
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_76": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataloader.AudiosetDataset(args.data_train, label_csv=args.label_csv, audio_conf=audio_conf)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_81": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataloader.AudiosetDataset(args.data_train, label_csv=args.label_csv, audio_conf=audio_conf)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "is_available_103": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/traintest.py": {
        "torch": {
            "device_21": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Adam_53": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "trainables",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[p for p in audio_model.parameters() if p.requires_grad]",
                            "ListComp"
                        ]
                    ]
                },
                "lr": {
                    "value": "args.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "5e-07",
                    "type": "float",
                    "possible_values": []
                },
                "betas": {
                    "value": "(0.95, 0.999)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "GradScaler_86": {
                "variable": {
                    "value": "scaler",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_262": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_330": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "load_333": {
                "variable": {
                    "value": "sdA",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "exp_dir + '/models/audio_model.' + str(start_epoch) + '.pth'",
                    "type": "BinOp",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "set_grad_enabled_23": {
                "mode": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataParallel_46": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.DataParallel(audio_model)",
                            "Call"
                        ],
                        [
                            "audio_model.to(device)",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(audio_model)",
                            "Call"
                        ],
                        [
                            "audio_model.to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "BCEWithLogitsLoss_65": {
                "variable": {
                    "value": "loss_fn",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_265": {
                "variable": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "audio_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.DataParallel(audio_model)",
                            "Call"
                        ],
                        [
                            "audio_model.to(device)",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(audio_model)",
                            "Call"
                        ],
                        [
                            "audio_model.to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_297": {
                "variable": {
                    "value": "audio_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "A_predictions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_298": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "A_targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "load_337": {
                "variable": {
                    "value": "sdB",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "exp_dir + '/models/audio_model.' + str(epoch) + '.pth'",
                    "type": "BinOp",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_352": {
                "obj": {
                    "value": "audio_model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "exp_dir + '/models/audio_model_wa.pth'",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "MultiStepLR_60": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.optim.Adam(trainables, args.lr, weight_decay=5e-07, betas=(0.95, 0.999))",
                            "Call"
                        ]
                    ]
                },
                "milestones": {
                    "value": "[2, 3, 4, 5]",
                    "type": "List",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.5",
                    "type": "float",
                    "possible_values": []
                },
                "last_epoch": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "MultiStepLR_63": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.optim.Adam(trainables, args.lr, weight_decay=5e-07, betas=(0.95, 0.999))",
                            "Call"
                        ]
                    ]
                },
                "milestones": {
                    "value": "[10, 15, 20, 25]",
                    "type": "List",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.5",
                    "type": "float",
                    "possible_values": []
                },
                "last_epoch": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "MultiStepLR_69": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.optim.Adam(trainables, args.lr, weight_decay=5e-07, betas=(0.95, 0.999))",
                            "Call"
                        ]
                    ]
                },
                "milestones": {
                    "value": "list(range(5, 26))",
                    "type": "Call",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.85",
                    "type": "float",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_71": {
                "variable": {
                    "value": "loss_fn",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_214": {
                "obj": {
                    "value": "audio_model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "'%s/models/audio_model.%d.pth' % (exp_dir, epoch)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "no_grad_274": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sigmoid_280": {
                "variable": {
                    "value": "audio_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "audio_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "audio_model(audio_input)",
                            "Call"
                        ],
                        [
                            "audio_model(audio_input)",
                            "Call"
                        ],
                        [
                            "torch.sigmoid(audio_output)",
                            "Call"
                        ],
                        [
                            "torch.cat(A_predictions)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_21": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "MultiStepLR_75": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.optim.Adam(trainables, args.lr, weight_decay=5e-07, betas=(0.95, 0.999))",
                            "Call"
                        ]
                    ]
                },
                "milestones": {
                    "value": "list(range(5, 26))",
                    "type": "Call",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.85",
                    "type": "float",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_77": {
                "variable": {
                    "value": "loss_fn",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_211": {
                "obj": {
                    "value": "audio_model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "'%s/models/best_audio_model.pth' % exp_dir",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "save_212": {
                "obj": {
                    "value": "optimizer.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "'%s/models/best_optim_state.pth' % exp_dir",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "save_216": {
                "obj": {
                    "value": "optimizer.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "'%s/models/optim_state.%d.pth' % (exp_dir, epoch)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "is_available_262": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_330": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "autocast_117": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "argmax_289": {
                "input": {
                    "value": "labels.long()",
                    "type": "Call",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_120": {
                "input": {
                    "value": "labels.long()",
                    "type": "Call",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "src/utilities/util.py": {
        "torch": {
            "mm_77": {
                "variable": {
                    "value": "matchmap",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "Ir",
                    "type": "variable",
                    "possible_values": [
                        [
                            "I.view(D, -1).t()",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "A",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_103": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "device": {
                    "value": "image_outputs.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_134": {
                "variable": {
                    "value": "S",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "S.size(0)",
                            "Call"
                        ],
                        [
                            "image_outputs.size(0)",
                            "Call"
                        ],
                        [
                            "image_outputs.size(0)",
                            "Call"
                        ],
                        [
                            "image_outputs.size(0)",
                            "Call"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "n",
                    "type": "variable",
                    "possible_values": [
                        [
                            "S.size(0)",
                            "Call"
                        ],
                        [
                            "image_outputs.size(0)",
                            "Call"
                        ],
                        [
                            "image_outputs.size(0)",
                            "Call"
                        ],
                        [
                            "image_outputs.size(0)",
                            "Call"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "device": {
                    "value": "image_outputs.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_152": {
                "variable": {
                    "value": "imagePoolfunc",
                    "type": "variable",
                    "possible_values": []
                },
                "output_size": {
                    "value": "(1, 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_154": {
                "variable": {
                    "value": "audioPoolfunc",
                    "type": "variable",
                    "possible_values": []
                },
                "output_size": {
                    "value": "(1, 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_159": {
                "variable": {
                    "value": "pooled_audio_outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "pooled_audio_outputs_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "squeeze_159": {
                "variable": {
                    "value": "pooled_audio_outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "mm_160": {
                "variable": {
                    "value": "S",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooled_image_outputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "imagePoolfunc(image_outputs).squeeze(3).squeeze(2)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "pooled_audio_outputs.t()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_189": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "diag_191": {
                "input": {
                    "value": "S",
                    "type": "variable",
                    "possible_values": [
                        [
                            "S.data",
                            "Attribute"
                        ],
                        [
                            "torch.zeros(n, n, device=image_outputs.device)",
                            "Call"
                        ],
                        [
                            "torch.mm(pooled_image_outputs, pooled_audio_outputs.t())",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_226": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "diag_228": {
                "input": {
                    "value": "S",
                    "type": "variable",
                    "possible_values": [
                        [
                            "S.data",
                            "Attribute"
                        ],
                        [
                            "torch.zeros(n, n, device=image_outputs.device)",
                            "Call"
                        ],
                        [
                            "torch.mm(pooled_image_outputs, pooled_audio_outputs.t())",
                            "Call"
                        ]
                    ]
                }
            },
            "min_197": {
                "input": {
                    "value": "Sdiff",
                    "type": "variable",
                    "possible_values": [
                        [
                            "S - torch.diag(S).view(-1, 1)",
                            "BinOp"
                        ],
                        [
                            "S - torch.diag(S).view(-1, 1)",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    }
}