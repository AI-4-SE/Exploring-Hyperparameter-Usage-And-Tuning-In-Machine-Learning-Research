{
    "examples/vkw2021/s0/local/vkw_kws_results.py": {
        "torch": {
            "DataLoader_196": {
                "variable": {
                    "value": "cv_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "cv_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Dataset(args.data_type, args.input_data, symbol_table, cv_conf, None, partition=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "args.pin_memory",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "prefetch_factor": {
                    "value": "args.prefetch",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_211": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if use_cuda else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "manual_seed_162": {
                "seed": {
                    "value": "777",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_210": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_217": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "runtime/gpu/model_repo/feature_extractor/1/model.py": {
        "torch": {
            "device_81": {
                "variable": {
                    "value": "opts.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_128": {
                "variable": {
                    "value": "speech",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(b, expect_feat_len, self.feature_size)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.output0_dtype",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_130": {
                "variable": {
                    "value": "speech_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(b, 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_120": {
                "variable": {
                    "value": "wav",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "wav[0:wav_len]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "runtime/gpu/model_repo_stateful/feature_extractor/1/model.py": {
        "torch": {
            "tensor_37": {
                "variable": {
                    "value": "self.wav",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'cpu'",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_48": {
                "variable": {
                    "value": "self.wav",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.wav, wav]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_128": {
                "variable": {
                    "value": "opts.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_238": {
                "variable": {
                    "value": "batch_speech",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, self.decoding_window, self.feature_size)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_240": {
                "variable": {
                    "value": "batch_speech_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_62": {
                "variable": {
                    "value": "self.frames",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.frames, frames]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_229": {
                "variable": {
                    "value": "temp",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.min_seg",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "runtime/gpu/model_repo_stateful/wenet/1/model.py": {
        "torch": {
            "clone_109": {
                "variable": {
                    "value": "in_2",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_167": {
                "variable": {
                    "value": "new_hist",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.seq_states[corr][1], cur_encoder_out[i]]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "runtime/gpu/model_repo_stateful/wenet/1/wenet_onnx_model.py": {
        "torch": {
            "zeros_216": {
                "variable": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(bz, max_len, f)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_218": {
                "variable": {
                    "value": "ctc_score",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(bz, beam_size)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clone_272": {
                "variable": {
                    "value": "best_index",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_151": {
                "variable": {
                    "value": "cur_enc",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hist_enc, cur_encoder_out[idx]]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "tools/compute_cmvn_stats.py": {
        "torch": {
            "DataLoader_110": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "AudioDataset(args.in_scp)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "20",
                            "int"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_func",
                    "type": "variable",
                    "possible_values": [
                        [
                            "CollateFunc(feat_dim, resample_rate)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_28": {
                "variable": {
                    "value": "mean_stat",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.feat_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_29": {
                "variable": {
                    "value": "var_stat",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.feat_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_119": {
                "variable": {
                    "value": "all_mean_stat",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "feat_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "configs['dataset_conf']['fbank_conf']['num_mel_bins']",
                            "Subscript"
                        ],
                        [
                            "feat_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_120": {
                "variable": {
                    "value": "all_var_stat",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "feat_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "configs['dataset_conf']['fbank_conf']['num_mel_bins']",
                            "Subscript"
                        ],
                        [
                            "feat_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_117": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sum_60": {
                "input": {
                    "value": "mat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "kaldi.fbank(waveform, num_mel_bins=self.feat_dim, dither=0.0, energy_floor=0.0, sample_frequency=resample_rate)",
                            "Call"
                        ]
                    ]
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_61": {
                "input": {
                    "value": "torch.square(mat)",
                    "type": "Call",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "square_61": {
                "input": {
                    "value": "mat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "kaldi.fbank(waveform, num_mel_bins=self.feat_dim, dither=0.0, energy_floor=0.0, sample_frequency=resample_rate)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "tools/make_shard_list.py": {
        "torch": {
            "set_num_threads_134": {
                "int": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/alignment.py": {
        "torch": {
            "DataLoader_183": {
                "variable": {
                    "value": "ali_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ali_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Dataset(args.data_type, args.input_file, symbol_table, ali_conf, args.bpe_model, non_lang_syms, partition=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_190": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if use_cuda else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_189": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_194": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/average_model.py": {
        "torch": {
            "load_85": {
                "variable": {
                    "value": "states",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "path_list",
                            "variable"
                        ]
                    ]
                },
                "map_location": {
                    "value": "torch.device('cpu')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "save_97": {
                "obj": {
                    "value": "avg",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "states",
                            "variable"
                        ]
                    ]
                },
                "f": {
                    "value": "args.dst_model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "true_divide_95": {
                "variable": {
                    "value": "avg[k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dividend": {
                    "value": "avg[k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "divisor": {
                    "value": "num",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.num",
                            "Attribute"
                        ]
                    ]
                }
            },
            "device_85": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/export_jit.py": {
        "torch": {
            "script_53": {
                "variable": {
                    "value": "script_model",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "init_model(configs)",
                            "Call"
                        ]
                    ]
                }
            },
            "script_63": {
                "variable": {
                    "value": "script_quant_model",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "quantized_model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "wenet/bin/export_onnx_cpu.py": {
        "torch": {
            "randn_79": {
                "variable": {
                    "value": "chunk",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args['batch'], args['decoding_window'], args['feature_size'])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_120": {
                "variable": {
                    "value": "cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args['num_blocks'], args['batch'], args['output_size'], args['cnn_module_kernel'] - 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_197": {
                "variable": {
                    "value": "torch_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "torch_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(torch_output, dim=1)",
                            "Call"
                        ],
                        [
                            "ctc(hidden)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_250": {
                "variable": {
                    "value": "hidden",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args['batch'], args['chunk_size'] if args['chunk_size'] > 0 else 16, args['output_size'])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randn_291": {
                "variable": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, 200, args['output_size'])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randint_292": {
                "variable": {
                    "value": "hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "args['vocab_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "get_args()",
                            "Call"
                        ],
                        [
                            "args",
                            "Method Argument"
                        ],
                        [
                            "args",
                            "Method Argument"
                        ],
                        [
                            "args",
                            "Method Argument"
                        ]
                    ]
                },
                "size": {
                    "value": "[10, 20]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "randint_295": {
                "variable": {
                    "value": "hyps_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "15",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "21",
                    "type": "int",
                    "possible_values": []
                },
                "size": {
                    "value": "[10]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "zeros_104": {
                "variable": {
                    "value": "att_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args['num_blocks'], args['head'], required_cache_size, args['output_size'] // args['head'] * 2)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "ones_108": {
                "variable": {
                    "value": "att_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args['batch'], 1, required_cache_size + args['chunk_size'])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_346": {
                "seed": {
                    "value": "777",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_115": {
                "variable": {
                    "value": "att_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args['num_blocks'], args['head'], 0, args['output_size'] // args['head'] * 2)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "ones_119": {
                "variable": {
                    "value": "att_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/export_onnx_gpu.py": {
        "torch": {
            "randn_296": {
                "variable": {
                    "value": "speech",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ],
                        [
                            "32",
                            "int"
                        ],
                        [
                            "self.beam_size",
                            "Attribute"
                        ]
                    ]
                },
                "out": {
                    "value": "seq_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "int"
                        ],
                        [
                            "100",
                            "int"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randint_297": {
                "variable": {
                    "value": "speech_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "10",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "seq_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "int"
                        ],
                        [
                            "100",
                            "int"
                        ]
                    ]
                },
                "size": {
                    "value": "(bz,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randn_363": {
                "variable": {
                    "value": "chunk_xs",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ]
                    ]
                },
                "out": {
                    "value": "audio_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoding_window",
                            "variable"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_366": {
                "variable": {
                    "value": "offset",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ]
                    ]
                }
            },
            "unsqueeze_366": {
                "variable": {
                    "value": "offset",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_370": {
                "variable": {
                    "value": "att_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ]
                    ]
                },
                "out": {
                    "value": "num_layers",
                    "type": "variable",
                    "possible_values": [
                        [
                            "configs['encoder_conf']['num_blocks']",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "layout": {
                    "value": "required_cache_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoding_chunk_size * num_decoding_left_chunks",
                            "BinOp"
                        ],
                        [
                            "required_cache_size",
                            "Method Argument"
                        ]
                    ]
                },
                "device": {
                    "value": "d_k * 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "randn_373": {
                "variable": {
                    "value": "cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ]
                    ]
                },
                "out": {
                    "value": "num_layers",
                    "type": "variable",
                    "possible_values": [
                        [
                            "configs['encoder_conf']['num_blocks']",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "layout": {
                    "value": "cnn_module_kernel",
                    "type": "variable",
                    "possible_values": [
                        [
                            "configs['encoder_conf'].get('cnn_module_kernel', 1) - 1",
                            "BinOp"
                        ]
                    ]
                }
            },
            "ones_376": {
                "variable": {
                    "value": "cache_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ]
                    ]
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randint_443": {
                "variable": {
                    "value": "hyps_pad_sos_eos",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "1000",
                    "type": "int",
                    "possible_values": []
                },
                "size": {
                    "value": "(bz, beam_size, seq_len)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randint_444": {
                "variable": {
                    "value": "hyps_lens_sos",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "seq_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "int"
                        ],
                        [
                            "100",
                            "int"
                        ]
                    ]
                },
                "size": {
                    "value": "(bz, beam_size)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randint_446": {
                "variable": {
                    "value": "r_hyps_pad_sos_eos",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "1000",
                    "type": "int",
                    "possible_values": []
                },
                "size": {
                    "value": "(bz, beam_size, seq_len)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randn_449": {
                "variable": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ],
                        [
                            "32",
                            "int"
                        ],
                        [
                            "self.beam_size",
                            "Attribute"
                        ]
                    ]
                },
                "out": {
                    "value": "seq_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "int"
                        ],
                        [
                            "100",
                            "int"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randint_450": {
                "variable": {
                    "value": "encoder_out_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "seq_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "int"
                        ],
                        [
                            "100",
                            "int"
                        ]
                    ]
                },
                "size": {
                    "value": "(bz,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randn_451": {
                "variable": {
                    "value": "ctc_score",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ],
                        [
                            "32",
                            "int"
                        ],
                        [
                            "self.beam_size",
                            "Attribute"
                        ]
                    ]
                },
                "out": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.beam_size",
                            "Attribute"
                        ],
                        [
                            "args.beam_size",
                            "Attribute"
                        ],
                        [
                            "beam_size",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "topk_70": {
                "variable": {
                    "value": "(beam_log_probs, beam_log_probs_idx)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "ctc_log_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.ctc.log_softmax(encoder_out)",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "self.beam_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "transpose_134": {
                "variable": {
                    "value": "att_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "att_cache",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.randn(batch_size, num_layers, head, required_cache_size, d_k * 2, dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "torch.transpose(att_cache, 0, 1)",
                            "Call"
                        ],
                        [
                            "att_cache",
                            "Method Argument"
                        ]
                    ]
                },
                "dim0": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim1": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "transpose_135": {
                "variable": {
                    "value": "cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cnn_cache",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.randn(batch_size, num_layers, output_size, cnn_module_kernel, dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "torch.transpose(cnn_cache, 0, 1)",
                            "Call"
                        ],
                        [
                            "cnn_cache",
                            "Method Argument"
                        ]
                    ]
                },
                "dim0": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim1": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_144": {
                "variable": {
                    "value": "masks",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(cache_mask, chunk_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_168": {
                "variable": {
                    "value": "r_att_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "r_att_cache",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(r_att_cache, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "topk_175": {
                "variable": {
                    "value": "(log_probs, log_probs_idx)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "log_ctc_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.ctc.log_softmax(chunk_out)",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "self.beam_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_244": {
                "variable": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad_sos, hyps_lens, r_hyps_pad_sos, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "decoder_out.view(B2, T2, V)",
                            "Call"
                        ],
                        [
                            "decoder_out.view(B, bz, T2, V)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_249": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hyps_pad_eos * mask",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_262": {
                "variable": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out.gather(2, index).squeeze(2)",
                            "Call"
                        ],
                        [
                            "score * mask",
                            "BinOp"
                        ],
                        [
                            "score * (1 - self.reverse_weight) + self.reverse_weight * r_score",
                            "BinOp"
                        ],
                        [
                            "torch.sum(score, axis=1)",
                            "Call"
                        ],
                        [
                            "torch.reshape(score, (B, bz)) + self.ctc_weight * ctc_score",
                            "BinOp"
                        ]
                    ]
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_264": {
                "variable": {
                    "value": "best_index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out.gather(2, index).squeeze(2)",
                            "Call"
                        ],
                        [
                            "score * mask",
                            "BinOp"
                        ],
                        [
                            "score * (1 - self.reverse_weight) + self.reverse_weight * r_score",
                            "BinOp"
                        ],
                        [
                            "torch.sum(score, axis=1)",
                            "Call"
                        ],
                        [
                            "torch.reshape(score, (B, bz)) + self.ctc_weight * ctc_score",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "manual_seed_544": {
                "seed": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "set_printoptions_545": {
                "precision": {
                    "value": "10",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_170": {
                "variable": {
                    "value": "r_cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "r_cnn_cache",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(r_cnn_cache, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_255": {
                "variable": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad_sos, hyps_lens, r_hyps_pad_sos, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(r_decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "r_decoder_out.view(B2, T2, V)",
                            "Call"
                        ],
                        [
                            "r_decoder_out.view(B, bz, T2, V)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_257": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_hyps_pad_eos * mask",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_323": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ones_364": {
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "int"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_404": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_477": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "reshape_263": {
                "input": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out.gather(2, index).squeeze(2)",
                            "Call"
                        ],
                        [
                            "score * mask",
                            "BinOp"
                        ],
                        [
                            "score * (1 - self.reverse_weight) + self.reverse_weight * r_score",
                            "BinOp"
                        ],
                        [
                            "torch.sum(score, axis=1)",
                            "Call"
                        ],
                        [
                            "torch.reshape(score, (B, bz)) + self.ctc_weight * ctc_score",
                            "BinOp"
                        ]
                    ]
                },
                "shape": {
                    "value": "(B, bz)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/recognize.py": {
        "torch": {
            "DataLoader_183": {
                "variable": {
                    "value": "test_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Dataset(args.data_type, args.test_data, symbol_table, test_conf, args.bpe_model, non_lang_syms, partition=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_194": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if use_cuda else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_193": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_198": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/recognize_onnx.py": {
        "torch": {
            "DataLoader_144": {
                "variable": {
                    "value": "test_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Dataset(args.data_type, args.test_data, symbol_table, test_conf, args.bpe_model, partition=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_147": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_168": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/bin/train.py": {
        "torch": {
            "DataLoader_166": {
                "variable": {
                    "value": "train_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Dataset(args.data_type, args.train_data, symbol_table, train_conf, args.bpe_model, non_lang_syms, True)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "args.pin_memory",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "prefetch_factor": {
                    "value": "args.prefetch",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_171": {
                "variable": {
                    "value": "cv_data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "cv_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Dataset(args.data_type, args.cv_data, symbol_table, cv_conf, args.bpe_model, non_lang_syms, partition=False)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "args.pin_memory",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "prefetch_factor": {
                    "value": "args.prefetch",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Adam_246": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "manual_seed_132": {
                "seed": {
                    "value": "777",
                    "type": "int",
                    "possible_values": []
                }
            },
            "script_204": {
                "variable": {
                    "value": "script_model",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "init_model(configs)",
                            "Call"
                        ],
                        [
                            "model.to(device)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, find_unused_parameters=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedDataParallel_231": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "init_model(configs)",
                            "Call"
                        ],
                        [
                            "model.to(device)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, find_unused_parameters=True)",
                            "Call"
                        ]
                    ]
                },
                "find_unused_parameters": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "device_233": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_243": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if use_cuda else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "GradScaler_262": {
                "variable": {
                    "value": "scaler",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_228": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_242": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/dataset/dataset.py": {
        "torch": {
            "is_available_57": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_initialized_58": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/dataset/processor.py": {
        "torch": {
            "tensor_598": {
                "variable": {
                    "value": "feats_length",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[x['feat'].size(0) for x in sample]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "argsort_600": {
                "variable": {
                    "value": "order",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "feats_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([x['feat'].size(0) for x in sample], dtype=torch.int32)",
                            "Call"
                        ]
                    ]
                },
                "descending": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "tensor_601": {
                "variable": {
                    "value": "feats_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[sample[i]['feat'].size(0) for i in order]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_608": {
                "variable": {
                    "value": "label_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[x.size(0) for x in sorted_labels]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_sequence_611": {
                "variable": {
                    "value": "padded_feats",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sorted_feats",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[sample[i]['feat'] for i in order]",
                            "ListComp"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pad_sequence_614": {
                "variable": {
                    "value": "padding_labels",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sorted_labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[torch.tensor(sample[i]['label'], dtype=torch.int64) for i in order]",
                            "ListComp"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_606": {
                "data": {
                    "value": "sample[i]['label']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/dataset/wav_distortion.py": {
        "torch": {
            "from_numpy_310": {
                "ndarray": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "distort_wav_conf(x, distort_type, distort_conf, rate)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "wenet/transducer/joint.py": {
        "torch": {
            "Linear_43": {
                "variable": {
                    "value": "self.ffn_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "join_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "voca_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_36": {
                "variable": {
                    "value": "self.enc_ffn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "enc_output_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "join_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_37": {
                "variable": {
                    "value": "self.pred_ffn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "pred_output_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "join_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_41": {
                "variable": {
                    "value": "self.post_ffn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "enc_output_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "join_dim",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transducer/predictor.py": {
        "torch": {
            "Embedding_75": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "voca_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_76": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "embed_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_86": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "output_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_156": {
                "variable": {
                    "value": "state_ms",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[states[0] for states in cache]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_157": {
                "variable": {
                    "value": "state_cs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[states[1] for states in cache]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_228": {
                "variable": {
                    "value": "self.pos_embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_size * self.context_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_heads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Embedding_231": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "voca_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_232": {
                "variable": {
                    "value": "self.embed_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "embed_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_233": {
                "variable": {
                    "value": "self.ffn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LayerNorm_234": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "eps": {
                    "value": "layer_norm_epsilon",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_276": {
                "variable": {
                    "value": "history",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[h[0] for h in cache]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_292": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(zeros, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_340": {
                "variable": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(history, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Embedding_385": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "voca_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_386": {
                "variable": {
                    "value": "self.embed_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "embed_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Conv1d_387": {
                "variable": {
                    "value": "self.conv",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "self.context_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "groups": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LayerNorm_393": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "layer_norm_epsilon",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_419": {
                "variable": {
                    "value": "history",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[h[0] for h in cache]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_451": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(zeros, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_474": {
                "variable": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(history, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "split_262": {
                "tensor": {
                    "value": "cache_0",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cache[0]",
                            "Subscript"
                        ],
                        [
                            "cache[0]",
                            "Subscript"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "split_434": {
                "tensor": {
                    "value": "cache_0",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cache[0]",
                            "Subscript"
                        ],
                        [
                            "cache[0]",
                            "Subscript"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "split_140": {
                "tensor": {
                    "value": "state_ms",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cache[0]",
                            "Subscript"
                        ],
                        [
                            "torch.cat([states[0] for states in cache], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "split_141": {
                "tensor": {
                    "value": "state_cs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cache[1]",
                            "Subscript"
                        ],
                        [
                            "torch.cat([states[1] for states in cache], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_170": {
                "*size": {
                    "value": "1 * self.n_layers",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_174": {
                "*size": {
                    "value": "1 * self.n_layers",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_244": {
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "self.context_size - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_403": {
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "self.context_size - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.embed_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transducer/search/greedy_search.py": {
        "torch": {
            "zeros_13": {
                "variable": {
                    "value": "padding",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_15": {
                "variable": {
                    "value": "pred_input_step",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[model.blank]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_15": {
                "variable": {
                    "value": "pred_input_step",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "shape": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transducer/search/prefix_beam_search.py": {
        "torch": {
            "zeros_35": {
                "variable": {
                    "value": "padding",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "pre_t.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "device": {
                    "value": "encoder_x.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_79": {
                "variable": {
                    "value": "input_hyp_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "input_hyp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[s.hyp[-1] for s in beam_init]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tensor_86": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[s.score for s in beam_init]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "log_99": {
                "variable": {
                    "value": "logp",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.add(transducer_weight * torch.exp(logp), ctc_weight * torch.exp(ctc_probs[i].unsqueeze(0)))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "add_105": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "other": {
                    "value": "top_k_logp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "logp.topk(beam_size)",
                            "Call"
                        ]
                    ]
                }
            },
            "add_100": {
                "input": {
                    "value": "transducer_weight * torch.exp(logp)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "ctc_weight * torch.exp(ctc_probs[i].unsqueeze(0))",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "exp_100": {
                "input": {
                    "value": "logp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.forward_decoder_one_step(encoder_out[:, i, :].unsqueeze(1), input_hyp_tensor, cache_batch)",
                            "Call"
                        ],
                        [
                            "logp.squeeze(1).squeeze(1)",
                            "Call"
                        ],
                        [
                            "torch.log(torch.add(transducer_weight * torch.exp(logp), ctc_weight * torch.exp(ctc_probs[i].unsqueeze(0))))",
                            "Call"
                        ]
                    ]
                }
            },
            "exp_101": {
                "input": {
                    "value": "ctc_probs[i].unsqueeze(0)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transducer/transducer.py": {
        "torch": {
            "where_97": {
                "variable": {
                    "value": "rnnt_text",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "rnnt_text == self.ignore_id",
                    "type": "Compare",
                    "possible_values": []
                },
                "x": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "y": {
                    "value": "rnnt_text",
                    "type": "variable",
                    "possible_values": [
                        [
                            "text.to(torch.int64)",
                            "Call"
                        ],
                        [
                            "torch.where(rnnt_text == self.ignore_id, 0, rnnt_text).to(torch.int32)",
                            "Call"
                        ],
                        [
                            "hyps_pad.to(torch.int64)",
                            "Call"
                        ],
                        [
                            "torch.where(rnnt_text == self.ignore_id, 0, rnnt_text).to(torch.int32)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_157": {
                "variable": {
                    "value": "rnnt_text",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "rnnt_text == self.ignore_id",
                    "type": "Compare",
                    "possible_values": []
                },
                "x": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "y": {
                    "value": "rnnt_text",
                    "type": "variable",
                    "possible_values": [
                        [
                            "text.to(torch.int64)",
                            "Call"
                        ],
                        [
                            "torch.where(rnnt_text == self.ignore_id, 0, rnnt_text).to(torch.int32)",
                            "Call"
                        ],
                        [
                            "hyps_pad.to(torch.int64)",
                            "Call"
                        ],
                        [
                            "torch.where(rnnt_text == self.ignore_id, 0, rnnt_text).to(torch.int32)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_softmax_188": {
                "variable": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad, hyps_lens, r_hyps_pad, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "decoder_out.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "self._cal_attn_score(encoder_out, encoder_mask, hyps_pad, hyps_lens)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_192": {
                "variable": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad, hyps_lens, r_hyps_pad, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(r_decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "r_decoder_out.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "self._cal_attn_score(encoder_out, encoder_mask, hyps_pad, hyps_lens)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "pad_sequence_323": {
                "variable": {
                    "value": "hyps_pad",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "[torch.tensor(hyp, device=device, dtype=torch.long) for hyp in hyps]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "self.ignore_id",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_326": {
                "variable": {
                    "value": "hyps_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[len(hyp) for hyp in hyps]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_331": {
                "variable": {
                    "value": "encoder_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_443": {
                "variable": {
                    "value": "padding",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_430": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "layout": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_431": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "layout": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_324": {
                "data": {
                    "value": "hyp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hyp in enumerate(hyps)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_453": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/asr_model.py": {
        "torch": {
            "tensor_138": {
                "variable": {
                    "value": "r_loss_att",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "ones_221": {
                "variable": {
                    "value": "hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "[running_size, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tensor_223": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[0.0] + [-float('inf')] * (beam_size - 1)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_227": {
                "variable": {
                    "value": "end_flag",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([0.0] + [-float('inf')] * (beam_size - 1), dtype=torch.float)",
                            "Call"
                        ],
                        [
                            "scores.to(device).repeat([batch_size]).unsqueeze(1).to(device)",
                            "Call"
                        ],
                        [
                            "scores.view(batch_size, beam_size)",
                            "Call"
                        ],
                        [
                            "scores + top_k_logp",
                            "BinOp"
                        ],
                        [
                            "scores.view(batch_size, beam_size * beam_size)",
                            "Call"
                        ],
                        [
                            "scores.topk(k=beam_size)",
                            "Call"
                        ],
                        [
                            "scores.view(-1, 1)",
                            "Call"
                        ],
                        [
                            "topk_prob.max(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "index_select_277": {
                "variable": {
                    "value": "best_hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hyps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.ones([running_size, 1], dtype=torch.long, device=device).fill_(self.sos)",
                            "Call"
                        ],
                        [
                            "torch.cat((last_best_k_hyps, best_k_pred.view(-1, 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "[hyp.tolist() for hyp in topk_index]",
                            "ListComp"
                        ],
                        [
                            "[remove_duplicates_and_blank(hyp) for hyp in hyps]",
                            "ListComp"
                        ],
                        [
                            "[(y[0], log_add([y[1][0], y[1][1]])) for y in cur_hyps]",
                            "ListComp"
                        ],
                        [
                            "self._ctc_prefix_beam_search(speech, speech_lengths, beam_size, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)",
                            "Call"
                        ],
                        [
                            "self._ctc_prefix_beam_search(speech, speech_lengths, beam_size, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "best_hyps_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "best_index + torch.arange(batch_size, dtype=torch.long, device=device) * beam_size",
                            "BinOp"
                        ],
                        [
                            "best_k_index // beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "pad_sequence_490": {
                "variable": {
                    "value": "hyps_pad",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "[torch.tensor(hyp[0], device=device, dtype=torch.long) for hyp in hyps]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "self.ignore_id",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_495": {
                "variable": {
                    "value": "hyps_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[len(hyp[0]) for hyp in hyps]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_501": {
                "variable": {
                    "value": "encoder_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "log_softmax_513": {
                "variable": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, ys_in_pad, ys_in_lens, r_ys_in_pad, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad, hyps_lens, r_hyps_pad, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "decoder_out.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps, hyps_lens, r_hyps, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(decoder_out, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_517": {
                "variable": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, ys_in_pad, ys_in_lens, r_ys_in_pad, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad, hyps_lens, r_hyps_pad, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(r_decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "r_decoder_out.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps, hyps_lens, r_hyps, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(r_decoder_out, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ones_660": {
                "variable": {
                    "value": "encoder_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_hyps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hyps.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "encoder_out.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "max_685": {
                "variable": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_hyps_lens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hyps_lens - 1",
                            "BinOp"
                        ]
                    ]
                }
            },
            "arange_686": {
                "variable": {
                    "value": "index_range",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.max(r_hyps_lens)",
                            "Call"
                        ]
                    ]
                },
                "step": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "gather_703": {
                "variable": {
                    "value": "r_hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_hyps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hyps[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "torch.gather(r_hyps, 1, index)",
                            "Call"
                        ],
                        [
                            "torch.where(seq_mask, r_hyps, self.eos)",
                            "Call"
                        ],
                        [
                            "torch.cat([hyps[:, 0:1], r_hyps], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "seq_len_expand - 1 - index_range",
                            "BinOp"
                        ],
                        [
                            "index * seq_mask",
                            "BinOp"
                        ]
                    ]
                }
            },
            "where_708": {
                "variable": {
                    "value": "r_hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "seq_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "seq_len_expand > index_range",
                            "Compare"
                        ]
                    ]
                },
                "x": {
                    "value": "r_hyps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hyps[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "torch.gather(r_hyps, 1, index)",
                            "Call"
                        ],
                        [
                            "torch.where(seq_mask, r_hyps, self.eos)",
                            "Call"
                        ],
                        [
                            "torch.cat([hyps[:, 0:1], r_hyps], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "self.eos",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_713": {
                "variable": {
                    "value": "r_hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hyps[:, 0:1], r_hyps]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_722": {
                "variable": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, ys_in_pad, ys_in_lens, r_ys_in_pad, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad, hyps_lens, r_hyps_pad, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "decoder_out.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps, hyps_lens, r_hyps, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(decoder_out, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_727": {
                "variable": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "r_decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoder_out, encoder_mask, ys_in_pad, ys_in_lens, r_ys_in_pad, self.reverse_weight)",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps_pad, hyps_lens, r_hyps_pad, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(r_decoder_out, dim=-1)",
                            "Call"
                        ],
                        [
                            "r_decoder_out.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "self.decoder(encoder_out, encoder_mask, hyps, hyps_lens, r_hyps, reverse_weight)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(r_decoder_out, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "arange_252": {
                "variable": {
                    "value": "base_k_index",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ],
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ],
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ],
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "index_select_259": {
                "variable": {
                    "value": "best_k_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "top_k_index.view(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "index": {
                    "value": "best_k_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "base_k_index.view(-1) + offset_k_index.view(-1)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "index_select_263": {
                "variable": {
                    "value": "last_best_k_hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hyps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.ones([running_size, 1], dtype=torch.long, device=device).fill_(self.sos)",
                            "Call"
                        ],
                        [
                            "torch.cat((last_best_k_hyps, best_k_pred.view(-1, 1)), dim=1)",
                            "Call"
                        ],
                        [
                            "[hyp.tolist() for hyp in topk_index]",
                            "ListComp"
                        ],
                        [
                            "[remove_duplicates_and_blank(hyp) for hyp in hyps]",
                            "ListComp"
                        ],
                        [
                            "[(y[0], log_add([y[1][0], y[1][1]])) for y in cur_hyps]",
                            "ListComp"
                        ],
                        [
                            "self._ctc_prefix_beam_search(speech, speech_lengths, beam_size, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)",
                            "Call"
                        ],
                        [
                            "self._ctc_prefix_beam_search(speech, speech_lengths, beam_size, decoding_chunk_size, num_decoding_left_chunks, simulate_streaming)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "best_hyps_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "best_index + torch.arange(batch_size, dtype=torch.long, device=device) * beam_size",
                            "BinOp"
                        ],
                        [
                            "best_k_index // beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "cat_265": {
                "variable": {
                    "value": "hyps",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(last_best_k_hyps, best_k_pred.view(-1, 1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "eq_269": {
                "variable": {
                    "value": "end_flag",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hyps[:, -1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "self.eos",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_572": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "layout": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_573": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "layout": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_275": {
                "start": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ],
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ],
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ],
                        [
                            "speech.shape[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tensor_491": {
                "data": {
                    "value": "hyp[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "speech.device",
                            "Attribute"
                        ],
                        [
                            "speech.device",
                            "Attribute"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/attention.py": {
        "torch": {
            "Linear_42": {
                "variable": {
                    "value": "self.linear_q",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_43": {
                "variable": {
                    "value": "self.linear_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_44": {
                "variable": {
                    "value": "self.linear_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_45": {
                "variable": {
                    "value": "self.linear_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_46": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dropout_rate",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "matmul_115": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "p_attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dropout(attn)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_183": {
                "variable": {
                    "value": "new_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(k, v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Linear_201": {
                "variable": {
                    "value": "self.linear_pos",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Parameter_204": {
                "variable": {
                    "value": "self.pos_bias_u",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.h, self.d_k)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_205": {
                "variable": {
                    "value": "self.pos_bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.h, self.d_k)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_219": {
                "variable": {
                    "value": "zero_pad",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(x.size()[0], x.size()[1], x.size()[2], 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "x.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "x.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_222": {
                "variable": {
                    "value": "x_padded",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[zero_pad, x]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_285": {
                "variable": {
                    "value": "new_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(k, v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "matmul_300": {
                "variable": {
                    "value": "matrix_ac",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q_with_bias_u",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(q + self.pos_bias_u).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "k.transpose(-2, -1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_304": {
                "variable": {
                    "value": "matrix_bd",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q_with_bias_v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(q + self.pos_bias_v).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "p.transpose(-2, -1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ones_79": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_106": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.masked_fill(mask, -float('inf'))",
                            "Call"
                        ],
                        [
                            "torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)",
                            "BinOp"
                        ],
                        [
                            "(matrix_ac + matrix_bd) / math.sqrt(self.d_k)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_112": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.masked_fill(mask, -float('inf'))",
                            "Call"
                        ],
                        [
                            "torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)",
                            "BinOp"
                        ],
                        [
                            "(matrix_ac + matrix_bd) / math.sqrt(self.d_k)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ones_124": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "empty_125": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_126": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "split_177": {
                "variable": {
                    "value": "(key_cache, value_cache)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "tensor": {
                    "value": "cache",
                    "type": "variable",
                    "possible_values": []
                },
                "split_size_or_sections": {
                    "value": "cache.size(-1) // 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_179": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_cache, k]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_180": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[value_cache, v]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_230": {
                "variable": {
                    "value": "ones",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(x.size(2), x.size(3))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "ones_237": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "empty_238": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_239": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "split_279": {
                "variable": {
                    "value": "(key_cache, value_cache)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "tensor": {
                    "value": "cache",
                    "type": "variable",
                    "possible_values": []
                },
                "split_size_or_sections": {
                    "value": "cache.size(-1) // 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_281": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_cache, k]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_282": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[value_cache, v]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "matmul_185": {
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.linear_q(query).view(n_batch, -1, self.h, self.d_k)",
                            "Call"
                        ],
                        [
                            "q.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.forward_qkv(query, key, value)",
                            "Call"
                        ],
                        [
                            "self.forward_qkv(query, key, value)",
                            "Call"
                        ],
                        [
                            "q.transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "k.transpose(-2, -1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tril_231": {
                "input": {
                    "value": "ones",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.ones((x.size(2), x.size(3)))",
                            "Call"
                        ]
                    ]
                },
                "diagonal": {
                    "value": "x.size(3) - x.size(2)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/cmvn.py": {
        "torch": {}
    },
    "wenet/transformer/convolution.py": {
        "torch": {
            "Conv1d_43": {
                "variable": {
                    "value": "self.pointwise_conv1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "2 * channels",
                    "type": "BinOp",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Conv1d_63": {
                "variable": {
                    "value": "self.depthwise_conv",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel_size",
                    "type": "variable",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "padding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "int"
                        ],
                        [
                            "(kernel_size - 1) // 2",
                            "BinOp"
                        ]
                    ]
                },
                "groups": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Conv1d_81": {
                "variable": {
                    "value": "self.pointwise_conv2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "glu_132": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "nn.functional.pad(x, (self.lorder, 0), 'constant', 0.0)",
                            "Call"
                        ],
                        [
                            "self.pointwise_conv1(x)",
                            "Call"
                        ],
                        [
                            "nn.functional.glu(x, dim=1)",
                            "Call"
                        ],
                        [
                            "self.depthwise_conv(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.activation(self.norm(x))",
                            "Call"
                        ],
                        [
                            "torch.cat((cache, x), dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.pointwise_conv2(x)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "BatchNorm1d_76": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_features": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LayerNorm_79": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ones_94": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_95": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_128": {
                "variable": {
                    "value": "new_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "x.dtype",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "x.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_117": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "nn.functional.pad(x, (self.lorder, 0), 'constant', 0.0)",
                            "Call"
                        ],
                        [
                            "self.pointwise_conv1(x)",
                            "Call"
                        ],
                        [
                            "nn.functional.glu(x, dim=1)",
                            "Call"
                        ],
                        [
                            "self.depthwise_conv(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.activation(self.norm(x))",
                            "Call"
                        ],
                        [
                            "torch.cat((cache, x), dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.pointwise_conv2(x)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(self.lorder, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "cat_121": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(cache, x)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/ctc.py": {
        "torch": {
            "Linear_41": {
                "variable": {
                    "value": "self.ctc_lo",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "eprojs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_output_size",
                            "variable"
                        ]
                    ]
                },
                "out_features": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "CTCLoss_44": {
                "variable": {
                    "value": "self.ctc_loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "reduction_type",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'sum' if reduce else 'none'",
                            "IfExp"
                        ]
                    ]
                }
            },
            "log_softmax_74": {
                "input": {
                    "value": "self.ctc_lo(hs_pad)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_84": {
                "input": {
                    "value": "self.ctc_lo(hs_pad)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_57": {
                "input": {
                    "value": "hs_pad",
                    "type": "variable",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout_rate",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/decoder.py": {
        "torch": {
            "LayerNorm_78": {
                "variable": {
                    "value": "self.after_norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "attention_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_output_size",
                            "variable"
                        ]
                    ]
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_80": {
                "variable": {
                    "value": "self.output_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "attention_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_output_size",
                            "variable"
                        ]
                    ]
                },
                "out_features": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ModuleList_82": {
                "variable": {
                    "value": "self.decoders",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[DecoderLayer(attention_dim, MultiHeadedAttention(attention_heads, attention_dim, self_attention_dropout_rate), MultiHeadedAttention(attention_heads, attention_dim, src_attention_dropout_rate), PositionwiseFeedForward(attention_dim, linear_units, dropout_rate), dropout_rate, normalize_before, concat_after) for _ in range(self.num_blocks)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "tensor_270": {
                "variable": {
                    "value": "r_x",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Sequential_70": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Embedding(vocab_size, attention_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "empty_103": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_184": {
                "variable": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.output_layer(y)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_142": {
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Embedding_71": {
                "num_embeddings": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "attention_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_output_size",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "wenet/transformer/decoder_layer.py": {
        "torch": {
            "LayerNorm_59": {
                "variable": {
                    "value": "self.norm1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LayerNorm_60": {
                "variable": {
                    "value": "self.norm2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LayerNorm_61": {
                "variable": {
                    "value": "self.norm3",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout_62": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_66": {
                "variable": {
                    "value": "self.concat_linear1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "size + size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_67": {
                "variable": {
                    "value": "self.concat_linear2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "size + size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Identity_69": {
                "variable": {
                    "value": "self.concat_linear1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Identity_70": {
                "variable": {
                    "value": "self.concat_linear2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_119": {
                "variable": {
                    "value": "tgt_concat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(tgt_q, self.self_attn(tgt_q, tgt, tgt, tgt_q_mask)[0])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_132": {
                "variable": {
                    "value": "x_concat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x, self.src_attn(x, memory, memory, memory_mask)[0])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_149": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[cache, x]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/embedding.py": {
        "torch": {
            "Dropout_43": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_46": {
                "variable": {
                    "value": "self.pe",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.max_len",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "self.d_model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_47": {
                "variable": {
                    "value": "position",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "self.max_len",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_47": {
                "variable": {
                    "value": "position",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_49": {
                "variable": {
                    "value": "div_term",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(0, self.d_model, 2, dtype=torch.float32) * -(math.log(10000.0) / self.d_model)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sin_52": {
                "variable": {
                    "value": "self.pe[:, 0::2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "position * div_term",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cos_53": {
                "variable": {
                    "value": "self.pe[:, 1::2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "position * div_term",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Dropout_149": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_157": {
                "variable": {
                    "value": "pos_emb",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "x.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.d_model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_162": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.d_model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "embedding_108": {
                "variable": {
                    "value": "pos_emb",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "offset.unsqueeze(1) + torch.arange(0, size).to(offset.device)",
                            "BinOp"
                        ],
                        [
                            "index * flag",
                            "BinOp"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.pe[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_50": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "self.d_model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "step": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_104": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "max_102": {
                "input": {
                    "value": "offset",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/encoder.py": {
        "torch": {
            "LayerNorm_126": {
                "variable": {
                    "value": "self.after_norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "output_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_size",
                            "Call"
                        ]
                    ]
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "ones_222": {
                "variable": {
                    "value": "tmp_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "xs.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "xs.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_264": {
                "variable": {
                    "value": "r_att_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "r_att_cache",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(r_att_cache, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_266": {
                "variable": {
                    "value": "r_cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "r_cnn_cache",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(r_cnn_cache, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_324": {
                "variable": {
                    "value": "ys",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_325": {
                "variable": {
                    "value": "masks",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, 1, ys.size(1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "ys.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_361": {
                "variable": {
                    "value": "self.encoders",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[TransformerEncoderLayer(output_size, MultiHeadedAttention(attention_heads, output_size, attention_dropout_rate), PositionwiseFeedForward(output_size, linear_units, dropout_rate), dropout_rate, normalize_before, concat_after) for _ in range(num_blocks)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_449": {
                "variable": {
                    "value": "self.encoders",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[ConformerEncoderLayer(output_size, encoder_selfattn_layer(*encoder_selfattn_layer_args), positionwise_layer(*positionwise_layer_args), positionwise_layer(*positionwise_layer_args) if macaron_style else None, convolution_layer(*convolution_layer_args) if use_cnn_module else None, dropout_rate, normalize_before, concat_after) for _ in range(num_blocks)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "zeros_186": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "layout": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_187": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "layout": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_188": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_310": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "xs.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_311": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "xs.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/encoder_layer.py": {
        "torch": {
            "LayerNorm_58": {
                "variable": {
                    "value": "self.norm1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LayerNorm_59": {
                "variable": {
                    "value": "self.norm2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout_60": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_122": {
                "variable": {
                    "value": "fake_cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "x.dtype",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "x.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LayerNorm_166": {
                "variable": {
                    "value": "self.norm_ff",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LayerNorm_167": {
                "variable": {
                    "value": "self.norm_mha",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout_178": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_246": {
                "variable": {
                    "value": "new_cnn_cache",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "x.dtype",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "x.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_65": {
                "variable": {
                    "value": "self.concat_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "size + size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Identity_67": {
                "variable": {
                    "value": "self.concat_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ones_74": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_75": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_76": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_108": {
                "variable": {
                    "value": "x_concat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x, x_att)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "LayerNorm_169": {
                "variable": {
                    "value": "self.norm_ff_macaron",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LayerNorm_174": {
                "variable": {
                    "value": "self.norm_conv",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LayerNorm_176": {
                "variable": {
                    "value": "self.norm_final",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_183": {
                "variable": {
                    "value": "self.concat_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "size + size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Identity_185": {
                "variable": {
                    "value": "self.concat_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ones_193": {
                "*size": {
                    "value": "(0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_194": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_195": {
                "*size": {
                    "value": "(0, 0, 0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_237": {
                "variable": {
                    "value": "x_concat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x, x_att)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/label_smoothing_loss.py": {
        "torch": {
            "KLDivLoss_61": {
                "variable": {
                    "value": "self.criterion",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "zeros_like_88": {
                "variable": {
                    "value": "true_dist",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.view(-1, self.size)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_softmax_94": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.view(-1, self.size)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/positionwise_feed_forward.py": {
        "torch": {
            "Linear_40": {
                "variable": {
                    "value": "self.w_1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "idim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_units",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_42": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_43": {
                "variable": {
                    "value": "self.w_2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_units",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "idim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ReLU_37": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/subsampling.py": {
        "torch": {
            "Sequential_48": {
                "variable": {
                    "value": "self.out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Linear(idim, odim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_94": {
                "variable": {
                    "value": "self.conv",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Conv2d(1, odim, 3, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_100": {
                "variable": {
                    "value": "self.out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 2), odim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_149": {
                "variable": {
                    "value": "self.conv",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Conv2d(1, odim, 3, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_155": {
                "variable": {
                    "value": "self.linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "odim * (((idim - 1) // 2 - 2) // 3)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Sequential_201": {
                "variable": {
                    "value": "self.conv",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Conv2d(1, odim, 3, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_209": {
                "variable": {
                    "value": "self.linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "odim * ((((idim - 1) // 2 - 1) // 2 - 1) // 2)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_49": {
                "in_features": {
                    "value": "idim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LayerNorm_50": {
                "normalized_shape": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-05",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout_51": {
                "p": {
                    "value": "dropout_rate",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Conv2d_95": {
                "in_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_96": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_97": {
                "in_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_98": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_101": {
                "in_features": {
                    "value": "odim * (((idim - 1) // 2 - 1) // 2)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Conv2d_150": {
                "in_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_151": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_152": {
                "in_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_153": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_202": {
                "in_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_203": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_204": {
                "in_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_205": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_206": {
                "in_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "odim",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_207": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "wenet/transformer/swish.py": {
        "torch": {
            "sigmoid_26": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/utils/checkpoint.py": {
        "torch": {
            "is_available_25": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_27": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "load_30": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "save_52": {
                "obj": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.module.state_dict()",
                            "Call"
                        ],
                        [
                            "model.module.state_dict()",
                            "Call"
                        ],
                        [
                            "model.state_dict()",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "load_91": {
                "variable": {
                    "value": "model_state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "enc_model_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.enc_init",
                            "Attribute"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/utils/common.py": {
        "torch": {
            "zeros_48": {
                "variable": {
                    "value": "pad",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "n_batch",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(xs)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max([x.size(0) for x in xs])",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "xs[0].dtype",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "xs[0].device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_81": {
                "variable": {
                    "value": "_blank",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[blank]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "device": {
                    "value": "ys_pad.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_86": {
                "variable": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[_blank, ys_pad]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_122": {
                "variable": {
                    "value": "_sos",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[sos]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "device": {
                    "value": "ys_pad.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_126": {
                "variable": {
                    "value": "_eos",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[eos]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "device": {
                    "value": "ys_pad.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_sequence_158": {
                "variable": {
                    "value": "r_ys_pad",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "[torch.flip(y.int()[:i], [0]) for (y, i) in zip(ys_pad, ys_lens)]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "pad_value",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sum_180": {
                "variable": {
                    "value": "numerator",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pad_pred.masked_select(mask) == pad_targets.masked_select(mask)",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "sum_182": {
                "variable": {
                    "value": "denominator",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pad_targets != ignore_label",
                            "Compare"
                        ]
                    ]
                }
            },
            "where_87": {
                "condition": {
                    "value": "out == ignore_id",
                    "type": "Compare",
                    "possible_values": []
                },
                "x": {
                    "value": "blank",
                    "type": "variable",
                    "possible_values": []
                },
                "y": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([_blank, ys_pad], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_131": {
                "tensors": {
                    "value": "[_sos, y]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_132": {
                "tensors": {
                    "value": "[y, _eos]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "flip_158": {
                "input": {
                    "value": "y.int()[:i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dims": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/utils/ctc_util.py": {
        "torch": {
            "zeros_41": {
                "variable": {
                    "value": "log_alpha",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(ctc_probs.size(0), len(y_insert_blank))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "tensor_70": {
                "variable": {
                    "value": "candidates",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[log_alpha[-1, len(y_insert_blank) - 1], log_alpha[-1, len(y_insert_blank) - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "zeros_43": {
                "*size": {
                    "value": "(ctc_probs.size(0), len(y_insert_blank))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int16",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_68": {
                "*size": {
                    "value": "(ctc_probs.size(0), 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int16",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "argmax_75": {
                "input": {
                    "value": "candidates",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([log_alpha[-1, len(y_insert_blank) - 1], log_alpha[-1, len(y_insert_blank) - 2]])",
                            "Call"
                        ],
                        [
                            "torch.tensor([log_alpha[t - 1, s], log_alpha[t - 1, s - 1]])",
                            "Call"
                        ],
                        [
                            "torch.tensor([log_alpha[t - 1, s], log_alpha[t - 1, s - 1], log_alpha[t - 1, s - 2]])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_55": {
                "variable": {
                    "value": "candidates",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[log_alpha[t - 1, s], log_alpha[t - 1, s - 1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_59": {
                "variable": {
                    "value": "candidates",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[log_alpha[t - 1, s], log_alpha[t - 1, s - 1], log_alpha[t - 1, s - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "max_65": {
                "input": {
                    "value": "candidates",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([log_alpha[-1, len(y_insert_blank) - 1], log_alpha[-1, len(y_insert_blank) - 2]])",
                            "Call"
                        ],
                        [
                            "torch.tensor([log_alpha[t - 1, s], log_alpha[t - 1, s - 1]])",
                            "Call"
                        ],
                        [
                            "torch.tensor([log_alpha[t - 1, s], log_alpha[t - 1, s - 1], log_alpha[t - 1, s - 2]])",
                            "Call"
                        ]
                    ]
                }
            },
            "argmax_66": {
                "input": {
                    "value": "candidates",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([log_alpha[-1, len(y_insert_blank) - 1], log_alpha[-1, len(y_insert_blank) - 2]])",
                            "Call"
                        ],
                        [
                            "torch.tensor([log_alpha[t - 1, s], log_alpha[t - 1, s - 1]])",
                            "Call"
                        ],
                        [
                            "torch.tensor([log_alpha[t - 1, s], log_alpha[t - 1, s - 1], log_alpha[t - 1, s - 2]])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "wenet/utils/executor.py": {
        "torch": {
            "no_grad_131": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "isfinite_143": {
                "input": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "loss_dict['loss'] / accum_grad",
                            "BinOp"
                        ],
                        [
                            "loss_dict['loss']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "clip_grad_norm__93": {
                "variable": {
                    "value": "grad_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "clip",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.get('grad_clip', 50.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__104": {
                "variable": {
                    "value": "grad_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "clip",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.get('grad_clip', 50.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "autocast_77": {
                "device_type": {
                    "value": "scaler is not None",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "isfinite_105": {
                "input": {
                    "value": "grad_norm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "clip_grad_norm_(model.parameters(), clip)",
                            "Call"
                        ],
                        [
                            "clip_grad_norm_(model.parameters(), clip)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "wenet/utils/init_model.py": {
        "torch": {
            "from_numpy_32": {
                "ndarray": {
                    "value": "mean",
                    "type": "variable",
                    "possible_values": [
                        [
                            "load_cmvn(configs['cmvn_file'], configs['is_json_cmvn'])",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_33": {
                "ndarray": {
                    "value": "istd",
                    "type": "variable",
                    "possible_values": [
                        [
                            "load_cmvn(configs['cmvn_file'], configs['is_json_cmvn'])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "wenet/utils/mask.py": {
        "torch": {
            "arange_82": {
                "variable": {
                    "value": "arange",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_116": {
                "variable": {
                    "value": "ret",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_214": {
                "variable": {
                    "value": "seq_range",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "xs.size(1)",
                            "Call"
                        ],
                        [
                            "max_len if max_len > 0 else lengths.max().item()",
                            "IfExp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "lengths.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_268": {
                "variable": {
                    "value": "zero_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "flag",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_55": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_93": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "cat_270": {
                "variable": {
                    "value": "unfinished",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(zero_mask, flag.repeat([1, beam_size - 1]))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_272": {
                "variable": {
                    "value": "finished",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(flag, zero_mask.repeat([1, beam_size - 1]))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randint_168": {
                "variable": {
                    "value": "chunk_size",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "xs.size(1)",
                            "Call"
                        ],
                        [
                            "max_len if max_len > 0 else lengths.max().item()",
                            "IfExp"
                        ]
                    ]
                },
                "size": {
                    "value": "(1,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randint_176": {
                "variable": {
                    "value": "num_left_chunks",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "max_left_chunks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(max_len - 1) // chunk_size",
                            "BinOp"
                        ]
                    ]
                },
                "size": {
                    "value": "(1,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "wenet/utils/scheduler.py": {
        "torch": {}
    }
}