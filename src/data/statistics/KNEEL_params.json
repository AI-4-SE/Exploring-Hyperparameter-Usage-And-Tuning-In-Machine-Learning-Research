{
    "kneel/data/dataset.py": {
        "torch": {}
    },
    "kneel/data/pipeline.py": {
        "torch": {
            "DataLoader_133": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_ds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "LandmarkDataset(data_root=kvs['args'].dataset_root, split=x_train, hc_spacing=kvs['args'].hc_spacing, lc_spacing=kvs['args'].lc_spacing, transform=kvs['train_trf'], ann_type=kvs['args'].annotations, image_pad=kvs['args'].img_pad)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "kvs['args'].bs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "kvs['args'].n_threads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "worker_init_fn": {
                    "value": "lambda wid: np.random.seed(np.uint32(torch.initial_seed() + wid))",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "DataLoader_142": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_ds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "LandmarkDataset(data_root=kvs['args'].dataset_root, split=x_val, hc_spacing=kvs['args'].hc_spacing, lc_spacing=kvs['args'].lc_spacing, transform=kvs['val_trf'], ann_type=kvs['args'].annotations, image_pad=kvs['args'].img_pad)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "kvs['args'].val_bs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "kvs['args'].n_threads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.utils.data.sampler.SequentialSampler(data_source=val_ds)",
                            "Call"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                }
            },
            "SequentialSampler_139": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "val_ds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "LandmarkDataset(data_root=kvs['args'].dataset_root, split=x_val, hc_spacing=kvs['args'].hc_spacing, lc_spacing=kvs['args'].lc_spacing, transform=kvs['val_trf'], ann_type=kvs['args'].annotations, image_pad=kvs['args'].img_pad)",
                            "Call"
                        ]
                    ]
                }
            },
            "initial_seed_136": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "kneel/data/utils.py": {
        "torch": {
            "from_numpy_14": {
                "variable": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.from_numpy(img).float()",
                            "Call"
                        ],
                        [
                            "img.unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "img.transpose(0, 2).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "np.frombuffer(data.PixelData, dtype=np.uint16).copy().astype(np.float64)",
                            "Call"
                        ],
                        [
                            "img.max() - img",
                            "BinOp"
                        ],
                        [
                            "img.reshape((data.Rows, data.Columns))",
                            "Call"
                        ],
                        [
                            "img.copy()",
                            "Call"
                        ],
                        [
                            "img * multiplier",
                            "BinOp"
                        ],
                        [
                            "img.squeeze()",
                            "Call"
                        ],
                        [
                            "convert_img(img)",
                            "Call"
                        ],
                        [
                            "process_xray(img).astype(np.uint8)",
                            "Call"
                        ],
                        [
                            "cv2.resize(img_original, (int(img_original.shape[1] * scale), int(img_original.shape[0] * scale)))",
                            "Call"
                        ],
                        [
                            "tmp",
                            "Name"
                        ],
                        [
                            "cv2.resize(img_original, (int(img_original.shape[1] * scale), int(img_original.shape[0] * scale)))",
                            "Call"
                        ],
                        [
                            "tmp",
                            "Name"
                        ]
                    ]
                }
            },
            "from_numpy_208": {
                "variable": {
                    "value": "landmarks",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "landmarks.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_195": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(target, 0).unsqueeze(0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_195": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "kneel/inference/_utils.py": {
        "torch": {
            "stack_24": {
                "tensors": {
                    "value": "norm_trf(list(map(convert_img, dc.data)))",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "kneel/inference/pipeline/_annotator.py": {
        "torch": {
            "trace_51": {
                "variable": {
                    "value": "self.net",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "self.net",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_40": {
                "f": {
                    "value": "snp_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.fold_snapshots",
                            "Attribute"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'cpu'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "no_grad_50": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_151": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "kneel/model/_hourglass.py": {
        "torch": {
            "Sequential_15": {
                "variable": {
                    "value": "self.layer1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(n_inputs, bw, kernel_size=7, stride=2, padding=3)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_23": {
                "variable": {
                    "value": "self.layer2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "self.__make_hg_block(bw * 2, bw * 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_32": {
                "variable": {
                    "value": "self.mixer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Dropout2d(p=0.25)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_37": {
                "variable": {
                    "value": "self.out_block",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv2d(bw * 4, n_outputs, kernel_size=1, padding=0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Conv2d_16": {
                "in_channels": {
                    "value": "n_inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "bw",
                    "type": "variable",
                    "possible_values": [
                        [
                            "64",
                            "MethodArgument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "7",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "BatchNorm2d_17": {
                "num_features": {
                    "value": "bw",
                    "type": "variable",
                    "possible_values": [
                        [
                            "64",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_18": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "MaxPool2d_20": {
                "kernel_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Dropout2d_32": {
                "p": {
                    "value": "0.25",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout2d_34": {
                "p": {
                    "value": "0.25",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Conv2d_37": {
                "in_channels": {
                    "value": "bw * 4",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "n_outputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "6",
                            "MethodArgument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "kneel/model/_utils.py": {
        "torch": {
            "load_35": {
                "f": {
                    "value": "glob.glob(pattern_snp)[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "kneel/training/_utils.py": {
        "torch": {
            "set_grad_enabled_28": {
                "mode": {
                    "value": "optimizer is not None",
                    "type": "Compare",
                    "possible_values": []
                }
            }
        }
    },
    "scripts/experiments_runner.py": {
        "torch": {
            "device_count_44": {
                "variable": {
                    "value": "n_gpus",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "scripts/oof_inference.py": {
        "torch": {
            "from_numpy_25": {
                "variable": {
                    "value": "mean_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "mean_vector",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.from_numpy(mean_vector).unsqueeze(1).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_25": {
                "variable": {
                    "value": "mean_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "from_numpy_26": {
                "variable": {
                    "value": "std_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "std_vector",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.from_numpy(std_vector).unsqueeze(1).unsqueeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_26": {
                "variable": {
                    "value": "std_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_57": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_64": {
                "variable": {
                    "value": "net",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "net",
                    "type": "variable",
                    "possible_values": [
                        [
                            "init_model()",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(net)",
                            "Call"
                        ]
                    ]
                }
            },
            "device_count_63": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_62": {
                "f": {
                    "value": "snp_weigths_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "glob.glob(os.path.join(snp_full_path, f'fold_{fold_id}*.pth'))[0]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    }
}