{
    "dependencies_graph/examine_predictions.py": {
        "sklearn": {
            "confusion_matrix_479": {
                "variable": {
                    "value": "cm",
                    "type": "variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "np.concatenate([np.asarray(x).reshape(-1) for x in golds])",
                    "type": "Call",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "np.concatenate([np.asarray(x).reshape(-1) for x in preds])",
                    "type": "Call",
                    "possible_values": []
                },
                "labels": {
                    "value": "[token_to_index[x] for x in labels]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "normalize": {
                    "value": "normalize",
                    "type": "variable",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "from_numpy_444": {
                "variable": {
                    "value": "gold_t",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "gold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "token_dep_to_adjenc(gold_[0], gold_[2], classes_counts)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_444": {
                "variable": {
                    "value": "gold_t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "from_numpy_445": {
                "variable": {
                    "value": "pred_t",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pred_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(np.arange(max(index_to_token.keys()) + 1) == pred[..., None]).astype(int)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_445": {
                "variable": {
                    "value": "pred_t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/data/fields/adjacency_field.py": {
        "torch": {
            "ones_41": {
                "*size": {
                    "value": "desired_num_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "padding_lengths['num_tokens']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "desired_num_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "padding_lengths['num_tokens']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "qdecomp_nlp/data/fields/multilabel_adjacency_field.py": {
        "torch": {
            "ones_129": {
                "*size": {
                    "value": "desired_num_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "padding_lengths['num_tokens']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "desired_num_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "padding_lengths['num_tokens']",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "self._num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/data/samplers/multidatasets_bucket_batch_sampler.py": {
        "torch": {}
    },
    "qdecomp_nlp/data/token_indexers/dependencies_graph_indexer.py": {
        "torch": {}
    },
    "qdecomp_nlp/data/token_indexers/multi_indexers_indexer.py": {
        "torch": {}
    },
    "qdecomp_nlp/models/dependencies_graph/biaffine_graph_parser.py": {
        "torch": {
            "Dropout_143": {
                "variable": {
                    "value": "self._input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "input_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_178": {
                "variable": {
                    "value": "self._arc_loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "eye_447": {
                "variable": {
                    "value": "diagonal_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "n": {
                    "value": "mask.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_228": {
                "variable": {
                    "value": "embedded_text_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text_input, embedded_pos_tags]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ones_like_450": {
                "variable": {
                    "value": "arc_tags_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.tag_bilinear(head_tag_representation, child_tag_representation)",
                            "Call"
                        ],
                        [
                            "arc_tag_logits.permute(0, 2, 3, 1).contiguous()",
                            "Call"
                        ]
                    ]
                }
            },
            "BCEWithLogitsLoss_179": {
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_180": {
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "sum_283": {
                "variable": {
                    "value": "arc_tags_count",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_probs > self.tag_prediction_threshold",
                    "type": "Compare",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "stack_308": {
                "variable": {
                    "value": "arc_tag_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[1 - arc_tag_probs, arc_tag_probs]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_297": {
                "variable": {
                    "value": "arc_tag_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[arc_tag_probs * pred_arcs, 1 - pred_arcs]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "stack_302": {
                "tensors": {
                    "value": "[one_minus_arc_probs, arc_probs]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "stack_303": {
                "tensors": {
                    "value": "[one_minus_arc_probs, arc_probs]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "diag_277": {
                "input": {
                    "value": "arc_mask.new_ones(arc_mask.size(-1)).int()",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/dependencies_graph/operators_aware_biaffine_graph_parser.py": {
        "torch": {
            "tensor_118": {
                "variable": {
                    "value": "operator_to_tag",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[[all((any((get_operator(t) == o for o in operator.split('&'))) for t in tag.split('&'))) or tag in ['NONE', 'duplicate'] for tag in vocab.get_token_to_index_vocabulary(self._tags_namespace)] for operator in vocab.get_token_to_index_vocabulary(self._operators_namespace)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_136": {
                "variable": {
                    "value": "self._operator_classification_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._operator_feedforward.get_output_dim()",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_operators",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab.get_vocab_size(self._operators_namespace)",
                            "Call"
                        ]
                    ]
                }
            },
            "Dropout_156": {
                "variable": {
                    "value": "self._input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "input_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_184": {
                "variable": {
                    "value": "self._operators_loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_185": {
                "variable": {
                    "value": "self._tag_loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "eye_416": {
                "variable": {
                    "value": "diagonal_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "n": {
                    "value": "mask.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ones_like_419": {
                "variable": {
                    "value": "arc_tags_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._tag_bilinear(head_tag_representation, child_tag_representation)",
                            "Call"
                        ],
                        [
                            "arc_tag_logits.permute(0, 2, 3, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "arc_tag_probs_ * torch.matmul(operator_probs, self._operator_to_tag.float()).unsqueeze(-2)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "ones_151": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_operators",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab.get_vocab_size(self._operators_namespace)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_245": {
                "variable": {
                    "value": "operators_emb",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "operator_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "masked_softmax(operator_logits, mask.unsqueeze(-1))",
                            "Call"
                        ],
                        [
                            "_prop_getter('operator_probs').cpu().detach()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self._operators_embedder_mask.unsqueeze(-1) * self._operators_embedder.weight",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_246": {
                "variable": {
                    "value": "encoded_text",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encoded_text, operators_emb]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "argmax_428": {
                "variable": {
                    "value": "operators",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "operator_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "masked_softmax(operator_logits, mask.unsqueeze(-1))",
                            "Call"
                        ],
                        [
                            "_prop_getter('operator_probs').cpu().detach()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "matmul_435": {
                "input": {
                    "value": "operator_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "masked_softmax(operator_logits, mask.unsqueeze(-1))",
                            "Call"
                        ],
                        [
                            "_prop_getter('operator_probs').cpu().detach()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self._operator_to_tag.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "unsqueeze_435": {
                "input": {
                    "value": "-2",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/dependencies_graph/pairwised_encoding_graph_parser.py": {
        "torch": {
            "Linear_89": {
                "variable": {
                    "value": "self._classification_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._pairs_encoder.get_output_dim()",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_108": {
                "variable": {
                    "value": "self._input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "input_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_110": {
                "variable": {
                    "value": "self._loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "softmax_168": {
                "variable": {
                    "value": "arc_tag_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._classification_layer(pairs_encodings)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_163": {
                "variable": {
                    "value": "pairs_encodings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encoded_text_head, encoded_text_child]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/hybrid/multitask_model.py": {
        "torch": {
            "tensor_60": {
                "variable": {
                    "value": "outoput[task_index]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "self._task_to_index[task]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/hybrid/multitask_rat_based.py": {
        "torch": {
            "CrossEntropyLoss_65": {
                "variable": {
                    "value": "self._arc_tags_loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "tensor_95": {
                "variable": {
                    "value": "output[is_seq2seq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "task == 'seq2seq'",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "ModuleList_59": {
                "variable": {
                    "value": "self._classification_layer_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[torch.nn.Linear(relations_encoding_dim, self._num_labels) for _ in range(N)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_60": {
                "variable": {
                    "value": "self._classification_layer_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[torch.nn.Linear(relations_encoding_dim, self._num_labels) for _ in range(N)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_62": {
                "variable": {
                    "value": "self._classification_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "2 * relations_encoding_dim",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_125": {
                "variable": {
                    "value": "arc_tag_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "agg_func(torch.stack([*arc_tag_probs_k, *arc_tag_probs_v], dim=-1), dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.softmax(arc_tag_probs, dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.softmax(arc_tag_logits, dim=-1)",
                            "Call"
                        ],
                        [
                            "_prop_getter('arc_tag_probs').cpu().detach().numpy()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_129": {
                "variable": {
                    "value": "relations_enc",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[relation_k[0], relation_v[0]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_131": {
                "variable": {
                    "value": "arc_tag_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._classification_layer(relations_enc)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_118": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_119": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "stack_124": {
                "tensors": {
                    "value": "[*arc_tag_probs_k, *arc_tag_probs_v]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Linear_59": {
                "in_features": {
                    "value": "relations_encoding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_60": {
                "in_features": {
                    "value": "relations_encoding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/hybrid/multitask_soft_rat_based.py": {
        "torch": {}
    },
    "qdecomp_nlp/models/seq2seq/copynet_seq2seq_dynamic.py": {
        "torch": {
            "Linear_130": {
                "variable": {
                    "value": "self._input_projection_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "target_embedding_dim + self.encoder_output_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.decoder_input_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTMCell_136": {
                "variable": {
                    "value": "self._decoder_cell",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self.decoder_input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self.decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_140": {
                "variable": {
                    "value": "self._output_generation_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._target_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_145": {
                "variable": {
                    "value": "self._output_copying_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.encoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_356": {
                "variable": {
                    "value": "decoder_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(embedded_input, attentive_read, selective_read)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tanh_397": {
                "variable": {
                    "value": "copy_projection",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "copy_projection",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._output_copying_layer(encoder_outputs)",
                            "Call"
                        ],
                        [
                            "torch.tanh(copy_projection)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_436": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores_mask, source_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_438": {
                "variable": {
                    "value": "all_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores, copy_scores)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_469": {
                "variable": {
                    "value": "combined_gen_and_copy",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_log_probs, copy_log_probs)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_556": {
                "variable": {
                    "value": "log_likelihoods",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_log_likelihoods",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_765": {
                "variable": {
                    "value": "modified_log_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "modified_log_probs_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_833": {
                "variable": {
                    "value": "all_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores, copy_scores)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_844": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(dynamic_mask, source_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "bmm_376": {
                "variable": {
                    "value": "dot_product_result",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['decoder_hidden'].view(batch_size, 1, embedding_dim)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "allowed_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['allowed_embedded_input'].transpose(1, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_376": {
                "variable": {
                    "value": "dot_product_result",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim0": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_like_384": {
                "variable": {
                    "value": "dynamic_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "generation_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._adjust_target_outputs(output_projections, state['allowed_token_ids'], state['allowed_mask'], fill_value=fill_value)",
                            "Call"
                        ],
                        [
                            "self._output_generation_layer(state['decoder_hidden'])",
                            "Call"
                        ]
                    ]
                }
            },
            "scatter_384": {
                "variable": {
                    "value": "dynamic_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "state['allowed_token_ids']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self._encode(source_tokens)",
                            "Call"
                        ],
                        [
                            "self._init_decoder_state(state)",
                            "Call"
                        ],
                        [
                            "self._init_decoder_state(state)",
                            "Call"
                        ],
                        [
                            "self._decoder_step(input_choices, selective_weights, state)",
                            "Call"
                        ],
                        [
                            "self._decoder_step(input_choices, selective_weights, state)",
                            "Call"
                        ]
                    ]
                },
                "value": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "autocast_361": {
                "device_type": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "cat_737": {
                "variable": {
                    "value": "combined",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(copy_log_probs_slice.unsqueeze(-1), future_copy_log_probs)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_541": {
                "tensors": {
                    "value": "[generation_scores_mask, source_mask]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "unsqueeze_541": {
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_715": {
                "tensors": {
                    "value": "(selected_generation_log_probs, copy_log_probs_to_add)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/seq2seq/custom_bart.py": {
        "torch": {
            "tensor_120": {
                "variable": {
                    "value": "initial_decoder_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[[self._decoder_start_id]]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "input_ids.dtype",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/seq2seq/custom_copynet_seq2seq.py": {
        "torch": {
            "Linear_128": {
                "variable": {
                    "value": "self._input_projection_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "target_embedding_dim + self.encoder_output_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.decoder_input_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTMCell_134": {
                "variable": {
                    "value": "self._decoder_cell",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self.decoder_input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self.decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_138": {
                "variable": {
                    "value": "self._output_generation_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._target_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_143": {
                "variable": {
                    "value": "self._output_copying_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.encoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_328": {
                "variable": {
                    "value": "decoder_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(embedded_input, attentive_read, selective_read)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tanh_350": {
                "variable": {
                    "value": "copy_projection",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "copy_projection",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._output_copying_layer(encoder_outputs)",
                            "Call"
                        ],
                        [
                            "torch.tanh(copy_projection)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_390": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores_mask, source_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_392": {
                "variable": {
                    "value": "all_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores, copy_scores)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_423": {
                "variable": {
                    "value": "combined_gen_and_copy",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_log_probs, copy_log_probs)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_509": {
                "variable": {
                    "value": "log_likelihoods",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_log_likelihoods",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_727": {
                "variable": {
                    "value": "modified_log_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "modified_log_probs_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_796": {
                "variable": {
                    "value": "all_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores, copy_scores)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_800": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores.new_full(generation_scores.size(), True, dtype=torch.bool), source_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "autocast_333": {
                "device_type": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "cat_695": {
                "variable": {
                    "value": "combined",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(copy_log_probs_slice.unsqueeze(-1), future_copy_log_probs)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_672": {
                "tensors": {
                    "value": "(selected_generation_log_probs, copy_log_probs_to_add)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/seq2seq/custom_copynet_seq2seq_for_rat.py": {
        "torch": {
            "sum_40": {
                "input": {
                    "value": "relations != -1",
                    "type": "Compare",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/seq2seq/custom_copynet_seq2seq_for_soft_rat.py": {
        "torch": {}
    },
    "qdecomp_nlp/models/seq2seq/seq2seq_transformers.py": {
        "torch": {
            "argmax_92": {
                "variable": {
                    "value": "predicted_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "predictions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "outputs[0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_88": {
                "data": {
                    "value": "dummy['input_ids']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/seq2seq/simple_seq2seq_custom.py": {
        "torch": {}
    },
    "qdecomp_nlp/models/seq2seq/simple_seq2seq_dynamic.py": {
        "torch": {
            "Linear_167": {
                "variable": {
                    "value": "self._output_projection_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.vocab.get_vocab_size(self._target_namespace)",
                            "Call"
                        ],
                        [
                            "allowed_mask.sum(dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_429": {
                "variable": {
                    "value": "predictions",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_predictions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "bmm_536": {
                "variable": {
                    "value": "dot_product_result",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "last_decoder_hidden.view(batch_size, 1, embedding_dim)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "allowed_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['allowed_embedded_input'].transpose(1, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_536": {
                "variable": {
                    "value": "dot_product_result",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim0": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "LSTM_157": {
                "variable": {
                    "value": "self._decoder_cell",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "self._decoder_input_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTMCell_163": {
                "variable": {
                    "value": "self._decoder_cell",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self._decoder_input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self._decoder_output_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "max_421": {
                "variable": {
                    "value": "(_, predicted_classes)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "class_probabilities",
                    "type": "variable",
                    "possible_values": [
                        [
                            "util.masked_softmax(output_projections, mask, dim=-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_435": {
                "variable": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_436": {
                "variable": {
                    "value": "logit_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_498": {
                "variable": {
                    "value": "decoder_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(attended_input, embedded_input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "autocast_510": {
                "device_type": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "autocast_518": {
                "device_type": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "rand_393": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/models/util.py": {
        "torch": {
            "log_softmax_56": {
                "variable": {
                    "value": "log_probs_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "logits.view(-1, logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_like_67": {
                "variable": {
                    "value": "one_hot_targets",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_probs_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(logits_flat, dim=-1)",
                            "Call"
                        ],
                        [
                            "log_probs_flat * logit_mask_flat",
                            "BinOp"
                        ]
                    ]
                }
            },
            "gather_76": {
                "input": {
                    "value": "log_probs_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(logits_flat, dim=-1)",
                            "Call"
                        ],
                        [
                            "log_probs_flat * logit_mask_flat",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "targets_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "targets.view(-1, 1).long()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "qdecomp_nlp/modules/seq2seq_encoders/latent_relation_aware_transformer.py": {
        "torch": {}
    },
    "qdecomp_nlp/modules/seq2seq_encoders/rat_sql_transformer_wrapper.py": {
        "torch": {
            "matmul_25": {
                "variable": {
                    "value": "qk_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query",
                    "type": "variable",
                    "possible_values": []
                },
                "other": {
                    "value": "key.transpose(-2, -1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_38": {
                "variable": {
                    "value": "q_tr_t_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.permute(0, 2, 1, 3)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "r_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "relation.transpose(-2, -1)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_83": {
                "variable": {
                    "value": "wv_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "other": {
                    "value": "value",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "matmul_91": {
                "variable": {
                    "value": "w_tr_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "w_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.permute(0, 2, 1, 3)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "relation",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "softmax_110": {
                "variable": {
                    "value": "p_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)",
                            "BinOp"
                        ],
                        [
                            "scores.masked_fill(mask == 0, -1000000000.0)",
                            "Call"
                        ],
                        [
                            "relative_attention_logits(query, key, relation_k)",
                            "Call"
                        ],
                        [
                            "scores.masked_fill(mask == 0, -1000000000.0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_180": {
                "variable": {
                    "value": "p_attn_orig",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)",
                            "BinOp"
                        ],
                        [
                            "scores.masked_fill(mask == 0, -1000000000.0)",
                            "Call"
                        ],
                        [
                            "relative_attention_logits(query, key, relation_k)",
                            "Call"
                        ],
                        [
                            "scores.masked_fill(mask == 0, -1000000000.0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ModuleList_101": {
                "modules": {
                    "value": "[module_fn() for _ in range(N)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Dropout_146": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.2",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_192": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.2",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Embedding_194": {
                "variable": {
                    "value": "self.relation_k_emb",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_relation_kinds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_195": {
                "variable": {
                    "value": "self.relation_v_emb",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_relation_kinds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_228": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.2",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "LayerNorm_272": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "layer_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LayerNorm_292": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_293": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.2",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_341": {
                "variable": {
                    "value": "self.w_1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_ff",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_342": {
                "variable": {
                    "value": "self.w_2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_ff",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Dropout_343": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.2",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ],
                        [
                            "0.1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "matmul_107": {
                "input": {
                    "value": "query",
                    "type": "variable",
                    "possible_values": []
                },
                "other": {
                    "value": "key.transpose(-2, -1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_114": {
                "input": {
                    "value": "p_attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.softmax(scores, dim=-1)",
                            "Call"
                        ],
                        [
                            "dropout(p_attn)",
                            "Call"
                        ],
                        [
                            "dropout(p_attn_orig)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_144": {
                "in_features": {
                    "value": "d_model",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_190": {
                "in_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_226": {
                "in_features": {
                    "value": "d_model",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "relu_346": {
                "input": {
                    "value": "self.w_1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/modules/seq2seq_encoders/relation_aware_transformer.py": {
        "torch": {}
    },
    "qdecomp_nlp/modules/seq2seq_encoders/soft_relation_aware_transformer.py": {
        "torch": {
            "matmul_69": {
                "variable": {
                    "value": "relation_k",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relation",
                    "type": "variable",
                    "possible_values": []
                },
                "other": {
                    "value": "self.relation_k_emb.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_70": {
                "variable": {
                    "value": "relation_v",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relation",
                    "type": "variable",
                    "possible_values": []
                },
                "other": {
                    "value": "self.relation_v_emb.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/modules/token_embedders/aggregated_pretrained_transformer_embedder.py": {
        "torch": {
            "stack_73": {
                "tensors": {
                    "value": "embeddings_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "tensor_63": {
                "data": {
                    "value": "indices['token_ids']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "unsqueeze_63": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_65": {
                "data": {
                    "value": "fixed_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[1 if t.text != self._tokenizer.tokenizer._pad_token else 0 for t in new_tokens]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "unsqueeze_65": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_66": {
                "data": {
                    "value": "indices['type_ids']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "unsqueeze_66": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/modules/token_embedders/custom_pretrained_transformer_mismatched.py": {
        "torch": {}
    },
    "qdecomp_nlp/modules/token_embedders/dependencies_graph_embedder.py": {
        "torch": {
            "cat_149": {
                "variable": {
                    "value": "in_arc_tag_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[expanded_head_encodings, arc_tags_embeddings]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_157": {
                "variable": {
                    "value": "out_arc_tag_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[expanded_child_encodings, arc_tags_embeddings]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_164": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encodings, in_embeddings, out_embeddings]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_94": {
                "variable": {
                    "value": "head_encodings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[internals['head_arc_feedforward'], internals['head_tag_feedforward']]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_95": {
                "variable": {
                    "value": "child_encodings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[internals['child_arc_feedforward'], internals['child_tag_feedforward']]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "arange_133": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "self._arc_tags_number",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "arc_probs.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/modules/token_embedders/fields_list_embedder.py": {
        "torch": {
            "ModuleList_35": {
                "modules": {
                    "value": "[Embedding(embedding_dim=emb_dim[i], vocab_namespace=namespaces[i], vocab=vocab, **kwargs) for i in range(self._parts_num)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "cat_50": {
                "variable": {
                    "value": "joint_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[emb(input[:, i].contiguous()) * mask[:, i].unsqueeze(-1) for (i, emb) in enumerate(self._embeddings)]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "qdecomp_nlp/training/learning_rate_schedulers/custom_slanted_triangular.py": {
        "torch": {}
    },
    "qdecomp_nlp/training/metrics/logical_form_em.py": {
        "torch": {}
    },
    "scripts/train/run_experiments.py": {
        "torch": {
            "empty_cache_141": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "scripts/utils/tar_to_tar.py": {
        "torch": {
            "load_25": {
                "variable": {
                    "value": "model_state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(tmpdirname, 'weights.th')",
                    "type": "Call",
                    "possible_values": []
                },
                "map_location": {
                    "value": "util.device_mapping(args.cuda_device)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "save_39": {
                "obj": {
                    "value": "model_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.load(os.path.join(tmpdirname, 'weights.th'), map_location=util.device_mapping(args.cuda_device))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(tmpdirname, 'weights.th')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    }
}