{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def df_to_latex(df: pd.DataFrame) -> None:\n",
    "    print(df.to_latex(index=False))\n",
    "\n",
    "def get_module(name, data):\n",
    "    module = next(filter(lambda x: name == x[\"name\"], data))\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "   Library &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      "   sklearn &      11573 & 1992 &      360 &    1632 \\\\\n",
      "tensorflow &       4446 &  415 &       41 &     374 \\\\\n",
      "     torch &      25644 & 6756 &      322 &    6434 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_all_parameters(library_name: str, library_dir: str, files: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [module[\"name\"] for module in library_data]\n",
    "\n",
    "        # Get Most used Class\n",
    "    classes = []\n",
    "    total_params_set = 0\n",
    "    total_params_available = 0\n",
    "    default_params = 0\n",
    "    customized_params = 0\n",
    "    for project in glob.glob(files):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "                                \n",
    "                                if class_name not in class_names:\n",
    "                                    continue\n",
    "\n",
    "                                library_module_data = get_module(class_name, library_data)\n",
    "                                library_module_params = library_module_data[\"params\"]\n",
    "                                total_params_available += len(library_module_params)\n",
    "\n",
    "                                for name, value in data.items():\n",
    "                                    if name in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        total_params_set += 1\n",
    "                                        if name in library_module_params.keys():\n",
    "\n",
    "                                            if str(library_module_params[name]).replace(\"'\", \"\") == value[\"value\"]:\n",
    "                                                default_params += 1\n",
    "                                            else:\n",
    "                                                customized_params += 1\n",
    "                                        else:\n",
    "                                            customized_params += 1\n",
    "\n",
    "\n",
    "    assert total_params_set == default_params + customized_params\n",
    "\n",
    "    #print(library_name)\n",
    "    #print(\"total params set:\", total_params_set)\n",
    "    #print(\"total params available:\", total_params_available)\n",
    "    #print(\"default params: \", default_params)\n",
    "    #print(\"custom params: \", customized_params)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"Library\"] = [library_name]\n",
    "    df[\"Available\"] = [total_params_available]\n",
    "    df[\"Set\"] = [total_params_set]\n",
    "    df[\"Default\"] = [default_params]\n",
    "    df[\"Custom\"] = [customized_params]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Count params of all methods\n",
    "df_sklearn = count_all_parameters(\"sklearn\", \"../modules/sklearn_estimators.json\" , \"../data/statistics/*\")\n",
    "df_tf = count_all_parameters(\"tensorflow\", \"../modules/tensorflow_optimizer.json\" , \"../data/statistics/*\")\n",
    "df_pytorch = count_all_parameters(\"torch\", \"../modules/torch_optimizer.json\" , \"../data/statistics/*\")\n",
    "df_all = pd.concat([df_sklearn, df_tf, df_pytorch])\n",
    "\n",
    "df_to_latex(df=df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "   Library &  Available &  Set &  Default &  Custom \\\\\n",
      "\\midrule\n",
      "   sklearn &       3558 &  622 &      120 &     502 \\\\\n",
      "tensorflow &       1547 &  157 &       20 &     137 \\\\\n",
      "     torch &       6801 & 1753 &       72 &    1681 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_ml_method_params(library_name: str, library_dir: str, files: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [module[\"name\"] for module in library_data]\n",
    "\n",
    "    total_params_set = 0\n",
    "    total_params_available = 0\n",
    "    default_params = 0\n",
    "    customized_params = 0\n",
    "\n",
    "    for project in files:\n",
    "        with open(\"../data/statistics/\" + project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "                                \n",
    "                                if class_name not in class_names:\n",
    "                                    continue\n",
    "\n",
    "                                library_module_data = get_module(class_name, library_data)\n",
    "                                library_module_params = library_module_data[\"params\"]\n",
    "                                total_params_available += len(library_module_params)\n",
    "\n",
    "                                for name, value in data.items():\n",
    "                                    if name in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        total_params_set += 1\n",
    "                                        if name in library_module_params.keys():\n",
    "\n",
    "                                            if str(library_module_params[name]).replace(\"'\", \"\") == value[\"value\"]:\n",
    "                                                default_params += 1\n",
    "                                            else:\n",
    "                                                customized_params += 1\n",
    "                                        else:\n",
    "                                            customized_params += 1\n",
    "\n",
    "\n",
    "    assert total_params_set == default_params + customized_params\n",
    "\n",
    "    #print(library_name)\n",
    "    #print(\"total params set:\", total_params_set)\n",
    "    #print(\"total params available:\", total_params_available)\n",
    "    #print(\"default params: \", default_params)\n",
    "    #print(\"custom params: \", customized_params)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"Library\"] = [library_name]\n",
    "    df[\"Available\"] = [total_params_available]\n",
    "    df[\"Set\"] = [total_params_set]\n",
    "    df[\"Default\"] = [default_params]\n",
    "    df[\"Custom\"] = [customized_params]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Count params of ML methods\n",
    "with open(\"../data/repos_hyperparameter_tuning.json\", \"r\", encoding=\"utf-8\") as src:\n",
    "    repos_files = json.load(src)\n",
    "\n",
    "df_sklearn = count_ml_method_params(\"sklearn\", \"../modules/sklearn_estimators.json\" , repos_files)\n",
    "df_tf = count_ml_method_params(\"tensorflow\", \"../modules/tensorflow_optimizer.json\" , repos_files)\n",
    "df_pytorch = count_ml_method_params(\"torch\", \"../modules/torch_optimizer.json\" , repos_files)\n",
    "df_all = pd.concat([df_sklearn, df_tf, df_pytorch])\n",
    "\n",
    "df_to_latex(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
