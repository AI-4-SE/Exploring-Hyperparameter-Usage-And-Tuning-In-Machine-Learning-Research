{
    "allennlp/allennlp/training/metrics/auc.py": {
        "sklearn": {
            "roc_curve_90": {
                "variable": {
                    "value": "(false_positive_rates, true_positive_rates, _)",
                    "possible_values": []
                },
                "y_true": {
                    "value": "self._all_gold_labels.numpy()",
                    "possible_values": []
                },
                "y_score": {
                    "value": "self._all_predictions.numpy()",
                    "possible_values": []
                },
                "pos_label": {
                    "value": "self._positive_label",
                    "possible_values": []
                }
            },
            "auc_95": {
                "variable": {
                    "value": "auc",
                    "possible_values": []
                },
                "x": {
                    "value": "false_positive_rates",
                    "possible_values": []
                },
                "y": {
                    "value": "true_positive_rates",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "unique_59": {
                "variable": {
                    "value": "unique_gold_labels",
                    "possible_values": []
                },
                "input": {
                    "value": "gold_labels",
                    "possible_values": []
                }
            },
            "cat_78": {
                "variable": {
                    "value": "self._all_predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self._all_predictions, torch.masked_select(predictions, mask).float()]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_82": {
                "variable": {
                    "value": "self._all_gold_labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self._all_gold_labels, torch.masked_select(gold_labels, mask).long()]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "ones_75": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "gold_labels.shape[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "masked_select_79": {
                "input": {
                    "value": "predictions",
                    "possible_values": []
                },
                "mask": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "torch.ones(batch_size)",
                            "Call"
                        ],
                        [
                            "mask.to(dtype=torch.bool)",
                            "Call"
                        ]
                    ]
                }
            },
            "masked_select_83": {
                "input": {
                    "value": "gold_labels",
                    "possible_values": []
                },
                "mask": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "torch.ones(batch_size)",
                            "Call"
                        ],
                        [
                            "mask.to(dtype=torch.bool)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "build_dgl_graph.py": {
        "sklearn": {
            "Normalizer_870": {
                "variable": {
                    "value": "self.normalizer",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "f1_score_355": {
                "y_true": {
                    "value": "graph_y.detach().float().cpu().numpy()",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "graph_logits.detach().cpu().numpy()",
                    "possible_values": []
                },
                "average": {
                    "value": "binary",
                    "possible_values": []
                }
            },
            "f1_score_381": {
                "y_true": {
                    "value": "nodes_y.detach().float().cpu().numpy()",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "nodes_logits.detach().cpu().numpy()",
                    "possible_values": []
                },
                "average": {
                    "value": "binary",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "device_44": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "GraphNN_492": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_505": {
                    "variable": {
                        "value": "self.node_type_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "len(K.id2node_type)",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "self.node_type_embedding_size",
                        "possible_values": []
                    }
                },
                "Linear_509": {
                    "variable": {
                        "value": "self.projection_layer_node_init",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.node_type_embedding_size + self.text_rep_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.node_hidden_size",
                        "possible_values": []
                    }
                },
                "Embedding_512": {
                    "variable": {
                        "value": "self.edge_type_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "len(K.id2edge_type)",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "self.edge_type_embedding_size",
                        "possible_values": []
                    }
                }
            },
            "ClfHead_685": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_688": {
                    "variable": {
                        "value": "self.lin1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "input_dim",
                        "possible_values": [
                            [
                                "config['node_hidden_size']",
                                "Subscript"
                            ],
                            [
                                "input_dim * 3",
                                "BinOp"
                            ],
                            [
                                "200",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "out_features": {
                        "value": "int(input_dim / 2)",
                        "possible_values": []
                    }
                },
                "Linear_689": {
                    "variable": {
                        "value": "self.lin2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "int(input_dim / 2)",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                }
            },
            "CombinedDataset_695": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.G_encoder": {
                    "value": "G_encoder",
                    "possible_values": [
                        [
                            "GAT(config['node_hidden_size'], config['node_hidden_size'], config['num_graph_heads'], merge=config['graph_head_merge_type'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "G_encoder.to(device)",
                            "Call"
                        ],
                        [
                            "GCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "TAGCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ]
                    ]
                },
                "self.neg_class": {
                    "value": "neg_class",
                    "possible_values": [
                        [
                            "-1 if isinstance(criterion, HingeLoss) or criterion == nn.HingeEmbeddingLoss else 0",
                            "IfExp"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.decay_factor": {
                    "value": "decay_factor",
                    "possible_values": []
                },
                "self.init_num_perturb_actions": {
                    "value": "init_num_perturb_actions",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "GraphDataset_752": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.G_encoder": {
                    "value": "G_encoder",
                    "possible_values": [
                        [
                            "GAT(config['node_hidden_size'], config['node_hidden_size'], config['num_graph_heads'], merge=config['graph_head_merge_type'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "G_encoder.to(device)",
                            "Call"
                        ],
                        [
                            "GCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "TAGCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ]
                    ]
                },
                "self.neg_class": {
                    "value": "neg_class",
                    "possible_values": [
                        [
                            "-1 if isinstance(criterion, HingeLoss) or criterion == nn.HingeEmbeddingLoss else 0",
                            "IfExp"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.decay_factor": {
                    "value": "decay_factor",
                    "possible_values": []
                },
                "self.init_num_perturb_actions": {
                    "value": "init_num_perturb_actions",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "NodesDataset_803": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.G_encoder": {
                    "value": "G_encoder",
                    "possible_values": [
                        [
                            "GAT(config['node_hidden_size'], config['node_hidden_size'], config['num_graph_heads'], merge=config['graph_head_merge_type'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "G_encoder.to(device)",
                            "Call"
                        ],
                        [
                            "GCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "TAGCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ]
                    ]
                },
                "self.neg_class": {
                    "value": "neg_class",
                    "possible_values": [
                        [
                            "-1 if isinstance(criterion, HingeLoss) or criterion == nn.HingeEmbeddingLoss else 0",
                            "IfExp"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.decay_factor": {
                    "value": "decay_factor",
                    "possible_values": []
                },
                "self.init_num_perturb_actions": {
                    "value": "init_num_perturb_actions",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "VanillaDataset_860": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.G_encoder": {
                    "value": "G_encoder",
                    "possible_values": [
                        [
                            "GAT(config['node_hidden_size'], config['node_hidden_size'], config['num_graph_heads'], merge=config['graph_head_merge_type'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "G_encoder.to(device)",
                            "Call"
                        ],
                        [
                            "GCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ],
                        [
                            "TAGCN(config['node_hidden_size'], config['node_hidden_size'], config['num_gencoder_layers'], None, config['gencoder_dropout'], aggregation=config['graph_aggregation'])",
                            "Call"
                        ]
                    ]
                },
                "self.x": {
                    "value": "x",
                    "possible_values": []
                },
                "self.y": {
                    "value": "y",
                    "possible_values": []
                }
            },
            "Adam_151": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "itertools.chain(G_encoder.parameters(), clf.parameters())",
                    "possible_values": []
                }
            },
            "StepLR_152": {
                "variable": {
                    "value": "scheduler",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "possible_values": [
                        [
                            "Adam(itertools.chain(G_encoder.parameters(), clf.parameters()))",
                            "Call"
                        ]
                    ]
                },
                "step_size": {
                    "value": "10",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.7",
                    "possible_values": []
                }
            },
            "MSELoss_892": {
                "variable": {
                    "value": "criterion",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "save_123": {
                "obj": {
                    "value": "{'clf_state_dict': clf.state_dict(), 'clfNodes': clfNodes.state_dict(), 'G_encoder_state_dict': G_encoder.state_dict()}",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(config['reward_serialization_dir'], '{}_{}.th'.format(args.model_name, args.encoder_type))",
                    "possible_values": []
                }
            },
            "L1Loss_143": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_44": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_73": {
                "tensors": {
                    "value": "batch",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "out": {
                    "value": "out",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "elem.new(storage)",
                            "Call"
                        ]
                    ]
                }
            },
            "eq_350": {
                "input": {
                    "value": "graph_logits.detach().cpu()",
                    "possible_values": []
                },
                "other": {
                    "value": "graph_y.detach().float().cpu()",
                    "possible_values": []
                }
            },
            "sum_350": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tensor_533": {
                "variable": {
                    "value": "text_encoding",
                    "possible_values": []
                }
            },
            "unsqueeze_533": {
                "variable": {
                    "value": "text_encoding",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_535": {
                "variable": {
                    "value": "init_vector",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[type_embedding, text_encoding]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Tensor_739": {
                "variable": {
                    "value": "nodes_Y",
                    "possible_values": []
                }
            },
            "Tensor_850": {
                "variable": {
                    "value": "nodes_Y",
                    "possible_values": []
                }
            },
            "DataLoader_157": {
                "dataset": {
                    "value": "train_data",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "32",
                            "MethodArgument"
                        ],
                        [
                            "32",
                            "MethodArgument"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "eq_376": {
                "input": {
                    "value": "nodes_logits.detach().cpu()",
                    "possible_values": []
                },
                "other": {
                    "value": "nodes_y.detach().float().cpu()",
                    "possible_values": []
                }
            },
            "sum_376": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "relu_692": {
                "input": {
                    "value": "self.lin1(x)",
                    "possible_values": []
                }
            },
            "Tensor_741": {
                "variable": {
                    "value": "nodes_Y",
                    "possible_values": []
                }
            },
            "Tensor_852": {
                "variable": {
                    "value": "nodes_Y",
                    "possible_values": []
                }
            },
            "tensor_89": {
                "data": {
                    "value": "batch",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "possible_values": []
                }
            },
            "DataLoader_163": {
                "dataset": {
                    "value": "train_dataset",
                    "possible_values": [
                        [
                            "CombinedDataset(G_encoder, train_data, neg_class, epoch, init_num_perturb_actions)",
                            "Call"
                        ],
                        [
                            "GraphDataset(G_encoder, train_data, neg_class, epoch, init_num_perturb_actions)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "32",
                            "MethodArgument"
                        ],
                        [
                            "32",
                            "MethodArgument"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "my_collate",
                    "possible_values": []
                }
            },
            "DataLoader_173": {
                "dataset": {
                    "value": "train_dataset",
                    "possible_values": [
                        [
                            "CombinedDataset(G_encoder, train_data, neg_class, epoch, init_num_perturb_actions)",
                            "Call"
                        ],
                        [
                            "GraphDataset(G_encoder, train_data, neg_class, epoch, init_num_perturb_actions)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "32",
                            "MethodArgument"
                        ],
                        [
                            "32",
                            "MethodArgument"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "DataLoader_178": {
                "dataset": {
                    "value": "val_data",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "32",
                            "MethodArgument"
                        ],
                        [
                            "32",
                            "MethodArgument"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "as_tensor_87": {
                "data": {
                    "value": "batch",
                    "possible_values": []
                }
            },
            "tensor_91": {
                "data": {
                    "value": "batch",
                    "possible_values": []
                }
            },
            "DataLoader_185": {
                "dataset": {
                    "value": "CombinedDataset(G_encoder, val_data, neg_class, decay_factor, init_num_perturb_actions)",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "32",
                            "MethodArgument"
                        ],
                        [
                            "32",
                            "MethodArgument"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "my_collate",
                    "possible_values": []
                }
            },
            "DataLoader_205": {
                "dataset": {
                    "value": "GraphDataset(G_encoder, val_data, neg_class, decay_factor, init_num_perturb_actions)",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "32",
                            "MethodArgument"
                        ],
                        [
                            "32",
                            "MethodArgument"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "as_tensor_85": {
                "data": {
                    "value": "b",
                    "possible_values": []
                }
            }
        }
    },
    "dgi.py": {
        "sklearn": {
            "LogisticRegression_253": {
                "variable": {
                    "value": "clf",
                    "possible_values": []
                },
                "penalty": {
                    "value": "*args",
                    "possible_values": []
                },
                "solver": {
                    "value": "solver",
                    "possible_values": [
                        [
                            "'lbfgs'",
                            "MethodArgument"
                        ]
                    ]
                },
                "multi_class": {
                    "value": "multi_class",
                    "possible_values": [
                        [
                            "'auto'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "accuracy_score_257": {
                "variable": {
                    "value": "acc",
                    "possible_values": []
                },
                "y_true": {
                    "value": "test_y.detach().cpu().numpy()",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "preds",
                    "possible_values": [
                        [
                            "clf.predict(test_z.detach().cpu().numpy())",
                            "Call"
                        ]
                    ]
                }
            },
            "f1_score_258": {
                "variable": {
                    "value": "f1",
                    "possible_values": []
                },
                "y_true": {
                    "value": "test_y.detach().cpu().numpy()",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "preds",
                    "possible_values": [
                        [
                            "clf.predict(test_z.detach().cpu().numpy())",
                            "Call"
                        ]
                    ]
                },
                "average": {
                    "value": "f1_average",
                    "possible_values": [
                        [
                            "'binary'",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        },
        "torch": {
            "device_28": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "Encoder_170": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.enc_type": {
                    "value": "encoder_type",
                    "possible_values": [
                        [
                            "'GCN'",
                            "MethodArgument"
                        ]
                    ]
                },
                "PReLU_180": {
                    "variable": {
                        "value": "self.prelu",
                        "possible_values": []
                    },
                    "num_parameters": {
                        "value": "hidden_channels",
                        "possible_values": []
                    }
                },
                "self.node_type_embedding_size": {
                    "value": "node_emb_size",
                    "possible_values": []
                },
                "Embedding_182": {
                    "variable": {
                        "value": "self.node_type_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "len(K.id2node_type)",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "self.node_type_embedding_size",
                        "possible_values": []
                    }
                }
            },
            "manual_seed_32": {
                "seed": {
                    "value": "42",
                    "possible_values": []
                }
            },
            "tensor_59": {
                "variable": {
                    "value": "dummy_span",
                    "possible_values": []
                },
                "data": {
                    "value": "np.zeros_like(graph.span_embeddings[0])",
                    "possible_values": []
                }
            },
            "tensor_99": {
                "variable": {
                    "value": "span_reps",
                    "possible_values": []
                },
                "data": {
                    "value": "np.stack(span_reps)",
                    "possible_values": []
                }
            },
            "tensor_100": {
                "variable": {
                    "value": "type_features",
                    "possible_values": []
                },
                "data": {
                    "value": "np.stack(type_features)",
                    "possible_values": []
                }
            },
            "tensor_104": {
                "variable": {
                    "value": "edge_index",
                    "possible_values": []
                },
                "data": {
                    "value": "edges",
                    "possible_values": []
                }
            },
            "permute_104": {
                "variable": {
                    "value": "edge_index",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                },
                "dims": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "tensor_105": {
                "variable": {
                    "value": "edge_attr",
                    "possible_values": []
                },
                "data": {
                    "value": "[1 if e == 'cor' else 0 for e in edge_types]",
                    "possible_values": []
                }
            },
            "cat_278": {
                "variable": {
                    "value": "train_z",
                    "possible_values": []
                },
                "tensors": {
                    "value": "train_z",
                    "possible_values": [
                        [
                            "torch.cat(train_z, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(train_z, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_279": {
                "variable": {
                    "value": "train_y",
                    "possible_values": []
                },
                "tensors": {
                    "value": "train_y",
                    "possible_values": [
                        [
                            "torch.cat(train_y, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(train_y, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_280": {
                "variable": {
                    "value": "dev_z",
                    "possible_values": []
                },
                "tensors": {
                    "value": "dev_z",
                    "possible_values": [
                        [
                            "torch.cat(dev_z, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(dev_z, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_281": {
                "variable": {
                    "value": "dev_y",
                    "possible_values": []
                },
                "tensors": {
                    "value": "dev_y",
                    "possible_values": [
                        [
                            "torch.cat(dev_y, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(dev_y, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "tensor_289": {
                "variable": {
                    "value": "pos_class",
                    "possible_values": []
                },
                "data": {
                    "value": "[1]",
                    "possible_values": []
                }
            },
            "tensor_290": {
                "variable": {
                    "value": "neg_class",
                    "possible_values": []
                },
                "data": {
                    "value": "[0]",
                    "possible_values": []
                }
            },
            "cat_312": {
                "variable": {
                    "value": "train_z",
                    "possible_values": []
                },
                "tensors": {
                    "value": "train_z",
                    "possible_values": [
                        [
                            "torch.cat(train_z, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(train_z, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_313": {
                "variable": {
                    "value": "train_y",
                    "possible_values": []
                },
                "tensors": {
                    "value": "train_y",
                    "possible_values": [
                        [
                            "torch.cat(train_y, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(train_y, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_314": {
                "variable": {
                    "value": "dev_z",
                    "possible_values": []
                },
                "tensors": {
                    "value": "dev_z",
                    "possible_values": [
                        [
                            "torch.cat(dev_z, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(dev_z, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_315": {
                "variable": {
                    "value": "dev_y",
                    "possible_values": []
                },
                "tensors": {
                    "value": "dev_y",
                    "possible_values": [
                        [
                            "torch.cat(dev_y, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(dev_y, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_199": {
                "variable": {
                    "value": "xs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[span_reps, node_type_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "sigmoid_222": {
                "input": {
                    "value": "z.mean(dim=0)",
                    "possible_values": []
                }
            },
            "save_331": {
                "obj": {
                    "value": "blob",
                    "possible_values": [
                        [
                            "{'encoder_state': encoder_state, 'classifier_state': pickle.dumps(clf), 'training_state': optimizer_state}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "save_path",
                    "possible_values": [
                        [
                            "os.path.join(config['reward_serialization_dir'], 'best_dgi_with_decay_{}_model.th'.format(perturbation_type))",
                            "Call"
                        ]
                    ]
                }
            },
            "Adam_355": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "0.0003",
                    "possible_values": []
                }
            },
            "is_available_28": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "tensor_115": {
                "data": {
                    "value": "y",
                    "possible_values": [
                        [
                            "list()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "finetune.py": {
        "sklearn": {},
        "torch": {
            "device_54": {
                "variable": {
                    "value": "CPU",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "device_55": {
                "variable": {
                    "value": "GPU",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "manual_seed_58": {
                "seed": {
                    "value": "42",
                    "possible_values": []
                }
            },
            "load_235": {
                "variable": {
                    "value": "state_dicts",
                    "possible_values": []
                },
                "f": {
                    "value": "mpath",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'best_dgi_with_decay_{}_model.th'.format(model_name))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "CPU",
                    "possible_values": [
                        [
                            "torch.device('cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_55": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_379": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[co['endpoint_span_embeddings'], co['attended_span_embeddings']]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "squeeze_379": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "save_344": {
                "obj": {
                    "value": "best_state_dict",
                    "possible_values": [
                        [
                            "ft_model.state_dict()",
                            "Call"
                        ],
                        [
                            "copy.deepcopy(ft_model.state_dict())",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(args.serialization_dir, 'best_finetuned_dgi_{}_{}.th'.format(to_finetune, finetune_dataset))",
                    "possible_values": []
                }
            },
            "Tensor_410": {
                "variable": {
                    "value": "reward",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/training/metrics/f1_score.py": {
        "sklearn": {
            "f1_score_25": {
                "y_true": {
                    "value": "labels.cpu().numpy()",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "logits.cpu().numpy()",
                    "possible_values": []
                },
                "average": {
                    "value": "binary",
                    "possible_values": []
                }
            }
        },
        "torch": {}
    },
    "allennlp/allennlp/__init__.py": {
        "torch": {}
    },
    "allennlp/allennlp/commands/elmo.py": {
        "torch": {
            "cat_253": {
                "variable": {
                    "value": "activations",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[ele[0].unsqueeze(1) for ele in without_bos_eos]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "no_grad_449": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/commands/train.py": {
        "torch": {
            "set_device_430": {
                "device": {
                    "value": "int(gpu_id)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/common/checks.py": {
        "torch": {
            "device_count_108": {
                "variable": {
                    "value": "num_devices_available",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/common/testing/model_test_case.py": {
        "torch": {
            "zeros_212": {
                "variable": {
                    "value": "zeros",
                    "possible_values": []
                },
                "*size": {
                    "value": "parameter.size()",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/common/util.py": {
        "torch": {
            "manual_seed_244": {
                "seed": {
                    "value": "torch_seed",
                    "possible_values": [
                        [
                            "params.pop_int('pytorch_seed', 133)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_246": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_617": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_initialized_617": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_644": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_initialized_644": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "manual_seed_all_247": {
                "seed": {
                    "value": "torch_seed",
                    "possible_values": [
                        [
                            "params.pop_int('pytorch_seed', 133)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/data/batch.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/dataset_readers/multiprocess_dataset_reader.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/fields/adjacency_field.py": {
        "torch": {
            "ones_124": {
                "*size": {
                    "value": "desired_num_tokens",
                    "possible_values": [
                        [
                            "padding_lengths['num_tokens']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "desired_num_tokens",
                    "possible_values": [
                        [
                            "padding_lengths['num_tokens']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/data/fields/array_field.py": {
        "torch": {
            "from_numpy_57": {
                "variable": {
                    "value": "tensor",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "return_array",
                    "possible_values": [
                        [
                            "numpy.asarray(numpy.ones(max_shape, dtype=self.dtype) * self.padding_value, dtype=self.dtype)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/data/fields/field.py": {
        "torch": {
            "stack_117": {
                "tensors": {
                    "value": "tensor_list",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/data/fields/index_field.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/fields/label_field.py": {
        "torch": {
            "tensor_105": {
                "variable": {
                    "value": "tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "self._label_id",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/data/fields/multilabel_field.py": {
        "torch": {
            "zeros_125": {
                "variable": {
                    "value": "tensor",
                    "possible_values": []
                },
                "*size": {
                    "value": "self._num_labels",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/data/fields/namespace_swapping_field.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/fields/sequence_label_field.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/fields/span_field.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/fields/text_field.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/iterators/data_iterator.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/iterators/multiprocess_iterator.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/token_indexers/elmo_indexer.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/token_indexers/pretrained_transformer_indexer.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/token_indexers/pretrained_transformer_mismatched_indexer.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/token_indexers/spacy_indexer.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/token_indexers/token_characters_indexer.py": {
        "torch": {}
    },
    "allennlp/allennlp/data/token_indexers/token_indexer.py": {
        "torch": {}
    },
    "allennlp/allennlp/interpret/attackers/hotflip.py": {
        "torch": {
            "einsum_382": {
                "variable": {
                    "value": "new_embed_dot_grad",
                    "possible_values": []
                },
                "equation": {
                    "value": "bij,kj->bik",
                    "possible_values": []
                },
                "*operands": {
                    "value": "(grad, self.embedding_matrix)",
                    "possible_values": []
                }
            },
            "einsum_383": {
                "variable": {
                    "value": "prev_embed_dot_grad",
                    "possible_values": []
                },
                "equation": {
                    "value": "bij,bij->bi",
                    "possible_values": []
                },
                "*operands": {
                    "value": "(grad, word_embedding)",
                    "possible_values": []
                }
            },
            "unsqueeze_383": {
                "variable": {
                    "value": "prev_embed_dot_grad",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "embedding_375": {
                "variable": {
                    "value": "word_embedding",
                    "possible_values": []
                },
                "input": {
                    "value": "util.move_to_device(torch.LongTensor([token_idx]), self.cuda_device)",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.embedding_matrix",
                    "possible_values": []
                }
            },
            "from_numpy_365": {
                "ndarray": {
                    "value": "grad",
                    "possible_values": [
                        [
                            "grads[grad_input_field][0]",
                            "Subscript"
                        ],
                        [
                            "util.move_to_device(torch.from_numpy(grad), self.cuda_device)",
                            "Call"
                        ],
                        [
                            "grad.unsqueeze(0).unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_140": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "unsqueeze_155": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "unsqueeze_167": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/interpret/attackers/input_reduction.py": {
        "torch": {}
    },
    "allennlp/allennlp/interpret/saliency_interpreters/smooth_gradient.py": {
        "torch": {
            "randn_61": {
                "*size": {
                    "value": "output.shape",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/archival.py": {
        "torch": {}
    },
    "allennlp/allennlp/models/basic_classifier.py": {
        "torch": {
            "Linear_92": {
                "variable": {
                    "value": "self._classification_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._classifier_input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._num_labels",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_96": {
                "variable": {
                    "value": "self._loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "softmax_139": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self._classification_layer(embedded_text)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_83": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/bert_for_classification.py": {
        "torch": {
            "Dropout_78": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "Linear_80": {
                "variable": {
                    "value": "self._classification_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "possible_values": [
                        [
                            "self.bert_model.config.hidden_size",
                            "Attribute"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "possible_values": [
                        [
                            "num_labels",
                            "Name"
                        ],
                        [
                            "vocab.get_vocab_size(namespace=self._label_namespace)",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_82": {
                "variable": {
                    "value": "self._loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "softmax_127": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self._classification_layer(pooled)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/biaffine_dependency_parser.py": {
        "torch": {
            "Bilinear_126": {
                "variable": {
                    "value": "self.tag_bilinear",
                    "possible_values": []
                },
                "in1_features": {
                    "value": "tag_representation_dim",
                    "possible_values": []
                },
                "in2_features": {
                    "value": "tag_representation_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_labels",
                    "possible_values": [
                        [
                            "self.vocab.get_vocab_size('head_tags')",
                            "Call"
                        ]
                    ]
                }
            },
            "Dropout_132": {
                "variable": {
                    "value": "self._input_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "input_dropout",
                    "possible_values": []
                }
            },
            "Parameter_133": {
                "variable": {
                    "value": "self._head_sentinel",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn([1, 1, encoder.get_output_dim()])",
                    "possible_values": []
                }
            },
            "cat_318": {
                "variable": {
                    "value": "encoded_text",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[head_sentinel, encoded_text]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_319": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mask.new_ones(batch_size, 1), mask]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_592": {
                "variable": {
                    "value": "normalized_pairwise_head_logits",
                    "possible_values": []
                },
                "input": {
                    "value": "pairwise_head_logits",
                    "possible_values": [
                        [
                            "self.tag_bilinear(head_tag_representation, child_tag_representation)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "3",
                    "possible_values": []
                }
            },
            "permute_592": {
                "variable": {
                    "value": "normalized_pairwise_head_logits",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dims": {
                    "value": "3",
                    "possible_values": []
                }
            },
            "log_softmax_604": {
                "variable": {
                    "value": "normalized_arc_logits",
                    "possible_values": []
                },
                "input": {
                    "value": "attended_arcs",
                    "possible_values": [
                        [
                            "self.arc_attention(head_arc_representation, child_arc_representation)",
                            "Call"
                        ],
                        [
                            "attended_arcs + minus_mask.unsqueeze(2) + minus_mask.unsqueeze(1)",
                            "BinOp"
                        ],
                        [
                            "attended_arcs + torch.diag(attended_arcs.new(mask.size(1)).fill_(-numpy.inf))",
                            "BinOp"
                        ],
                        [
                            "attended_arcs + minus_mask.unsqueeze(2) + minus_mask.unsqueeze(1)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "transpose_604": {
                "variable": {
                    "value": "normalized_arc_logits",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                },
                "dim0": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "exp_610": {
                "variable": {
                    "value": "batch_energy",
                    "possible_values": []
                },
                "input": {
                    "value": "normalized_arc_logits.unsqueeze(1) + normalized_pairwise_head_logits",
                    "possible_values": []
                }
            },
            "cat_238": {
                "variable": {
                    "value": "embedded_text_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text_input, embedded_pos_tags]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_321": {
                "variable": {
                    "value": "head_indices",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[head_indices.new_zeros(batch_size, 1), head_indices]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_325": {
                "variable": {
                    "value": "head_tags",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[head_tags.new_zeros(batch_size, 1), head_tags]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "randn_134": {
                "*size": {
                    "value": "[1, 1, encoder.get_output_dim()]",
                    "possible_values": []
                }
            },
            "diag_504": {
                "input": {
                    "value": "attended_arcs.new(mask.size(1)).fill_(-numpy.inf)",
                    "possible_values": []
                }
            },
            "from_numpy_644": {
                "ndarray": {
                    "value": "numpy.stack(heads)",
                    "possible_values": []
                }
            },
            "from_numpy_645": {
                "ndarray": {
                    "value": "numpy.stack(head_tags)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/biaffine_dependency_parser_multilang.py": {
        "torch": {
            "cat_145": {
                "variable": {
                    "value": "embedded_text_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text_input, embedded_pos_tags]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/biattentive_classification_network.py": {
        "torch": {
            "Dropout_103": {
                "variable": {
                    "value": "self._embedding_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "embedding_dropout",
                    "possible_values": []
                }
            },
            "Dropout_109": {
                "variable": {
                    "value": "self._integrator_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "integrator_dropout",
                    "possible_values": []
                }
            },
            "Linear_151": {
                "variable": {
                    "value": "self._self_attentive_pooling_projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._combined_integrator_output_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_209": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_284": {
                "variable": {
                    "value": "integrator_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encoded_tokens, encoded_tokens - encoded_text, encoded_tokens * encoded_text]",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_322": {
                "variable": {
                    "value": "pooled_representations",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[max_pool, min_pool, mean_pool, self_attentive_pool]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "softmax_330": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self._output_layer(pooled_representations_dropped)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_296": {
                "variable": {
                    "value": "integrated_encodings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[integrated_encodings, integrator_output_elmo]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_268": {
                "variable": {
                    "value": "embedded_text",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text, input_elmo]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "max_304": {
                "input": {
                    "value": "max_masked_integrated_encodings",
                    "possible_values": [
                        [
                            "util.replace_masked_values(integrated_encodings, text_mask.unsqueeze(2), -10000000.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "min_308": {
                "input": {
                    "value": "min_masked_integrated_encodings",
                    "possible_values": [
                        [
                            "util.replace_masked_values(integrated_encodings, text_mask.unsqueeze(2), +10000000.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_309": {
                "input": {
                    "value": "text_mask",
                    "possible_values": [
                        [
                            "util.get_text_field_mask(tokens).float()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/bimpm.py": {
        "torch": {
            "Dropout_115": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_119": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "softmax_228": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self.classifier_feedforward(torch.cat([aggregated_premise, aggregated_hypothesis], dim=-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_210": {
                "tensors": {
                    "value": "matching_vector_premise",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_213": {
                "tensors": {
                    "value": "matching_vector_hypothesis",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_226": {
                "tensors": {
                    "value": "[aggregated_premise, aggregated_hypothesis]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/constituency_parser.py": {
        "torch": {
            "cat_206": {
                "variable": {
                    "value": "embedded_text_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text_input, embedded_pos_tags]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_110": {
                "in_features": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "feedforward.get_output_dim()",
                            "Call"
                        ],
                        [
                            "span_extractor.get_output_dim()",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.num_classes",
                    "possible_values": []
                }
            },
            "max_350": {
                "variable": {
                    "value": "(label_prob, label_index)",
                    "possible_values": []
                },
                "input": {
                    "value": "prediction",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/coreference_resolution/coref.py": {
        "torch": {
            "Sequential_85": {
                "variable": {
                    "value": "feedforward_scorer",
                    "possible_values": []
                },
                "*args": {
                    "value": "TimeDistributed(mention_feedforward)",
                    "possible_values": []
                }
            },
            "relu_183": {
                "variable": {
                    "value": "spans",
                    "possible_values": []
                },
                "input": {
                    "value": "spans.float()",
                    "possible_values": []
                }
            },
            "cat_197": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[endpoint_span_embeddings, attended_span_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "relu_505": {
                "variable": {
                    "value": "valid_antecedent_indices",
                    "possible_values": []
                },
                "input": {
                    "value": "raw_antecedent_indices.float()",
                    "possible_values": []
                }
            },
            "cat_570": {
                "variable": {
                    "value": "span_pair_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[target_embeddings, antecedent_embeddings, antecedent_embeddings * target_embeddings, antecedent_distance_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_619": {
                "variable": {
                    "value": "pairwise_labels_with_dummy_label",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[dummy_labels, pairwise_labels]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_673": {
                "variable": {
                    "value": "coreference_scores",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[dummy_scores, antecedent_scores]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_116": {
                "variable": {
                    "value": "self._lexical_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "lexical_dropout",
                    "possible_values": []
                }
            },
            "Linear_91": {
                "in_features": {
                    "value": "antecedent_feedforward.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_87": {
                "in_features": {
                    "value": "mention_feedforward.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/crf_tagger.py": {
        "torch": {
            "Dropout_96": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "Linear_105": {
                "in_features": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "feedforward.get_output_dim()",
                            "Call"
                        ],
                        [
                            "self.encoder.get_output_dim()",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.num_tags",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/decomposable_attention.py": {
        "torch": {
            "CrossEntropyLoss_108": {
                "variable": {
                    "value": "self._loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_176": {
                "variable": {
                    "value": "premise_compare_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_premise, attended_hypothesis]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_179": {
                "variable": {
                    "value": "hypothesis_compare_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_hypothesis, attended_premise]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_193": {
                "variable": {
                    "value": "aggregate_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[compared_premise, compared_hypothesis]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "softmax_195": {
                "variable": {
                    "value": "label_probs",
                    "possible_values": []
                },
                "input": {
                    "value": "label_logits",
                    "possible_values": [
                        [
                            "self._aggregate_feedforward(aggregate_input)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/encoder_decoders/composed_seq2seq.py": {
        "torch": {}
    },
    "allennlp/allennlp/models/encoder_decoders/copynet_seq2seq.py": {
        "torch": {
            "Linear_144": {
                "variable": {
                    "value": "self._input_projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "target_embedding_dim + self.encoder_output_dim * 2",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.decoder_input_dim",
                    "possible_values": []
                }
            },
            "LSTMCell_150": {
                "variable": {
                    "value": "self._decoder_cell",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self.decoder_input_dim",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self.decoder_output_dim",
                    "possible_values": []
                }
            },
            "Linear_154": {
                "variable": {
                    "value": "self._output_generation_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.decoder_output_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "target_vocab_size",
                    "possible_values": [
                        [
                            "self.vocab.get_vocab_size(self._target_namespace)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_161": {
                "variable": {
                    "value": "self._output_copying_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.encoder_output_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.decoder_output_dim",
                    "possible_values": []
                }
            },
            "cat_368": {
                "variable": {
                    "value": "decoder_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(embedded_input, attentive_read, selective_read)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "tanh_386": {
                "variable": {
                    "value": "copy_projection",
                    "possible_values": []
                },
                "input": {
                    "value": "copy_projection",
                    "possible_values": [
                        [
                            "self._output_copying_layer(trimmed_encoder_outputs)",
                            "Call"
                        ],
                        [
                            "torch.tanh(copy_projection)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_432": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores_mask, copy_mask)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_434": {
                "variable": {
                    "value": "all_scores",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores, copy_scores)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_468": {
                "variable": {
                    "value": "combined_gen_and_copy",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_log_probs, copy_log_probs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_560": {
                "variable": {
                    "value": "log_likelihoods",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_log_likelihoods",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_793": {
                "variable": {
                    "value": "modified_log_probs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "modified_log_probs_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_868": {
                "variable": {
                    "value": "all_scores",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores, copy_scores)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_872": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(generation_scores.new_full(generation_scores.size(), 1.0), copy_mask)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_766": {
                "variable": {
                    "value": "combined",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(copy_log_probs_slice.unsqueeze(-1), future_copy_log_probs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_744": {
                "tensors": {
                    "value": "(selected_generation_log_probs, copy_log_probs_to_add)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/encoder_decoders/simple_seq2seq.py": {
        "torch": {
            "LSTMCell_160": {
                "variable": {
                    "value": "self._decoder_cell",
                    "possible_values": []
                },
                "input_size": {
                    "value": "self._decoder_input_dim",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "self._decoder_output_dim",
                    "possible_values": []
                }
            },
            "Linear_164": {
                "variable": {
                    "value": "self._output_projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._decoder_output_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "self.vocab.get_vocab_size(self._target_namespace)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_softmax_205": {
                "variable": {
                    "value": "class_log_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "output_projections",
                    "possible_values": [
                        [
                            "self._output_projection_layer(decoder_hidden)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_387": {
                "variable": {
                    "value": "predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_predictions",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "softmax_376": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "output_projections",
                    "possible_values": [
                        [
                            "self._output_projection_layer(decoder_hidden)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "max_379": {
                "variable": {
                    "value": "(_, predicted_classes)",
                    "possible_values": []
                },
                "input": {
                    "value": "class_probabilities",
                    "possible_values": [
                        [
                            "F.softmax(output_projections, dim=-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_393": {
                "variable": {
                    "value": "logits",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_455": {
                "variable": {
                    "value": "decoder_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(attended_input, embedded_input)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "rand_355": {
                "*size": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/ensemble.py": {
        "torch": {
            "ModuleList_31": {
                "variable": {
                    "value": "self.submodels",
                    "possible_values": []
                },
                "modules": {
                    "value": "submodels",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/esim.py": {
        "torch": {
            "CrossEntropyLoss_111": {
                "variable": {
                    "value": "self._loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_179": {
                "variable": {
                    "value": "premise_enhanced",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encoded_premise, attended_hypothesis, encoded_premise - attended_hypothesis, encoded_premise * attended_hypothesis]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_188": {
                "variable": {
                    "value": "hypothesis_enhanced",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encoded_hypothesis, attended_premise, encoded_hypothesis - attended_premise, encoded_hypothesis * attended_premise]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_234": {
                "variable": {
                    "value": "v_all",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v_a_avg, v_a_max, v_b_avg, v_b_max]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "softmax_242": {
                "variable": {
                    "value": "label_probs",
                    "possible_values": []
                },
                "input": {
                    "value": "label_logits",
                    "possible_values": [
                        [
                            "self._output_logit(output_hidden)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_80": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "sum_225": {
                "input": {
                    "value": "premise_mask",
                    "possible_values": [
                        [
                            "get_text_field_mask(premise).float()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_228": {
                "input": {
                    "value": "hypothesis_mask",
                    "possible_values": [
                        [
                            "get_text_field_mask(hypothesis).float()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/event2mind.py": {
        "torch": {
            "StateDecoder_389": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "GRUCell_398": {
                    "variable": {
                        "value": "self.decoder_cell",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "output_dim",
                        "possible_values": []
                    }
                },
                "Linear_399": {
                    "variable": {
                        "value": "self.output_projection_layer",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "output_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "num_classes",
                        "possible_values": [
                            [
                                "self.vocab.get_vocab_size(self._target_namespace)",
                                "Call"
                            ]
                        ]
                    }
                }
            },
            "Dropout_80": {
                "variable": {
                    "value": "self._embedding_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "embedding_dropout",
                    "possible_values": []
                }
            },
            "ModuleDict_104": {
                "variable": {
                    "value": "self._states",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_256": {
                "variable": {
                    "value": "logits",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_299": {
                "variable": {
                    "value": "all_predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[ps.unsqueeze(1) for ps in predictions]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_410": {
                "variable": {
                    "value": "class_log_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "output_projections",
                    "possible_values": [
                        [
                            "output_projection_layer(decoder_hidden)",
                            "Call"
                        ],
                        [
                            "output_projection_layer(decoder_hidden)",
                            "Call"
                        ],
                        [
                            "self.output_projection_layer(decoder_hidden)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "softmax_296": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "output_projections",
                    "possible_values": [
                        [
                            "output_projection_layer(decoder_hidden)",
                            "Call"
                        ],
                        [
                            "output_projection_layer(decoder_hidden)",
                            "Call"
                        ],
                        [
                            "self.output_projection_layer(decoder_hidden)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "max_297": {
                "variable": {
                    "value": "(_, predicted_classes)",
                    "possible_values": []
                },
                "input": {
                    "value": "class_probabilities",
                    "possible_values": [
                        [
                            "F.softmax(output_projections, dim=-1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/models/graph_parser.py": {
        "torch": {
            "Dropout_118": {
                "variable": {
                    "value": "self._input_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "input_dropout",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_144": {
                "variable": {
                    "value": "self._arc_loss",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_145": {
                "variable": {
                    "value": "self._tag_loss",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "diag_374": {
                "variable": {
                    "value": "inf_diagonal_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_scores.new(mask.size(1)).fill_(-numpy.inf)",
                    "possible_values": []
                }
            },
            "softmax_385": {
                "variable": {
                    "value": "arc_tag_probs",
                    "possible_values": []
                },
                "input": {
                    "value": "arc_tag_logits",
                    "possible_values": [
                        [
                            "self.tag_bilinear(head_tag_representation, child_tag_representation)",
                            "Call"
                        ],
                        [
                            "arc_tag_logits.permute(0, 2, 3, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "arc_tag_logits + inf_diagonal_mask.unsqueeze(0).unsqueeze(-1)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_179": {
                "variable": {
                    "value": "embedded_text_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text_input, embedded_pos_tags]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "stack_250": {
                "tensors": {
                    "value": "[one_minus_arc_probs, arc_probs]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/language_model.py": {
        "torch": {
            "_SoftmaxLoss_17": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Parameter_30": {
                    "variable": {
                        "value": "self.softmax_w",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.randn(embedding_dim, num_words) / np.sqrt(embedding_dim)",
                        "possible_values": []
                    }
                },
                "Parameter_33": {
                    "variable": {
                        "value": "self.softmax_b",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(num_words)",
                        "possible_values": []
                    }
                }
            },
            "log_softmax_40": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.matmul(embeddings, self.softmax_w) + self.softmax_b",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "nll_loss_44": {
                "input": {
                    "value": "probs",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(torch.matmul(embeddings, self.softmax_w) + self.softmax_b, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets.long()",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "possible_values": []
                }
            },
            "Dropout_143": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "cat_157": {
                "variable": {
                    "value": "shifted_mask",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[zero_col, mask[:, 0:-1]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_159": {
                "variable": {
                    "value": "shifted_mask",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mask[:, 1:], zero_col]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_303": {
                "variable": {
                    "value": "forward_targets",
                    "possible_values": []
                },
                "input": {
                    "value": "token_ids",
                    "possible_values": [
                        [
                            "token_id_dict['tokens']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "sum_323": {
                "variable": {
                    "value": "num_targets",
                    "possible_values": []
                },
                "input": {
                    "value": "(forward_targets > 0).long()",
                    "possible_values": []
                }
            },
            "zeros_33": {
                "*size": {
                    "value": "num_words",
                    "possible_values": []
                }
            },
            "zeros_138": {
                "*size": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_307": {
                "variable": {
                    "value": "backward_targets",
                    "possible_values": []
                },
                "input": {
                    "value": "token_ids",
                    "possible_values": [
                        [
                            "token_id_dict['tokens']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "tensor_332": {
                "variable": {
                    "value": "average_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "randn_31": {
                "*size": {
                    "value": "embedding_dim",
                    "possible_values": []
                },
                "out": {
                    "value": "num_words",
                    "possible_values": []
                }
            },
            "matmul_41": {
                "input": {
                    "value": "embeddings",
                    "possible_values": [
                        [
                            "self._text_field_embedder(source)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.softmax_w",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/masked_language_model.py": {
        "torch": {
            "Dropout_69": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "arange_123": {
                "variable": {
                    "value": "batch_index",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "batch_size",
                    "possible_values": []
                }
            },
            "unsqueeze_123": {
                "variable": {
                    "value": "batch_index",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "softmax_129": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "target_logits",
                    "possible_values": [
                        [
                            "self._language_model_head(self._dropout(mask_embeddings))",
                            "Call"
                        ],
                        [
                            "target_logits.view(batch_size * num_masks, vocab_size)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cross_entropy_140": {
                "variable": {
                    "value": "loss",
                    "possible_values": []
                },
                "input": {
                    "value": "target_logits",
                    "possible_values": [
                        [
                            "self._language_model_head(self._dropout(mask_embeddings))",
                            "Call"
                        ],
                        [
                            "target_logits.view(batch_size * num_masks, vocab_size)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "target_ids['bert']['token_ids']",
                            "Subscript"
                        ],
                        [
                            "list(target_ids.values())[0]['tokens']",
                            "Subscript"
                        ],
                        [
                            "targets.view(batch_size * num_masks)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/models/model.py": {
        "torch": {
            "Model_28": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.vocab": {
                    "value": "vocab",
                    "possible_values": [
                        [
                            "vocab_class.from_files(vocab_dir, vocab_params.get('padding_token', None), vocab_params.get('oov_token', None))",
                            "Call"
                        ]
                    ]
                },
                "self._regularizer": {
                    "value": "regularizer",
                    "possible_values": []
                }
            },
            "load_302": {
                "variable": {
                    "value": "model_state",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_file",
                    "possible_values": [
                        [
                            "weights_file or os.path.join(serialization_dir, _DEFAULT_WEIGHTS)",
                            "BoolOp"
                        ]
                    ]
                },
                "map_location": {
                    "value": "util.device_mapping(cuda_device)",
                    "possible_values": []
                }
            },
            "no_grad_159": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/next_token_lm.py": {
        "torch": {
            "Dropout_70": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "softmax_96": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "input": {
                    "value": "target_logits",
                    "possible_values": [
                        [
                            "self._language_model_head(self._dropout(final_embeddings))",
                            "Call"
                        ],
                        [
                            "target_logits.view(batch_size, vocab_size)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cross_entropy_109": {
                "variable": {
                    "value": "loss",
                    "possible_values": []
                },
                "input": {
                    "value": "target_logits",
                    "possible_values": [
                        [
                            "self._language_model_head(self._dropout(final_embeddings))",
                            "Call"
                        ],
                        [
                            "target_logits.view(batch_size, vocab_size)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets",
                    "possible_values": [
                        [
                            "util.get_token_ids_from_text_field_tensors(target_ids).view(batch_size)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/models/semantic_role_labeler.py": {
        "torch": {
            "Dropout_96": {
                "variable": {
                    "value": "self.embedding_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "embedding_dropout",
                    "possible_values": []
                }
            },
            "cat_157": {
                "variable": {
                    "value": "embedded_text_with_verb_indicator",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedded_text_input, embedded_verb_indicator]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "softmax_166": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_log_probs",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_283": {
                "variable": {
                    "value": "transition_matrix",
                    "possible_values": []
                },
                "*size": {
                    "value": "[num_labels, num_labels]",
                    "possible_values": []
                }
            },
            "zeros_307": {
                "variable": {
                    "value": "start_transitions",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_labels",
                    "possible_values": [
                        [
                            "len(all_labels)",
                            "Call"
                        ],
                        [
                            "len(all_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_94": {
                "in_features": {
                    "value": "self.encoder.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_classes",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/simple_tagger.py": {
        "torch": {
            "softmax_150": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_log_probs",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_73": {
                "in_features": {
                    "value": "self.encoder.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_classes",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/models/srl_bert.py": {
        "torch": {
            "Linear_67": {
                "variable": {
                    "value": "self.tag_projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.bert_model.config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_classes",
                    "possible_values": []
                }
            },
            "Dropout_71": {
                "variable": {
                    "value": "self.embedding_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "embedding_dropout",
                    "possible_values": []
                }
            },
            "softmax_127": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_log_probs",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_266": {
                "variable": {
                    "value": "transition_matrix",
                    "possible_values": []
                },
                "*size": {
                    "value": "[num_labels, num_labels]",
                    "possible_values": []
                }
            },
            "zeros_290": {
                "variable": {
                    "value": "start_transitions",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_labels",
                    "possible_values": [
                        [
                            "len(all_labels)",
                            "Call"
                        ],
                        [
                            "len(all_labels)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/attention/additive_attention.py": {
        "torch": {
            "Parameter_37": {
                "variable": {
                    "value": "self._w_matrix",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(vector_dim, vector_dim)",
                    "possible_values": []
                }
            },
            "Parameter_38": {
                "variable": {
                    "value": "self._u_matrix",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(matrix_dim, vector_dim)",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "variable": {
                    "value": "self._v_vector",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(vector_dim, 1)",
                    "possible_values": []
                }
            },
            "tanh_54": {
                "variable": {
                    "value": "intermediate",
                    "possible_values": []
                },
                "input": {
                    "value": "intermediate",
                    "possible_values": [
                        [
                            "vector.matmul(self._w_matrix).unsqueeze(1) + matrix.matmul(self._u_matrix)",
                            "BinOp"
                        ],
                        [
                            "torch.tanh(intermediate)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/attention/attention.py": {
        "torch": {
            "Attention_13": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._normalize": {
                    "value": "normalize",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/attention/bilinear_attention.py": {
        "torch": {
            "Parameter_42": {
                "variable": {
                    "value": "self._weight_matrix",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(vector_dim, matrix_dim)",
                    "possible_values": []
                }
            },
            "Parameter_43": {
                "variable": {
                    "value": "self._bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/attention/cosine_attention.py": {
        "torch": {
            "bmm_18": {
                "input": {
                    "value": "a_norm.unsqueeze(dim=1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "b_norm.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "squeeze_18": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/attention/dot_product_attention.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/attention/legacy_attention.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/attention/linear_attention.py": {
        "torch": {
            "Parameter_58": {
                "variable": {
                    "value": "self._weight_vector",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(combined_dim)",
                    "possible_values": []
                }
            },
            "Parameter_59": {
                "variable": {
                    "value": "self._bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/augmented_lstm.py": {
        "torch": {
            "AugmentedLstm_17": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.input_size": {
                    "value": "input_size",
                    "possible_values": []
                },
                "self.hidden_size": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "self.go_forward": {
                    "value": "go_forward",
                    "possible_values": []
                },
                "self.use_highway": {
                    "value": "use_highway",
                    "possible_values": []
                },
                "self.recurrent_dropout_probability": {
                    "value": "recurrent_dropout_probability",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_143": {
                "variable": {
                    "value": "(sequence_tensor, batch_lengths)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "inputs",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_257": {
                "variable": {
                    "value": "output_accumulator",
                    "possible_values": []
                },
                "input": {
                    "value": "output_accumulator",
                    "possible_values": [
                        [
                            "sequence_tensor.new_zeros(batch_size, total_timesteps, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "pack_padded_sequence(output_accumulator, batch_lengths, batch_first=True)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "batch_lengths",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Linear_83": {
                "variable": {
                    "value": "self.input_linearity",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "6 * hidden_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "use_input_projection_bias",
                    "possible_values": []
                }
            },
            "Linear_86": {
                "variable": {
                    "value": "self.state_linearity",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "5 * hidden_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Linear_90": {
                "variable": {
                    "value": "self.input_linearity",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "4 * hidden_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "use_input_projection_bias",
                    "possible_values": []
                }
            },
            "Linear_93": {
                "variable": {
                    "value": "self.state_linearity",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "4 * hidden_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sigmoid_216": {
                "variable": {
                    "value": "input_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 0 * self.hidden_size:1 * self.hidden_size] + projected_state[:, 0 * self.hidden_size:1 * self.hidden_size]",
                    "possible_values": []
                }
            },
            "sigmoid_220": {
                "variable": {
                    "value": "forget_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 1 * self.hidden_size:2 * self.hidden_size] + projected_state[:, 1 * self.hidden_size:2 * self.hidden_size]",
                    "possible_values": []
                }
            },
            "tanh_224": {
                "variable": {
                    "value": "memory_init",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 2 * self.hidden_size:3 * self.hidden_size] + projected_state[:, 2 * self.hidden_size:3 * self.hidden_size]",
                    "possible_values": []
                }
            },
            "sigmoid_228": {
                "variable": {
                    "value": "output_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 3 * self.hidden_size:4 * self.hidden_size] + projected_state[:, 3 * self.hidden_size:4 * self.hidden_size]",
                    "possible_values": []
                }
            },
            "sigmoid_236": {
                "variable": {
                    "value": "highway_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 4 * self.hidden_size:5 * self.hidden_size] + projected_state[:, 4 * self.hidden_size:5 * self.hidden_size]",
                    "possible_values": []
                }
            },
            "tanh_233": {
                "input": {
                    "value": "memory",
                    "possible_values": [
                        [
                            "input_gate * memory_init + forget_gate * previous_memory",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/bimpm_matching.py": {
        "torch": {
            "BiMpmMatching_108": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.hidden_dim": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "self.num_perspectives": {
                    "value": "num_perspectives",
                    "possible_values": [
                        [
                            "weight.size(0)",
                            "Call"
                        ]
                    ]
                },
                "self.is_forward": {
                    "value": "is_forward",
                    "possible_values": []
                },
                "self.with_full_match": {
                    "value": "with_full_match",
                    "possible_values": []
                },
                "self.with_maxpool_match": {
                    "value": "with_maxpool_match",
                    "possible_values": []
                },
                "self.with_attentive_match": {
                    "value": "with_attentive_match",
                    "possible_values": []
                },
                "self.with_max_attentive_match": {
                    "value": "with_max_attentive_match",
                    "possible_values": []
                },
                "self.output_dim": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "2",
                            "Constant"
                        ],
                        [
                            "output_dim + (num_perspectives + 1)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "cosine_similarity_47": {
                "variable": {
                    "value": "similarity_single",
                    "possible_values": []
                },
                "x1": {
                    "value": "vector1",
                    "possible_values": [
                        [
                            "weight * vector1.unsqueeze(2)",
                            "BinOp"
                        ],
                        [
                            "weight * vector1.unsqueeze(1).expand(-1, num_perspectives, -1, -1)",
                            "BinOp"
                        ]
                    ]
                },
                "x2": {
                    "value": "vector2",
                    "possible_values": [
                        [
                            "weight * vector2.unsqueeze(2)",
                            "BinOp"
                        ],
                        [
                            "weight * vector2.unsqueeze(1).expand(-1, num_perspectives, -1, -1)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "unsqueeze_47": {
                "variable": {
                    "value": "similarity_single",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cosine_similarity_56": {
                "variable": {
                    "value": "similarity_multi",
                    "possible_values": []
                },
                "x1": {
                    "value": "vector1",
                    "possible_values": [
                        [
                            "weight * vector1.unsqueeze(2)",
                            "BinOp"
                        ],
                        [
                            "weight * vector1.unsqueeze(1).expand(-1, num_perspectives, -1, -1)",
                            "BinOp"
                        ]
                    ]
                },
                "x2": {
                    "value": "vector2",
                    "possible_values": [
                        [
                            "weight * vector2.unsqueeze(2)",
                            "BinOp"
                        ],
                        [
                            "weight * vector2.unsqueeze(1).expand(-1, num_perspectives, -1, -1)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "3",
                    "possible_values": []
                }
            },
            "matmul_101": {
                "variable": {
                    "value": "mul_result",
                    "possible_values": []
                },
                "input": {
                    "value": "vector1",
                    "possible_values": [
                        [
                            "weight * vector1.unsqueeze(2)",
                            "BinOp"
                        ],
                        [
                            "weight * vector1.unsqueeze(1).expand(-1, num_perspectives, -1, -1)",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "vector2.transpose(2, 3)",
                    "possible_values": []
                }
            },
            "cosine_similarity_272": {
                "variable": {
                    "value": "cosine_sim",
                    "possible_values": []
                },
                "x1": {
                    "value": "context_1.unsqueeze(-2)",
                    "possible_values": []
                },
                "x2": {
                    "value": "context_2.unsqueeze(-3)",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "possible_values": []
                }
            },
            "Parameter_171": {
                "variable": {
                    "value": "param",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(num_perspectives, hidden_dim)",
                    "possible_values": []
                }
            },
            "zeros_171": {
                "*size": {
                    "value": "num_perspectives",
                    "possible_values": [
                        [
                            "weight.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/conditional_random_field.py": {
        "torch": {
            "ConditionalRandomField_168": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_tags": {
                    "value": "num_tags",
                    "possible_values": []
                },
                "Parameter_198": {
                    "variable": {
                        "value": "self.transitions",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.Tensor(num_tags, num_tags)",
                        "possible_values": []
                    }
                },
                "Parameter_210": {
                    "variable": {
                        "value": "self._constraint_mask",
                        "possible_values": []
                    },
                    "data": {
                        "value": "constraint_mask",
                        "possible_values": [
                            [
                                "torch.Tensor(num_tags + 2, num_tags + 2).fill_(1.0)",
                                "Call"
                            ],
                            [
                                "torch.Tensor(num_tags + 2, num_tags + 2).fill_(0.0)",
                                "Call"
                            ]
                        ]
                    },
                    "requires_grad": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "self.include_start_end_transitions": {
                    "value": "include_start_end_transitions",
                    "possible_values": []
                }
            },
            "Tensor_206": {
                "variable": {
                    "value": "constraint_mask",
                    "possible_values": []
                }
            },
            "Parameter_215": {
                "variable": {
                    "value": "self.start_transitions",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_tags)",
                    "possible_values": []
                }
            },
            "Parameter_216": {
                "variable": {
                    "value": "self.end_transitions",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_tags)",
                    "possible_values": []
                }
            },
            "ones_339": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "*tags.size()",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "sum_344": {
                "input": {
                    "value": "log_numerator - log_denominator",
                    "possible_values": []
                }
            },
            "ones_361": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "*logits.shape[:2]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "logits.device",
                    "possible_values": []
                }
            },
            "index_select_414": {
                "variable": {
                    "value": "masked_prediction",
                    "possible_values": []
                },
                "input": {
                    "value": "prediction",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "mask_indices",
                    "possible_values": [
                        [
                            "prediction_mask.nonzero().squeeze()",
                            "Call"
                        ]
                    ]
                }
            },
            "Tensor_198": {},
            "Tensor_215": {},
            "Tensor_216": {}
        }
    },
    "allennlp/allennlp/modules/elmo.py": {
        "torch": {
            "Elmo_40": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._keep_sentence_boundaries": {
                    "value": "keep_sentence_boundaries",
                    "possible_values": []
                },
                "Dropout_127": {
                    "variable": {
                        "value": "self._dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": []
                    }
                }
            },
            "_ElmoCharacterEncoder_259": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._weight_file": {
                    "value": "weight_file",
                    "possible_values": []
                },
                "self.requires_grad": {
                    "value": "requires_grad",
                    "possible_values": []
                },
                "from_numpy_313": {
                    "variable": {
                        "value": "self._beginning_of_sentence_characters",
                        "possible_values": []
                    },
                    "ndarray": {
                        "value": "numpy.array(ELMoCharacterMapper.beginning_of_sentence_characters) + 1",
                        "possible_values": []
                    }
                },
                "from_numpy_316": {
                    "variable": {
                        "value": "self._end_of_sentence_characters",
                        "possible_values": []
                    },
                    "ndarray": {
                        "value": "numpy.array(ELMoCharacterMapper.end_of_sentence_characters) + 1",
                        "possible_values": []
                    }
                }
            },
            "_ElmoBiLm_502": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._requires_grad": {
                    "value": "requires_grad",
                    "possible_values": []
                }
            },
            "embedding_355": {
                "variable": {
                    "value": "character_embedding",
                    "possible_values": []
                },
                "input": {
                    "value": "character_ids_with_bos_eos.view(-1, max_chars_per_token)",
                    "possible_values": []
                },
                "weight": {
                    "value": "self._char_embedding_weights",
                    "possible_values": []
                }
            },
            "transpose_370": {
                "variable": {
                    "value": "character_embedding",
                    "possible_values": []
                },
                "input": {
                    "value": "character_embedding",
                    "possible_values": [
                        [
                            "torch.nn.functional.embedding(character_ids_with_bos_eos.view(-1, max_chars_per_token), self._char_embedding_weights)",
                            "Call"
                        ],
                        [
                            "torch.transpose(character_embedding, 1, 2)",
                            "Call"
                        ]
                    ]
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_381": {
                "variable": {
                    "value": "token_embedding",
                    "possible_values": []
                },
                "tensors": {
                    "value": "convs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Parameter_413": {
                "variable": {
                    "value": "self._char_embedding_weights",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(weights)",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "self.requires_grad",
                    "possible_values": []
                }
            },
            "Linear_489": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_filters",
                    "possible_values": [
                        [
                            "sum((f[1] for f in filters))",
                            "Call"
                        ],
                        [
                            "sum((f[1] for f in filters))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.output_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_686": {
                "variable": {
                    "value": "full_embedding",
                    "possible_values": []
                },
                "tensors": {
                    "value": "all_embeddings",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "max_376": {
                "variable": {
                    "value": "(convolved, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "convolved",
                    "possible_values": [
                        [
                            "conv(character_embedding)",
                            "Call"
                        ],
                        [
                            "activation(convolved)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Conv1d_424": {
                "variable": {
                    "value": "conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "char_embed_dim",
                    "possible_values": [
                        [
                            "cnn_options['embedding']['dim']",
                            "Subscript"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "num",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "width",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "chunk_638": {
                "input": {
                    "value": "lstm_outputs",
                    "possible_values": [
                        [
                            "self._elmo_lstm(type_representation, mask)",
                            "Call"
                        ]
                    ]
                },
                "chunks": {
                    "value": "lstm_outputs.size(0)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_635": {
                "tensors": {
                    "value": "[type_representation, type_representation]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/elmo_lstm.py": {
        "torch": {
            "pad_packed_sequence_213": {
                "variable": {
                    "value": "(inputs, batch_lengths)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "inputs",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_144": {
                "variable": {
                    "value": "stacked_sequence_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[stacked_sequence_output, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "stacked_sequence_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[stacked_sequence_output, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "stack_262": {
                "tensors": {
                    "value": "sequence_outputs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_268": {
                "tensors": {
                    "value": "final_hidden_states",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_269": {
                "tensors": {
                    "value": "final_memory_states",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_251": {
                "tensors": {
                    "value": "[forward_output_sequence, backward_output_sequence]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_151": {
                "tensors": {
                    "value": "[state, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_257": {
                "tensors": {
                    "value": "[forward_state[0], backward_state[0]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_258": {
                "tensors": {
                    "value": "[forward_state[1], backward_state[1]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/encoder_base.py": {
        "torch": {
            "_EncoderBase_15": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.stateful": {
                    "value": "stateful",
                    "possible_values": []
                }
            },
            "sum_97": {
                "variable": {
                    "value": "num_valid",
                    "possible_values": []
                },
                "input": {
                    "value": "mask[:, 0]",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_108": {
                "variable": {
                    "value": "packed_sequence_input",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_inputs[:num_valid, :, :]",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_sequence_lengths[:num_valid].data.tolist()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_198": {
                "tensors": {
                    "value": "[state, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/feedforward.py": {
        "torch": {
            "FeedForward_13": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._activations": {
                    "value": "activations",
                    "possible_values": [
                        [
                            "[activations] * num_layers",
                            "BinOp"
                        ]
                    ]
                },
                "ModuleList_72": {
                    "variable": {
                        "value": "self._linear_layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "linear_layers",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                },
                "ModuleList_74": {
                    "variable": {
                        "value": "self._dropout",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "dropout_layers",
                        "possible_values": [
                            [
                                "[torch.nn.Dropout(p=value) for value in dropout]",
                                "ListComp"
                            ]
                        ]
                    }
                },
                "self.input_dim": {
                    "value": "input_dim",
                    "possible_values": []
                }
            },
            "Dropout_73": {
                "p": {
                    "value": "value",
                    "possible_values": []
                }
            },
            "Linear_71": {
                "in_features": {
                    "value": "layer_input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "layer_output_dim",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/gated_sum.py": {
        "torch": {
            "GatedSum_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.input_dim": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "Linear_25": {
                    "variable": {
                        "value": "self._gate",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "input_dim * 2",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "self._activation": {
                    "value": "activation",
                    "possible_values": []
                }
            },
            "Sigmoid_21": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "cat_39": {
                "tensors": {
                    "value": "[input_a, input_b]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/highway.py": {
        "torch": {
            "Highway_12": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._input_dim": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "ModuleList_41": {
                    "variable": {
                        "value": "self._layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[torch.nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]",
                        "possible_values": []
                    }
                },
                "self._activation": {
                    "value": "activation",
                    "possible_values": []
                }
            },
            "sigmoid_62": {
                "variable": {
                    "value": "gate",
                    "possible_values": []
                },
                "input": {
                    "value": "gate",
                    "possible_values": [
                        [
                            "torch.sigmoid(gate)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_42": {
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim * 2",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/input_variational_dropout.py": {
        "torch": {
            "InputVariationalDropout_4": {
                "base_class_0": {
                    "value": "torch.nn.Dropout",
                    "possible_values": []
                }
            },
            "dropout_31": {
                "variable": {
                    "value": "dropout_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "ones",
                    "possible_values": [
                        [
                            "input_tensor.data.new_ones(input_tensor.shape[0], input_tensor.shape[-1])",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.p",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/language_model_heads/bert.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/language_model_heads/gpt2.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/language_model_heads/language_model_head.py": {
        "torch": {
            "LanguageModelHead_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/layer_norm.py": {
        "torch": {
            "LayerNorm_4": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Parameter_30": {
                    "variable": {
                        "value": "self.gamma",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.ones(dimension)",
                        "possible_values": []
                    }
                },
                "Parameter_31": {
                    "variable": {
                        "value": "self.beta",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(dimension)",
                        "possible_values": []
                    }
                },
                "self.eps": {
                    "value": "eps",
                    "possible_values": []
                }
            },
            "ones_30": {
                "*size": {
                    "value": "dimension",
                    "possible_values": []
                }
            },
            "zeros_31": {
                "*size": {
                    "value": "dimension",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/lstm_cell_with_projection.py": {
        "torch": {
            "LstmCellWithProjection_14": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.input_size": {
                    "value": "input_size",
                    "possible_values": []
                },
                "self.hidden_size": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "self.cell_size": {
                    "value": "cell_size",
                    "possible_values": []
                },
                "self.go_forward": {
                    "value": "go_forward",
                    "possible_values": []
                },
                "self.state_projection_clip_value": {
                    "value": "state_projection_clip_value",
                    "possible_values": []
                },
                "self.memory_cell_clip_value": {
                    "value": "memory_cell_clip_value",
                    "possible_values": []
                },
                "self.recurrent_dropout_probability": {
                    "value": "recurrent_dropout_probability",
                    "possible_values": []
                },
                "Linear_79": {
                    "variable": {
                        "value": "self.input_linearity",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "input_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "4 * cell_size",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "Linear_80": {
                    "variable": {
                        "value": "self.state_linearity",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "4 * cell_size",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "Linear_83": {
                    "variable": {
                        "value": "self.state_projection",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "cell_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "hidden_size",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                }
            },
            "sigmoid_200": {
                "variable": {
                    "value": "input_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 0 * self.cell_size:1 * self.cell_size] + projected_state[:, 0 * self.cell_size:1 * self.cell_size]",
                    "possible_values": []
                }
            },
            "sigmoid_204": {
                "variable": {
                    "value": "forget_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 1 * self.cell_size:2 * self.cell_size] + projected_state[:, 1 * self.cell_size:2 * self.cell_size]",
                    "possible_values": []
                }
            },
            "tanh_208": {
                "variable": {
                    "value": "memory_init",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 2 * self.cell_size:3 * self.cell_size] + projected_state[:, 2 * self.cell_size:3 * self.cell_size]",
                    "possible_values": []
                }
            },
            "sigmoid_212": {
                "variable": {
                    "value": "output_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 3 * self.cell_size:4 * self.cell_size] + projected_state[:, 3 * self.cell_size:4 * self.cell_size]",
                    "possible_values": []
                }
            },
            "clamp_224": {
                "variable": {
                    "value": "memory",
                    "possible_values": []
                },
                "input": {
                    "value": "memory",
                    "possible_values": [
                        [
                            "input_gate * memory_init + forget_gate * previous_memory",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(memory, -self.memory_cell_clip_value, self.memory_cell_clip_value)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "-self.memory_cell_clip_value",
                    "possible_values": []
                },
                "max": {
                    "value": "self.memory_cell_clip_value",
                    "possible_values": []
                }
            },
            "clamp_235": {
                "variable": {
                    "value": "timestep_output",
                    "possible_values": []
                },
                "input": {
                    "value": "timestep_output",
                    "possible_values": [
                        [
                            "self.state_projection(pre_projection_timestep_output)",
                            "Call"
                        ],
                        [
                            "torch.clamp(timestep_output, -self.state_projection_clip_value, self.state_projection_clip_value)",
                            "Call"
                        ],
                        [
                            "timestep_output * dropout_mask[0:current_length_index + 1]",
                            "BinOp"
                        ]
                    ]
                },
                "min": {
                    "value": "-self.state_projection_clip_value",
                    "possible_values": []
                },
                "max": {
                    "value": "self.state_projection_clip_value",
                    "possible_values": []
                }
            },
            "tanh_229": {
                "input": {
                    "value": "memory",
                    "possible_values": [
                        [
                            "input_gate * memory_init + forget_gate * previous_memory",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(memory, -self.memory_cell_clip_value, self.memory_cell_clip_value)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/masked_layer_norm.py": {
        "torch": {
            "MaskedLayerNorm_4": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Parameter_13": {
                    "variable": {
                        "value": "self.gamma",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.ones(1, 1, size) * gamma0",
                        "possible_values": []
                    }
                },
                "Parameter_14": {
                    "variable": {
                        "value": "self.beta",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(1, 1, size)",
                        "possible_values": []
                    }
                },
                "self.size": {
                    "value": "size",
                    "possible_values": []
                },
                "self.eps": {
                    "value": "eps",
                    "possible_values": []
                }
            },
            "sqrt_24": {
                "variable": {
                    "value": "std",
                    "possible_values": []
                },
                "input": {
                    "value": "(masked_centered * masked_centered).sum() / num_elements + self.eps",
                    "possible_values": []
                }
            },
            "zeros_14": {
                "*size": {
                    "value": "1",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "possible_values": []
                },
                "dtype": {
                    "value": "size",
                    "possible_values": []
                }
            },
            "ones_13": {
                "*size": {
                    "value": "1",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "possible_values": []
                },
                "dtype": {
                    "value": "size",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/matrix_attention/bilinear_matrix_attention.py": {
        "torch": {
            "Parameter_59": {
                "variable": {
                    "value": "self._bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1)",
                    "possible_values": []
                }
            },
            "matmul_81": {
                "variable": {
                    "value": "intermediate",
                    "possible_values": []
                },
                "input": {
                    "value": "matrix_1.unsqueeze(1)",
                    "possible_values": []
                },
                "other": {
                    "value": "weight",
                    "possible_values": [
                        [
                            "self._weight_matrix",
                            "Attribute"
                        ],
                        [
                            "weight.unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_82": {
                "variable": {
                    "value": "final",
                    "possible_values": []
                },
                "input": {
                    "value": "intermediate",
                    "possible_values": [
                        [
                            "torch.matmul(matrix_1.unsqueeze(1), weight)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "matrix_2.unsqueeze(1).transpose(2, 3)",
                    "possible_values": []
                }
            },
            "Parameter_53": {
                "variable": {
                    "value": "self._weight_matrix",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(matrix_1_dim, matrix_2_dim)",
                    "possible_values": []
                }
            },
            "Parameter_55": {
                "variable": {
                    "value": "self._weight_matrix",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(label_dim, matrix_1_dim, matrix_2_dim)",
                    "possible_values": []
                }
            },
            "cat_75": {
                "variable": {
                    "value": "matrix_1",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[matrix_1, bias1]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_76": {
                "variable": {
                    "value": "matrix_2",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[matrix_2, bias2]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/matrix_attention/cosine_matrix_attention.py": {
        "torch": {
            "bmm_18": {
                "input": {
                    "value": "a_norm",
                    "possible_values": [
                        [
                            "matrix_1 / (matrix_1.norm(p=2, dim=-1, keepdim=True) + 1e-13)",
                            "BinOp"
                        ]
                    ]
                },
                "mat2": {
                    "value": "b_norm.transpose(-1, -2)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/matrix_attention/dot_product_matrix_attention.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/matrix_attention/legacy_matrix_attention.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/matrix_attention/linear_matrix_attention.py": {
        "torch": {
            "Parameter_58": {
                "variable": {
                    "value": "self._weight_vector",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(combined_dim)",
                    "possible_values": []
                }
            },
            "Parameter_59": {
                "variable": {
                    "value": "self._bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/matrix_attention/matrix_attention.py": {
        "torch": {
            "MatrixAttention_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/maxout.py": {
        "torch": {
            "Maxout_12": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._pool_sizes": {
                    "value": "pool_sizes",
                    "possible_values": [
                        [
                            "[pool_sizes] * num_layers",
                            "BinOp"
                        ]
                    ]
                },
                "ModuleList_74": {
                    "variable": {
                        "value": "self._linear_layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "linear_layers",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                },
                "ModuleList_76": {
                    "variable": {
                        "value": "self._dropout",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "dropout_layers",
                        "possible_values": [
                            [
                                "[torch.nn.Dropout(p=value) for value in dropout]",
                                "ListComp"
                            ]
                        ]
                    }
                },
                "self._output_dims": {
                    "value": "output_dims",
                    "possible_values": [
                        [
                            "[output_dims] * num_layers",
                            "BinOp"
                        ]
                    ]
                },
                "self._input_dim": {
                    "value": "input_dim",
                    "possible_values": []
                }
            },
            "Dropout_75": {
                "p": {
                    "value": "value",
                    "possible_values": []
                }
            },
            "Linear_72": {
                "in_features": {
                    "value": "layer_input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "layer_output_dim * pool_size",
                    "possible_values": []
                }
            },
            "max_99": {
                "input": {
                    "value": "affine_output.view(*shape)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/pruner.py": {
        "torch": {
            "Pruner_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._scorer": {
                    "value": "scorer",
                    "possible_values": []
                }
            },
            "where_115": {
                "variable": {
                    "value": "top_indices",
                    "possible_values": []
                },
                "condition": {
                    "value": "top_indices_mask",
                    "possible_values": [
                        [
                            "util.get_mask_from_sequence_lengths(num_items_to_keep, max_items_to_keep)",
                            "Call"
                        ],
                        [
                            "top_indices_mask.byte()",
                            "Call"
                        ]
                    ]
                },
                "x": {
                    "value": "top_indices",
                    "possible_values": [
                        [
                            "top_indices.squeeze(-1)",
                            "Call"
                        ],
                        [
                            "torch.where(top_indices_mask, top_indices, fill_value)",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "fill_value",
                    "possible_values": [
                        [
                            "fill_value.unsqueeze(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sort_120": {
                "variable": {
                    "value": "(top_indices, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "top_indices",
                    "possible_values": [
                        [
                            "top_indices.squeeze(-1)",
                            "Call"
                        ],
                        [
                            "torch.where(top_indices_mask, top_indices, fill_value)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ones_76": {
                "*size": {
                    "value": "[batch_size]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "mask.device",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/residual_with_layer_dropout.py": {
        "torch": {
            "ResidualWithLayerDropout_4": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.undecayed_dropout_prob": {
                    "value": "undecayed_dropout_prob",
                    "possible_values": []
                }
            },
            "rand_61": {
                "*size": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/sampled_softmax_loss.py": {
        "torch": {
            "SampledSoftmaxLoss_45": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.sparse": {
                    "value": "sparse",
                    "possible_values": []
                },
                "self.use_character_inputs": {
                    "value": "use_character_inputs",
                    "possible_values": []
                },
                "self._num_samples": {
                    "value": "num_samples",
                    "possible_values": []
                },
                "self._embedding_dim": {
                    "value": "embedding_dim",
                    "possible_values": []
                },
                "self._num_words": {
                    "value": "num_words",
                    "possible_values": [
                        [
                            "self.softmax_w.weight.size(0)",
                            "Call"
                        ],
                        [
                            "self.softmax_w.size(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_188": {
                "variable": {
                    "value": "all_ids",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[long_targets, sampled_ids]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_232": {
                "variable": {
                    "value": "logits",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[true_logits.unsqueeze(1), masked_sampled_logits]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_235": {
                "variable": {
                    "value": "log_softmax",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "torch.cat([true_logits.unsqueeze(1), masked_sampled_logits], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_255": {
                "variable": {
                    "value": "log_softmax",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.matmul(embeddings, w.t()) + b",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "from_numpy_284": {
                "variable": {
                    "value": "sampled_ids",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np_sampled_ids",
                    "possible_values": []
                }
            },
            "Embedding_99": {
                "variable": {
                    "value": "self.softmax_w",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_words",
                    "possible_values": [
                        [
                            "self.softmax_w.weight.size(0)",
                            "Call"
                        ],
                        [
                            "self.softmax_w.size(0)",
                            "Call"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "possible_values": []
                },
                "sparse": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Embedding_103": {
                "variable": {
                    "value": "self.softmax_b",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_words",
                    "possible_values": [
                        [
                            "self.softmax_w.weight.size(0)",
                            "Call"
                        ],
                        [
                            "self.softmax_w.size(0)",
                            "Call"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "1",
                    "possible_values": []
                },
                "sparse": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Parameter_108": {
                "variable": {
                    "value": "self.softmax_w",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn(num_words, embedding_dim) / np.sqrt(embedding_dim)",
                    "possible_values": []
                }
            },
            "Parameter_111": {
                "variable": {
                    "value": "self.softmax_b",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(num_words)",
                    "possible_values": []
                }
            },
            "embedding_195": {
                "variable": {
                    "value": "all_w",
                    "possible_values": []
                },
                "input": {
                    "value": "all_ids",
                    "possible_values": [
                        [
                            "torch.cat([long_targets, sampled_ids], dim=0)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.softmax_w",
                    "possible_values": []
                }
            },
            "embedding_198": {
                "variable": {
                    "value": "all_b",
                    "possible_values": []
                },
                "input": {
                    "value": "all_ids",
                    "possible_values": [
                        [
                            "torch.cat([long_targets, sampled_ids], dim=0)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.softmax_b.unsqueeze(1)",
                    "possible_values": []
                }
            },
            "squeeze_198": {
                "variable": {
                    "value": "all_b",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "nll_loss_262": {
                "input": {
                    "value": "log_softmax",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(logits, dim=1)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.log_softmax(torch.matmul(embeddings, w.t()) + b, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets_.long()",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "possible_values": []
                }
            },
            "tensor_153": {
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "log_213": {
                "input": {
                    "value": "target_expected_count + 1e-07",
                    "possible_values": []
                }
            },
            "log_219": {
                "input": {
                    "value": "sampled_expected_count + 1e-07",
                    "possible_values": []
                }
            },
            "log_289": {
                "input": {
                    "value": "(targets.float() + 2.0) / (targets.float() + 1.0)",
                    "possible_values": []
                }
            },
            "log_296": {
                "input": {
                    "value": "(sampled_ids.float() + 2.0) / (sampled_ids.float() + 1.0)",
                    "possible_values": []
                }
            },
            "zeros_111": {
                "*size": {
                    "value": "num_words",
                    "possible_values": [
                        [
                            "self.softmax_w.weight.size(0)",
                            "Call"
                        ],
                        [
                            "self.softmax_w.size(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_217": {
                "input": {
                    "value": "embeddings",
                    "possible_values": []
                },
                "other": {
                    "value": "sampled_w.t()",
                    "possible_values": []
                }
            },
            "matmul_256": {
                "input": {
                    "value": "embeddings",
                    "possible_values": []
                },
                "other": {
                    "value": "w.t()",
                    "possible_values": []
                }
            },
            "exp_293": {
                "input": {
                    "value": "num_tries * torch.log1p(-target_probs)",
                    "possible_values": []
                }
            },
            "exp_300": {
                "input": {
                    "value": "num_tries * torch.log1p(-sampled_probs)",
                    "possible_values": []
                }
            },
            "randn_109": {
                "*size": {
                    "value": "num_words",
                    "possible_values": [
                        [
                            "self.softmax_w.weight.size(0)",
                            "Call"
                        ],
                        [
                            "self.softmax_w.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "embedding_dim",
                    "possible_values": []
                }
            },
            "log1p_293": {
                "input": {
                    "value": "-target_probs",
                    "possible_values": []
                }
            },
            "log1p_300": {
                "input": {
                    "value": "-sampled_probs",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/scalar_mix.py": {
        "torch": {
            "ScalarMix_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.mixture_size": {
                    "value": "mixture_size",
                    "possible_values": []
                },
                "self.do_layer_norm": {
                    "value": "do_layer_norm",
                    "possible_values": []
                },
                "ParameterList_37": {
                    "variable": {
                        "value": "self.scalar_parameters",
                        "possible_values": []
                    },
                    "parameters": {
                        "value": "[Parameter(torch.FloatTensor([initial_scalar_parameters[i]]), requires_grad=trainable) for i in range(mixture_size)]",
                        "possible_values": []
                    }
                },
                "Parameter_46": {
                    "variable": {
                        "value": "self.gamma",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.FloatTensor([1.0])",
                        "possible_values": []
                    },
                    "requires_grad": {
                        "value": "trainable",
                        "possible_values": []
                    }
                }
            },
            "softmax_77": {
                "variable": {
                    "value": "normed_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.cat([parameter for parameter in self.scalar_parameters])",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "split_80": {
                "variable": {
                    "value": "normed_weights",
                    "possible_values": []
                },
                "tensor": {
                    "value": "normed_weights",
                    "possible_values": [
                        [
                            "torch.nn.functional.softmax(torch.cat([parameter for parameter in self.scalar_parameters]), dim=0)",
                            "Call"
                        ],
                        [
                            "torch.split(normed_weights, split_size_or_sections=1)",
                            "Call"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_78": {
                "tensors": {
                    "value": "[parameter for parameter in self.scalar_parameters]",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "data": {
                    "value": "torch.FloatTensor([initial_scalar_parameters[i]])",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "trainable",
                    "possible_values": []
                }
            },
            "sum_70": {
                "input": {
                    "value": "tensor_masked",
                    "possible_values": [
                        [
                            "tensor * broadcast_mask",
                            "BinOp"
                        ]
                    ]
                }
            },
            "sum_72": {
                "input": {
                    "value": "((tensor_masked - mean) * broadcast_mask) ** 2",
                    "possible_values": []
                }
            },
            "sqrt_75": {
                "input": {
                    "value": "variance + 1e-12",
                    "possible_values": []
                }
            },
            "sum_92": {
                "input": {
                    "value": "mask_float",
                    "possible_values": [
                        [
                            "mask.float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_decoders/auto_regressive_seq_decoder.py": {
        "torch": {
            "Linear_107": {
                "variable": {
                    "value": "self._output_projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._decoder_net.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "target_vocab_size",
                    "possible_values": [
                        [
                            "self._vocab.get_vocab_size(self._target_namespace)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_softmax_417": {
                "variable": {
                    "value": "class_log_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "output_projections",
                    "possible_values": [
                        [
                            "self._output_projection_layer(decoder_output)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Tensor_203": {
                "variable": {
                    "value": "steps_embeddings",
                    "possible_values": []
                }
            },
            "cat_262": {
                "variable": {
                    "value": "logits",
                    "possible_values": []
                },
                "tensors": {
                    "value": "step_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_308": {
                "variable": {
                    "value": "previous_steps_predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[previous_steps_predictions, last_predictions_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_240": {
                "variable": {
                    "value": "(_, predicted_classes)",
                    "possible_values": []
                },
                "input": {
                    "value": "output_projections",
                    "possible_values": [
                        [
                            "self._output_projection_layer(decoder_output)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_257": {
                "variable": {
                    "value": "steps_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[steps_embeddings, last_predictions_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Tensor_224": {
                "variable": {
                    "value": "state[previous_steps_predictions]",
                    "possible_values": []
                }
            },
            "rand_210": {
                "*size": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_decoders/decoder_net.py": {
        "torch": {
            "DecoderNet_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.target_embedding_dim": {
                    "value": "target_embedding_dim",
                    "possible_values": []
                },
                "self.decoding_dim": {
                    "value": "decoding_dim",
                    "possible_values": []
                },
                "self.decodes_parallel": {
                    "value": "decodes_parallel",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_decoders/lstm_cell_decoder_net.py": {
        "torch": {
            "LSTMCell_59": {
                "variable": {
                    "value": "self._decoder_cell",
                    "possible_values": []
                },
                "input_size": {
                    "value": "decoder_input_dim",
                    "possible_values": [
                        [
                            "self.target_embedding_dim",
                            "Attribute"
                        ],
                        [
                            "decoder_input_dim + decoding_dim",
                            "BinOp"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "self.decoding_dim",
                    "possible_values": []
                }
            },
            "cat_130": {
                "variable": {
                    "value": "decoder_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(attended_input, last_predictions_embedding)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_decoders/seq_decoder.py": {
        "torch": {
            "SeqDecoder_10": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.target_embedder": {
                    "value": "target_embedder",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_decoders/stacked_self_attention_decoder_net.py": {
        "torch": {
            "Decoder_145": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "DecoderLayer_170": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.size": {
                    "value": "size",
                    "possible_values": []
                },
                "self.self_attn": {
                    "value": "self_attn",
                    "possible_values": []
                },
                "self.src_attn": {
                    "value": "src_attn",
                    "possible_values": []
                },
                "self.feed_forward": {
                    "value": "feed_forward",
                    "possible_values": [
                        [
                            "PositionwiseFeedForward(decoding_dim, feedforward_hidden_dim, dropout_prob)",
                            "Call"
                        ]
                    ]
                }
            },
            "Dropout_87": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_prob",
                    "possible_values": []
                }
            },
            "ModuleList_142": {
                "modules": {
                    "value": "[copy.deepcopy(module) for _ in range(num_layers)]",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/__init__.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/seq2seq_encoders/bidirectional_language_model_transformer.py": {
        "torch": {
            "PositionalEncoding_50": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "zeros_57": {
                    "variable": {
                        "value": "positional_encoding",
                        "possible_values": []
                    },
                    "*size": {
                        "value": "max_len",
                        "possible_values": []
                    },
                    "out": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "requires_grad": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "arange_58": {
                    "variable": {
                        "value": "position",
                        "possible_values": []
                    },
                    "start": {
                        "value": "0",
                        "possible_values": []
                    },
                    "end": {
                        "value": "max_len",
                        "possible_values": []
                    }
                },
                "unsqueeze_58": {
                    "variable": {
                        "value": "position",
                        "possible_values": []
                    },
                    "input": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "exp_59": {
                    "variable": {
                        "value": "div_term",
                        "possible_values": []
                    },
                    "input": {
                        "value": "torch.arange(0, input_dim, 2).float() * -(math.log(10000.0) / input_dim)",
                        "possible_values": []
                    }
                },
                "sin_62": {
                    "variable": {
                        "value": "positional_encoding[:, 0::2]",
                        "possible_values": []
                    },
                    "input": {
                        "value": "position * div_term",
                        "possible_values": []
                    }
                },
                "cos_63": {
                    "variable": {
                        "value": "positional_encoding[:, 1::2]",
                        "possible_values": []
                    },
                    "input": {
                        "value": "position * div_term",
                        "possible_values": []
                    }
                }
            },
            "PositionwiseFeedForward_72": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_77": {
                    "variable": {
                        "value": "self.w_1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "ff_dim",
                        "possible_values": []
                    }
                },
                "Linear_78": {
                    "variable": {
                        "value": "self.w_2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "ff_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "input_dim",
                        "possible_values": []
                    }
                },
                "Dropout_79": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": []
                    }
                }
            },
            "TransformerEncoder_86": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.return_all_layers": {
                    "value": "return_all_layers",
                    "possible_values": []
                }
            },
            "SublayerConnection_111": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Dropout_120": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": []
                    }
                }
            },
            "EncoderLayer_129": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.self_attn": {
                    "value": "self_attn",
                    "possible_values": []
                },
                "self.feed_forward": {
                    "value": "feed_forward",
                    "possible_values": []
                },
                "self.size": {
                    "value": "size",
                    "possible_values": []
                }
            },
            "MultiHeadedAttention_151": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_heads": {
                    "value": "num_heads",
                    "possible_values": []
                },
                "Dropout_161": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": []
                    }
                }
            },
            "softmax_36": {
                "variable": {
                    "value": "p_attn",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "possible_values": [
                        [
                            "torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)",
                            "BinOp"
                        ],
                        [
                            "scores.masked_fill(mask == 0, -1000000000.0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "tril_44": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.ones(size, size, device=device, dtype=torch.int32)",
                    "possible_values": []
                }
            },
            "unsqueeze_44": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "matmul_33": {
                "input": {
                    "value": "query",
                    "possible_values": []
                },
                "other": {
                    "value": "key.transpose(-2, -1)",
                    "possible_values": []
                }
            },
            "matmul_39": {
                "input": {
                    "value": "p_attn",
                    "possible_values": [
                        [
                            "F.softmax(scores, dim=-1)",
                            "Call"
                        ],
                        [
                            "dropout(p_attn)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value",
                    "possible_values": []
                }
            },
            "Dropout_260": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "input_dropout",
                    "possible_values": []
                }
            },
            "cat_304": {
                "tensors": {
                    "value": "[forward_output, backward_output]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_160": {
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim",
                    "possible_values": []
                }
            },
            "ones_45": {
                "*size": {
                    "value": "size",
                    "possible_values": []
                },
                "out": {
                    "value": "size",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "mask.device",
                            "Attribute"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int32",
                    "possible_values": []
                }
            },
            "arange_60": {
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "step": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "relu_83": {
                "input": {
                    "value": "self.w_1(x)",
                    "possible_values": []
                }
            },
            "cat_301": {
                "tensors": {
                    "value": "[forward, backward]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/compose_encoder.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/seq2seq_encoders/feedforward_encoder.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/seq2seq_encoders/gated_cnn_encoder.py": {
        "torch": {
            "ResidualBlock_10": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.dropout": {
                    "value": "dropout",
                    "possible_values": []
                },
                "ModuleList_22": {
                    "variable": {
                        "value": "self._convolutions",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "last_dim": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "self._direction": {
                    "value": "direction",
                    "possible_values": []
                }
            },
            "ModuleList_168": {
                "variable": {
                    "value": "self._forward_residual_blocks",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ModuleList_169": {
                "variable": {
                    "value": "self._backward_residual_blocks",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "transpose_186": {
                "variable": {
                    "value": "transposed_embeddings",
                    "possible_values": []
                },
                "input": {
                    "value": "token_embeddings",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "glu_105": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "conv_out",
                    "possible_values": [
                        [
                            "convolution(out)",
                            "Call"
                        ],
                        [
                            "conv_out.narrow(2, 0, timesteps)",
                            "Call"
                        ],
                        [
                            "conv_out.narrow(2, dims_to_remove, timesteps)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Conv1d_30": {
                "variable": {
                    "value": "conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "last_dim",
                    "possible_values": [
                        [
                            "input_dim",
                            "Name"
                        ],
                        [
                            "layer[1]",
                            "Subscript"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "layer[1] * 2",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "layer[0]",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "layer[0] - 1",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "weight_norm_70": {
                "variable": {
                    "value": "conv",
                    "possible_values": []
                },
                "module": {
                    "value": "conv",
                    "possible_values": [
                        [
                            "torch.nn.Conv1d(last_dim, layer[1] * 2, layer[0], stride=1, padding=layer[0] - 1, bias=True)",
                            "Call"
                        ],
                        [
                            "torch.nn.Conv1d(last_dim, layer[1] * 2, layer[0], stride=1, padding=layer[2], dilation=layer[2], bias=True)",
                            "Call"
                        ],
                        [
                            "torch.nn.utils.weight_norm(conv, name='weight', dim=0)",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "weight",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "dropout_90": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "possible_values": [
                        [
                            "x",
                            "Name"
                        ],
                        [
                            "torch.nn.functional.dropout(out, self.dropout, self.training)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.glu(conv_out, dim=1)",
                            "Call"
                        ],
                        [
                            "transposed_embeddings",
                            "Name"
                        ],
                        [
                            "block(out.masked_fill(mask_for_fill, 0.0))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "cat_220": {
                "tensors": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "transpose_220": {
                "input": {
                    "value": "1",
                    "possible_values": []
                },
                "dim0": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "Conv1d_41": {
                "variable": {
                    "value": "conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "last_dim",
                    "possible_values": [
                        [
                            "input_dim",
                            "Name"
                        ],
                        [
                            "layer[1]",
                            "Subscript"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "layer[1] * 2",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "layer[0]",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "layer[2]",
                    "possible_values": [
                        [
                            "layers",
                            "Name"
                        ]
                    ]
                },
                "dilation": {
                    "value": "layer[2]",
                    "possible_values": [
                        [
                            "layers",
                            "Name"
                        ]
                    ]
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_215": {
                "tensors": {
                    "value": "[fwd, bwd]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "transpose_215": {
                "input": {
                    "value": "1",
                    "possible_values": []
                },
                "dim0": {
                    "value": "2",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/intra_sentence_attention.py": {
        "torch": {
            "Linear_69": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "projection_dim",
                    "possible_values": [
                        [
                            "input_dim",
                            "Name"
                        ]
                    ]
                }
            },
            "Linear_94": {
                "variable": {
                    "value": "self._output_projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "combined_dim",
                    "possible_values": [
                        [
                            "util.get_combined_dim(combination, [input_dim, projection_dim])",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/multi_head_self_attention.py": {
        "torch": {
            "Linear_70": {
                "variable": {
                    "value": "self._combined_projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2 * attention_dim + values_dim",
                    "possible_values": []
                }
            },
            "Linear_73": {
                "variable": {
                    "value": "self._output_projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "values_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self._output_dim",
                    "possible_values": []
                }
            },
            "Dropout_74": {
                "variable": {
                    "value": "self._attention_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "attention_dropout_prob",
                    "possible_values": []
                }
            },
            "cat_117": {
                "variable": {
                    "value": "values",
                    "possible_values": []
                },
                "tensors": {
                    "value": "values",
                    "possible_values": [
                        [
                            "torch.cat(values, -1).contiguous()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "bmm_146": {
                "variable": {
                    "value": "scaled_similarities",
                    "possible_values": []
                },
                "input": {
                    "value": "queries_per_head / self._scale",
                    "possible_values": []
                },
                "mat2": {
                    "value": "keys_per_head.transpose(1, 2)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/pass_through_encoder.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py": {
        "torch": {
            "pad_packed_sequence_93": {
                "variable": {
                    "value": "(unpacked_sequence_tensor, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "packed_sequence_output",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_109": {
                "variable": {
                    "value": "unpacked_sequence_tensor",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[unpacked_sequence_tensor, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_135": {
                "variable": {
                    "value": "unpacked_sequence_tensor",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[unpacked_sequence_tensor, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_119": {
                "tensors": {
                    "value": "[state, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/qanet_encoder.py": {
        "torch": {
            "ModuleList_81": {
                "variable": {
                    "value": "self._encoder_blocks",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "possible_values": []
                }
            },
            "ModuleList_190": {
                "variable": {
                    "value": "self._conv_norm_layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(hidden_dim) for _ in range(num_convs)]",
                    "possible_values": []
                }
            },
            "ModuleList_193": {
                "variable": {
                    "value": "self._conv_layers",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "LayerNorm_211": {
                "variable": {
                    "value": "self.attention_norm_layer",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            },
            "LayerNorm_219": {
                "variable": {
                    "value": "self.feedforward_norm_layer",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            },
            "Dropout_228": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_prob",
                    "possible_values": []
                }
            },
            "Linear_77": {
                "variable": {
                    "value": "self._input_projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            },
            "ConstantPad1d_195": {
                "variable": {
                    "value": "padding",
                    "possible_values": []
                },
                "padding": {
                    "value": "(conv_kernel_size // 2, (conv_kernel_size - 1) // 2)",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Conv1d_198": {
                "variable": {
                    "value": "depthwise_conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "conv_kernel_size",
                    "possible_values": []
                },
                "groups": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            },
            "Conv1d_201": {
                "variable": {
                    "value": "pointwise_conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "LayerNorm_191": {
                "normalized_shape": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            },
            "Sequential_203": {
                "*args": {
                    "value": "padding",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2seq_encoders/stacked_self_attention.py": {
        "torch": {
            "Dropout_124": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "residual_dropout_prob",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2vec_encoders/__init__.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/seq2vec_encoders/bert_pooler.py": {
        "torch": {
            "Dropout_52": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2vec_encoders/boe_encoder.py": {
        "torch": {
            "max_53": {
                "variable": {
                    "value": "lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "possible_values": [
                        [
                            "get_lengths_from_binary_sequence_mask(mask)",
                            "Call"
                        ],
                        [
                            "torch.max(lengths, lengths.new_ones(1))",
                            "Call"
                        ],
                        [
                            "tokens.new_full((1,), fill_value=tokens.size(1))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2vec_encoders/cnn_encoder.py": {
        "torch": {
            "transpose_100": {
                "variable": {
                    "value": "tokens",
                    "possible_values": []
                },
                "input": {
                    "value": "tokens",
                    "possible_values": [
                        [
                            "tokens * mask.unsqueeze(-1).float()",
                            "BinOp"
                        ],
                        [
                            "torch.transpose(tokens, 1, 2)",
                            "Call"
                        ]
                    ]
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "Linear_79": {
                "variable": {
                    "value": "self.projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "maxpool_output_dim",
                    "possible_values": [
                        [
                            "self._num_filters * len(self._ngram_filter_sizes)",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self._output_dim",
                    "possible_values": []
                }
            },
            "Conv1d_67": {
                "in_channels": {
                    "value": "self._embedding_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "self._num_filters",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "ngram_size",
                    "possible_values": []
                }
            },
            "cat_118": {
                "tensors": {
                    "value": "filter_outputs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2vec_encoders/cnn_highway_encoder.py": {
        "torch": {
            "Linear_98": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "num_filters",
                    "possible_values": [
                        [
                            "sum((num for (_, num) in filters))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "projection_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_142": {
                "variable": {
                    "value": "token_embedding",
                    "possible_values": []
                },
                "tensors": {
                    "value": "convolutions",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Conv1d_69": {
                "variable": {
                    "value": "conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "embedding_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "num",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "width",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_137": {
                "variable": {
                    "value": "(convolved, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "convolved",
                    "possible_values": [
                        [
                            "char_conv_i(inputs)",
                            "Call"
                        ],
                        [
                            "self._activation(convolved)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py": {
        "torch": {
            "cat_94": {
                "variable": {
                    "value": "state",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[state, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/similarity_functions/bilinear.py": {
        "torch": {
            "Parameter_35": {
                "variable": {
                    "value": "self._weight_matrix",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(tensor_1_dim, tensor_2_dim)",
                    "possible_values": []
                }
            },
            "Parameter_36": {
                "variable": {
                    "value": "self._bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1)",
                    "possible_values": []
                }
            },
            "matmul_46": {
                "variable": {
                    "value": "intermediate",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor_1",
                    "possible_values": []
                },
                "other": {
                    "value": "self._weight_matrix",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/similarity_functions/cosine.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/similarity_functions/dot_product.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/similarity_functions/linear.py": {
        "torch": {
            "Parameter_56": {
                "variable": {
                    "value": "self._weight_vector",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(combined_dim)",
                    "possible_values": []
                }
            },
            "Parameter_57": {
                "variable": {
                    "value": "self._bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1)",
                    "possible_values": []
                }
            },
            "matmul_69": {
                "variable": {
                    "value": "dot_product",
                    "possible_values": []
                },
                "input": {
                    "value": "combined_tensors",
                    "possible_values": [
                        [
                            "util.combine_tensors(self._combination, [tensor_1, tensor_2])",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self._weight_vector",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/similarity_functions/multiheaded.py": {
        "torch": {
            "Parameter_74": {
                "variable": {
                    "value": "self._tensor_1_projection",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(tensor_1_dim, tensor_1_projected_dim)",
                    "possible_values": []
                }
            },
            "Parameter_77": {
                "variable": {
                    "value": "self._tensor_2_projection",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(tensor_2_dim, tensor_2_projected_dim)",
                    "possible_values": []
                }
            },
            "matmul_88": {
                "variable": {
                    "value": "projected_tensor_1",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor_1",
                    "possible_values": []
                },
                "other": {
                    "value": "self._tensor_1_projection",
                    "possible_values": []
                }
            },
            "matmul_89": {
                "variable": {
                    "value": "projected_tensor_2",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor_2",
                    "possible_values": []
                },
                "other": {
                    "value": "self._tensor_2_projection",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/similarity_functions/similarity_function.py": {
        "torch": {
            "SimilarityFunction_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/span_extractors/bidirectional_endpoint_span_extractor.py": {
        "torch": {
            "cat_247": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[forward_spans, backward_spans]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Parameter_105": {
                "variable": {
                    "value": "self._start_sentinel",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn([1, 1, int(input_dim / 2)])",
                    "possible_values": []
                }
            },
            "Parameter_106": {
                "variable": {
                    "value": "self._end_sentinel",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn([1, 1, int(input_dim / 2)])",
                    "possible_values": []
                }
            },
            "cat_260": {
                "tensors": {
                    "value": "[span_embeddings, span_width_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "randn_105": {
                "*size": {
                    "value": "[1, 1, int(input_dim / 2)]",
                    "possible_values": []
                }
            },
            "randn_106": {
                "*size": {
                    "value": "[1, 1, int(input_dim / 2)]",
                    "possible_values": []
                }
            },
            "ones_like_168": {
                "input": {
                    "value": "sequence_tensor[:, 0, 0]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/span_extractors/endpoint_span_extractor.py": {
        "torch": {
            "Parameter_69": {
                "variable": {
                    "value": "self._start_sentinel",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn([1, 1, int(input_dim)])",
                    "possible_values": []
                }
            },
            "cat_170": {
                "variable": {
                    "value": "combined_tensors",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[combined_tensors, span_width_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "randn_69": {
                "*size": {
                    "value": "[1, 1, int(input_dim)]",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/span_extractors/self_attentive_span_extractor.py": {
        "torch": {
            "cat_56": {
                "variable": {
                    "value": "concat_tensor",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[sequence_tensor, global_attention_logits]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_37": {
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/span_extractors/span_extractor.py": {
        "torch": {
            "SpanExtractor_7": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/stacked_alternating_lstm.py": {
        "torch": {
            "StackedAlternatingLstm_15": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.input_size": {
                    "value": "input_size",
                    "possible_values": []
                },
                "self.hidden_size": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "self.num_layers": {
                    "value": "num_layers",
                    "possible_values": []
                },
                "lstm_input_size": {
                    "value": "input_size",
                    "possible_values": []
                },
                "self.lstm_layers": {
                    "value": "layers",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_122": {
                "tensors": {
                    "value": "state_list",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/stacked_bidirectional_lstm.py": {
        "torch": {
            "StackedBidirectionalLstm_12": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.input_size": {
                    "value": "input_size",
                    "possible_values": []
                },
                "self.hidden_size": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "self.num_layers": {
                    "value": "num_layers",
                    "possible_values": []
                },
                "lstm_input_size": {
                    "value": "input_size",
                    "possible_values": []
                },
                "self.lstm_layers": {
                    "value": "layers",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_151": {
                "variable": {
                    "value": "final_h",
                    "possible_values": []
                },
                "tensors": {
                    "value": "final_h",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(final_h, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_152": {
                "variable": {
                    "value": "final_c",
                    "possible_values": []
                },
                "tensors": {
                    "value": "final_c",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(final_c, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_134": {
                "variable": {
                    "value": "(forward_output, lengths)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "forward_output",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_137": {
                "variable": {
                    "value": "(backward_output, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "backward_output",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_139": {
                "variable": {
                    "value": "output_sequence",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[forward_output, backward_output]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_144": {
                "variable": {
                    "value": "output_sequence",
                    "possible_values": []
                },
                "input": {
                    "value": "output_sequence",
                    "possible_values": [
                        [
                            "inputs",
                            "Name"
                        ],
                        [
                            "torch.cat([forward_output, backward_output], -1)",
                            "Call"
                        ],
                        [
                            "self.layer_dropout(output_sequence)",
                            "Call"
                        ],
                        [
                            "pack_padded_sequence(output_sequence, lengths, batch_first=True)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "lengths",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/text_field_embedders/basic_text_field_embedder.py": {
        "torch": {
            "cat_94": {
                "tensors": {
                    "value": "embedded_representations",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/text_field_embedders/text_field_embedder.py": {
        "torch": {
            "TextFieldEmbedder_7": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/time_distributed.py": {
        "torch": {
            "TimeDistributed_13": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self._module": {
                    "value": "module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/bag_of_word_counts_token_embedder.py": {
        "torch": {
            "cat_86": {
                "variable": {
                    "value": "bag_of_words_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "bag_of_words_vectors",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Linear_43": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.vocab_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "projection_dim",
                    "possible_values": []
                }
            },
            "masked_select_82": {
                "variable": {
                    "value": "document",
                    "possible_values": []
                },
                "input": {
                    "value": "document",
                    "possible_values": [
                        [
                            "torch.masked_select(document, doc_mask.to(dtype=torch.bool))",
                            "Call"
                        ]
                    ]
                },
                "mask": {
                    "value": "doc_mask.to(dtype=torch.bool)",
                    "possible_values": []
                }
            },
            "bincount_83": {
                "variable": {
                    "value": "vec",
                    "possible_values": []
                },
                "input": {
                    "value": "document",
                    "possible_values": [
                        [
                            "torch.masked_select(document, doc_mask.to(dtype=torch.bool))",
                            "Call"
                        ]
                    ]
                },
                "minlength": {
                    "value": "self.vocab_size",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/bert_token_embedder.py": {
        "torch": {
            "stack_200": {
                "variable": {
                    "value": "all_encoder_layers",
                    "possible_values": []
                },
                "tensors": {
                    "value": "all_encoder_layers",
                    "possible_values": [
                        [
                            "torch.stack(all_encoder_layers)",
                            "Call"
                        ]
                    ]
                }
            },
            "pad_167": {
                "variable": {
                    "value": "split_input_ids[-1]",
                    "possible_values": []
                },
                "input": {
                    "value": "split_input_ids[-1]",
                    "possible_values": []
                },
                "pad": {
                    "value": "[0, padding_amount]",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_172": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "tensors": {
                    "value": "split_input_ids",
                    "possible_values": [
                        [
                            "list(input_ids.split(self.max_pieces, dim=-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_like_189": {
                "variable": {
                    "value": "token_type_ids",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "possible_values": [
                        [
                            "torch.cat(split_input_ids, dim=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "split_204": {
                "variable": {
                    "value": "unpacked_embeddings",
                    "possible_values": []
                },
                "tensor": {
                    "value": "all_encoder_layers",
                    "possible_values": [
                        [
                            "torch.stack(all_encoder_layers)",
                            "Call"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "batch_size",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_205": {
                "variable": {
                    "value": "unpacked_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "unpacked_embeddings",
                    "possible_values": [
                        [
                            "torch.split(all_encoder_layers, batch_size, dim=1)",
                            "Call"
                        ],
                        [
                            "torch.cat(unpacked_embeddings, dim=2)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "pad_182": {
                "variable": {
                    "value": "split_token_type_ids[-1]",
                    "possible_values": []
                },
                "input": {
                    "value": "split_token_type_ids[-1]",
                    "possible_values": []
                },
                "pad": {
                    "value": "[0, padding_amount]",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_186": {
                "variable": {
                    "value": "token_type_ids",
                    "possible_values": []
                },
                "tensors": {
                    "value": "split_token_type_ids",
                    "possible_values": [
                        [
                            "list(token_type_ids.split(self.max_pieces, dim=-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/elmo_token_embedder.py": {
        "torch": {
            "Linear_74": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self._elmo.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "projection_dim",
                    "possible_values": [
                        [
                            "params.pop_int('projection_dim', None)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/elmo_token_embedder_multilang.py": {
        "torch": {
            "Linear_99": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "output_dim_tmp",
                            "Name"
                        ]
                    ]
                },
                "out_features": {
                    "value": "projection_dim",
                    "possible_values": [
                        [
                            "params.pop_int('projection_dim', None)",
                            "Call"
                        ]
                    ]
                }
            },
            "eye_106": {
                "variable": {
                    "value": "aligning_matrix",
                    "possible_values": []
                },
                "n": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "output_dim_tmp",
                            "Name"
                        ]
                    ]
                }
            },
            "Linear_111": {
                "variable": {
                    "value": "aligning",
                    "possible_values": []
                },
                "in_features": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "output_dim_tmp",
                            "Name"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "output_dim_tmp",
                            "Name"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Parameter_112": {
                "variable": {
                    "value": "aligning.weight",
                    "possible_values": []
                },
                "data": {
                    "value": "aligning_matrix",
                    "possible_values": [
                        [
                            "torch.eye(output_dim)",
                            "Call"
                        ],
                        [
                            "torch.FloatTensor(torch.load(aligninig_path))",
                            "Call"
                        ]
                    ]
                },
                "requires_grad": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "load_109": {
                "f": {
                    "value": "aligninig_path",
                    "possible_values": [
                        [
                            "cached_path(aligning_files[lang])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/embedding.py": {
        "torch": {
            "embedding_151": {
                "variable": {
                    "value": "embedded",
                    "possible_values": []
                },
                "input": {
                    "value": "tokens",
                    "possible_values": [
                        [
                            "util.combine_initial_dims(tokens)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.padding_index",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "self.max_norm",
                    "possible_values": []
                },
                "norm_type": {
                    "value": "self.norm_type",
                    "possible_values": []
                },
                "scale_grad_by_freq": {
                    "value": "self.scale_grad_by_freq",
                    "possible_values": []
                },
                "sparse": {
                    "value": "self.sparse",
                    "possible_values": []
                }
            },
            "cat_277": {
                "variable": {
                    "value": "extended_weight",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.weight.data, extra_weight.to(device)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Parameter_278": {
                "variable": {
                    "value": "self.weight",
                    "possible_values": []
                },
                "data": {
                    "value": "extended_weight",
                    "possible_values": [
                        [
                            "torch.cat([self.weight.data, extra_weight.to(device)], dim=0)",
                            "Call"
                        ]
                    ]
                },
                "requires_grad": {
                    "value": "self.weight.requires_grad",
                    "possible_values": []
                }
            },
            "Parameter_121": {
                "variable": {
                    "value": "self.weight",
                    "possible_values": []
                },
                "data": {
                    "value": "weight",
                    "possible_values": [
                        [
                            "torch.FloatTensor(num_embeddings, embedding_dim)",
                            "Call"
                        ],
                        [
                            "_read_pretrained_embeddings_file(pretrained_file, embedding_dim, vocab, vocab_namespace)",
                            "Call"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                },
                "requires_grad": {
                    "value": "trainable",
                    "possible_values": []
                }
            },
            "Parameter_128": {
                "variable": {
                    "value": "self.weight",
                    "possible_values": []
                },
                "data": {
                    "value": "weight",
                    "possible_values": [
                        [
                            "torch.FloatTensor(num_embeddings, embedding_dim)",
                            "Call"
                        ],
                        [
                            "_read_pretrained_embeddings_file(pretrained_file, embedding_dim, vocab, vocab_namespace)",
                            "Call"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                },
                "requires_grad": {
                    "value": "trainable",
                    "possible_values": []
                }
            },
            "Linear_134": {
                "variable": {
                    "value": "self._projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embedding_dim",
                    "possible_values": [
                        [
                            "self.weight.data.shape[-1]",
                            "Subscript"
                        ]
                    ]
                },
                "out_features": {
                    "value": "projection_dim",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/empty_embedder.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/token_embedders/language_model_token_embedder.py": {
        "torch": {
            "cat_189": {
                "variable": {
                    "value": "duplicated_character_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[noncontextual_token_embeddings] * self._character_embedding_duplication_count",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_120": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/pass_through_token_embedder.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/token_embedders/pretrained_transformer_embedder.py": {
        "torch": {
            "cat_287": {
                "variable": {
                    "value": "embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embeddings, torch.zeros_like(end_token_embeddings)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_297": {
                "variable": {
                    "value": "embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[start_token_embeddings, embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "pad_180": {
                "variable": {
                    "value": "tensor",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor",
                    "possible_values": [
                        [
                            "F.pad(tensor, [0, length_to_pad], value=0)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "[0, length_to_pad]",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "arange_227": {
                "start": {
                    "value": "max_len",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "embeddings.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "arange_257": {
                "start": {
                    "value": "self._num_added_end_tokens",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "embeddings.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_like_287": {
                "input": {
                    "value": "end_token_embeddings",
                    "possible_values": [
                        [
                            "batched_index_select(embeddings, end_token_indices)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/pretrained_transformer_mismatched_embedder.py": {
        "torch": {}
    },
    "allennlp/allennlp/modules/token_embedders/token_characters_encoder.py": {
        "torch": {
            "Dropout_28": {
                "variable": {
                    "value": "self._dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/modules/token_embedders/token_embedder.py": {
        "torch": {
            "TokenEmbedder_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/nn/activations.py": {
        "torch": {
            "tanh_61": {
                "input": {
                    "value": "torch.nn.functional.softplus(x)",
                    "possible_values": []
                }
            },
            "sigmoid_62": {
                "input": {
                    "value": "x",
                    "possible_values": []
                }
            },
            "softplus_61": {
                "input": {
                    "value": "x",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/nn/beam_search.py": {
        "torch": {
            "cat_296": {
                "variable": {
                    "value": "all_predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "list(reversed(reconstructed_predictions))",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "where_188": {
                "variable": {
                    "value": "cleaned_log_probabilities",
                    "possible_values": []
                },
                "condition": {
                    "value": "last_predictions_expanded == self._end_index",
                    "possible_values": []
                },
                "x": {
                    "value": "log_probs_after_end",
                    "possible_values": [
                        [
                            "start_class_log_probabilities.new_full((batch_size * self.beam_size, num_classes), float('-inf'))",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "class_log_probabilities",
                    "possible_values": []
                }
            },
            "isfinite_266": {
                "input": {
                    "value": "last_log_probabilities",
                    "possible_values": [
                        [
                            "start_top_log_probabilities",
                            "Name"
                        ],
                        [
                            "restricted_beam_log_probs",
                            "Name"
                        ]
                    ]
                }
            },
            "all_266": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/nn/initializers.py": {
        "torch": {
            "load_270": {
                "f": {
                    "value": "weights_file_path",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/nn/regularizers/regularizer.py": {
        "torch": {}
    },
    "allennlp/allennlp/nn/regularizers/regularizer_applicator.py": {
        "torch": {}
    },
    "allennlp/allennlp/nn/regularizers/regularizers.py": {
        "torch": {
            "sum_14": {
                "input": {
                    "value": "torch.abs(parameter)",
                    "possible_values": []
                }
            },
            "sum_25": {
                "input": {
                    "value": "torch.pow(parameter, 2)",
                    "possible_values": []
                }
            },
            "abs_14": {
                "input": {
                    "value": "parameter",
                    "possible_values": []
                }
            },
            "pow_25": {
                "input": {
                    "value": "parameter",
                    "possible_values": []
                },
                "exponent": {
                    "value": "2",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/nn/util.py": {
        "torch": {
            "arange_181": {
                "variable": {
                    "value": "index_range",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "len(sequence_lengths)",
                    "possible_values": []
                },
                "device": {
                    "value": "sequence_lengths.device",
                    "possible_values": []
                }
            },
            "sum_405": {
                "variable": {
                    "value": "value_sum",
                    "possible_values": []
                },
                "input": {
                    "value": "replaced_vector",
                    "possible_values": [
                        [
                            "vector.masked_fill(one_minus_mask, min_val)",
                            "Call"
                        ],
                        [
                            "vector.masked_fill(one_minus_mask, 0.0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "keepdim",
                    "possible_values": []
                }
            },
            "sum_406": {
                "variable": {
                    "value": "value_count",
                    "possible_values": []
                },
                "input": {
                    "value": "mask.float()",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "keepdim",
                    "possible_values": []
                }
            },
            "flip_432": {
                "variable": {
                    "value": "flipped_padded_sequence",
                    "possible_values": []
                },
                "input": {
                    "value": "padded_sequence",
                    "possible_values": []
                },
                "dims": {
                    "value": "[1]",
                    "possible_values": []
                }
            },
            "topk_599": {
                "variable": {
                    "value": "(viterbi_scores, best_paths)",
                    "possible_values": []
                },
                "input": {
                    "value": "path_scores_v",
                    "possible_values": [
                        [
                            "path_scores[-1].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "max_k",
                    "possible_values": [
                        [
                            "min(summed_potentials.size()[0], top_k)",
                            "Call"
                        ],
                        [
                            "min(path_scores_v.size()[0], top_k)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "log_softmax_816": {
                "variable": {
                    "value": "log_probs_flat",
                    "possible_values": []
                },
                "input": {
                    "value": "logits_flat",
                    "possible_values": [
                        [
                            "logits.view(-1, logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "relu_1397": {
                "variable": {
                    "value": "span_indices",
                    "possible_values": []
                },
                "input": {
                    "value": "raw_span_indices.float()",
                    "possible_values": []
                }
            },
            "cat_1649": {
                "variable": {
                    "value": "sinusoids",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.sin(scaled_time), torch.cos(scaled_time)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_96": {
                "variable": {
                    "value": "batched_tensor",
                    "possible_values": []
                },
                "tensors": {
                    "value": "tensor_list",
                    "possible_values": []
                }
            },
            "cat_227": {
                "variable": {
                    "value": "final_encoder_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[final_forward_output, final_backward_output]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "softmax_288": {
                "variable": {
                    "value": "result",
                    "possible_values": []
                },
                "input": {
                    "value": "vector",
                    "possible_values": [
                        [
                            "vector + (mask + 1e-45).log()",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "log_softmax_339": {
                "input": {
                    "value": "vector",
                    "possible_values": [
                        [
                            "vector + (mask + 1e-45).log()",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "pad_sequence_437": {
                "sequences": {
                    "value": "sequences",
                    "possible_values": [
                        [
                            "[flipped_padded_sequence[i, num_timesteps - length:] for (i, length) in enumerate(sequence_lengths)]",
                            "ListComp"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "zeros_514": {
                "variable": {
                    "value": "new_transition_matrix",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                },
                "out": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "cat_519": {
                "variable": {
                    "value": "allowed_start_transitions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[allowed_start_transitions, torch.tensor([-math.inf, -math.inf])]",
                    "possible_values": []
                }
            },
            "cat_522": {
                "variable": {
                    "value": "allowed_end_transitions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[allowed_end_transitions, torch.tensor([-math.inf, -math.inf])]",
                    "possible_values": []
                }
            },
            "zeros_550": {
                "variable": {
                    "value": "zero_sentinel",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "possible_values": []
                },
                "out": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "cat_552": {
                "variable": {
                    "value": "tag_sequence",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[tag_sequence, extra_tags_sentinel]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_553": {
                "variable": {
                    "value": "tag_sequence",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[zero_sentinel, tag_sequence, zero_sentinel]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_560": {
                "variable": {
                    "value": "one_hot",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "topk_574": {
                "variable": {
                    "value": "(scores, paths)",
                    "possible_values": []
                },
                "input": {
                    "value": "summed_potentials",
                    "possible_values": [
                        [
                            "path_scores[timestep - 1].unsqueeze(2) + transition_matrix",
                            "BinOp"
                        ],
                        [
                            "summed_potentials.view(-1, num_tags)",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "max_k",
                    "possible_values": [
                        [
                            "min(summed_potentials.size()[0], top_k)",
                            "Call"
                        ],
                        [
                            "min(path_scores_v.size()[0], top_k)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "gather_824": {
                "variable": {
                    "value": "probs_flat",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_flat",
                    "possible_values": [
                        [
                            "log_probs_flat.exp()",
                            "Call"
                        ],
                        [
                            "torch.gather(probs_flat, dim=1, index=targets_flat)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "targets_flat",
                    "possible_values": [
                        [
                            "targets.view(-1, 1).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "gather_861": {
                "variable": {
                    "value": "alpha_factor",
                    "possible_values": []
                },
                "input": {
                    "value": "alpha_factor",
                    "possible_values": [
                        [
                            "torch.tensor([1.0 - float(alpha), float(alpha)], dtype=weights.dtype, device=weights.device)",
                            "Call"
                        ],
                        [
                            "torch.gather(alpha_factor, dim=0, index=targets_flat.view(-1)).view(*targets.size())",
                            "Call"
                        ],
                        [
                            "torch.tensor(alpha, dtype=weights.dtype, device=weights.device)",
                            "Call"
                        ],
                        [
                            "alpha_factor.view(1)",
                            "Call"
                        ],
                        [
                            "torch.cat([1 - alpha_factor, alpha_factor])",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "targets_flat.view(-1)",
                    "possible_values": []
                }
            },
            "zeros_like_870": {
                "variable": {
                    "value": "one_hot_targets",
                    "possible_values": []
                },
                "input": {
                    "value": "log_probs_flat",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(logits_flat, dim=-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_1015": {
                "tensors": {
                    "value": "to_concatenate",
                    "possible_values": [
                        [
                            "[_get_combination(piece, tensors) for piece in combination.split(',')]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_1654": {
                "variable": {
                    "value": "sinusoids",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[sinusoids, sinusoids.new_zeros(timesteps, 1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ModuleList_1660": {
                "modules": {
                    "value": "[copy.deepcopy(module) for _ in range(num_copies)]",
                    "possible_values": []
                }
            },
            "softmax_295": {
                "variable": {
                    "value": "result",
                    "possible_values": []
                },
                "input": {
                    "value": "vector * mask",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "softmax_302": {
                "variable": {
                    "value": "result",
                    "possible_values": []
                },
                "input": {
                    "value": "masked_vector",
                    "possible_values": [
                        [
                            "vector.masked_fill((1 - mask).to(dtype=torch.bool), mask_fill_value)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "zeros_509": {
                "variable": {
                    "value": "allowed_end_transitions",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "zeros_511": {
                "variable": {
                    "value": "allowed_start_transitions",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "zeros_589": {
                "variable": {
                    "value": "one_hot",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_tags",
                    "possible_values": [
                        [
                            "num_tags + 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "tensor_836": {
                "variable": {
                    "value": "alpha_factor",
                    "possible_values": []
                },
                "data": {
                    "value": "[1.0 - float(alpha), float(alpha)]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "weights.dtype",
                    "possible_values": []
                },
                "device": {
                    "value": "weights.device",
                    "possible_values": []
                }
            },
            "matmul_1106": {
                "input": {
                    "value": "tensors[index]",
                    "possible_values": []
                },
                "other": {
                    "value": "weight",
                    "possible_values": [
                        [
                            "weights[dims_so_far:dims_so_far + combination_dim]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "matmul_1124": {
                "variable": {
                    "value": "result",
                    "possible_values": []
                },
                "input": {
                    "value": "intermediate",
                    "possible_values": [
                        [
                            "attention.unsqueeze(-1).expand_as(matrix) * matrix",
                            "BinOp"
                        ],
                        [
                            "first_tensor * weight",
                            "BinOp"
                        ],
                        [
                            "first_tensor * weight",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "second_tensor.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "arange_1450": {
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "size",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "exp_1642": {
                "input": {
                    "value": "timescale_range * -log_timescale_increments",
                    "possible_values": []
                }
            },
            "ones_551": {
                "*size": {
                    "value": "sequence_length",
                    "possible_values": [
                        [
                            "tag_sequence.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "tensor_845": {
                "variable": {
                    "value": "alpha_factor",
                    "possible_values": []
                },
                "data": {
                    "value": "alpha",
                    "possible_values": []
                },
                "dtype": {
                    "value": "weights.dtype",
                    "possible_values": []
                },
                "device": {
                    "value": "weights.device",
                    "possible_values": []
                }
            },
            "gather_883": {
                "input": {
                    "value": "log_probs_flat",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(logits_flat, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "targets_flat",
                    "possible_values": [
                        [
                            "targets.view(-1, 1).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_1139": {
                "variable": {
                    "value": "result",
                    "possible_values": []
                },
                "input": {
                    "value": "intermediate",
                    "possible_values": [
                        [
                            "attention.unsqueeze(-1).expand_as(matrix) * matrix",
                            "BinOp"
                        ],
                        [
                            "first_tensor * weight",
                            "BinOp"
                        ],
                        [
                            "first_tensor * weight",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "second_tensor.pow(-1).transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "max_1264": {
                "input": {
                    "value": "indices",
                    "possible_values": []
                }
            },
            "min_1264": {
                "input": {
                    "value": "indices",
                    "possible_values": []
                }
            },
            "cumsum_1448": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "sin_1649": {
                "input": {
                    "value": "scaled_time",
                    "possible_values": [
                        [
                            "timestep_range.unsqueeze(1) * inverse_timescales.unsqueeze(0)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "cos_1649": {
                "input": {
                    "value": "scaled_time",
                    "possible_values": [
                        [
                            "timestep_range.unsqueeze(1) * inverse_timescales.unsqueeze(0)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "rand_253": {
                "*size": {
                    "value": "tensor_for_masking.size()",
                    "possible_values": []
                }
            },
            "tensor_520": {
                "data": {
                    "value": "[-math.inf, -math.inf]",
                    "possible_values": []
                }
            },
            "tensor_523": {
                "data": {
                    "value": "[-math.inf, -math.inf]",
                    "possible_values": []
                }
            },
            "cat_853": {
                "variable": {
                    "value": "alpha_factor",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[1 - alpha_factor, alpha_factor]",
                    "possible_values": []
                }
            },
            "matmul_1144": {
                "input": {
                    "value": "second_tensor",
                    "possible_values": [
                        [
                            "_get_combination(combination[2], tensors)",
                            "Call"
                        ],
                        [
                            "_get_combination(combination[2], tensors)",
                            "Call"
                        ],
                        [
                            "second_tensor.squeeze(expanded_dim)",
                            "Call"
                        ],
                        [
                            "second_tensor.squeeze(expanded_dim)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "weight",
                    "possible_values": [
                        [
                            "weights[dims_so_far:dims_so_far + combination_dim]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "min_1266": {
                "input": {
                    "value": "indices",
                    "possible_values": []
                }
            },
            "max_1266": {
                "input": {
                    "value": "indices",
                    "possible_values": []
                }
            },
            "matmul_1148": {
                "input": {
                    "value": "second_tensor",
                    "possible_values": [
                        [
                            "_get_combination(combination[2], tensors)",
                            "Call"
                        ],
                        [
                            "_get_combination(combination[2], tensors)",
                            "Call"
                        ],
                        [
                            "second_tensor.squeeze(expanded_dim)",
                            "Call"
                        ],
                        [
                            "second_tensor.squeeze(expanded_dim)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "weight",
                    "possible_values": [
                        [
                            "weights[dims_so_far:dims_so_far + combination_dim]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/predictors/predictor.py": {
        "torch": {}
    },
    "allennlp/allennlp/tools/create_elmo_embeddings_from_vocab.py": {
        "torch": {
            "cat_85": {
                "variable": {
                    "value": "embedding_weight",
                    "possible_values": []
                },
                "tensors": {
                    "value": "all_embeddings",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_68": {
                "variable": {
                    "value": "batch",
                    "possible_values": []
                },
                "tensors": {
                    "value": "sentences[i * batch_size:(i + 1) * batch_size]",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/callback_trainer.py": {
        "torch": {
            "DistributedDataParallel_157": {
                "variable": {
                    "value": "self._pytorch_model",
                    "possible_values": []
                },
                "module": {
                    "value": "self.model",
                    "possible_values": []
                },
                "device_ids": {
                    "value": "[self._rank]",
                    "possible_values": []
                }
            },
            "isnan_213": {
                "input": {
                    "value": "loss",
                    "possible_values": [
                        [
                            "output_dict['loss']",
                            "Subscript"
                        ],
                        [
                            "loss + self.model.get_regularization_penalty()",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "self.batch_loss(batch, for_training=True)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/training/callbacks/log_to_tensorboard.py": {
        "torch": {
            "norm_102": {
                "variable": {
                    "value": "update_norm",
                    "possible_values": []
                },
                "input": {
                    "value": "self.param_updates[name].view(-1)",
                    "possible_values": []
                }
            },
            "norm_103": {
                "variable": {
                    "value": "param_norm",
                    "possible_values": []
                },
                "input": {
                    "value": "param.view(-1)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/callbacks/update_learning_rate.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/callbacks/update_momentum.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/callbacks/validate.py": {
        "torch": {
            "no_grad_62": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/checkpointer.py": {
        "torch": {
            "load_169": {
                "variable": {
                    "value": "model_state",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'model_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(self._serialization_dir, 'model_state_epoch_{}.th'.format(epoch_to_load))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "nn_util.device_mapping(-1)",
                    "possible_values": []
                }
            },
            "load_170": {
                "variable": {
                    "value": "training_state",
                    "possible_values": []
                },
                "f": {
                    "value": "training_state_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'training_state_epoch_{}.th'.format(epoch_to_load))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "nn_util.device_mapping(-1)",
                    "possible_values": []
                }
            },
            "save_52": {
                "obj": {
                    "value": "model_state",
                    "possible_values": [
                        [
                            "torch.load(model_path, map_location=nn_util.device_mapping(-1))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'model_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(self._serialization_dir, 'model_state_epoch_{}.th'.format(epoch_to_load))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_56": {
                "obj": {
                    "value": "{**training_states, 'epoch': epoch}",
                    "possible_values": []
                },
                "f": {
                    "value": "training_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'training_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_179": {
                "f": {
                    "value": "best_model_state_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'best.th')",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "nn_util.device_mapping(-1)",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/learning_rate_schedulers/cosine.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/learning_rate_schedulers/learning_rate_scheduler.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/learning_rate_schedulers/noam.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/learning_rate_schedulers/slanted_triangular.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/attachment_scores.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/bleu.py": {
        "torch": {
            "ones_113": {
                "variable": {
                    "value": "valid_tokens_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "tensor.size()",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/boolean_accuracy.py": {
        "torch": {
            "ones_74": {
                "variable": {
                    "value": "keep",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "predictions.size(0)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/categorical_accuracy.py": {
        "torch": {
            "arange_85": {
                "start": {
                    "value": "gold_labels.numel()",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/conll_coref_scores.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/covariance.py": {
        "torch": {
            "sum_64": {
                "variable": {
                    "value": "num_batch_items",
                    "possible_values": []
                },
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "mask.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_94": {
                "variable": {
                    "value": "batch_co_moment",
                    "possible_values": []
                },
                "input": {
                    "value": "batch_coresiduals * mask",
                    "possible_values": []
                }
            },
            "sum_96": {
                "variable": {
                    "value": "batch_co_moment",
                    "possible_values": []
                },
                "input": {
                    "value": "batch_coresiduals",
                    "possible_values": [
                        [
                            "(predictions - batch_mean_prediction) * (gold_labels - batch_mean_label)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "sum_76": {
                "input": {
                    "value": "predictions",
                    "possible_values": [
                        [
                            "predictions.view(-1)",
                            "Call"
                        ],
                        [
                            "predictions * mask",
                            "BinOp"
                        ]
                    ]
                }
            },
            "sum_83": {
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "gold_labels.view(-1)",
                            "Call"
                        ],
                        [
                            "gold_labels * mask",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/entropy.py": {
        "torch": {
            "log_softmax_34": {
                "variable": {
                    "value": "log_probs",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ones_32": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "logits.size()[:-1]",
                    "possible_values": []
                }
            },
            "exp_35": {
                "input": {
                    "value": "log_probs",
                    "possible_values": [
                        [
                            "torch.nn.functional.log_softmax(logits, dim=-1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/fbeta_measure.py": {
        "torch": {
            "zeros_122": {
                "variable": {
                    "value": "self._true_positive_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_123": {
                "variable": {
                    "value": "self._true_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_124": {
                "variable": {
                    "value": "self._pred_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_125": {
                "variable": {
                    "value": "self._total_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_128": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "gold_labels.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_139": {
                "variable": {
                    "value": "true_positive_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "bincount_141": {
                "variable": {
                    "value": "true_positive_sum",
                    "possible_values": []
                },
                "input": {
                    "value": "true_positives_bins.long()",
                    "possible_values": []
                },
                "minlength": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "bincount_149": {
                "variable": {
                    "value": "pred_sum",
                    "possible_values": []
                },
                "input": {
                    "value": "pred_bins",
                    "possible_values": [
                        [
                            "argmax_predictions[mask].long()",
                            "Call"
                        ]
                    ]
                },
                "minlength": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_151": {
                "variable": {
                    "value": "pred_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "bincount_155": {
                "variable": {
                    "value": "true_sum",
                    "possible_values": []
                },
                "input": {
                    "value": "gold_labels_bins",
                    "possible_values": [
                        [
                            "gold_labels[mask].long()",
                            "Call"
                        ]
                    ]
                },
                "minlength": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_157": {
                "variable": {
                    "value": "true_sum",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "predictions.size(-1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/mean_absolute_error.py": {
        "torch": {
            "abs_39": {
                "variable": {
                    "value": "absolute_errors",
                    "possible_values": []
                },
                "input": {
                    "value": "predictions - gold_labels",
                    "possible_values": []
                }
            },
            "sum_45": {
                "input": {
                    "value": "absolute_errors",
                    "possible_values": [
                        [
                            "torch.abs(predictions - gold_labels)",
                            "Call"
                        ],
                        [
                            "absolute_errors * mask",
                            "BinOp"
                        ]
                    ]
                }
            },
            "sum_42": {
                "input": {
                    "value": "mask",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/mention_recall.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/metric.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/pearson_correlation.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/perplexity.py": {
        "torch": {
            "exp_32": {
                "input": {
                    "value": "average_loss",
                    "possible_values": [
                        [
                            "super().get_metric(reset)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/sequence_accuracy.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/metrics/span_based_f1_measure.py": {
        "torch": {
            "ones_like_128": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "torch.gather(prediction_map, 1, gold_labels.long())",
                            "Call"
                        ]
                    ]
                }
            },
            "gather_145": {
                "variable": {
                    "value": "argmax_predictions",
                    "possible_values": []
                },
                "input": {
                    "value": "prediction_map",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "argmax_predictions",
                    "possible_values": [
                        [
                            "predictions.max(-1)[1]",
                            "Subscript"
                        ],
                        [
                            "torch.gather(prediction_map, 1, argmax_predictions)",
                            "Call"
                        ],
                        [
                            "argmax_predictions.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "gather_146": {
                "variable": {
                    "value": "gold_labels",
                    "possible_values": []
                },
                "input": {
                    "value": "prediction_map",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "index": {
                    "value": "gold_labels.long()",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/spearman_correlation.py": {
        "torch": {
            "zeros_24": {
                "variable": {
                    "value": "self.total_predictions",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_25": {
                "variable": {
                    "value": "self.total_gold_labels",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_82": {
                "variable": {
                    "value": "self.total_predictions",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_83": {
                "variable": {
                    "value": "self.total_gold_labels",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_54": {
                "variable": {
                    "value": "self.total_predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.total_predictions, predictions * mask)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_57": {
                "variable": {
                    "value": "self.total_gold_labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.total_gold_labels, gold_labels * mask)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_61": {
                "variable": {
                    "value": "self.total_predictions",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.total_predictions, predictions)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_62": {
                "variable": {
                    "value": "self.total_gold_labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.total_gold_labels, gold_labels)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/metrics/unigram_recall.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/momentum_schedulers/inverted_triangular.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/momentum_schedulers/momentum_scheduler.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/moving_average.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/optimizers.py": {
        "torch": {
            "AdamOptimizer_164": {
                "base_class_0": {
                    "value": "torch.optim.Adam",
                    "possible_values": []
                }
            },
            "SparseAdamOptimizer_186": {
                "base_class_0": {
                    "value": "torch.optim.SparseAdam",
                    "possible_values": []
                }
            },
            "AdamaxOptimizer_204": {
                "base_class_0": {
                    "value": "torch.optim.Adamax",
                    "possible_values": []
                }
            },
            "AdamWOptimizer_224": {
                "base_class_0": {
                    "value": "torch.optim.AdamW",
                    "possible_values": []
                }
            },
            "AdagradOptimizer_268": {
                "base_class_0": {
                    "value": "torch.optim.Adagrad",
                    "possible_values": []
                }
            },
            "AdadeltaOptimizer_290": {
                "base_class_0": {
                    "value": "torch.optim.Adadelta",
                    "possible_values": []
                }
            },
            "SgdOptimizer_310": {
                "base_class_0": {
                    "value": "torch.optim.SGD",
                    "possible_values": []
                }
            },
            "RmsPropOptimizer_332": {
                "base_class_0": {
                    "value": "torch.optim.RMSprop",
                    "possible_values": []
                }
            },
            "AveragedSgdOptimizer_356": {
                "base_class_0": {
                    "value": "torch.optim.ASGD",
                    "possible_values": []
                }
            },
            "DenseSparseAdam_378": {
                "base_class_0": {
                    "value": "torch.optim.Optimizer",
                    "possible_values": []
                }
            },
            "zeros_like_445": {
                "variable": {
                    "value": "state[exp_avg]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "zeros_like_447": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/scheduler.py": {
        "torch": {}
    },
    "allennlp/allennlp/training/tensorboard_writer.py": {
        "torch": {
            "prod_121": {
                "input": {
                    "value": "torch.tensor(grad_data.shape)",
                    "possible_values": []
                }
            },
            "tensor_121": {
                "data": {
                    "value": "grad_data.shape",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/trainer.py": {
        "torch": {
            "DistributedDataParallel_289": {
                "variable": {
                    "value": "self._pytorch_model",
                    "possible_values": []
                },
                "module": {
                    "value": "self.model",
                    "possible_values": []
                },
                "device_ids": {
                    "value": "[self.cuda_device]",
                    "possible_values": []
                },
                "find_unused_parameters": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "isnan_379": {
                "input": {
                    "value": "loss",
                    "possible_values": [
                        [
                            "output_dict['loss']",
                            "Subscript"
                        ],
                        [
                            "loss + self.model.get_regularization_penalty()",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "self.batch_loss(batch, for_training=True)",
                            "Call"
                        ],
                        [
                            "loss / len(batch_group)",
                            "BinOp"
                        ],
                        [
                            "self.batch_loss(batch, for_training=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_405": {
                "variable": {
                    "value": "update_norm",
                    "possible_values": []
                },
                "input": {
                    "value": "param_updates[name].view(-1)",
                    "possible_values": []
                }
            },
            "norm_406": {
                "variable": {
                    "value": "param_norm",
                    "possible_values": []
                },
                "input": {
                    "value": "param.view(-1)",
                    "possible_values": []
                }
            },
            "no_grad_586": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/allennlp/training/util.py": {
        "torch": {
            "no_grad_368": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "tensor_347": {
                "variable": {
                    "value": "metric_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "metric_val",
                    "possible_values": []
                }
            },
            "tensor_351": {
                "variable": {
                    "value": "metric_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "metric_val",
                    "possible_values": []
                }
            },
            "device_348": {
                "type": {
                    "value": "cuda_device[0]",
                    "possible_values": []
                }
            },
            "device_351": {
                "type": {
                    "value": "cuda_device",
                    "possible_values": []
                }
            }
        }
    },
    "allennlp/scripts/write_srl_predictions_to_conll_format.py": {
        "torch": {
            "no_grad_72": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "evaluate.py": {
        "torch": {
            "is_available_54": {
                "variable": {
                    "value": "run_on_gpu",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "load_282": {
                "variable": {
                    "value": "best_model_state",
                    "possible_values": []
                },
                "f": {
                    "value": "best_model_state_path",
                    "possible_values": [
                        [
                            "os.path.join(args.serialization_dir, 'best_{}.th'.format(args.task))",
                            "Call"
                        ],
                        [
                            "os.path.join(args.serialization_dir, 'best_finetuned_dgi_{}_{}.th'.format(args.task, args.data))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda if run_on_gpu else cpu",
                    "possible_values": []
                }
            },
            "no_grad_88": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "graph_util/graph_aggregate.py": {
        "torch": {
            "is_available_5": {
                "variable": {
                    "value": "use_cuda",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "device_6": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if use_cuda else cpu",
                    "possible_values": []
                }
            },
            "GraphAggregate_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.graph_hidden_size": {
                    "value": "node_hidden_size",
                    "possible_values": []
                },
                "Sequential_17": {
                    "variable": {
                        "value": "self.node_gating",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "nn.Linear(node_hidden_size, 1)",
                        "possible_values": []
                    }
                },
                "Linear_18": {
                    "variable": {
                        "value": "self.node_to_graph",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "node_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.graph_hidden_size",
                        "possible_values": []
                    }
                },
                "self.type": {
                    "value": "aggregation_type",
                    "possible_values": []
                },
                "Linear_23": {
                    "variable": {
                        "value": "self.W_verbs",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "node_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "node_hidden_size",
                        "possible_values": []
                    }
                },
                "Linear_24": {
                    "variable": {
                        "value": "self.W_nodes",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "node_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "node_hidden_size",
                        "possible_values": []
                    }
                },
                "Linear_25": {
                    "variable": {
                        "value": "self.W_out",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "node_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Tanh_26": {
                    "variable": {
                        "value": "self.activation",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "Softmax_27": {
                    "variable": {
                        "value": "self.softmax",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "Linear_17": {
                "in_features": {
                    "value": "node_hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sigmoid_17": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_58": {
                "variable": {
                    "value": "graph_rep",
                    "possible_values": []
                },
                "input": {
                    "value": "weighted_nodes",
                    "possible_values": [
                        [
                            "node_weights * hvs",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            }
        }
    },
    "graph_util/graph_encoder_gat.py": {
        "torch": {
            "GATLayer_20": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_24": {
                    "variable": {
                        "value": "self.fc",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "in_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "out_dim",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "Linear_26": {
                    "variable": {
                        "value": "self.attn_fc",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * out_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                }
            },
            "MultiHeadGATLayer_57": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_60": {
                    "variable": {
                        "value": "self.heads",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "self.merge": {
                    "value": "merge",
                    "possible_values": [
                        [
                            "'max'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "GAT_81": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.aggregation": {
                    "value": "aggregation",
                    "possible_values": [
                        [
                            "'none'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_30": {
                "variable": {
                    "value": "z2",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[edges.src['z'], edges.dst['z']]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "softmax_41": {
                "variable": {
                    "value": "alpha",
                    "possible_values": []
                },
                "input": {
                    "value": "nodes.mailbox['e']",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_43": {
                "variable": {
                    "value": "h",
                    "possible_values": []
                },
                "input": {
                    "value": "alpha * nodes.mailbox['z']",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "elu_101": {
                "variable": {
                    "value": "h",
                    "possible_values": []
                },
                "input": {
                    "value": "h",
                    "possible_values": [
                        [
                            "torch.sum(alpha * nodes.mailbox['z'], dim=1)",
                            "Call"
                        ],
                        [
                            "self.layer1(g, h)",
                            "Call"
                        ],
                        [
                            "F.elu(h)",
                            "Call"
                        ],
                        [
                            "self.layer2(g, h)",
                            "Call"
                        ]
                    ]
                }
            },
            "leaky_relu_32": {
                "input": {
                    "value": "a",
                    "possible_values": [
                        [
                            "self.attn_fc(z2)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_69": {
                "tensors": {
                    "value": "head_outs",
                    "possible_values": [
                        [
                            "[attn_head(g, h) for attn_head in self.heads]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_72": {
                "variable": {
                    "value": "(max_pooled, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.stack(head_outs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_72": {
                "tensors": {
                    "value": "head_outs",
                    "possible_values": [
                        [
                            "[attn_head(g, h) for attn_head in self.heads]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "mean_76": {
                "input": {
                    "value": "torch.stack(head_outs)",
                    "possible_values": []
                }
            },
            "stack_76": {
                "tensors": {
                    "value": "head_outs",
                    "possible_values": [
                        [
                            "[attn_head(g, h) for attn_head in self.heads]",
                            "ListComp"
                        ]
                    ]
                }
            }
        }
    },
    "graph_util/graph_encoder_gcn.py": {
        "torch": {
            "TAGCN_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_14": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "Dropout_22": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": []
                    }
                },
                "self.aggregation": {
                    "value": "aggregation",
                    "possible_values": [
                        [
                            "'none'",
                            "MethodArgument"
                        ],
                        [
                            "'none'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "GCN_42": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_48": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "Dropout_56": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": []
                    }
                },
                "self.aggregation": {
                    "value": "aggregation",
                    "possible_values": [
                        [
                            "'none'",
                            "MethodArgument"
                        ],
                        [
                            "'none'",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "hmtl/models/coref_base.py": {
        "torch": {
            "Sequential_84": {
                "variable": {
                    "value": "feedforward_scorer",
                    "possible_values": []
                },
                "*args": {
                    "value": "TimeDistributed(mention_feedforward)",
                    "possible_values": []
                }
            },
            "relu_182": {
                "variable": {
                    "value": "spans",
                    "possible_values": []
                },
                "input": {
                    "value": "spans.float()",
                    "possible_values": []
                }
            },
            "cat_196": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[endpoint_span_embeddings, attended_span_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "relu_504": {
                "variable": {
                    "value": "valid_antecedent_indices",
                    "possible_values": []
                },
                "input": {
                    "value": "raw_antecedent_indices.float()",
                    "possible_values": []
                }
            },
            "cat_569": {
                "variable": {
                    "value": "span_pair_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[target_embeddings, antecedent_embeddings, antecedent_embeddings * target_embeddings, antecedent_distance_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_618": {
                "variable": {
                    "value": "pairwise_labels_with_dummy_label",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[dummy_labels, pairwise_labels]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_672": {
                "variable": {
                    "value": "coreference_scores",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[dummy_scores, antecedent_scores]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_115": {
                "variable": {
                    "value": "self._lexical_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "lexical_dropout",
                    "possible_values": []
                }
            },
            "Linear_90": {
                "in_features": {
                    "value": "antecedent_feedforward.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_86": {
                "in_features": {
                    "value": "mention_feedforward.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/models/coref_custom.py": {
        "torch": {
            "relu_136": {
                "variable": {
                    "value": "spans",
                    "possible_values": []
                },
                "input": {
                    "value": "spans.float()",
                    "possible_values": []
                }
            },
            "cat_151": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[endpoint_span_embeddings, attended_span_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "stack_125": {
                "variable": {
                    "value": "gm",
                    "possible_values": []
                },
                "tensors": {
                    "value": "s",
                    "possible_values": [
                        [
                            "[torch.as_tensor(pair, dtype=torch.long, device=device) for cluster in metadata[0]['clusters'] for pair in cluster]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "unsqueeze_125": {
                "variable": {
                    "value": "gm",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Categorical_217": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "probs": {
                    "value": "F.softmax(coreference_scores, dim=2)",
                    "possible_values": []
                }
            },
            "device_116": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "possible_values": []
                }
            },
            "device_118": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "as_tensor_121": {
                "data": {
                    "value": "pair",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda')",
                            "Call"
                        ],
                        [
                            "torch.device('cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_217": {
                "input": {
                    "value": "coreference_scores",
                    "possible_values": [
                        [
                            "self._compute_coreference_scores(span_pair_embeddings, top_span_mention_scores, candidate_antecedent_mention_scores, valid_antecedent_log_mask)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/models/layerCoref.py": {
        "torch": {}
    },
    "hmtl/models/layerCorefSrl.py": {
        "torch": {}
    },
    "hmtl/models/layerCorefSrlBert.py": {
        "torch": {}
    },
    "hmtl/models/layerSrl.py": {
        "torch": {}
    },
    "hmtl/models/srl_custom.py": {
        "torch": {
            "Dropout_97": {
                "variable": {
                    "value": "self.embedding_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "embedding_dropout",
                    "possible_values": []
                }
            },
            "cat_128": {
                "variable": {
                    "value": "encoded_text_with_verb_indicator",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[encoded_text, embedded_verb_indicator]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ones_139": {
                "variable": {
                    "value": "secondary_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "secondary_mask_size",
                    "possible_values": [
                        [
                            "[encoded_text_with_verb_indicator.size(0), encoded_text_with_verb_indicator.size(1)]",
                            "List"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "'cpu' if d < 0 else d",
                    "possible_values": []
                }
            },
            "softmax_165": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_logits",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ],
                        [
                            "reshaped_logits * scaler",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_287": {
                "variable": {
                    "value": "transition_matrix",
                    "possible_values": []
                },
                "*size": {
                    "value": "[num_labels, num_labels]",
                    "possible_values": []
                }
            },
            "zeros_310": {
                "variable": {
                    "value": "start_transitions",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_labels",
                    "possible_values": [
                        [
                            "len(all_labels)",
                            "Call"
                        ],
                        [
                            "len(all_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "Categorical_153": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "probs": {
                    "value": "F.softmax(reshaped_logits, dim=-1)",
                    "possible_values": []
                }
            },
            "ones_like_158": {
                "variable": {
                    "value": "scaler",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_logits",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ],
                        [
                            "reshaped_logits * scaler",
                            "BinOp"
                        ]
                    ]
                }
            },
            "Linear_95": {
                "in_features": {
                    "value": "self.secondary_encoder.get_output_dim()",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_classes",
                    "possible_values": []
                }
            },
            "softmax_153": {
                "input": {
                    "value": "reshaped_logits",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ],
                        [
                            "reshaped_logits * scaler",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "arange_159": {
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "scaler.size(0)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/models/srl_custom_bert.py": {
        "torch": {
            "Linear_75": {
                "variable": {
                    "value": "self.tag_projection_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.bert_model.config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_classes",
                    "possible_values": []
                }
            },
            "Dropout_79": {
                "variable": {
                    "value": "self.embedding_dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "embedding_dropout",
                    "possible_values": []
                }
            },
            "softmax_161": {
                "variable": {
                    "value": "class_probabilities",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_logits",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ],
                        [
                            "reshaped_logits * scaler",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_307": {
                "variable": {
                    "value": "transition_matrix",
                    "possible_values": []
                },
                "*size": {
                    "value": "[num_labels, num_labels]",
                    "possible_values": []
                }
            },
            "zeros_331": {
                "variable": {
                    "value": "start_transitions",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_labels",
                    "possible_values": [
                        [
                            "len(all_labels)",
                            "Call"
                        ],
                        [
                            "len(all_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "Categorical_147": {
                "variable": {
                    "value": "probs",
                    "possible_values": []
                },
                "probs": {
                    "value": "F.softmax(reshaped_logits, dim=-1)",
                    "possible_values": []
                }
            },
            "ones_like_152": {
                "variable": {
                    "value": "scaler",
                    "possible_values": []
                },
                "input": {
                    "value": "reshaped_logits",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ],
                        [
                            "reshaped_logits * scaler",
                            "BinOp"
                        ]
                    ]
                }
            },
            "softmax_147": {
                "input": {
                    "value": "reshaped_logits",
                    "possible_values": [
                        [
                            "logits.view(-1, self.num_classes)",
                            "Call"
                        ],
                        [
                            "reshaped_logits * scaler",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "arange_154": {
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "scaler.size(0)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/modules/seq2seq_encoders/stacked_gru.py": {
        "torch": {
            "GRU_76": {
                "variable": {
                    "value": "gru_layer",
                    "possible_values": []
                },
                "input_size": {
                    "value": "input_size",
                    "possible_values": [
                        [
                            "self._input_dim if k == 0 else self._hidden_sizes[k - 1]",
                            "IfExp"
                        ],
                        [
                            "input_size * 2",
                            "BinOp"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "self._hidden_sizes[k]",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self._dropouts[k]",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "1",
                    "possible_values": []
                },
                "bidirectional": {
                    "value": "self._bidirectional",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/modules/text_field_embedders/shortcut_connect_text_field_embedder.py": {
        "torch": {
            "cat_64": {
                "variable": {
                    "value": "text_field_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[base_representation, text_field_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_68": {
                "tensors": {
                    "value": "[text_field_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/training/loss/hinge_loss.py": {
        "torch": {
            "HingeLoss_5": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.margin": {
                    "value": "margin",
                    "possible_values": [
                        [
                            "1.0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sum_13": {
                "input": {
                    "value": "hinge_loss",
                    "possible_values": [
                        [
                            "self.margin - torch.mul(output, target)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "mul_11": {
                "input": {
                    "value": "output",
                    "possible_values": []
                },
                "other": {
                    "value": "target",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/training/metrics/accuracy.py": {
        "torch": {
            "eq_24": {
                "input": {
                    "value": "logits.cpu()",
                    "possible_values": []
                },
                "other": {
                    "value": "labels.cpu()",
                    "possible_values": []
                }
            },
            "sum_24": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/training/metrics/relation_f1_measure.py": {
        "torch": {
            "stack_63": {
                "variable": {
                    "value": "squared_mask",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[e.view(padded_document_length, 1) * e for e in mask]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "ones_like_46": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "gold_labels.cpu()",
                            "Call"
                        ],
                        [
                            "gold_labels * squared_mask",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "hmtl/training/multi_task_trainer.py": {
        "torch": {
            "load_374": {
                "variable": {
                    "value": "model_state",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'model_state.th')",
                            "Call"
                        ],
                        [
                            "os.path.join(self._serialization_dir, 'model_state.th')",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "possible_values": []
                }
            },
            "load_375": {
                "variable": {
                    "value": "training_state",
                    "possible_values": []
                },
                "f": {
                    "value": "training_state_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'training_state.th')",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "possible_values": []
                }
            },
            "save_287": {
                "obj": {
                    "value": "training_state",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'should_stop': should_stop, 'metric_infos': self._metric_infos, 'task_infos': self._task_infos, 'schedulers': {}, 'optimizers': {}}",
                            "Dict"
                        ],
                        [
                            "torch.load(training_state_path, map_location=device_mapping(-1))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "training_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'training_state.th')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_294": {
                "obj": {
                    "value": "model_state",
                    "possible_values": [
                        [
                            "self._model.state_dict()",
                            "Call"
                        ],
                        [
                            "torch.load(model_path, map_location=device_mapping(-1))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "os.path.join(self._serialization_dir, 'model_state.th')",
                            "Call"
                        ],
                        [
                            "os.path.join(self._serialization_dir, 'model_state.th')",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "hmtl/utils/builder.py": {
        "torch": {
            "load_74": {
                "variable": {
                    "value": "state",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(serialization_dir, best_model)",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "possible_values": []
                }
            },
            "is_available_29": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "zeros_97": {
                "variable": {
                    "value": "zeros",
                    "possible_values": []
                },
                "*size": {
                    "value": "shape",
                    "possible_values": [
                        [
                            "list(batch['spans'].shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_128": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "input_ids",
                    "possible_values": [
                        [
                            "roberta_tokenizer.encode([token for sentence in sentences for token in sentence], add_special_tokens=False)",
                            "Call"
                        ],
                        [
                            "input_ids + [roberta_tokenizer.pad_token_id] * to_fill",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(input_ids).view(-1, 512)",
                            "Call"
                        ],
                        [
                            "torch.tensor(input_ids).unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_130": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "input_ids",
                    "possible_values": [
                        [
                            "roberta_tokenizer.encode([token for sentence in sentences for token in sentence], add_special_tokens=False)",
                            "Call"
                        ],
                        [
                            "input_ids + [roberta_tokenizer.pad_token_id] * to_fill",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(input_ids).view(-1, 512)",
                            "Call"
                        ],
                        [
                            "torch.tensor(input_ids).unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "unsqueeze_130": {
                "variable": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "max_135": {
                "variable": {
                    "value": "(pooled, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "last_hidden_states[0][start:end + 1]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_137": {
                "tensors": {
                    "value": "reps",
                    "possible_values": [
                        [
                            "{'original_text': batch['metadata'][0]['original_text'], 'all_spans': output['all_spans'], 'endpoint_span_embeddings': output['endpoint_span_embeddings'], 'attended_span_embeddings': output['attended_span_embeddings']}",
                            "Dict"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "unsqueeze_137": {
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "device_30": {
                "type": {
                    "value": "cuda:0",
                    "possible_values": []
                }
            },
            "device_32": {
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "no_grad_131": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "hmtl/utils/embs.py": {
        "torch": {
            "cat_28": {
                "variable": {
                    "value": "span_embeddings",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[endpoint_span_embeddings, attended_span_embeddings]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "predictor.py": {
        "torch": {
            "device_25": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "load_43": {
                "variable": {
                    "value": "state",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(args.serialization_dir, best_model)",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_25": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "train.py": {
        "torch": {
            "load_169": {
                "variable": {
                    "value": "best_model_state",
                    "possible_values": []
                },
                "f": {
                    "value": "best_model_state_path",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'best_{}.th'.format(task._name))",
                            "Call"
                        ]
                    ]
                }
            },
            "set_default_dtype_234": {
                "d": {
                    "value": "torch.float32",
                    "possible_values": []
                }
            }
        }
    }
}