{
    "src/utils/text.py": {
        "sklearn": {}
    },
    "src/inference_mapping_class.py": {
        "torch": {
            "device_30": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "DataLoader_46": {
                "variable": {
                    "value": "test_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestClassDataset(test_json_path, tokenizer, num_classes)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_class_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_56": {
                "variable": {
                    "value": "test_masked_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset_masked",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestMaskedClassDataset(test_json_path, tokenizer, num_classes)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_class_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataParallel_63": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "SentenceMappingsProducer(bert_name, config, final_project_size=num_classes)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_66": {
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_77": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "argmax_83": {
                "variable": {
                    "value": "y_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output_mappings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "argmax_108": {
                "variable": {
                    "value": "y_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output_mappings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/inference_mapping_reg.py": {
        "torch": {
            "device_28": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "DataLoader_36": {
                "variable": {
                    "value": "test_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestRegDataset(test_json_path, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_reg_test_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_42": {
                "variable": {
                    "value": "test_masked_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_masked_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestMaskedRegDataset(test_json_path, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_reg_test_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataParallel_50": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "SentenceMappingsProducer(bert_name, config, final_project_size=3)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_54": {
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_69": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_28": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/train_mapping_class.py": {
        "torch": {
            "device_39": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "DataLoader_61": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTrainClassDataset(train_json_path, tokenizer, num_classes, organ_names)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_class_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_68": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestClassDataset(val_json_path, tokenizer, num_classes)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_class_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_74": {
                "variable": {
                    "value": "val_masked_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_masked_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestMaskedClassDataset(val_json_path, tokenizer, num_classes)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_class_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataParallel_81": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "SentenceMappingsProducer(bert_name, config, final_project_size=num_classes)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_84": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Adam_86": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "type": "variable",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "weight_decay",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "load_92": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_39": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_131": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "argmax_138": {
                "variable": {
                    "value": "y_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output_mappings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_139": {
                "variable": {
                    "value": "y_one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "organ_indices.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(organ_names)",
                            "Call"
                        ]
                    ]
                }
            },
            "argmax_155": {
                "variable": {
                    "value": "y_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output_mappings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "model(input_ids=sentences, attention_mask=attn_mask)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_156": {
                "variable": {
                    "value": "y_one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "organ_indices.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(organ_names)",
                            "Call"
                        ]
                    ]
                }
            },
            "save_181": {
                "obj": {
                    "value": "{'epoch': epoch + 1, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'best_avg_ior': best_avg_ior}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "save_intermediate_model_path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "clip_grad_norm__122": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "clip_val",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "save_174": {
                "obj": {
                    "value": "model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "save_model_path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "where_141": {
                "condition": {
                    "value": "y_one_hot == 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "where_158": {
                "condition": {
                    "value": "y_one_hot == 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "arange_140": {
                "start": {
                    "value": "organ_indices.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_157": {
                "start": {
                    "value": "organ_indices.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "src/train_mapping_reg.py": {
        "torch": {
            "device_73": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "DataLoader_108": {
                "variable": {
                    "value": "train_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTrainRegDataset(train_json_path, tokenizer, organ_names, ind2anchors)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_reg_train_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_115": {
                "variable": {
                    "value": "val_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestRegDataset(val_json_path, tokenizer, ind2anchors)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_reg_test_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataLoader_121": {
                "variable": {
                    "value": "val_masked_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_masked_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "VoxelSentenceMappingTestMaskedRegDataset(val_json_path, tokenizer, ind2anchors)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_pad_sentence_reg_test_batch",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DataParallel_128": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "SentenceMappingsProducer(bert_name, config, final_project_size=3)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Adam_132": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "type": "variable",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "weight_decay",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "load_140": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_73": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_193": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_258": {
                "obj": {
                    "value": "{'epoch': epoch + 1, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'best_distance': evaluator.best_avg_distance}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "save_intermediate_model_path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "clip_grad_norm__182": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "clip_val",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "save_251": {
                "obj": {
                    "value": "model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "save_model_path",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "src/utils/metrics.py": {
        "torch": {
            "abs_29": {
                "input": {
                    "value": "pred - centers",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "src/voxel_mapping/datasets.py": {
        "torch": {
            "pad_sequence_111": {
                "variable": {
                    "value": "padded_sentences",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sentences",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pad_sequence_114": {
                "variable": {
                    "value": "padded_mappings",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "mappings",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_117": {
                "variable": {
                    "value": "num_organs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[*num_organs]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "pad_sequence_126": {
                "variable": {
                    "value": "padded_sentences",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sentences",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pad_sequence_127": {
                "variable": {
                    "value": "padded_organ_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "organ_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor(self.organs_indices[idx])",
                            "Call"
                        ],
                        [
                            "torch.tensor(self.organs_indices[idx])",
                            "Call"
                        ],
                        [
                            "torch.tensor(self.organs_indices[idx])",
                            "Call"
                        ],
                        [
                            "torch.tensor(self.organs_indices[idx])",
                            "Call"
                        ],
                        [
                            "torch.tensor(self.organs_indices[idx])",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "pad_sequence_229": {
                "variable": {
                    "value": "padded_sentences",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sentences",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "tensor_61": {
                "variable": {
                    "value": "tokenized_sentence",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.tokenizer.encode(masked_sentence)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_62": {
                "variable": {
                    "value": "mapping",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.mappings[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_78": {
                "variable": {
                    "value": "tokenized_sentence",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.tokenizer.encode(self.sentences[idx])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_79": {
                "variable": {
                    "value": "organ_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.organs_indices[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_101": {
                "variable": {
                    "value": "tokenized_sentence",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.tokenizer.encode(masked_sentence)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_102": {
                "variable": {
                    "value": "organ_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.organs_indices[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_175": {
                "variable": {
                    "value": "tokenized_sentence",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.tokenizer.encode(masked_sentence)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_176": {
                "variable": {
                    "value": "organ_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.organs_indices[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_177": {
                "variable": {
                    "value": "one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.num_classes",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_191": {
                "variable": {
                    "value": "tokenized_sentence",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.tokenizer.encode(self.sentences[idx])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_192": {
                "variable": {
                    "value": "organ_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.organs_indices[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_193": {
                "variable": {
                    "value": "one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.num_classes",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_219": {
                "variable": {
                    "value": "tokenized_sentence",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.tokenizer.encode(masked_sentence)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_220": {
                "variable": {
                    "value": "organ_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "self.organs_indices[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_221": {
                "variable": {
                    "value": "one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.num_classes",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "where_119": {
                "condition": {
                    "value": "attn_mask > 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "where_131": {
                "condition": {
                    "value": "attn_mask > 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "where_231": {
                "condition": {
                    "value": "attn_mask > 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "stack_233": {
                "tensors": {
                    "value": "[*organ_indices]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "bernoulli_166": {
                "input": {
                    "value": "torch.tensor([0.5])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bernoulli_210": {
                "input": {
                    "value": "torch.tensor([0.5])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_166": {
                "data": {
                    "value": "[0.5]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_210": {
                "data": {
                    "value": "[0.5]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "src/voxel_mapping/losses.py": {
        "torch": {
            "softmin_62": {
                "variable": {
                    "value": "distances_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "distances_masked",
                    "type": "variable",
                    "possible_values": [
                        [
                            "distances * mask",
                            "BinOp"
                        ],
                        [
                            "distances * mask",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmin_64": {
                "variable": {
                    "value": "organ_distances_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "organ_distances_masked",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(distances_masked * distances_weights).sum(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmin_98": {
                "variable": {
                    "value": "loss_softmined",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "loss_masked",
                    "type": "variable",
                    "possible_values": [
                        [
                            "loss * mask",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "where_23": {
                "condition": {
                    "value": "mask == 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "where_57": {
                "condition": {
                    "value": "mask == 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "where_94": {
                "condition": {
                    "value": "mask == 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "arange_18": {
                "start": {
                    "value": "torch.max(lengths)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_52": {
                "start": {
                    "value": "torch.max(lengths)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_89": {
                "start": {
                    "value": "torch.max(lengths)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "max_19": {
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "max_53": {
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "max_90": {
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "max_18": {
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "max_52": {
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "max_89": {
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "src/voxel_mapping/models.py": {
        "torch": {
            "Linear_14": {
                "variable": {
                    "value": "self.projector",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "final_project_size",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    }
}