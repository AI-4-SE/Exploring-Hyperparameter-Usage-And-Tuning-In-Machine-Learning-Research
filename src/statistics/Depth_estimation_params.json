{
    "Densenet_depth_model/DepthData.py": {
        "torch": {
            "DepthDataset_24": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.traincsv": {
                    "value": "traincsv",
                    "possible_values": []
                },
                "self.root_dir": {
                    "value": "root_dir",
                    "possible_values": []
                },
                "self.transform": {
                    "value": "transform",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "clamp_100": {
                "variable": {
                    "value": "depth",
                    "possible_values": []
                },
                "input": {
                    "value": "depth",
                    "possible_values": [
                        [
                            "Image.open(depth_name)",
                            "Call"
                        ],
                        [
                            "depth.transpose(Image.FLIP_LEFT_RIGHT)",
                            "Call"
                        ],
                        [
                            "depth.resize((160, 120))",
                            "Call"
                        ],
                        [
                            "self.to_tensor(depth).float() / 1000",
                            "BinOp"
                        ],
                        [
                            "self.to_tensor(depth).float() * 1000",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(depth, 10, 1000)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "10",
                    "possible_values": []
                },
                "max": {
                    "value": "1000",
                    "possible_values": []
                }
            },
            "from_numpy_113": {
                "variable": {
                    "value": "img",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pic.transpose((2, 0, 1))",
                    "possible_values": []
                }
            }
        }
    },
    "Densenet_depth_model/UtilityTest.py": {
        "torch": {
            "DepthDataset_19": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.root_dir": {
                    "value": "root_dir",
                    "possible_values": []
                },
                "self.transform": {
                    "value": "transform",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "from_numpy_61": {
                "variable": {
                    "value": "img",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pic.transpose((2, 0, 1))",
                    "possible_values": []
                }
            }
        }
    },
    "Densenet_depth_model/model_dense.py": {
        "torch": {
            "UpSample_11": {
                "base_class_0": {
                    "value": "torch.nn.Sequential",
                    "possible_values": []
                },
                "Conv2d_14": {
                    "variable": {
                        "value": "self.convA",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "skip_input",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "output_features",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "LeakyReLU_15": {
                    "variable": {
                        "value": "self.leakyreluA",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.2",
                        "possible_values": []
                    }
                },
                "Conv2d_16": {
                    "variable": {
                        "value": "self.convB",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "output_features",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "output_features",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "LeakyReLU_17": {
                    "variable": {
                        "value": "self.leakyreluB",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.2",
                        "possible_values": []
                    }
                }
            },
            "Decoder_24": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv2d_29": {
                    "variable": {
                        "value": "self.conv2",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "num_features",
                        "possible_values": [
                            [
                                "2208",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "out_channels": {
                        "value": "features",
                        "possible_values": [
                            [
                                "int(num_features * decoder_width)",
                                "Call"
                            ],
                            [
                                "[x]",
                                "List"
                            ]
                        ]
                    },
                    "kernel_size": {
                        "value": "1",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Conv2d_37": {
                    "variable": {
                        "value": "self.conv3",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "features // 16",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "1",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                }
            },
            "Encoder_56": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "Model_67": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "interpolate_21": {
                "variable": {
                    "value": "up_x",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": []
                },
                "size": {
                    "value": "[concat_with.size(2), concat_with.size(3)]",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_22": {
                "tensors": {
                    "value": "[up_x, concat_with]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "DepthData_mob.py": {
        "torch": {
            "DepthDataset_24": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.traincsv": {
                    "value": "traincsv",
                    "possible_values": []
                },
                "self.root_dir": {
                    "value": "root_dir",
                    "possible_values": []
                },
                "self.transform": {
                    "value": "transform",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "clamp_100": {
                "variable": {
                    "value": "depth",
                    "possible_values": []
                },
                "input": {
                    "value": "depth",
                    "possible_values": [
                        [
                            "Image.open(depth_name)",
                            "Call"
                        ],
                        [
                            "depth.transpose(Image.FLIP_LEFT_RIGHT)",
                            "Call"
                        ],
                        [
                            "depth.resize((320, 240))",
                            "Call"
                        ],
                        [
                            "self.to_tensor(depth).float() / 1000",
                            "BinOp"
                        ],
                        [
                            "self.to_tensor(depth).float() * 1000",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(depth, 10, 1000)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "10",
                    "possible_values": []
                },
                "max": {
                    "value": "1000",
                    "possible_values": []
                }
            },
            "from_numpy_113": {
                "variable": {
                    "value": "img",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pic.transpose((2, 0, 1))",
                    "possible_values": []
                }
            }
        }
    },
    "Mobile_model.py": {
        "torch": {
            "UpSample_5": {
                "base_class_0": {
                    "value": "torch.nn.Sequential",
                    "possible_values": []
                },
                "Conv2d_8": {
                    "variable": {
                        "value": "self.convA",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "skip_input",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "output_features",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "LeakyReLU_9": {
                    "variable": {
                        "value": "self.leakyreluA",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.2",
                        "possible_values": []
                    }
                },
                "Conv2d_10": {
                    "variable": {
                        "value": "self.convB",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "output_features",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "output_features",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "LeakyReLU_11": {
                    "variable": {
                        "value": "self.leakyreluB",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.2",
                        "possible_values": []
                    }
                }
            },
            "Decoder_17": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv2d_22": {
                    "variable": {
                        "value": "self.conv2",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "num_features",
                        "possible_values": [
                            [
                                "1280",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "out_channels": {
                        "value": "features",
                        "possible_values": [
                            [
                                "int(num_features * decoder_width)",
                                "Call"
                            ],
                            [
                                "[x]",
                                "List"
                            ]
                        ]
                    },
                    "kernel_size": {
                        "value": "1",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Conv2d_31": {
                    "variable": {
                        "value": "self.conv3",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "features // 16",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "1",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "3",
                        "possible_values": []
                    },
                    "stride": {
                        "value": "1",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "1",
                        "possible_values": []
                    }
                }
            },
            "Encoder_44": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "Model_55": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "interpolate_14": {
                "variable": {
                    "value": "up_x",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": []
                },
                "size": {
                    "value": "[concat_with.size(2), concat_with.size(3)]",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_15": {
                "tensors": {
                    "value": "[up_x, concat_with]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "UtilityTest.py": {
        "torch": {
            "DepthDataset_19": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.root_dir": {
                    "value": "root_dir",
                    "possible_values": []
                },
                "self.transform": {
                    "value": "transform",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "from_numpy_61": {
                "variable": {
                    "value": "img",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pic.transpose((2, 0, 1))",
                    "possible_values": []
                }
            }
        }
    }
}