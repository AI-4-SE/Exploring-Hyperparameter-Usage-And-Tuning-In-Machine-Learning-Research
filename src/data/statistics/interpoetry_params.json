{
    "main.py": {
        "torch": {
            "load_284": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params.model_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_282": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "preprocess.py": {
        "torch": {
            "load_251": {
                "variable": {
                    "value": "datasss",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "voc_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sys.argv[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "save_291": {
                "obj": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'dico': tokenizer, 'positions': positions, 'sentences': sentences, 'positions_abs': positions_abs, 'sentences_abs': sentences_abs, 'unk_words': unk_words}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "bin_path_tr",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sys.argv[2] + '.tr.pth'",
                            "BinOp"
                        ],
                        [
                            "txt_path.strip()[:-4]",
                            "Subscript"
                        ],
                        [
                            "bin_path_tr + '.pth'",
                            "BinOp"
                        ]
                    ]
                }
            },
            "save_338": {
                "obj": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'dico': tokenizer, 'positions': positions, 'sentences': sentences, 'positions_abs': positions_abs, 'sentences_abs': sentences_abs, 'unk_words': unk_words}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "bin_path_tr",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sys.argv[2] + '.tr.pth'",
                            "BinOp"
                        ],
                        [
                            "txt_path.strip()[:-4]",
                            "Subscript"
                        ],
                        [
                            "bin_path_tr + '.pth'",
                            "BinOp"
                        ]
                    ]
                }
            },
            "save_376": {
                "obj": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'dico': tokenizer, 'positions': positions, 'sentences': sentences, 'positions_abs': positions_abs, 'sentences_abs': sentences_abs, 'unk_words': unk_words}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "bin_path_vl",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sys.argv[2] + '.vl.pth'",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "src/adam_inverse_sqrt_with_warmup.py": {
        "torch": {}
    },
    "src/data/dataset.py": {
        "torch": {
            "from_numpy_71": {
                "ndarray": {
                    "value": "pos[:, 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "from_numpy_211": {
                "ndarray": {
                    "value": "pos1[:, 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "from_numpy_212": {
                "ndarray": {
                    "value": "pos2[:, 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "src/data/dictionary.py": {
        "torch": {}
    },
    "src/data/loader.py": {
        "torch": {
            "load_25": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "src/evaluator.py": {
        "torch": {
            "device_235": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_326": {
                "variable": {
                    "value": "loss_fn2",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang3_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_434": {
                "variable": {
                    "value": "loss_fn3",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang3_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "device_527": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_584": {
                "variable": {
                    "value": "loss_fn2",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang3_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pad_287": {
                "variable": {
                    "value": "x_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_pred",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x_pred.cpu()",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.pad(x_pred, p1d, 'constant', 0)",
                            "Call"
                        ],
                        [
                            "x_pred[0:diff_len, :]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "p1d",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(0, 0, 0, diff_len)",
                            "Tuple"
                        ]
                    ]
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_529": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_235": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_527": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/evaluator_double.py": {
        "torch": {
            "device_370": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_460": {
                "variable": {
                    "value": "loss_fn2",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang3_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_567": {
                "variable": {
                    "value": "loss_fn3",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang3_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "device_660": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_733": {
                "variable": {
                    "value": "loss_fn2",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang3_id].weight.clone()",
                            "Call"
                        ],
                        [
                            "self.decoder.loss_fn[lang2_id].weight.clone()",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pad_422": {
                "variable": {
                    "value": "x_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_pred",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x_pred.cpu()",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.pad(x_pred, p1d, 'constant', 0)",
                            "Call"
                        ],
                        [
                            "x_pred[0:diff_len, :]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "p1d",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(0, 0, 0, diff_len)",
                            "Tuple"
                        ]
                    ]
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_671": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_370": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_660": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/evaluator_para.py": {
        "torch": {
            "device_293": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_382": {
                "variable": {
                    "value": "loss_fn3",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.decoder.loss_fn[lang3_id].weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "device_464": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_508": {
                "variable": {
                    "value": "loss_fn2",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.decoder.loss_fn[lang2_id].weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pad_345": {
                "variable": {
                    "value": "x_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_pred",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x_pred.cpu()",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.pad(x_pred, p1d, 'constant', 0)",
                            "Call"
                        ],
                        [
                            "x_pred[0:diff_len, :]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "p1d",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(0, 0, 0, diff_len)",
                            "Tuple"
                        ]
                    ]
                },
                "mode": {
                    "value": "constant",
                    "type": "str",
                    "possible_values": []
                },
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_175": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_466": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_293": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_464": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/gumbel.py": {
        "torch": {
            "log_17": {
                "input": {
                    "value": "u + eps",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Softmax_25": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "src/model/attention.py": {
        "torch": {
            "ModuleList_795": {
                "variable": {
                    "value": "decoder.loss_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "loss_fn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "ModuleList_68": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_81": {
                "variable": {
                    "value": "self.lstm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.LSTM(self.emb_dim, self.hidden_dim, num_layers=self.n_enc_layers, dropout=self.dropout, bidirectional=True) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "ModuleList_91": {
                "variable": {
                    "value": "self.proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[proj_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(2 * self.hidden_dim, self.emb_dim, bias=False) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(proj_output_dim, n_words) for n_words in self.n_words]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "dropout_119": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_120": {
                "variable": {
                    "value": "lstm_input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "sorted(lengths.tolist(), reverse=True)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_129": {
                "variable": {
                    "value": "(padded_output, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "sequence": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_232": {
                "variable": {
                    "value": "self.lstm1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.LSTM(self.lstm1_input_size, self.hidden_dim, num_layers=1, dropout=self.dropout, bias=True) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "ModuleList_233": {
                "variable": {
                    "value": "self.lstm2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.LSTM(self.lstm2_input_size, self.hidden_dim, num_layers=self.n_dec_layers - 1, dropout=self.dropout, bias=True) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                }
            },
            "ModuleList_242": {
                "variable": {
                    "value": "self.att_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "att_proj",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[att_proj_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(self.hidden_dim, self.emb_dim) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "self.att_proj[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.att_proj[lang_id]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "ModuleList_275": {
                "variable": {
                    "value": "self.proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[proj_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(2 * self.hidden_dim, self.emb_dim, bias=False) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(proj_output_dim, n_words) for n_words in self.n_words]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "LogSoftmax_277": {
                "variable": {
                    "value": "self.log_sm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "softmax_290": {
                "variable": {
                    "value": "att_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "att_weights.transpose(0, 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "transpose_290": {
                "variable": {
                    "value": "att_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_318": {
                "variable": {
                    "value": "att_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "att_weights.view(bs * ylen, xlen)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_367": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_415": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_57": {
                "variable": {
                    "value": "layer_0",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.n_words[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_86": {
                "variable": {
                    "value": "proj_0",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "2 * self.hidden_dim",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "ModuleList_206": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_238": {
                "variable": {
                    "value": "att_proj_0",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_252": {
                "variable": {
                    "value": "self.lstm_proj_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm_proj_layers",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.Linear(self.hidden_dim, self.emb_dim) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "cat_388": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "hidden_states[1:]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_404": {
                "variable": {
                    "value": "att_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[latent.data.new(1, bs, self.hidden_dim).zero_(), lstm_output[:-1]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_409": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_410": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lstm_output, attention]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "relu_417": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_proj_layer(output)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_465": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_487": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_534": {
                "variable": {
                    "value": "one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x.unsqueeze(0) for x in one_hot]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_592": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x.index_select(1, sort_len))",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim).index_select(1, sort_len)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(y_len * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(y_len, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_614": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_825": {
                "variable": {
                    "value": "reloaded",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params.reload_model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_64": {
                "variable": {
                    "value": "layer_i",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTM_72": {
                "*args": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "self.n_enc_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bidirectional": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Embedding_195": {
                "variable": {
                    "value": "layer_0",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.n_words[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTM_213": {
                "*args": {
                    "value": "self.lstm1_input_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_259": {
                "in_features": {
                    "value": "proj_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.hidden_dim",
                            "Attribute"
                        ],
                        [
                            "self.emb_dim",
                            "Attribute"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "cat_382": {
                "variable": {
                    "value": "lstm_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lstm_input, attention]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_393": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_473": {
                "variable": {
                    "value": "lstm_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lstm_input, attention]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_480": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_489": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_proj_layer(output)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "multinomial_504": {
                "variable": {
                    "value": "next_words",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "(scores / temperature).exp()",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "squeeze_504": {
                "variable": {
                    "value": "next_words",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_600": {
                "variable": {
                    "value": "lstm_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lstm_input, attention]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_607": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(hidden_states[1:], 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(lstm_output, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([lstm_output, attention], 2)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_89": {
                "in_features": {
                    "value": "2 * self.hidden_dim",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Embedding_202": {
                "variable": {
                    "value": "layer_i",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTM_218": {
                "*args": {
                    "value": "self.lstm2_input_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "self.n_dec_layers - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_241": {
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_246": {
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_482": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lstm_output, attention]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_609": {
                "variable": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lstm_output, attention]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_787": {
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.FloatTensor(n_words).fill_(1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "topk_506": {
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj_layer(output)",
                            "Call"
                        ],
                        [
                            "proj_layer(output).view(bs, n_words)",
                            "Call"
                        ],
                        [
                            "scores.data",
                            "Attribute"
                        ],
                        [
                            "self.log_sm(proj_layer(lstm_output.view(-1, self.hidden_dim)).view(bs * beam_size, n_words))",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "src/model/discriminator.py": {
        "torch": {
            "Sequential_39": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Linear_35": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.input_dim",
                            "Attribute"
                        ],
                        [
                            "input_dim * (2 if params.attention and (not params.dis_input_proj) else 1)",
                            "BinOp"
                        ],
                        [
                            "self.dis_hidden_dim",
                            "Attribute"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dis_hidden_dim if i < self.dis_layers else self.n_langs",
                            "IfExp"
                        ]
                    ]
                }
            },
            "LeakyReLU_37": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout_38": {
                "p": {
                    "value": "self.dis_dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "src/model/lm.py": {
        "torch": {
            "ModuleList_92": {
                "variable": {
                    "value": "self.lstm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.LSTM(self.emb_dim, self.hidden_dim, num_layers=max(n_rec_share, 1), dropout=self.dropout) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "dropout_120": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.embeddings",
                            "Attribute"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_72": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.embeddings",
                            "Attribute"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_99": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(self.hidden_dim, n_words) for n_words in self.n_words]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Embedding_68": {
                "variable": {
                    "value": "layer_i",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.n_words",
                            "Attribute"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTM_78": {
                "*args": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "max(n_rec_share, 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_99": {
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.n_words",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "src/model/pretrain_embeddings.py": {
        "torch": {
            "load_25": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "split",
                            "Name"
                        ]
                    ]
                }
            },
            "load_38": {
                "variable": {
                    "value": "vectors",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "split",
                            "Name"
                        ]
                    ]
                }
            },
            "from_numpy_147": {
                "variable": {
                    "value": "vec",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pretrained[i][word2id[i][word]]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "from_numpy_153": {
                "variable": {
                    "value": "vec",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "pretrained[i][word2id[i][word.lower()]]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "src/model/seq2seq.py": {
        "torch": {
            "ModuleList_429": {
                "variable": {
                    "value": "decoder.loss_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "loss_fn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "ModuleList_80": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(slen * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([embeddings, latent], 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_93": {
                "variable": {
                    "value": "self.lstm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.LSTM(self.emb_dim, self.hidden_dim, num_layers=self.n_enc_layers, dropout=self.dropout) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.LSTM(input_dim, self.hidden_dim, num_layers=self.n_dec_layers, dropout=self.dropout) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "dropout_130": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(slen * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([embeddings, latent], 1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_228": {
                "variable": {
                    "value": "self.lstm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.LSTM(self.emb_dim, self.hidden_dim, num_layers=self.n_enc_layers, dropout=self.dropout) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.LSTM(input_dim, self.hidden_dim, num_layers=self.n_dec_layers, dropout=self.dropout) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "ModuleList_261": {
                "variable": {
                    "value": "self.proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[proj_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(self.hidden_dim, self.enc_dim) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(proj_output_dim, n_words) for n_words in self.n_words]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "dropout_294": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(slen * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([embeddings, latent], 1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_311": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_67": {
                "variable": {
                    "value": "layer_0",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.n_words[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_103": {
                "variable": {
                    "value": "self.proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[proj_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(self.hidden_dim, self.enc_dim) for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[nn.Linear(proj_output_dim, n_words) for n_words in self.n_words]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "ModuleList_213": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(slen * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([embeddings, latent], 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_238": {
                "variable": {
                    "value": "self.lstm_proj_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "lstm_proj_layers",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.Linear(self.hidden_dim, self.emb_dim) for _ in range(self.n_langs)]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "cat_304": {
                "variable": {
                    "value": "lstm_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embeddings, encoded]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "relu_313": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_proj_layer(output)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_354": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "emb_layer(x)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_enc_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.view(slen * bs, -1).mm(emb_layer.weight).view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ],
                        [
                            "y.view(slen * bs, n_words).mm(emb_layer.weight)",
                            "Call"
                        ],
                        [
                            "embeddings.view(slen, bs, self.emb_dim)",
                            "Call"
                        ],
                        [
                            "emb_layer(y)",
                            "Call"
                        ],
                        [
                            "embeddings.detach() if self.freeze_dec_emb else embeddings",
                            "IfExp"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "emb_layer(decoded[cur_len - 1])",
                            "Call"
                        ],
                        [
                            "F.dropout(embeddings, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([embeddings, latent], 1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_358": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_output",
                    "type": "variable",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_400": {
                "variable": {
                    "value": "one_hot",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x.unsqueeze(0) for x in one_hot]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "load_459": {
                "variable": {
                    "value": "reloaded",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params.reload_model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_75": {
                "variable": {
                    "value": "layer_i",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTM_84": {
                "*args": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "self.n_enc_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_99": {
                "variable": {
                    "value": "proj_0",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.enc_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_200": {
                "variable": {
                    "value": "layer_0",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.n_words[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LSTM_219": {
                "*args": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "self.n_dec_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_245": {
                "in_features": {
                    "value": "proj_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.hidden_dim",
                            "Attribute"
                        ],
                        [
                            "self.emb_dim",
                            "Attribute"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "cat_356": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embeddings, latent]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "relu_360": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lstm_proj_layer(output)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "multinomial_375": {
                "variable": {
                    "value": "next_words",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "(scores / temperature).exp()",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "squeeze_375": {
                "variable": {
                    "value": "next_words",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_428": {
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.FloatTensor(n_words).fill_(1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Embedding_208": {
                "variable": {
                    "value": "layer_i",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words",
                            "Attribute"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ],
                        [
                            "self.n_words[lang_id]",
                            "Subscript"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.pad_index",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_232": {
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_102": {
                "in_features": {
                    "value": "self.hidden_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.enc_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "src/model/transformer.py": {
        "torch": {
            "Embedding_526": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_538": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ModuleList_48": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[Embedding(n_words, embed_dim, padding_idx=args.pad_index) for n_words in self.n_words]",
                            "ListComp"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[Embedding(n_words, self.emb_dim, padding_idx=self.pad_index) for n_words in self.n_words]",
                            "ListComp"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ]
                    ]
                }
            },
            "Embedding_57": {
                "variable": {
                    "value": "self.embed_tone",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "args.encoder_embed_dim",
                            "Attribute"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_59": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_95": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_176": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_212": {
                "variable": {
                    "value": "self.proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[nn.Linear(self.emb_dim, n_words) for n_words in self.n_words]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "dropout_233": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_435": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for i in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_441": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_447": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_448": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_450": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_481": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for i in range(3)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_490": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_501": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_507": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_508": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_510": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_enc_emb else x",
                            "IfExp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_input.view(slen * bs, -1).mm(embed_tokens.weight).view(slen, bs, self.embed_dim)",
                            "BinOp"
                        ],
                        [
                            "layer[lang_id](x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "x.detach() if self.freeze_dec_emb else x",
                            "IfExp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "layer[lang_id](x, encoder_out['encoder_out'], encoder_out['encoder_padding_mask'], incremental_state=incremental_state, out_attn=out_attn)",
                            "Call"
                        ],
                        [
                            "proj_layer(x)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(2, x, after=True)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_168": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "modules": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[Embedding(n_words, embed_dim, padding_idx=args.pad_index) for n_words in self.n_words]",
                            "ListComp"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "encoder.embeddings",
                            "Attribute"
                        ],
                        [
                            "[layer_0 for _ in range(self.n_langs)]",
                            "ListComp"
                        ],
                        [
                            "[Embedding(n_words, self.emb_dim, padding_idx=self.pad_index) for n_words in self.n_words]",
                            "ListComp"
                        ],
                        [
                            "nn.ModuleList(embeddings)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_196": {
                "in_features": {
                    "value": "self.emb_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "n_words",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "multinomial_343": {
                "variable": {
                    "value": "next_words",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "(scores / temperature).exp()",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "squeeze_343": {
                "variable": {
                    "value": "next_words",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_66": {
                "modules": {
                    "value": "[TransformerEncoderLayer(args)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "ModuleList_183": {
                "modules": {
                    "value": "[TransformerDecoderLayer(args)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "topk_346": {
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.forward(encoded, decoded[:cur_len], lang_id, one_hot, incremental_state)",
                            "Call"
                        ],
                        [
                            "scores.data[-1, :, :]",
                            "Subscript"
                        ]
                    ]
                },
                "k": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "src/modules/label_smoothed_cross_entropy.py": {
        "torch": {
            "log_softmax_24": {
                "variable": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "src/modules/layer_norm.py": {
        "torch": {
            "Parameter_22": {
                "variable": {
                    "value": "self.gain",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(features)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_23": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(features)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "batch_norm_53": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous()",
                            "Call"
                        ],
                        [
                            "input.view(1, -1, shape[-1])",
                            "Call"
                        ]
                    ]
                },
                "running_mean": {
                    "value": "dummy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dummy[:n]",
                            "Subscript"
                        ]
                    ]
                },
                "running_var": {
                    "value": "dummy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dummy[:n]",
                            "Subscript"
                        ]
                    ]
                },
                "weight": {
                    "value": "w",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.w[:n]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "b",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.b[:n]",
                            "Subscript"
                        ]
                    ]
                },
                "training": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "eps": {
                    "value": "self.eps",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "addcmul_54": {
                "input": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensor1": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "tensor2": {
                    "value": "output.view(*shape)",
                    "type": "Call",
                    "possible_values": []
                },
                "value": {
                    "value": "self.gain",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_22": {
                "*size": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_23": {
                "*size": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "src/modules/multihead_attention.py": {
        "torch": {
            "Parameter_33": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_38": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "bmm_123": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_140": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.buffered_mask(attn_weights.data).detach().unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -1e+18)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_141": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.buffered_mask(attn_weights.data).detach().unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -1e+18)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_143": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.buffered_mask(attn_weights.data).detach().unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -1e+18)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_v(value)",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat((saved_state['prev_value'], v), dim=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_35": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_185": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[:end, :]",
                            "Subscript"
                        ],
                        [
                            "weight[start:, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "triu_190": {
                "variable": {
                    "value": "self._mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor.new(dim, dim).fill_(-1e+18)",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_192": {
                "variable": {
                    "value": "self._mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "self._mask.resize_(dim, dim).fill_(-1e+18)",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_101": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(saved_state['prev_key'], k)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_103": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(saved_state['prev_value'], v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "src/modules/sinusoidal_positional_embedding.py": {
        "torch": {
            "exp_63": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(half_dim, dtype=torch.float32) * -emb",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_65": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.sin(emb), torch.cos(emb)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_27": {
                "start": {
                    "value": "padding_idx + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "end": {
                    "value": "max_pos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "padding_idx + 1 + tensor.size(0)",
                            "BinOp"
                        ],
                        [
                            "self.padding_idx + 1 + seq_len",
                            "BinOp"
                        ]
                    ]
                },
                "out": {
                    "value": "make_positions.range_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_68": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[emb, torch.zeros(num_embeddings, 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_64": {
                "start": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_64": {
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_63": {
                "start": {
                    "value": "half_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim // 2",
                            "BinOp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_68": {
                "*size": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sin_65": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float32).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cos_65": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float32).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "src/multiprocessing_event_loop.py": {
        "torch": {}
    },
    "src/rl_tools.py": {
        "torch": {
            "CrossEntropyLoss_135": {
                "variable": {
                    "value": "loss_fn_no_mean",
                    "type": "variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "loss_weight",
                    "type": "variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "argmax_32": {
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.cpu()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "no_grad_23": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "softmax_25": {
                "variable": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores[l]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "multinomial_26": {
                "variable": {
                    "value": "sample_l",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.softmax(scores[l], -1)",
                            "Call"
                        ]
                    ]
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "src/sequence_generator.py": {
        "torch": {
            "arange_77": {
                "variable": {
                    "value": "cand_offsets",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "cand_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2 * beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "gather_351": {
                "variable": {
                    "value": "active_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1).data).expand(-1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_scores.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ones_309": {
                "variable": {
                    "value": "batch_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_lengths.size(0)",
                            "Call"
                        ],
                        [
                            "new_bsz",
                            "Name"
                        ]
                    ]
                }
            },
            "add_333": {
                "input": {
                    "value": "eos_mask.type_as(cand_offsets) * cand_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "cand_offsets[:eos_mask.size(1)]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                }
            },
            "topk_342": {
                "input": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "beam_size if beam_size is not None else self.beam_size",
                            "IfExp"
                        ],
                        [
                            "min(beam_size, self.vocab_size - 1)",
                            "Call"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "largest": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(_ignore, active_hypos)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "gather_347": {
                "input": {
                    "value": "cand_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ],
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_358": {
                "input": {
                    "value": "tokens[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "tokens.clone()",
                            "Call"
                        ],
                        [
                            "old_tokens",
                            "Name"
                        ]
                    ]
                }
            },
            "gather_362": {
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_indices')",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).expand(bsz, cand_size).data",
                            "Attribute"
                        ],
                        [
                            "cand_indices.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "tokens_buf.view(bsz, beam_size, -1)[:, :, step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "gather_371": {
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1).data).expand(-1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_scores.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "scores_buf.view(bsz, beam_size, -1)[:, :, step]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "log_softmax_396": {
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(encoded, tokens, lang_id, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "decoder_out[-1, :, :]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "gather_218": {
                "variable": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_slice",
                    "type": "variable",
                    "possible_values": [
                        [
                            "probs.view(bsz, -1, probs.size(-1))[:, 0, :]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "prefix_tokens[:, step].view(-1, 1).data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sort_263": {
                "input": {
                    "value": "probs[:, self.eos]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(eos_scores, eos_bbsz_idx)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "masked_select_284": {
                "input": {
                    "value": "cand_bbsz_idx[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "cand_indices.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_bbsz_idx')",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_367": {
                "input": {
                    "value": "scores[:, :step]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf[:, :step]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "scores.clone()",
                            "Call"
                        ],
                        [
                            "scores_buf.type_as(probs)",
                            "Call"
                        ],
                        [
                            "old_scores",
                            "Name"
                        ]
                    ]
                }
            },
            "masked_select_290": {
                "input": {
                    "value": "cand_scores[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "cand_indices.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "eos_scores / (step + 1) ** self.len_penalty",
                            "BinOp"
                        ]
                    ]
                }
            },
            "arange_192": {
                "start": {
                    "value": "batch_idxs.numel()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_234": {
                "input": {
                    "value": "exp_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "probs.exp_().view(-1, self.vocab_size)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_indices')",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).expand(bsz, cand_size).data",
                            "Attribute"
                        ],
                        [
                            "cand_indices.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1).data).expand(-1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_scores.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_239": {
                "variable": {
                    "value": "cand_beams",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_lengths.size(0)",
                            "Call"
                        ],
                        [
                            "new_bsz",
                            "Name"
                        ]
                    ]
                },
                "out": {
                    "value": "cand_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2 * beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "arange_241": {
                "variable": {
                    "value": "cand_beams",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "beam_size if beam_size is not None else self.beam_size",
                            "IfExp"
                        ],
                        [
                            "min(beam_size, self.vocab_size - 1)",
                            "Call"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "topk_253": {
                "input": {
                    "value": "probs.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "k": {
                    "value": "min(cand_size, probs.view(bsz, -1).size(1) - 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "(cand_scores, cand_indices)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "div_258": {
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_indices')",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).expand(bsz, cand_size).data",
                            "Attribute"
                        ],
                        [
                            "cand_indices.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "other": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "cand_beams",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_beams')",
                            "Call"
                        ],
                        [
                            "torch.zeros(bsz, cand_size).type_as(cand_indices)",
                            "Call"
                        ],
                        [
                            "torch.arange(0, beam_size).repeat(bsz, 2).type_as(cand_indices)",
                            "Call"
                        ],
                        [
                            "cand_beams[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "arange_76": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_lengths.size(0)",
                            "Call"
                        ],
                        [
                            "new_bsz",
                            "Name"
                        ]
                    ]
                }
            },
            "multinomial_229": {
                "input": {
                    "value": "exp_probs[:, 2:]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "beam_size if beam_size is not None else self.beam_size",
                            "IfExp"
                        ],
                        [
                            "min(beam_size, self.vocab_size - 1)",
                            "Call"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_indices')",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).expand(bsz, cand_size).data",
                            "Attribute"
                        ],
                        [
                            "cand_indices.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "multinomial_232": {
                "input": {
                    "value": "exp_probs[:, 2:]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_indices')",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).expand(bsz, cand_size).data",
                            "Attribute"
                        ],
                        [
                            "cand_indices.view(bsz, -1).repeat(1, 2)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "gather_244": {
                "input": {
                    "value": "scores[:, step - 1].view(bsz, beam_size)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "cand_beams",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('cand_beams')",
                            "Call"
                        ],
                        [
                            "torch.zeros(bsz, cand_size).type_as(cand_indices)",
                            "Call"
                        ],
                        [
                            "torch.arange(0, beam_size).repeat(bsz, 2).type_as(cand_indices)",
                            "Call"
                        ],
                        [
                            "cand_beams[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "src/test_bleu.py": {
        "torch": {}
    },
    "src/trainer.py": {
        "torch": {
            "cat_375": {
                "variable": {
                    "value": "encoded",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "dis_inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[x.dis_input.view(-1, x.dis_input.size(-1)) for x in encoded]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_379": {
                "variable": {
                    "value": "self.dis_target",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.zeros(sz).fill_(i) for (i, sz) in enumerate(ntokens)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "cross_entropy_383": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "predictions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.discriminator(encoded.data)",
                            "Call"
                        ],
                        [
                            "self.discriminator(encoded.dis_input.view(-1, encoded.dis_input.size(-1)))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dis_target",
                            "Attribute"
                        ]
                    ]
                }
            },
            "device_467": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_704": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_810": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "load_975": {
                "variable": {
                    "value": "checkpoint_data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(self.params.dump_path, 'checkpoint.pth')",
                            "Call"
                        ],
                        [
                            "os.path.join(self.params.dump_path, 'checkpoint.pth')",
                            "Call"
                        ]
                    ]
                }
            },
            "cross_entropy_512": {
                "variable": {
                    "value": "dis_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "predictions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.discriminator(encoded.data)",
                            "Call"
                        ],
                        [
                            "self.discriminator(encoded.dis_input.view(-1, encoded.dis_input.size(-1)))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "fake_y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.LongTensor(predictions.size(0)).random_(1, params.n_langs)",
                            "Call"
                        ],
                        [
                            "(fake_y + lang1_id) % params.n_langs",
                            "BinOp"
                        ],
                        [
                            "fake_y.cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_720": {
                "variable": {
                    "value": "sent2_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[bos, F.softmax(scores / backprop_temperature, -1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "from_numpy_735": {
                "variable": {
                    "value": "samples",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "get_samples(scores)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_736": {
                "variable": {
                    "value": "bases",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "get_bases(scores)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_742": {
                "variable": {
                    "value": "rl_loss_ap",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "rl_loss_ap_unweighted * weights_ap",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "mean_750": {
                "variable": {
                    "value": "rl_loss_ar",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "rl_loss_ar_unweighted * weights_ar",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "from_numpy_755": {
                "variable": {
                    "value": "samples",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "get_samples(scores)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_756": {
                "variable": {
                    "value": "bases",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "get_bases(scores)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_760": {
                "variable": {
                    "value": "rl_loss_cv",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "rl_loss_cv_unweighted * weights_cv",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_826": {
                "variable": {
                    "value": "sent2_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[bos, F.softmax(scores / backprop_temperature, -1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "save_937": {
                "obj": {
                    "value": "{'enc': self.encoder, 'dec': self.decoder, 'dis': self.discriminator, 'lm': self.lm}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(self.params.dump_path, '%s.pth' % name)",
                            "Call"
                        ]
                    ]
                }
            },
            "save_964": {
                "obj": {
                    "value": "checkpoint_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'encoder': self.encoder, 'decoder': self.decoder, 'discriminator': self.discriminator, 'lm': self.lm, 'enc_optimizer': self.enc_optimizer, 'dec_optimizer': self.dec_optimizer, 'dis_optimizer': self.dis_optimizer, 'lm_optimizer': self.lm_optimizer, 'epoch': self.epoch, 'n_total_iter': self.n_total_iter, 'best_metrics': self.best_metrics, 'best_stopping_criterion': self.best_stopping_criterion}",
                            "Dict"
                        ],
                        [
                            "torch.load(checkpoint_path)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(self.params.dump_path, 'checkpoint.pth')",
                            "Call"
                        ],
                        [
                            "os.path.join(self.params.dump_path, 'checkpoint.pth')",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__330": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "self.params.clip_grad_norm",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_646": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_369": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_379": {
                "*size": {
                    "value": "sz",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "is_available_467": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_704": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_810": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "from_numpy_223": {
                "ndarray": {
                    "value": "permutation",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.argsort()",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_720": {
                "input": {
                    "value": "scores / backprop_temperature",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_826": {
                "input": {
                    "value": "scores / backprop_temperature",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Tensor_741": {},
            "Tensor_749": {}
        }
    },
    "src/utils.py": {
        "torch": {
            "arange_341": {
                "variable": {
                    "value": "inv_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "lengths.max() - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "end": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "step": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "manual_seed_71": {
                "seed": {
                    "value": "params.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_72": {
                "seed": {
                    "value": "params.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "test.py": {
        "torch": {}
    },
    "tools/mosesdecoder/scripts/generic/bsbleu.py": {
        "torch": {}
    }
}