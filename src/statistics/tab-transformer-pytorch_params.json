{
    "tab_transformer_pytorch/tab_transformer_pytorch.py": {
        "torch": {
            "LayerNorm_28": {
                "variable": {
                    "value": "self.norm",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "Sequential_44": {
                "variable": {
                    "value": "self.net",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(dim, dim * mult * 2)",
                    "possible_values": []
                }
            },
            "Linear_67": {
                "variable": {
                    "value": "self.to_qkv",
                    "possible_values": []
                },
                "in_features": {
                    "value": "dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "inner_dim * 3",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_68": {
                "variable": {
                    "value": "self.to_out",
                    "possible_values": []
                },
                "in_features": {
                    "value": "inner_dim",
                    "possible_values": [
                        [
                            "dim_head * heads",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "Dropout_70": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.0",
                            "MethodArgument"
                        ],
                        [
                            "0.0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "einsum_81": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "equation": {
                    "value": "b h i j, b h j d -> b h i d",
                    "possible_values": []
                },
                "*operands": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "sim.softmax(dim=-1)",
                            "Call"
                        ],
                        [
                            "self.dropout(attn)",
                            "Call"
                        ]
                    ]
                }
            },
            "Embedding_90": {
                "variable": {
                    "value": "self.embeds",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_tokens",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "ModuleList_91": {
                "variable": {
                    "value": "self.layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "possible_values": []
                }
            },
            "Sequential_125": {
                "variable": {
                    "value": "self.mlp",
                    "possible_values": []
                },
                "*args": {
                    "value": "*layers",
                    "possible_values": []
                }
            },
            "pad_165": {
                "variable": {
                    "value": "categories_offset",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tensor(list(categories))",
                    "possible_values": []
                },
                "pad": {
                    "value": "(1, 0)",
                    "possible_values": []
                },
                "value": {
                    "value": "num_special_tokens",
                    "possible_values": [
                        [
                            "2",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "LayerNorm_175": {
                "variable": {
                    "value": "self.norm",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "num_continuous",
                    "possible_values": []
                }
            },
            "cat_216": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(flat_categ, normed_cont)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_116": {
                "variable": {
                    "value": "linear",
                    "possible_values": []
                },
                "in_features": {
                    "value": "dim_in",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim_out",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "gelu_39": {
                "input": {
                    "value": "gates",
                    "possible_values": []
                }
            },
            "Linear_45": {
                "in_features": {
                    "value": "dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim * mult * 2",
                    "possible_values": []
                }
            },
            "Dropout_47": {
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.0",
                            "MethodArgument"
                        ],
                        [
                            "0.0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_48": {
                "in_features": {
                    "value": "dim * mult",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "einsum_76": {
                "equation": {
                    "value": "b h i d, b h j d -> b h i j",
                    "possible_values": []
                },
                "*operands": {
                    "value": "q",
                    "possible_values": []
                }
            },
            "tensor_165": {
                "data": {
                    "value": "list(categories)",
                    "possible_values": []
                }
            },
            "ModuleList_94": {
                "modules": {
                    "value": "[Residual(PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=attn_dropout))), Residual(PreNorm(dim, FeedForward(dim, dropout=ff_dropout)))]",
                    "possible_values": []
                }
            },
            "ReLU_122": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    }
}