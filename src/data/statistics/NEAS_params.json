{
    "lib/dataset/processing.py": {
        "tensorflow": {
            "equal_64": {
                "variable": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "a",
                    "type": "Variable",
                    "possible_values": []
                },
                "y": {
                    "value": "b",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cast_65": {
                "variable": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.equal(a, b)",
                            "Call"
                        ],
                        [
                            "tf.cast(match, tf.int32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "constant_71": {
                "variable": {
                    "value": "bbox",
                    "type": "Variable",
                    "possible_values": []
                },
                "value": {
                    "value": "[0.0, 0.0, 1.0, 1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shape": {
                    "value": "[1, 1, 4]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "extract_jpeg_shape_80": {
                "variable": {
                    "value": "original_shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cond_83": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "pred": {
                    "value": "bad",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "_at_least_x_are_equal(original_shape, tf.shape(image), 3)",
                            "Call"
                        ]
                    ]
                },
                "true_fn": {
                    "value": "lambda : _decode_and_center_crop(image_bytes, image_size)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "false_fn": {
                    "value": "lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "extract_jpeg_shape_93": {
                "variable": {
                    "value": "shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cast_97": {
                "variable": {
                    "value": "padded_center_crop_size",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "image_size / (image_size + CROP_PADDING) * tf.cast(tf.minimum(image_height, image_width), tf.float32)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_104": {
                "variable": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": []
                },
                "values": {
                    "value": "[offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "decode_and_crop_jpeg_106": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                },
                "crop_window": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.stack([offset_y, offset_x, target_height, target_width])",
                            "Call"
                        ],
                        [
                            "tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])",
                            "Call"
                        ]
                    ]
                },
                "channels": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "random_flip_left_right_114": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "reshape_131": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[image_size, image_size, 3]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "convert_image_dtype_132": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.bfloat16 if use_bfloat16 else tf.float32",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "reshape_149": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[image_size, image_size, 3]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "convert_image_dtype_150": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.bfloat16 if use_bfloat16 else tf.float32",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "extract_jpeg_shape_42": {
                "variable": {
                    "value": "shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sample_distorted_bounding_box_43": {
                "variable": {
                    "value": "sample_distorted_bounding_box",
                    "type": "Variable",
                    "possible_values": []
                },
                "image_size": {
                    "value": "shape",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.extract_jpeg_shape(image_bytes)",
                            "Call"
                        ],
                        [
                            "tf.image.extract_jpeg_shape(image_bytes)",
                            "Call"
                        ]
                    ]
                },
                "bounding_boxes": {
                    "value": "bbox",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])",
                            "Call"
                        ]
                    ]
                },
                "min_object_covered": {
                    "value": "min_object_covered",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                },
                "aspect_ratio_range": {
                    "value": "aspect_ratio_range",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(0.75",
                            "MethodArgument"
                        ]
                    ]
                },
                "area_range": {
                    "value": "area_range",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(0.05",
                            "MethodArgument"
                        ]
                    ]
                },
                "max_attempts": {
                    "value": "max_attempts",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "100",
                            "MethodArgument"
                        ]
                    ]
                },
                "use_image_if_no_bounding_boxes": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "unstack_54": {
                "variable": {
                    "value": "(offset_y, offset_x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "bbox_begin",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "unstack_55": {
                "variable": {
                    "value": "(target_height, target_width, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "bbox_size",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "stack_56": {
                "variable": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": []
                },
                "values": {
                    "value": "[offset_y, offset_x, target_height, target_width]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "decode_and_crop_jpeg_57": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                },
                "crop_window": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.stack([offset_y, offset_x, target_height, target_width])",
                            "Call"
                        ],
                        [
                            "tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])",
                            "Call"
                        ]
                    ]
                },
                "channels": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "greater_equal_66": {
                "x": {
                    "value": "tf.reduce_sum(match)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "name_scope_41": {
                "name": {
                    "value": "scope",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "reduce_sum_66": {
                "input_tensor": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.equal(a, b)",
                            "Call"
                        ],
                        [
                            "tf.cast(match, tf.int32)",
                            "Call"
                        ]
                    ]
                }
            },
            "shape_81": {
                "input": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "resize_107": {
                "images": {
                    "value": "[image]",
                    "type": "List",
                    "possible_values": []
                },
                "size": {
                    "value": "[image_size, image_size]",
                    "type": "List",
                    "possible_values": []
                },
                "method": {
                    "value": "resize_method",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ],
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ]
                    ]
                }
            },
            "placeholder_188": {
                "variable": {
                    "value": "self._image_bytes",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shape": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.string",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Session_198": {
                "variable": {
                    "value": "self.sess",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cast_99": {
                "x": {
                    "value": "tf.minimum(image_height, image_width)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_187": {
                "device_name": {
                    "value": "/cpu:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "resize_86": {
                "images": {
                    "value": "[image]",
                    "type": "List",
                    "possible_values": []
                },
                "size": {
                    "value": "[image_size, image_size]",
                    "type": "List",
                    "possible_values": []
                },
                "method": {
                    "value": "resize_method",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ],
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ]
                    ]
                }
            },
            "minimum_99": {
                "x": {
                    "value": "image_height",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "shape[0]",
                            "Subscript"
                        ]
                    ]
                },
                "y": {
                    "value": "image_width",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "shape[1]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "lib/core/train_function.py": {
        "torch": {
            "ModuleList_35": {
                "variable": {
                    "value": "loss_fns",
                    "type": "Variable",
                    "possible_values": []
                },
                "modules": {
                    "value": "[loss_fn.cuda() for i in range(k)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "synchronize_54": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "lib/core/valid_function.py": {
        "torch": {
            "no_grad_15": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "synchronize_39": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "lib/dataset/base_dataset.py": {
        "torch": {
            "zeros_88": {
                "variable": {
                    "value": "target",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_153": {
                "variable": {
                    "value": "target",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "lib/dataset/cifar.py": {
        "torch": {
            "DataLoader_60": {
                "variable": {
                    "value": "train_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "dset_cls(root=config.data_dir, train=True, download=True, transform=train_transform)",
                            "Call"
                        ],
                        [
                            "dset_cls(root=config.data, train=True, download=True, transform=train_transform)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "config.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "SubsetDistributedSampler(train_data, indices[:split_mid])",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(train_data)",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "config.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_65": {
                "variable": {
                    "value": "valid_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "dset_cls(root=config.data_dir, train=True, download=True, transform=train_transform)",
                            "Call"
                        ],
                        [
                            "dset_cls(root=config.data, train=True, download=True, transform=train_transform)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "config.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "sampler": {
                    "value": "valid_sampler",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "SubsetDistributedSampler(train_data, indices[split_mid:num_train])",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "config.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_91": {
                "variable": {
                    "value": "train_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "dset_cls(root=config.data_dir, train=True, download=True, transform=train_transform)",
                            "Call"
                        ],
                        [
                            "dset_cls(root=config.data, train=True, download=True, transform=train_transform)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "config.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "SubsetDistributedSampler(train_data, indices[:split_mid])",
                            "Call"
                        ],
                        [
                            "torch.utils.data.distributed.DistributedSampler(train_data)",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "config.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_96": {
                "variable": {
                    "value": "test_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_data",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "dset_cls(root=config.data_dir, train=False, download=True, transform=valid_transform)",
                            "Call"
                        ],
                        [
                            "dset_cls(root=config.data, train=False, download=True, transform=valid_transform)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "config.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "sampler": {
                    "value": "test_sampler",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(test_data)",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "config.workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DistributedSampler_82": {
                "variable": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "dset_cls(root=config.data_dir, train=True, download=True, transform=train_transform)",
                            "Call"
                        ],
                        [
                            "dset_cls(root=config.data, train=True, download=True, transform=train_transform)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_83": {
                "variable": {
                    "value": "test_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_data",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "dset_cls(root=config.data_dir, train=False, download=True, transform=valid_transform)",
                            "Call"
                        ],
                        [
                            "dset_cls(root=config.data, train=False, download=True, transform=valid_transform)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "lib/dataset/cifar_utils.py": {
        "torch": {
            "tensor_358": {
                "variable": {
                    "value": "targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[target[1] for target in batch]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_361": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(len(imgs), 3, h, w)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Generator_46": {
                "variable": {
                    "value": "g",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Stream_75": {
                "variable": {
                    "value": "self.stream",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_76": {
                "variable": {
                    "value": "self.mean",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[0.485 * 255, 0.456 * 255, 0.406 * 255]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_77": {
                "variable": {
                    "value": "self.std",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[0.229 * 255, 0.224 * 255, 0.225 * 255]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "from_numpy_125": {
                "variable": {
                    "value": "mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "mask",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "np.ones((h, w), np.float32)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(mask)",
                            "Call"
                        ],
                        [
                            "mask.expand_as(img)",
                            "Call"
                        ]
                    ]
                }
            },
            "randperm_382": {
                "variable": {
                    "value": "index",
                    "type": "Variable",
                    "possible_values": []
                },
                "n": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "x.size()[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "randperm_384": {
                "variable": {
                    "value": "index",
                    "type": "Variable",
                    "possible_values": []
                },
                "n": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "x.size()[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "current_stream_102": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "from_numpy_368": {
                "ndarray": {
                    "value": "nump_array",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "np.asarray(img, dtype=np.uint8)",
                            "Call"
                        ],
                        [
                            "np.expand_dims(nump_array, axis=-1)",
                            "Call"
                        ],
                        [
                            "np.rollaxis(nump_array, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_28": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "randperm_50": {
                "n": {
                    "value": "len(self.indices)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "lib/dataset/loader.py": {
        "torch": {
            "zeros_69": {
                "variable": {
                    "value": "targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "flattened_batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "batch_size * inner_tuple_size",
                            "BinOp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_70": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(flattened_batch_size, *batch[0][0][0].shape)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_107": {
                "variable": {
                    "value": "self.mean",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[x * 255 for x in mean]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "tensor_108": {
                "variable": {
                    "value": "self.std",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[x * 255 for x in std]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Stream_120": {
                "variable": {
                    "value": "stream",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_78": {
                "variable": {
                    "value": "targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[b[1] for b in batch]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_80": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, *batch[0][0].shape)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DistributedSampler_209": {
                "variable": {
                    "value": "sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "tensor_85": {
                "variable": {
                    "value": "targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[b[1] for b in batch]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_87": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, *batch[0][0].shape)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "current_stream_139": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_34": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "from_numpy_75": {
                "ndarray": {
                    "value": "batch[i][0][j]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "from_numpy_82": {
                "ndarray": {
                    "value": "batch[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "lib/dataset/transform.py": {
        "torch": {
            "tensor_122": {
                "data": {
                    "value": "mean",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_123": {
                "data": {
                    "value": "std",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_187": {
                "data": {
                    "value": "mean",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_188": {
                "data": {
                    "value": "std",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ],
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "lib/dataset/utils.py": {
        "torch": {
            "from_numpy_30": {
                "ndarray": {
                    "value": "np_img",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "np.array(pil_img, dtype=np.uint8)",
                            "Call"
                        ],
                        [
                            "np.expand_dims(np_img, axis=-1)",
                            "Call"
                        ],
                        [
                            "np.rollaxis(np_img, 2)",
                            "Call"
                        ],
                        [
                            "np.array(pil_img, dtype=np.uint8)",
                            "Call"
                        ],
                        [
                            "np.expand_dims(np_img, axis=-1)",
                            "Call"
                        ],
                        [
                            "np.rollaxis(np_img, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "empty_159": {
                "*size": {
                    "value": "patch_size",
                    "type": "Variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "dtype",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.float32",
                            "MethodArgument"
                        ],
                        [
                            "torch.float32",
                            "MethodArgument"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "'cuda'",
                            "MethodArgument"
                        ],
                        [
                            "'cuda'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "empty_161": {
                "*size": {
                    "value": "(patch_size[0], 1, 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "dtype",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.float32",
                            "MethodArgument"
                        ],
                        [
                            "torch.float32",
                            "MethodArgument"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "'cuda'",
                            "MethodArgument"
                        ],
                        [
                            "'cuda'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_163": {
                "*size": {
                    "value": "(patch_size[0], 1, 1)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "dtype",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.float32",
                            "MethodArgument"
                        ],
                        [
                            "torch.float32",
                            "MethodArgument"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "'cuda'",
                            "MethodArgument"
                        ],
                        [
                            "'cuda'",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "lib/models/NEAS_builder.py": {
        "torch": {
            "Sequential_324": {
                "*args": {
                    "value": "*blocks",
                    "type": "Starred",
                    "possible_values": []
                }
            }
        }
    },
    "lib/models/NEAS_subnet.py": {
        "torch": {
            "Sequential_59": {
                "variable": {
                    "value": "self.sharing_blocks",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*builder(self._in_chs, sharing_args)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "ModuleList_64": {
                "variable": {
                    "value": "self.blocks",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "self.blocks",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_71": {
                "variable": {
                    "value": "self.conv_heads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[create_conv2d(self._in_chs, self.num_features, 1, padding=pad_type, bias=head_bias) for i in range(k)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_72": {
                "variable": {
                    "value": "self.acts",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[act_layer(inplace=True) for i in range(k)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_76": {
                "variable": {
                    "value": "self.classifiers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(self.num_features * self.global_pool.feat_mult(), self.num_classes) for i in range(k)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_78": {
                "variable": {
                    "value": "self.pool_bns",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.BatchNorm1d(1) for i in range(self.k)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_88": {
                "in_features": {
                    "value": "self.num_features * self.global_pool.feat_mult()",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1000",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "dropout_132": {
                "variable": {
                    "value": "xs[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "xs[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "p": {
                    "value": "self.drop_rate",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_135": {
                "variable": {
                    "value": "xs[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "xs[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "squeeze_137": {
                "variable": {
                    "value": "xs[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "xs[i]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Sequential_63": {
                "*args": {
                    "value": "*builder(self.head_in_chs, split_args[i])",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Linear_76": {
                "in_features": {
                    "value": "self.num_features * self.global_pool.feat_mult()",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.num_classes",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "BatchNorm1d_78": {
                "num_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "lib/models/units.py": {
        "torch": {
            "AdaptiveAvgPool2d_119": {
                "variable": {
                    "value": "self.avg_pool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "output_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Conv2d_120": {
                "variable": {
                    "value": "self.conv_reduce",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "in_chs",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "reduced_chs",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "make_divisible((reduced_base_chs or in_chs) * se_ratio, divisor)",
                            "Call"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Conv2d_122": {
                "variable": {
                    "value": "self.conv_expand",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "reduced_chs",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "make_divisible((reduced_base_chs or in_chs) * se_ratio, divisor)",
                            "Call"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "in_chs",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "MaxPool2d_177": {
                "variable": {
                    "value": "self.pooling",
                    "type": "Attribute",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_272": {
                "variable": {
                    "value": "self.pool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "output_size": {
                    "value": "output_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Identity_82": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "lib/models/utils.py": {
        "torch": {
            "pad_24": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)",
                            "Call"
                        ],
                        [
                            "pad_same(x, weight.shape[-2:], stride, dilation)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "[pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]",
                    "type": "List",
                    "possible_values": []
                },
                "value": {
                    "value": "value",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "conv2d_31": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)",
                            "Call"
                        ],
                        [
                            "pad_same(x, weight.shape[-2:], stride, dilation)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "Variable",
                    "possible_values": []
                },
                "stride": {
                    "value": "stride",
                    "type": "Variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "(0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dilation": {
                    "value": "dilation",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "groups": {
                    "value": "groups",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "out_chs if depthwise else 1",
                            "IfExp"
                        ]
                    ]
                }
            },
            "Conv2d_101": {
                "in_channels": {
                    "value": "in_chs",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_chs",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel_size",
                    "type": "Variable",
                    "possible_values": []
                },
                "padding": {
                    "value": "padding",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "((stride - 1 + dilation[0] * (kernel_size - 1)) // 2, (stride - 1 + dilation[1] * (kernel_size - 1)) // 2)",
                            "Tuple"
                        ],
                        [
                            "(stride - 1 + dilation * (kernel_size - 1)) // 2",
                            "BinOp"
                        ],
                        [
                            "padding.lower()",
                            "Call"
                        ],
                        [
                            "get_padding(kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "get_padding(kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "kwargs.pop('padding', '')",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "lib/utils/EMA.py": {
        "torch": {
            "load_39": {
                "variable": {
                    "value": "checkpoint",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "Variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "no_grad_58": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "lib/utils/flops_table.py": {
        "torch": {
            "randn_20": {
                "variable": {
                    "value": "input",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(2, 3, 224, 224)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "lib/utils/helpers.py": {
        "torch": {
            "load_37": {
                "variable": {
                    "value": "checkpoint",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "Variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_65": {
                "variable": {
                    "value": "checkpoint",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "Variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "broadcast_157": {
                "tensor": {
                    "value": "bn_buf",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "bn_buf / float(world_size)",
                            "BinOp"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "lib/utils/loss.py": {
        "torch": {
            "LogSoftmax_6": {
                "variable": {
                    "value": "logsoftmax",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "mean_7": {
                "input": {
                    "value": "torch.sum(-soft_target * logsoftmax(pred), 1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_19": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "weight",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_21": {
                "variable": {
                    "value": "self.temp",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "temp",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "log_softmax_29": {
                "variable": {
                    "value": "logprobs",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_53": {
                "variable": {
                    "value": "self.temp",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "temp",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "log_softmax_63": {
                "variable": {
                    "value": "logprobs",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "sum_7": {
                "input": {
                    "value": "-soft_target * logsoftmax(pred)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_26": {
                "variable": {
                    "value": "logprobs_weiight",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_weight",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "x / self.temp",
                            "BinOp"
                        ],
                        [
                            "x / self.temp",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_59": {
                "variable": {
                    "value": "logprobs_weiight",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_weight",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "x / self.temp",
                            "BinOp"
                        ],
                        [
                            "x / self.temp",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "lib/utils/optimizer.py": {
        "torch": {
            "SGD_147": {
                "variable": {
                    "value": "optimizer",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "add_weight_decay(model, weight_decay)",
                            "Call"
                        ],
                        [
                            "model.parameters()",
                            "Call"
                        ]
                    ]
                },
                "lr": {
                    "value": "args.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "momentum": {
                    "value": "args.momentum",
                    "type": "Attribute",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "weight_decay",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "args.weight_decay",
                            "Attribute"
                        ],
                        [
                            "0.0",
                            "Constant"
                        ],
                        [
                            "1e-05",
                            "MethodArgument"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "nesterov": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "SGD_150": {
                "variable": {
                    "value": "optimizer",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "add_weight_decay(model, weight_decay)",
                            "Call"
                        ],
                        [
                            "model.parameters()",
                            "Call"
                        ]
                    ]
                },
                "lr": {
                    "value": "args.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "momentum": {
                    "value": "args.momentum",
                    "type": "Attribute",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "weight_decay",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "args.weight_decay",
                            "Attribute"
                        ],
                        [
                            "0.0",
                            "Constant"
                        ],
                        [
                            "1e-05",
                            "MethodArgument"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "nesterov": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Adam_153": {
                "variable": {
                    "value": "optimizer",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "add_weight_decay(model, weight_decay)",
                            "Call"
                        ],
                        [
                            "model.parameters()",
                            "Call"
                        ]
                    ]
                },
                "lr": {
                    "value": "args.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "weight_decay",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "args.weight_decay",
                            "Attribute"
                        ],
                        [
                            "0.0",
                            "Constant"
                        ],
                        [
                            "1e-05",
                            "MethodArgument"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "eps": {
                    "value": "args.opt_eps",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_like_75": {
                "variable": {
                    "value": "state[square_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_77": {
                "variable": {
                    "value": "state[momentum_buffer]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_79": {
                "variable": {
                    "value": "state[grad_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "lib/utils/saver.py": {
        "torch": {
            "save_106": {
                "obj": {
                    "value": "save_state",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'arch': args.model, 'state_dict': get_state_dict(model), 'optimizer': optimizer.state_dict(), 'args': args, 'version': 2}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "save_path",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "os.path.join(self.checkpoint_dir, filename)",
                            "Call"
                        ],
                        [
                            "os.path.join(self.recovery_dir, filename)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "lib/utils/scheduler.py": {
        "torch": {
            "Generator_92": {
                "variable": {
                    "value": "g",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CyclicLR_303": {
                "variable": {
                    "value": "lr_scheduler",
                    "type": "Variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "Variable",
                    "possible_values": []
                },
                "step_size_up": {
                    "value": "500",
                    "type": "int",
                    "possible_values": []
                },
                "base_lr": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                },
                "max_lr": {
                    "value": "0.064",
                    "type": "float",
                    "possible_values": []
                }
            },
            "LambdaLR_307": {
                "variable": {
                    "value": "lr_scheduler",
                    "type": "Variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "Variable",
                    "possible_values": []
                },
                "lr_lambda": {
                    "value": "lambda step: 1.0 - step / ITERS if step <= ITERS else 0",
                    "type": "Lambda",
                    "possible_values": []
                },
                "last_epoch": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "randn_97": {
                "variable": {
                    "value": "noise",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "generator": {
                    "value": "g",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.Generator()",
                            "Call"
                        ]
                    ]
                }
            },
            "rand_101": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "generator": {
                    "value": "g",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.Generator()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "lib/utils/util.py": {
        "torch": {
            "SummaryWriter_24": {
                "variable": {
                    "value": "writer",
                    "type": "Variable",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "os.path.join(output_dir, 'runs')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "tools/retrain.py": {
        "torch": {
            "CrossEntropyLoss_232": {
                "variable": {
                    "value": "validate_loss_fn",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "SummaryWriter_115": {
                "variable": {
                    "value": "writer",
                    "type": "Variable",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "os.path.join(output_dir, 'runs')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "tools/utils.py": {
        "torch": {
            "load_262": {
                "variable": {
                    "value": "checkpoint",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "Variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "set_device_322": {
                "device": {
                    "value": "args.gpu",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_105": {
                "obj": {
                    "value": "save_state",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'arch': args.model, 'state_dict': get_state_dict(model), 'optimizer': optimizer.state_dict(), 'args': args, 'version': 2}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "save_path",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "os.path.join(self.checkpoint_dir, filename)",
                            "Call"
                        ],
                        [
                            "os.path.join(self.recovery_dir, filename)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_281": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_306": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "broadcast_223": {
                "tensor": {
                    "value": "bn_buf",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "bn_buf / float(world_size)",
                            "BinOp"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_count_313": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}