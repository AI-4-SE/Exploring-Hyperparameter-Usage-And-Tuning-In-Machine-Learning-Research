{
    "BlockWiseEmbedding.py": {
        "tensorflow": {
            "ones_126": {
                "variable": {
                    "value": "ones",
                    "type": "variable",
                    "possible_values": []
                },
                "shape": {
                    "value": "[tf.size(labels)]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_152": {
                "variable": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sparse_softmax_cross_entropy_with_logits_153": {
                "variable": {
                    "value": "firstblock_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ]
                    ]
                },
                "labels": {
                    "value": "firstblock_labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels",
                            "variable"
                        ],
                        [
                            "tf.where(mask, ones * (self.block[0] + i), firstblock_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "add_156": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "loss",
                            "Call"
                        ],
                        [
                            "tf.add(loss, firstblock_loss, name=name)",
                            "Call"
                        ],
                        [
                            "tf.sparse_tensor_to_dense(aligned_block_i_loss) if i == 0 else loss + tf.sparse_tensor_to_dense(aligned_block_i_loss)",
                            "IfExp"
                        ]
                    ]
                },
                "y": {
                    "value": "firstblock_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.sparse_softmax_cross_entropy_with_logits(logits=firstblock_logits, labels=firstblock_labels)",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "'loss'",
                            "Method Argument"
                        ],
                        [
                            "'softmax'",
                            "Method Argument"
                        ],
                        [
                            "'softmax'",
                            "Method Argument"
                        ],
                        [
                            "'log_softmax'",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "matmul_162": {
                "variable": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_163": {
                "variable": {
                    "value": "firstblock_softmax",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_173": {
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.otherblock_w[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "softmax_174": {
                "variable": {
                    "value": "block_i_softmax",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "block_i_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(tf.nn.dropout(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), keep_prob=1 - self.dropout), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ]
                    ]
                }
            },
            "top_k_177": {
                "variable": {
                    "value": "(block_i_top_value, block_i_top_indices)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "block_i_pro",
                    "type": "variable",
                    "possible_values": [
                        [
                            "block_i_softmax * firstblock_softmax[:, index:index + 1]",
                            "BinOp"
                        ]
                    ]
                },
                "k": {
                    "value": "top_v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "5",
                            "Method Argument"
                        ],
                        [
                            "5",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "matmul_183": {
                "variable": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_184": {
                "variable": {
                    "value": "firstblock_softmax",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ]
                    ]
                }
            },
            "top_k_185": {
                "variable": {
                    "value": "(temp_top_value, temp_top_indices)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "firstblock_softmax[:, :self.block[0]]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "k": {
                    "value": "top_v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "5",
                            "Method Argument"
                        ],
                        [
                            "5",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "matmul_198": {
                "variable": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "log_softmax_199": {
                "variable": {
                    "value": "firstblock_logsoftmax",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "firstblock_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ],
                        [
                            "tf.matmul(inputs, self.firstblock_w)",
                            "Call"
                        ]
                    ]
                }
            },
            "get_variable_22": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "word_embedding_",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[self.vocab_size, self.embed_dim]",
                    "type": "List",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.random_uniform_initializer(-stdv, stdv)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "get_variable_33": {
                "variable": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "blockwiseembedding_block1_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[firstblock_K, self.embed_dim]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "embedding_lookup_47": {
                "variable": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ids": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_52": {
                "variable": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": []
                },
                "shape": {
                    "value": "input_size + [self.embed_dim]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "get_variable_106": {
                "variable": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "blockwiseembedding_softmax_block1_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[input_dim, firstblock_K]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_123": {
                "variable": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "keep_prob": {
                    "value": "1 - self.dropout",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "logical_and_128": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "tf.greater_equal(labels, self.block[i])",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "tf.less(labels, self.block[i + 1])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "where_131": {
                "variable": {
                    "value": "firstblock_labels",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                },
                "x": {
                    "value": "ones * (self.block[0] + i)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "y": {
                    "value": "firstblock_labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels",
                            "variable"
                        ],
                        [
                            "tf.where(mask, ones * (self.block[0] + i), firstblock_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "boolean_mask_134": {
                "variable": {
                    "value": "block_i_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "mask": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                }
            },
            "boolean_mask_142": {
                "variable": {
                    "value": "block_i_labels",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "labels - self.block[i]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "mask": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                }
            },
            "sparse_softmax_cross_entropy_with_logits_143": {
                "variable": {
                    "value": "block_i_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "block_i_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(tf.nn.dropout(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), keep_prob=1 - self.dropout), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ]
                    ]
                },
                "labels": {
                    "value": "block_i_labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.boolean_mask(labels - self.block[i], mask)",
                            "Call"
                        ]
                    ]
                }
            },
            "SparseTensor_145": {
                "variable": {
                    "value": "aligned_block_i_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "indices": {
                    "value": "tf.squeeze(tf.where(mask))",
                    "type": "Call",
                    "possible_values": []
                },
                "values": {
                    "value": "block_i_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.sparse_softmax_cross_entropy_with_logits(logits=block_i_logits, labels=block_i_labels)",
                            "Call"
                        ]
                    ]
                },
                "dense_shape": {
                    "value": "[tf.size(labels, out_type=tf.int64)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "matmul_166": {
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.otherblock_w[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "softmax_167": {
                "variable": {
                    "value": "block_i_softmax",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "block_i_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(tf.nn.dropout(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), keep_prob=1 - self.dropout), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ]
                    ]
                }
            },
            "concat_170": {
                "values": {
                    "value": "softmax_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[firstblock_softmax[:, :self.block[0]]]",
                            "List"
                        ]
                    ]
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "name": {
                    "value": "name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "'loss'",
                            "Method Argument"
                        ],
                        [
                            "'softmax'",
                            "Method Argument"
                        ],
                        [
                            "'softmax'",
                            "Method Argument"
                        ],
                        [
                            "'log_softmax'",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "in_top_k_189": {
                "variable": {
                    "value": "top_other",
                    "type": "variable",
                    "possible_values": []
                },
                "targets": {
                    "value": "firstblock_softmax",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.softmax(firstblock_logits)",
                            "Call"
                        ],
                        [
                            "tf.nn.softmax(firstblock_logits)",
                            "Call"
                        ],
                        [
                            "firstblock_softmax",
                            "Method Argument"
                        ]
                    ]
                },
                "predictions": {
                    "value": "[self.block[0] + i]",
                    "type": "List",
                    "possible_values": []
                },
                "k": {
                    "value": "top_v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "5",
                            "Method Argument"
                        ],
                        [
                            "5",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cond_190": {
                "variable": {
                    "value": "block_i_top",
                    "type": "variable",
                    "possible_values": []
                },
                "pred": {
                    "value": "tf.equal(top_other[0], tf.constant(True))",
                    "type": "Call",
                    "possible_values": []
                },
                "true_fn": {
                    "value": "lambda : self.block_i_top_v(inputs, firstblock_softmax, i, top_v)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "false_fn": {
                    "value": "lambda : list(((tf.constant(-1, dtype=tf.float32), tf.constant(-1, dtype=tf.int32)) for i in range(top_v)))",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "matmul_202": {
                "a": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "b": {
                    "value": "self.otherblock_w[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "log_softmax_203": {
                "variable": {
                    "value": "block_i_logsoftmax",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "block_i_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.matmul(tf.nn.dropout(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), keep_prob=1 - self.dropout), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ],
                        [
                            "tf.matmul(tf.matmul(inputs, self.otherblock_w[i][0]), self.otherblock_w[i][1])",
                            "Call"
                        ]
                    ]
                }
            },
            "concat_206": {
                "values": {
                    "value": "logsoftmax_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[firstblock_logsoftmax[:, :self.block[0]]]",
                            "List"
                        ]
                    ]
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "name": {
                    "value": "name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "'loss'",
                            "Method Argument"
                        ],
                        [
                            "'softmax'",
                            "Method Argument"
                        ],
                        [
                            "'softmax'",
                            "Method Argument"
                        ],
                        [
                            "'log_softmax'",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "logical_and_58": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "tf.greater_equal(inputs, low_idx)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "tf.less(inputs, high_idx)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cast_61": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "float",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "variable_scope_105": {
                "name_or_scope": {
                    "value": "name or type(self).__name__",
                    "type": "BoolOp",
                    "possible_values": []
                },
                "initializer": {
                    "value": "initializer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "matmul_136": {
                "variable": {
                    "value": "block_i_logits",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "tf.nn.dropout(tf.matmul(block_i_inputs, self.otherblock_w[i][0]), keep_prob=1 - self.dropout)",
                    "type": "Call",
                    "possible_values": []
                },
                "b": {
                    "value": "self.otherblock_w[i][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "matmul_140": {
                "a": {
                    "value": "block_i_inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(inputs - low_idx) * tf.cast(mask, dtype=tf.int32)",
                            "BinOp"
                        ],
                        [
                            "tf.boolean_mask(inputs, mask)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.otherblock_w[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "embedding_lookup_68": {
                "variable": {
                    "value": "firstblock_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "self.firstblock_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ids": {
                    "value": "firstblock_inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(inputs - low_idx) * tf.cast(mask, dtype=tf.int32)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "tensordot_73": {
                "variable": {
                    "value": "block_i_embed",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "tf.nn.embedding_lookup(self.otherblock_w[i - 1][1], block_i_inputs)",
                    "type": "Call",
                    "possible_values": []
                },
                "b": {
                    "value": "self.otherblock_w[i - 1][0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "size_126": {
                "input": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "greater_equal_128": {
                "x": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels",
                            "Method Argument"
                        ]
                    ]
                },
                "y": {
                    "value": "self.block[i]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "less_128": {
                "x": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels",
                            "Method Argument"
                        ]
                    ]
                },
                "y": {
                    "value": "self.block[i + 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "squeeze_145": {
                "input": {
                    "value": "tf.where(mask)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "equal_190": {
                "x": {
                    "value": "top_other[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "tf.constant(True)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "random_uniform_initializer_23": {
                "minval": {
                    "value": "-stdv",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "maxval": {
                    "value": "stdv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.sqrt(1.0 / self.vocab_size)",
                            "Call"
                        ]
                    ]
                }
            },
            "greater_equal_58": {
                "x": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "y": {
                    "value": "low_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "block_value[i]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "less_58": {
                "x": {
                    "value": "inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.dropout(inputs, keep_prob=1 - self.dropout)",
                            "Call"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ],
                        [
                            "inputs",
                            "Method Argument"
                        ]
                    ]
                },
                "y": {
                    "value": "high_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "block_value[i + 1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "expand_dims_76": {
                "input": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                },
                "axis": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_137": {
                "x": {
                    "value": "tf.matmul(block_i_inputs, self.otherblock_w[i][0])",
                    "type": "Call",
                    "possible_values": []
                },
                "keep_prob": {
                    "value": "1 - self.dropout",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "where_145": {
                "condition": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                }
            },
            "size_146": {
                "input": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "labels",
                            "Method Argument"
                        ]
                    ]
                },
                "out_type": {
                    "value": "tf.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "constant_190": {
                "value": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "get_variable_39": {
                "name": {
                    "value": "'blockwiseembedding_block{}_proj_w'.format(i + 2)",
                    "type": "Call",
                    "possible_values": []
                },
                "shape": {
                    "value": "[block_i_dim, self.embed_dim]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "get_variable_40": {
                "name": {
                    "value": "'blockwiseembedding_block{}_w'.format(i + 2)",
                    "type": "Call",
                    "possible_values": []
                },
                "shape": {
                    "value": "[block_i_K, block_i_dim]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cast_66": {
                "x": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cast_72": {
                "x": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.logical_and(tf.greater_equal(inputs, low_idx), tf.less(inputs, high_idx))",
                            "Call"
                        ],
                        [
                            "tf.cast(mask, dtype=float)",
                            "Call"
                        ],
                        [
                            "tf.logical_and(tf.greater_equal(labels, self.block[i]), tf.less(labels, self.block[i + 1]))",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "embedding_lookup_73": {
                "params": {
                    "value": "self.otherblock_w[i - 1][1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ids": {
                    "value": "block_i_inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(inputs - low_idx) * tf.cast(mask, dtype=tf.int32)",
                            "BinOp"
                        ],
                        [
                            "tf.boolean_mask(inputs, mask)",
                            "Call"
                        ]
                    ]
                }
            },
            "get_variable_111": {
                "name": {
                    "value": "'blockwiseembedding_softmax_block{}_proj_w'.format(i + 2)",
                    "type": "Call",
                    "possible_values": []
                },
                "shape": {
                    "value": "[input_dim, block_i_dim]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "get_variable_113": {
                "name": {
                    "value": "'blockwiseembedding_softmax_block{}_w'.format(i + 2)",
                    "type": "Call",
                    "possible_values": []
                },
                "shape": {
                    "value": "[block_i_dim, block_i_K]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "matmul_137": {
                "a": {
                    "value": "block_i_inputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(inputs - low_idx) * tf.cast(mask, dtype=tf.int32)",
                            "BinOp"
                        ],
                        [
                            "tf.boolean_mask(inputs, mask)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.otherblock_w[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "constant_192": {
                "value": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "Data_loader.py": {
        "tensorflow": {}
    },
    "generator_recsys.py": {
        "tensorflow": {
            "placeholder_37": {
                "variable": {
                    "value": "self.itemseq_input",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "int32",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['batch_size'], model_para['seq_len']]",
                    "type": "List",
                    "possible_values": []
                },
                "name": {
                    "value": "itemseq_input",
                    "type": "str",
                    "possible_values": []
                }
            },
            "reduce_mean_129": {
                "variable": {
                    "value": "self.loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_tensor": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.sampled_softmax_loss(self.softmax_w, self.softmax_b, label_flat, logits_2D, num_sampled, model_para['item_size'])",
                            "Call"
                        ],
                        [
                            "tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_flat, logits=logits_2D)",
                            "Call"
                        ],
                        [
                            "tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_flat, logits=logits_2D)",
                            "Call"
                        ],
                        [
                            "tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_flat, logits=logits_2D)",
                            "Call"
                        ],
                        [
                            "softmax_layer.loss(logits_2D, tf.reshape(label_seq, [-1]), 'loss')",
                            "Call"
                        ],
                        [
                            "softmax_layer.loss(logits_2D, tf.reshape(label_seq, [-1]), 'loss')",
                            "Call"
                        ],
                        [
                            "softmax_layer.loss(logits_2D, tf.reshape(label_seq, [-1]), 'loss')",
                            "Call"
                        ],
                        [
                            "softmax_layer.loss(logits_2D, tf.reshape(label_seq, [-1]), 'loss')",
                            "Call"
                        ]
                    ]
                }
            },
            "placeholder_188": {
                "variable": {
                    "value": "self.input_predict",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "int32",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['batch_size'], model_para['seq_len']]",
                    "type": "List",
                    "possible_values": []
                },
                "name": {
                    "value": "input_predict",
                    "type": "str",
                    "possible_values": []
                }
            },
            "placeholder_189": {
                "variable": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "int32",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['batch_size'], model_para['seq_len']]",
                    "type": "List",
                    "possible_values": []
                },
                "name": {
                    "value": "input_recall",
                    "type": "str",
                    "possible_values": []
                }
            },
            "placeholder_281": {
                "variable": {
                    "value": "self.input_predict",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "int32",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['batch_size'], model_para['seq_len']]",
                    "type": "List",
                    "possible_values": []
                },
                "name": {
                    "value": "input_predict",
                    "type": "str",
                    "possible_values": []
                }
            },
            "placeholder_282": {
                "variable": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "int32",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['batch_size'], model_para['seq_len']]",
                    "type": "List",
                    "possible_values": []
                },
                "name": {
                    "value": "input_recall",
                    "type": "str",
                    "possible_values": []
                }
            },
            "softmax_300": {
                "variable": {
                    "value": "probs_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "softmax",
                    "type": "str",
                    "possible_values": []
                }
            },
            "top_k_307": {
                "variable": {
                    "value": "self.top_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "self.g_probs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "k": {
                    "value": "model_para['top_k']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.model_para",
                            "Attribute"
                        ],
                        [
                            "self.model_para",
                            "Attribute"
                        ],
                        [
                            "self.model_para",
                            "Attribute"
                        ],
                        [
                            "self.model_para",
                            "Attribute"
                        ],
                        [
                            "model_para",
                            "Method Argument"
                        ]
                    ]
                },
                "name": {
                    "value": "top-k",
                    "type": "str",
                    "possible_values": []
                }
            },
            "reshape_45": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "get_variable_46": {
                "variable": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['item_size'], model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.random_normal_initializer(0.0, 0.01)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "get_variable_47": {
                "variable": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_b",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['item_size']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.constant_initializer(0.1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "reshape_48": {
                "variable": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, 1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "sampled_softmax_loss_51": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "weights": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "biases": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                },
                "labels": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(label_seq, [-1, 1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ]
                    ]
                },
                "inputs": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "num_sampled": {
                    "value": "num_sampled",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(0.2 * model_para['item_size'])",
                            "Call"
                        ]
                    ]
                },
                "num_classes": {
                    "value": "model_para['item_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "get_variable_151": {
                "variable": {
                    "value": "embed_proj_w",
                    "type": "variable",
                    "possible_values": []
                },
                "name": {
                    "value": "embed_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['in_embed_size'], model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensordot_152": {
                "variable": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "embed_proj_w",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.get_variable('embed_w', [model_para['in_embed_size'], model_para['dilated_channels']])",
                            "Call"
                        ]
                    ]
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "embedding_lookup_196": {
                "variable": {
                    "value": "recall_mat",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ids": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_197": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "tf.transpose(recall_mat, [0, 2, 1])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "reshape_198": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, tf.shape(self.input_recall)[1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "embedding_lookup_199": {
                "variable": {
                    "value": "recall_bias",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ids": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "add_200": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "recall_bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.embedding_lookup(self.softmax_b, self.input_recall)",
                            "Call"
                        ],
                        [
                            "tf.nn.embedding_lookup(self.softmax_b, self.input_recall)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_201": {
                "variable": {
                    "value": "probs_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "softmax",
                    "type": "str",
                    "possible_values": []
                }
            },
            "embedding_lookup_289": {
                "variable": {
                    "value": "recall_mat",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ids": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_290": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "tf.transpose(recall_mat, [0, 2, 1])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "reshape_291": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, tf.shape(self.input_recall)[1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "embedding_lookup_292": {
                "variable": {
                    "value": "recall_bias",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ids": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "add_293": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "recall_bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.embedding_lookup(self.softmax_b, self.input_recall)",
                            "Call"
                        ],
                        [
                            "tf.nn.embedding_lookup(self.softmax_b, self.input_recall)",
                            "Call"
                        ]
                    ]
                }
            },
            "reshape_298": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input), model_para['item_size'], name='logits')",
                            "Call"
                        ],
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input[:, -1:, :]), model_para['item_size'], name='logits')",
                            "Call"
                        ],
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input[:, -1:, :]), model_para['item_size'], name='logits')",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['item_size']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_60": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input), model_para['item_size'], name='logits')",
                            "Call"
                        ],
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input[:, -1:, :]), model_para['item_size'], name='logits')",
                            "Call"
                        ],
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input[:, -1:, :]), model_para['item_size'], name='logits')",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['item_size']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_61": {
                "variable": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "sparse_softmax_cross_entropy_with_logits_62": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "labels": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(label_seq, [-1, 1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ]
                    ]
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                }
            },
            "reduce_mean_130": {
                "input_tensor": {
                    "value": "[tf.nn.l2_loss(v) for v in tf.trainable_variables()]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "get_variable_scope_186": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "reshape_203": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['out_embed_size']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "matmul_204": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "tf.transpose(self.softmax_w)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bias_add_205": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "value": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_206": {
                "variable": {
                    "value": "probs_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                }
            },
            "get_variable_scope_279": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "random_normal_initializer_46": {
                "mean": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "stddev": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "constant_initializer_47": {
                "value": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            },
            "get_variable_55": {
                "variable": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_pro_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['dilated_channels'], model_para['embed_size']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.random_normal_initializer(0.0, 0.01)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensordot_57": {
                "variable": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "get_variable_70": {
                "variable": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['out_embed_size'], model_para['item_size']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.random_normal_initializer(0.0, 0.01)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "get_variable_72": {
                "variable": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_b",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['item_size']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.constant_initializer(0.1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "reshape_75": {
                "variable": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_76": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['out_embed_size']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "matmul_77": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bias_add_78": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "value": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sparse_softmax_cross_entropy_with_logits_79": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "labels": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(label_seq, [-1, 1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ]
                    ]
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_197": {
                "a": {
                    "value": "recall_mat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.embedding_lookup(self.softmax_w, self.input_recall)",
                            "Call"
                        ],
                        [
                            "tf.nn.embedding_lookup(self.softmax_w, self.input_recall)",
                            "Call"
                        ]
                    ]
                },
                "perm": {
                    "value": "[0, 2, 1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_213": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input), model_para['item_size'], name='logits')",
                            "Call"
                        ],
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input[:, -1:, :]), model_para['item_size'], name='logits')",
                            "Call"
                        ],
                        [
                            "ops_compress.conv1d(tf.nn.relu(dilate_input[:, -1:, :]), model_para['item_size'], name='logits')",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['item_size']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "softmax_214": {
                "variable": {
                    "value": "probs_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "softmax",
                    "type": "str",
                    "possible_values": []
                }
            },
            "transpose_290": {
                "a": {
                    "value": "recall_mat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.embedding_lookup(self.softmax_w, self.input_recall)",
                            "Call"
                        ],
                        [
                            "tf.nn.embedding_lookup(self.softmax_w, self.input_recall)",
                            "Call"
                        ]
                    ]
                },
                "perm": {
                    "value": "[0, 2, 1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "relu_297": {
                "features": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "relu_59": {
                "features": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "get_variable_66": {
                "variable": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_pro_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['dilated_channels'], model_para['out_embed_size']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.random_normal_initializer(0.0, 0.01)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensordot_68": {
                "variable": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "transpose_87": {
                "variable": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "a": {
                    "value": "self.allitem_embeddings.embedding",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "reshape_91": {
                "variable": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_92": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "matmul_93": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sparse_softmax_cross_entropy_with_logits_95": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "labels": {
                    "value": "label_flat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(label_seq, [-1, 1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ],
                        [
                            "tf.reshape(label_seq, [-1])",
                            "Call"
                        ]
                    ]
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                }
            },
            "l2_loss_130": {
                "t": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "transpose_204": {
                "a": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensordot_210": {
                "variable": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "reshape_220": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['out_embed_size']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "matmul_221": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_w",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bias_add_222": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "value": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "self.softmax_b",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_223": {
                "variable": {
                    "value": "probs_flat",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input, [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(self.softmax_w))",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['out_embed_size']])",
                            "Call"
                        ],
                        [
                            "tf.matmul(logits_2D, self.softmax_w)",
                            "Call"
                        ],
                        [
                            "tf.nn.bias_add(logits_2D, self.softmax_b)",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "tf.reshape(dilate_input[:, -1:, :], [-1, model_para['dilated_channels']])",
                            "Call"
                        ],
                        [
                            "dilate_input[:, -1:, :]",
                            "Subscript"
                        ],
                        [
                            "tf.matmul(logits_2D, tf.transpose(recall_mat, [0, 2, 1]))",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits_2D, [-1, tf.shape(self.input_recall)[1]])",
                            "Call"
                        ],
                        [
                            "tf.add(logits_2D, recall_bias)",
                            "Call"
                        ],
                        [
                            "tf.reshape(logits, [-1, model_para['item_size']])",
                            "Call"
                        ]
                    ]
                }
            },
            "random_normal_initializer_56": {
                "mean": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "stddev": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "random_normal_initializer_71": {
                "mean": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "stddev": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "constant_initializer_73": {
                "value": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            },
            "get_variable_83": {
                "variable": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "name": {
                    "value": "softmax_pro_w",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[model_para['dilated_channels'], model_para['embed_size']]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.random_normal_initializer(0.0, 0.01)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensordot_85": {
                "variable": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "reshape_98": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "trainable_variables_130": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "shape_198": {
                "input": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_212": {
                "features": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensordot_218": {
                "variable": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": []
                },
                "a": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "b": {
                    "value": "self.softmax_pro_w",
                    "type": "Attribute",
                    "possible_values": []
                },
                "axes": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "reshape_226": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "shape_291": {
                "input": {
                    "value": "self.input_recall",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "random_normal_initializer_67": {
                "mean": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "stddev": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "reshape_107": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_234": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "random_normal_initializer_84": {
                "mean": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "stddev": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "reshape_103": {
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_115": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_242": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_112": {
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_123": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "context_embedding",
                            "variable"
                        ],
                        [
                            "tf.tensordot(dilate_input, embed_proj_w, axes=1)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_cross_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_block_adjacent_layer(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "ops_compress.nextitnet_residual_adjacent_block(dilate_input, dilation, layer_id, model_para['dilated_channels'], model_para['kernel_size'], causal=True, train=train)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "tf.tensordot(dilate_input, self.softmax_pro_w, axes=1)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_250": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_119": {
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_258": {
                "variable": {
                    "value": "logits_2D",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "dilate_input[:, -1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shape": {
                    "value": "[-1, model_para['dilated_channels']]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "reshape_127": {
                "tensor": {
                    "value": "label_seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model_graph(self.itemseq_input, train=True)",
                            "Call"
                        ],
                        [
                            "itemseq_input[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ],
                        [
                            "self.model_graph(self.input_predict, train=False)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "nextitrec_eval.py": {
        "tensorflow": {}
    },
    "ops_compress.py": {
        "tensorflow": {
            "relu_22": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_34": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_54": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_64": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_86": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_99": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_122": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_135": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_154": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_165": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_178": {
                "variable": {
                    "value": "relu1",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "input_ln",
                    "type": "variable",
                    "possible_values": [
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm1', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm2', trainable=train)",
                            "Call"
                        ],
                        [
                            "layer_norm(input_, name='layer_norm1', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_181": {
                "variable": {
                    "value": "relu2",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "conv1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv1d(relu1, int(0.5 * residual_channels), name='conv1d_1')",
                            "Call"
                        ],
                        [
                            "layer_norm(conv1, name='layer_norm2', trainable=train)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_190": {
                "variable": {
                    "value": "relu3",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "dilated_conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv1')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv2')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv1')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv2')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv1')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv2')",
                            "Call"
                        ],
                        [
                            "conv1d(relu2, int(0.5 * residual_channels), dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm3', trainable=train)",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ]
                    ]
                }
            },
            "tanh_210": {
                "variable": {
                    "value": "tanh",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "dilated_conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv1')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv2')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv1')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv2')",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv1')",
                            "Call"
                        ],
                        [
                            "conv1d(relu1, residual_channels, 2 * dilation, kernel_size, causal=causal, name='dilated_conv2')",
                            "Call"
                        ],
                        [
                            "conv1d(relu2, int(0.5 * residual_channels), dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ],
                        [
                            "layer_norm(dilated_conv, name='layer_norm3', trainable=train)",
                            "Call"
                        ],
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='dilated_conv')",
                            "Call"
                        ]
                    ]
                }
            },
            "sigmoid_217": {
                "variable": {
                    "value": "sigm",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "gate_conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv1d(input_, residual_channels, dilation, kernel_size, causal=causal, name='gate_conv')",
                            "Call"
                        ]
                    ]
                }
            },
            "multiply_218": {
                "variable": {
                    "value": "multi",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "tanh",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.tanh(dilated_conv)",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "sigm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.sigmoid(gate_conv)",
                            "Call"
                        ]
                    ]
                }
            },
            "get_variable_230": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "name": {
                    "value": "weight",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[1, kernel_size, input_.get_shape()[-1], output_channels]",
                    "type": "List",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.truncated_normal_initializer(stddev=0.02, seed=1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "get_variable_231": {
                "variable": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": []
                },
                "name": {
                    "value": "bias",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[output_channels]",
                    "type": "List",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.constant_initializer(0.0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "get_variable_251": {
                "variable": {
                    "value": "beta",
                    "type": "variable",
                    "possible_values": []
                },
                "name": {
                    "value": "beta",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[int(shape[-1])]",
                    "type": "List",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.constant_initializer(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "trainable": {
                    "value": "trainable",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "get_variable_253": {
                "variable": {
                    "value": "gamma",
                    "type": "variable",
                    "possible_values": []
                },
                "name": {
                    "value": "gamma",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "[int(shape[-1])]",
                    "type": "List",
                    "possible_values": []
                },
                "initializer": {
                    "value": "tf.constant_initializer(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "trainable": {
                    "value": "trainable",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "moments_256": {
                "variable": {
                    "value": "(mean, variance)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "x": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(x - mean) / tf.sqrt(variance + epsilon)",
                            "BinOp"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "axes": {
                    "value": "[len(shape) - 1]",
                    "type": "List",
                    "possible_values": []
                },
                "keep_dims": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "variable_scope_10": {
                "name_or_scope": {
                    "value": "resblock_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer'.format(resblock_type)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block_one_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'gatedCNN_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_19": {
                "name_or_scope": {
                    "value": "resblock_norm_name1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_24": {
                "name_or_scope": {
                    "value": "resblock_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer'.format(resblock_type)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block_one_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'gatedCNN_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_31": {
                "name_or_scope": {
                    "value": "resblock_norm_name2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_45": {
                "name_or_scope": {
                    "value": "resblock_name1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_0'.format(resblock_type, layer_id / 2)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_0'.format(resblock_type)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_75": {
                "name_or_scope": {
                    "value": "resblock_name1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_0'.format(resblock_type, layer_id / 2)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_0'.format(resblock_type)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_83": {
                "name_or_scope": {
                    "value": "resblock_norm_name1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_89": {
                "name_or_scope": {
                    "value": "resblock_name2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_1'.format(resblock_type, layer_id / 2)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_1'.format(resblock_type)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_96": {
                "name_or_scope": {
                    "value": "resblock_norm_name2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_111": {
                "name_or_scope": {
                    "value": "resblock_name1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_0'.format(resblock_type, layer_id / 2)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_0'.format(resblock_type)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_119": {
                "name_or_scope": {
                    "value": "resblock_norm_name1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm1'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                }
            },
            "variable_scope_125": {
                "name_or_scope": {
                    "value": "resblock_name2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_1'.format(resblock_type, layer_id / 2)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_1'.format(resblock_type)",
                            "Call"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "variable_scope_132": {
                "name_or_scope": {
                    "value": "resblock_norm_name2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}_norm2'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                }
            },
            "variable_scope_145": {
                "name_or_scope": {
                    "value": "resblock_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer'.format(resblock_type)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block_one_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'gatedCNN_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                }
            },
            "variable_scope_176": {
                "name_or_scope": {
                    "value": "resblock_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer'.format(resblock_type)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block_one_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'gatedCNN_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                }
            },
            "variable_scope_202": {
                "name_or_scope": {
                    "value": "resblock_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'nextitnet_residual_block{}_layer'.format(resblock_type)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'nextitnet_residual_block_one_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ],
                        [
                            "'gatedCNN_{}_layer_{}_{}'.format(resblock_type, layer_id, dilation)",
                            "Call"
                        ]
                    ]
                }
            },
            "variable_scope_228": {
                "name_or_scope": {
                    "value": "name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'dilated_conv'",
                            "Method Argument"
                        ],
                        [
                            "name",
                            "Method Argument"
                        ]
                    ]
                },
                "reuse": {
                    "value": "tf.AUTO_REUSE",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_236": {
                "variable": {
                    "value": "padded",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "input_",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ]
                    ]
                },
                "paddings": {
                    "value": "padding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[[0, 0], [(kernel_size - 1) * dilation, 0], [0, 0]]",
                            "List"
                        ]
                    ]
                }
            },
            "expand_dims_237": {
                "variable": {
                    "value": "input_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "padded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.pad(input_, padding)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "expand_dims_240": {
                "variable": {
                    "value": "input_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ],
                        [
                            "input_",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "squeeze_244": {
                "input": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.atrous_conv2d(input_expanded, weight, rate=dilation, padding='VALID') + bias",
                            "BinOp"
                        ],
                        [
                            "tf.nn.conv2d(input_expanded, weight, strides=[1, 1, 1, 1], padding='SAME') + bias",
                            "BinOp"
                        ]
                    ]
                },
                "axis": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "variable_scope_249": {
                "name_or_scope": {
                    "value": "name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'dilated_conv'",
                            "Method Argument"
                        ],
                        [
                            "name",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "sqrt_258": {
                "x": {
                    "value": "variance + epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "truncated_normal_initializer_230": {
                "stddev": {
                    "value": "0.02",
                    "type": "float",
                    "possible_values": []
                },
                "seed": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "constant_initializer_232": {
                "value": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "atrous_conv2d_238": {
                "value": {
                    "value": "input_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.expand_dims(padded, dim=1)",
                            "Call"
                        ],
                        [
                            "tf.expand_dims(input_, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "filters": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.get_variable('weight', [1, kernel_size, input_.get_shape()[-1], output_channels], initializer=tf.truncated_normal_initializer(stddev=0.02, seed=1))",
                            "Call"
                        ]
                    ]
                },
                "rate": {
                    "value": "dilation",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "dilation",
                            "Method Argument"
                        ],
                        [
                            "1",
                            "Method Argument"
                        ]
                    ]
                },
                "padding": {
                    "value": "VALID",
                    "type": "str",
                    "possible_values": []
                }
            },
            "conv2d_242": {
                "input": {
                    "value": "input_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.expand_dims(padded, dim=1)",
                            "Call"
                        ],
                        [
                            "tf.expand_dims(input_, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "filters": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.get_variable('weight', [1, kernel_size, input_.get_shape()[-1], output_channels], initializer=tf.truncated_normal_initializer(stddev=0.02, seed=1))",
                            "Call"
                        ]
                    ]
                },
                "strides": {
                    "value": "[1, 1, 1, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "padding": {
                    "value": "SAME",
                    "type": "str",
                    "possible_values": []
                }
            },
            "constant_initializer_252": {
                "value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "constant_initializer_254": {
                "value": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    }
}