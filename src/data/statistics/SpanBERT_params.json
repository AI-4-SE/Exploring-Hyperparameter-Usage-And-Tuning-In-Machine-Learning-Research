{
    "code/run_glue.py": {
        "sklearn": {
            "f1_score_586": {
                "variable": {
                    "value": "f1",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "preds",
                    "type": "Call",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "preds[0]",
                            "Subscript"
                        ],
                        [
                            "np.argmax(preds, axis=1)",
                            "Call"
                        ],
                        [
                            "np.squeeze(preds)",
                            "Call"
                        ]
                    ]
                }
            },
            "matthews_corrcoef_607": {
                "y_true": {
                    "value": "labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "preds",
                    "type": "Call",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "preds[0]",
                            "Subscript"
                        ],
                        [
                            "np.argmax(preds, axis=1)",
                            "Call"
                        ],
                        [
                            "np.squeeze(preds)",
                            "Call"
                        ]
                    ]
                }
            }
        },
        "torch": {
            "device_684": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_685": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_698": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_736": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_737": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_738": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_747": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_748": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_760": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_761": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_762": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_771": {
                "variable": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_772": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "manual_seed_all_700": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_741": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_765": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_929": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_930": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_931": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_932": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_933": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_644": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_650": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_743": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_767": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataParallel_796": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForSequenceClassification.from_pretrained(args.output_dir, num_labels=num_labels)",
                            "Call"
                        ],
                        [
                            "BertForSequenceClassification.from_pretrained(args.model, cache_dir=cache_dir, num_labels=num_labels)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "MSELoss_653": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_684": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_847": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "MSELoss_850": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_909": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(args.output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/pytorch_pretrained_bert/modeling.py": {
        "tensorflow": {
            "list_variables_66": {
                "variable": {
                    "value": "init_vars",
                    "type": "Variable",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "tf_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.abspath(tf_checkpoint_path)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_variable_71": {
                "variable": {
                    "value": "array",
                    "type": "Variable",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "tf_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.abspath(tf_checkpoint_path)",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "name",
                    "type": "Name",
                    "possible_values": [
                        [
                            "name.split('/')",
                            "Call"
                        ]
                    ]
                }
            }
        },
        "torch": {
            "from_numpy_115": {
                "variable": {
                    "value": "pointer.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "array",
                    "type": "Call",
                    "possible_values": [
                        [
                            "tf.train.load_variable(tf_path, name)",
                            "Call"
                        ],
                        [
                            "np.transpose(array)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_237": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_238": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_252": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Embedding_253": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_254": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_259": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_263": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_289": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_290": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_291": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_293": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_310": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_314": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_scores",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.matmul(query_layer, key_layer.transpose(-1, -2))",
                            "Call"
                        ],
                        [
                            "attention_scores / math.sqrt(self.attention_head_size)",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(attention_scores, -10000.0, 10000.0)",
                            "Call"
                        ],
                        [
                            "attention_scores + attention_mask",
                            "BinOp"
                        ]
                    ]
                },
                "min": {
                    "value": "-10000.0",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "max": {
                    "value": "10000.0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "matmul_325": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_335": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_337": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_361": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_376": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_378": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_405": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_421": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tanh_422": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_436": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_457": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_461": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_482": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_493": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_984": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_985": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_labels",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Dropout_1049": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1050": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_1119": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1120": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_labels",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Linear_1195": {
                "variable": {
                    "value": "self.qa_outputs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sigmoid_129": {
                "input": {
                    "value": "x",
                    "type": "Name",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_266": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "load_603": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, TF_WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ones_like_711": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_like_713": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_803": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_866": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_928": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_994": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1063": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1129": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1216": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "ignored_index",
                    "type": "Name",
                    "possible_values": [
                        [
                            "start_logits.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "erf_125": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_237": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_238": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sqrt_244": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Softmax_319": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_461": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/pytorch_pretrained_bert/optimization.py": {
        "torch": {
            "zeros_like_130": {
                "variable": {
                    "value": "state[next_m]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_132": {
                "variable": {
                    "value": "state[next_v]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__139": {
                "parameters": {
                    "value": "p",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "code/run_mrqa.py": {
        "torch": {
            "device_638": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_639": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_645": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_694": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_695": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_696": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_697": {
                "variable": {
                    "value": "all_example_index",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "all_input_ids.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_698": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_699": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_718": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_719": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_720": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_721": {
                "variable": {
                    "value": "all_start_positions",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.start_position for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_722": {
                "variable": {
                    "value": "all_end_positions",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.end_position for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_723": {
                "variable": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_725": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_start_positions, all_end_positions)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_647": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_864": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_865": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_866": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_867": {
                "variable": {
                    "value": "all_example_index",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "all_input_ids.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_868": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_869": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_614": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_746": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForQuestionAnswering.from_pretrained(args.output_dir)",
                            "Call"
                        ],
                        [
                            "BertForQuestionAnswering.from_pretrained(args.model, cache_dir=PYTORCH_PRETRAINED_BERT_CACHE)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_638": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_838": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(args.output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/run_squad.py": {
        "torch": {
            "device_816": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_817": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_823": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_873": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_874": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_875": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_876": {
                "variable": {
                    "value": "all_example_index",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "all_input_ids.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_877": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_878": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_896": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_897": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_898": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_899": {
                "variable": {
                    "value": "all_start_positions",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.start_position for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_900": {
                "variable": {
                    "value": "all_end_positions",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.end_position for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_901": {
                "variable": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_903": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_start_positions, all_end_positions)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_825": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_1047": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_1048": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_1049": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_1050": {
                "variable": {
                    "value": "all_example_index",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "all_input_ids.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_1051": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_1052": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_764": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_926": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForQuestionAnswering.from_pretrained(args.output_dir)",
                            "Call"
                        ],
                        [
                            "BertForQuestionAnswering.from_pretrained(args.model, cache_dir=PYTORCH_PRETRAINED_BERT_CACHE)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_816": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_1020": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(args.output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/run_tacred.py": {
        "torch": {
            "device_301": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_302": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_278": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_311": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_343": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_344": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_345": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_346": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_347": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_348": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_361": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_362": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_363": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_364": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in train_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_365": {
                "variable": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_366": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_313": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_504": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_505": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_506": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_507": {
                "variable": {
                    "value": "all_label_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in eval_features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_508": {
                "variable": {
                    "value": "eval_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_509": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_data",
                    "type": "Call",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_276": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_388": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForSequenceClassification.from_pretrained(args.output_dir, num_labels=num_labels)",
                            "Call"
                        ],
                        [
                            "BertForSequenceClassification.from_pretrained(args.model, cache_dir=str(PYTORCH_PRETRAINED_BERT_CACHE), num_labels=num_labels)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_301": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_487": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(args.output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/criterions/bert_loss.py": {
        "torch": {
            "cross_entropy_40": {
                "variable": {
                    "value": "lm_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lm_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[0]",
                            "Subscript"
                        ],
                        [
                            "lm_logits.view(-1, lm_logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "lm_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['lm_target'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cross_entropy_50": {
                "variable": {
                    "value": "sentence_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "sentence_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[1]",
                            "Subscript"
                        ]
                    ]
                },
                "target": {
                    "value": "sentence_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['sentence_target'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/criterions/composite_loss.py": {
        "torch": {}
    },
    "pretraining/fairseq/criterions/cross_entropy.py": {
        "torch": {
            "nll_loss_35": {
                "variable": {
                    "value": "loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "model.get_normalized_probs(net_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "lprobs.view(-1, lprobs.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "Name",
                    "possible_values": [
                        [
                            "model.get_targets(sample, net_output).view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/criterions/fairseq_criterion.py": {
        "torch": {}
    },
    "pretraining/fairseq/criterions/mlm_loss.py": {
        "torch": {
            "cross_entropy_37": {
                "variable": {
                    "value": "lm_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lm_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[0]",
                            "Subscript"
                        ],
                        [
                            "lm_logits.view(-1, lm_logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "lm_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['lm_target'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/criterions/mlm_nsp_sbo_loss.py": {
        "torch": {
            "cross_entropy_42": {
                "variable": {
                    "value": "lm_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lm_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[0]",
                            "Subscript"
                        ],
                        [
                            "lm_logits.view(-1, lm_logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "lm_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['lm_target'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cross_entropy_54": {
                "variable": {
                    "value": "pair_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pair_target_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[2]",
                            "Subscript"
                        ],
                        [
                            "pair_target_logits.view(-1, pair_target_logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "pair_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['pair_targets'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cross_entropy_64": {
                "variable": {
                    "value": "sentence_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "sentence_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[1]",
                            "Subscript"
                        ]
                    ]
                },
                "target": {
                    "value": "sentence_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['sentence_target'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/criterions/spanbert_loss.py": {
        "torch": {
            "cross_entropy_40": {
                "variable": {
                    "value": "lm_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lm_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[0]",
                            "Subscript"
                        ],
                        [
                            "lm_logits.view(-1, lm_logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "lm_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['lm_target'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cross_entropy_52": {
                "variable": {
                    "value": "pair_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pair_target_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[2]",
                            "Subscript"
                        ],
                        [
                            "pair_target_logits.view(-1, pair_target_logits.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "pair_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "sample['pair_targets'].view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "Name",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/data/dictionary.py": {
        "torch": {
            "Tensor_197": {
                "variable": {
                    "value": "t",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "is_tensor_53": {
                "obj": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/data/fairseq_dataset.py": {
        "torch": {}
    },
    "pretraining/fairseq/data/indexed_dataset.py": {
        "torch": {
            "from_numpy_93": {
                "variable": {
                    "value": "item",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_150": {
                "variable": {
                    "value": "item",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_175": {
                "ndarray": {
                    "value": "a",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/data/iterators.py": {
        "torch": {
            "DataLoader_175": {
                "dataset": {
                    "value": "self.dataset",
                    "type": "Attribute",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "self.collate_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_sampler": {
                    "value": "batches",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(list(batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "list(ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[]))",
                            "Call"
                        ],
                        [
                            "shuffle_batches(list(self.frozen_batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(batches, self.seed + epoch + self.shard_id)",
                            "Call"
                        ],
                        [
                            "ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/data/masking.py": {
        "torch": {}
    },
    "pretraining/fairseq/data/no_nsp_span_bert_dataset.py": {
        "torch": {
            "zeros_217": {
                "variable": {
                    "value": "segment_labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "tgt_len",
                    "type": "Name",
                    "possible_values": [
                        [
                            "min(tgt_len, max_positions)",
                            "Call"
                        ],
                        [
                            "12",
                            "MethodArgument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_218": {
                "variable": {
                    "value": "pair_targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, self.args.max_pair_targets + 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_162": {
                "variable": {
                    "value": "pair_targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(pair_targets)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_164": {
                "variable": {
                    "value": "pair_targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, self.args.max_pair_targets + 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_167": {
                "ndarray": {
                    "value": "item",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.concatenate([[self.vocab.cls()], masked_block, [self.vocab.sep()]])",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_168": {
                "ndarray": {
                    "value": "seg",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros(block[1] - block[0] + 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_169": {
                "ndarray": {
                    "value": "target",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.concatenate([[self.vocab.pad()], masked_tgt, [self.vocab.pad()]])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/data/span_bert_dataset.py": {
        "torch": {
            "zeros_414": {
                "variable": {
                    "value": "segment_labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "tgt_len",
                    "type": "Name",
                    "possible_values": [
                        [
                            "min(tgt_len, max_positions)",
                            "Call"
                        ],
                        [
                            "12",
                            "MethodArgument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_415": {
                "variable": {
                    "value": "pair_targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, self.args.max_pair_targets + 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_357": {
                "variable": {
                    "value": "pair_targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(pair_targets)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_359": {
                "variable": {
                    "value": "pair_targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, self.args.max_pair_targets + 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_362": {
                "ndarray": {
                    "value": "item",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.concatenate([item1, item2])",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_363": {
                "ndarray": {
                    "value": "seg",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.concatenate([seg1, seg2])",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_364": {
                "ndarray": {
                    "value": "target",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.concatenate([target1, target2])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/distributed_utils.py": {
        "torch": {}
    },
    "pretraining/fairseq/legacy_distributed_data_parallel.py": {
        "torch": {
            "zeros_like_101": {
                "input": {
                    "value": "param",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/models/distributed_fairseq_model.py": {
        "torch": {}
    },
    "pretraining/fairseq/models/fairseq_decoder.py": {
        "torch": {
            "log_softmax_46": {
                "input": {
                    "value": "logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[0].float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_48": {
                "input": {
                    "value": "logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output[0].float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/models/fairseq_encoder.py": {
        "torch": {}
    },
    "pretraining/fairseq/models/fairseq_model.py": {
        "torch": {
            "is_tensor_40": {
                "obj": {
                    "value": "net_output",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "remove_weight_norm_96": {
                "module": {
                    "value": "module",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "log_softmax_43": {
                "input": {
                    "value": "logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_45": {
                "input": {
                    "value": "logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/models/hf_bert.py": {
        "torch": {
            "Parameter_134": {
                "variable": {
                    "value": "self.gamma",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_135": {
                "variable": {
                    "value": "self.beta",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_149": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_150": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_151": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_156": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_160": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_184": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_185": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_186": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_188": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_205": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_219": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_229": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_231": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_255": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_268": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_270": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_297": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_313": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tanh_314": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_328": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_347": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_351": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_372": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sigmoid_35": {
                "input": {
                    "value": "x",
                    "type": "Name",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_163": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids[:, :max_position_embeddings]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "clamp_208": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_scores",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.matmul(query_layer, key_layer.transpose(-1, -2))",
                            "Call"
                        ],
                        [
                            "attention_scores / math.sqrt(self.attention_head_size)",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(attention_scores, -very_small_number, very_small_number)",
                            "Call"
                        ],
                        [
                            "attention_scores + attention_mask",
                            "BinOp"
                        ]
                    ]
                },
                "min": {
                    "value": "-very_small_number",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "max": {
                    "value": "very_small_number",
                    "type": "Name",
                    "possible_values": [
                        [
                            "32000",
                            "Constant"
                        ]
                    ]
                }
            },
            "load_482": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_583": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids[:, :max_position_embeddings]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_like_585": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids[:, :max_position_embeddings]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_784": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "erf_31": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_134": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_135": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sqrt_141": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Softmax_213": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_351": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_383": {
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/models/pair_bert.py": {
        "torch": {
            "Parameter_133": {
                "variable": {
                    "value": "self.gamma",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_134": {
                "variable": {
                    "value": "self.beta",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_148": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_149": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_150": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_155": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_159": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_183": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_184": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_185": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_187": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_204": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_218": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_228": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_230": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_254": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_267": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_269": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_296": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_312": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tanh_313": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_327": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_342": {
                "variable": {
                    "value": "self.linear1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_size",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_345": {
                "variable": {
                    "value": "self.linear2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_359": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_363": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_373": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "max_targets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "20",
                            "MethodArgument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "position_embedding_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "200",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_377": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_381": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_390": {
                "variable": {
                    "value": "left_hidden",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden_states",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.dropout(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.LayerNorm(hidden_states + input_tensor)",
                            "Call"
                        ],
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.intermediate_act_fn(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.dropout(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.LayerNorm(hidden_states + input_tensor)",
                            "Call"
                        ],
                        [
                            "layer_module(hidden_states, attention_mask)",
                            "Call"
                        ],
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.transform_act_fn(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.LayerNorm(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.transform(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.decoder(hidden_states) + self.bias",
                            "BinOp"
                        ],
                        [
                            "self.mlp_layer_norm(torch.cat((left_hidden, right_hidden, position_embeddings.unsqueeze(0).repeat(bs * num_pairs, 1, 1)), -1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "left.unsqueeze(2).repeat(1, 1, dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_393": {
                "variable": {
                    "value": "right_hidden",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden_states",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.dropout(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.LayerNorm(hidden_states + input_tensor)",
                            "Call"
                        ],
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.intermediate_act_fn(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.dropout(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.LayerNorm(hidden_states + input_tensor)",
                            "Call"
                        ],
                        [
                            "layer_module(hidden_states, attention_mask)",
                            "Call"
                        ],
                        [
                            "self.dense(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.transform_act_fn(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.LayerNorm(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.transform(hidden_states)",
                            "Call"
                        ],
                        [
                            "self.decoder(hidden_states) + self.bias",
                            "BinOp"
                        ],
                        [
                            "self.mlp_layer_norm(torch.cat((left_hidden, right_hidden, position_embeddings.unsqueeze(0).repeat(bs * num_pairs, 1, 1)), -1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "right.unsqueeze(2).repeat(1, 1, dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_418": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sigmoid_34": {
                "input": {
                    "value": "x",
                    "type": "Name",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_162": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids[:, :max_position_embeddings]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "clamp_207": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_scores",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.matmul(query_layer, key_layer.transpose(-1, -2))",
                            "Call"
                        ],
                        [
                            "attention_scores / math.sqrt(self.attention_head_size)",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(attention_scores, -10000.0, 10000.0)",
                            "Call"
                        ],
                        [
                            "attention_scores + attention_mask",
                            "BinOp"
                        ]
                    ]
                },
                "min": {
                    "value": "-10000.0",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "max": {
                    "value": "10000.0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "load_531": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_632": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids[:, :max_position_embeddings]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_like_634": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids[:, :max_position_embeddings]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_829": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "erf_30": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_133": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_134": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sqrt_140": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Softmax_212": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_363": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_381": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_399": {
                "tensors": {
                    "value": "(left_hidden, right_hidden, position_embeddings.unsqueeze(0).repeat(bs * num_pairs, 1, 1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Linear_431": {
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/adaptive_input.py": {
        "torch": {
            "ModuleList_39": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_44": {
                "variable": {
                    "value": "seq",
                    "type": "Variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Embedding(size, dim, padding_idx)",
                    "type": null,
                    "possible_values": []
                }
            },
            "Embedding_45": {
                "num_embeddings": {
                    "value": "size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.cutoff[i] - prev",
                            "BinOp"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Linear_46": {
                "in_features": {
                    "value": "dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/adaptive_inputs.py": {
        "torch": {
            "ModuleList_39": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_44": {
                "variable": {
                    "value": "seq",
                    "type": "Variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Embedding(size, dim, padding_idx)",
                    "type": null,
                    "possible_values": []
                }
            },
            "Embedding_45": {
                "num_embeddings": {
                    "value": "size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.cutoff[i] - prev",
                            "BinOp"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Linear_46": {
                "in_features": {
                    "value": "dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/adaptive_softmax.py": {
        "torch": {
            "Linear_39": {
                "variable": {
                    "value": "self.class_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "LogSoftmax_76": {
                "variable": {
                    "value": "self.lsm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ModuleList_98": {
                "variable": {
                    "value": "self.tail",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_164": {
                "variable": {
                    "value": "input",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "Call",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_23": {
                "input": {
                    "value": "input",
                    "type": "Call",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight.t() if self.transpose else self.weight",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Sequential_34": {
                "variable": {
                    "value": "self.word_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(input_dim, emb_dim, bias=False)",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_81": {
                "variable": {
                    "value": "self.head",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "cutoff[0] + len(cutoff) - 1",
                            "BinOp"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Sequential_113": {
                "variable": {
                    "value": "m",
                    "type": "Variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "proj",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_111": {
                "variable": {
                    "value": "proj",
                    "type": "Variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + extra_denom))",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_35": {
                "in_features": {
                    "value": "input_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "emb_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_109": {
                "variable": {
                    "value": "proj",
                    "type": "Variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "tied_proj.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "tied_proj.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_115": {
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_116": {
                "in_features": {
                    "value": "dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + extra_denom))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.cutoff[i + 1] - self.cutoff[i]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/beamable_mm.py": {
        "torch": {
            "mm_41": {
                "variable": {
                    "value": "output",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mat2": {
                    "value": "input2[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/bidirectional_multihead_attention.py": {
        "torch": {
            "Parameter_39": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(chunks * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_44": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_74": {
                "variable": {
                    "value": "padded_fwd_x",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[fwd_x.new_zeros(1, bsz, embed_dim), fwd_x]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_75": {
                "variable": {
                    "value": "padded_bwd_x",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[bwd_x, bwd_x.new_zeros(1, bsz, embed_dim)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "arange_77": {
                "variable": {
                    "value": "fwd_idxs",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "tgt_len",
                    "type": "Variable",
                    "possible_values": []
                },
                "out": {
                    "value": "fwd_x.new().long()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_78": {
                "variable": {
                    "value": "bwd_idxs",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "end": {
                    "value": "tgt_len + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out": {
                    "value": "fwd_x.new().long()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_84": {
                "variable": {
                    "value": "kv",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[fwd_x, bwd_x]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "bmm_95": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.cat([padded_fwd_x[fwd_idxs], padded_bwd_x[bwd_idxs]], dim=-1)",
                            "Call"
                        ],
                        [
                            "padded_fwd_x[fwd_idxs] + padded_bwd_x[bwd_idxs]",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_110": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_111": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.mask(attn_weights, mask_curr_state).unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.repeat(1, 2).unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_113": {
                "variable": {
                    "value": "attn",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.mask(attn_weights, mask_curr_state).unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.repeat(1, 2).unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "Name",
                    "possible_values": [
                        [
                            "v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_34": {
                "variable": {
                    "value": "self.q_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Parameter_41": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(chunks * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_81": {
                "variable": {
                    "value": "q",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[padded_fwd_x[fwd_idxs], padded_bwd_x[bwd_idxs]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "linear_145": {
                "input": {
                    "value": "input",
                    "type": "Variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[:end, :]",
                            "Subscript"
                        ],
                        [
                            "weight[start:, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/modules/downsampled_multihead_attention.py": {
        "torch": {
            "Linear_244": {
                "variable": {
                    "value": "m",
                    "type": "Variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_features",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Sequential_54": {
                "variable": {
                    "value": "self.in_proj_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*k_layers",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_55": {
                "variable": {
                    "value": "self.in_proj_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*v_layers",
                    "type": null,
                    "possible_values": []
                }
            },
            "bmm_108": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "Call",
                    "possible_values": [
                        [
                            "query",
                            "Name"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "q.view(tgt_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "q.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_138": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_139": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_141": {
                "variable": {
                    "value": "attn",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "Call",
                    "possible_values": [
                        [
                            "value",
                            "Name"
                        ],
                        [
                            "self.in_proj_v(v)",
                            "Call"
                        ],
                        [
                            "v.view(src_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "v.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "scalar_bias(v, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_247": {
                "module": {
                    "value": "m",
                    "type": "Name",
                    "possible_values": [
                        [
                            "nn.Linear(in_features, out_features, bias=bias)",
                            "Call"
                        ]
                    ]
                }
            },
            "Sequential_252": {
                "*args": {
                    "value": "Linear(in_features, out_features * 4, dropout, bias)",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_214": {
                "variable": {
                    "value": "full_attn",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_223": {
                "variable": {
                    "value": "full_attn",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_224": {
                "variable": {
                    "value": "full_attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "GLU_254": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_256": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "unsqueeze_112": {
                "input": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "unsqueeze_116": {
                "input": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "tril_112": {
                "input": {
                    "value": "attn_weights.data.new([1]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "triu_116": {
                "input": {
                    "value": "attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/grad_multiply.py": {
        "torch": {}
    },
    "pretraining/fairseq/modules/highway.py": {
        "torch": {
            "ModuleList_27": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ReLU_29": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sigmoid_53": {
                "variable": {
                    "value": "gate",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "gate",
                    "type": "Name",
                    "possible_values": [
                        [
                            "F.sigmoid(gate)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_27": {
                "in_features": {
                    "value": "input_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/learned_positional_embedding.py": {
        "torch": {}
    },
    "pretraining/fairseq/modules/multihead_attention.py": {
        "torch": {
            "Parameter_32": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * self.embed_dim, self.input_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_37": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "bmm_166": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "Call",
                    "possible_values": [
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "padded_fwd_x[fwd_idxs] + padded_bwd_x[bwd_idxs]",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_180": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_181": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.mask(attn_weights).unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.repeat(1, 2).unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_183": {
                "variable": {
                    "value": "attn",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.mask(attn_weights).unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.repeat(1, 2).unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.in_proj_v(value)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, self.bias_v.repeat(1, bsz, 1)])",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "saved_state['prev_value']",
                            "Subscript"
                        ],
                        [
                            "torch.cat((saved_state['prev_value'], v), dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_259": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_264": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_290": {
                "variable": {
                    "value": "padded_fwd_x",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[fwd_x.new_zeros(1, bsz, embed_dim), fwd_x]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_291": {
                "variable": {
                    "value": "padded_bwd_x",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[bwd_x, bwd_x.new_zeros(1, bsz, embed_dim)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "arange_293": {
                "variable": {
                    "value": "fwd_idxs",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "tgt_len",
                    "type": "Variable",
                    "possible_values": []
                },
                "out": {
                    "value": "fwd_x.new().long()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_294": {
                "variable": {
                    "value": "bwd_idxs",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "end": {
                    "value": "tgt_len + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out": {
                    "value": "fwd_x.new().long()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_297": {
                "variable": {
                    "value": "kv",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[fwd_x, bwd_x]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "bmm_308": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "Call",
                    "possible_values": [
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "padded_fwd_x[fwd_idxs] + padded_bwd_x[bwd_idxs]",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_322": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_323": {
                "variable": {
                    "value": "attn_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.mask(attn_weights).unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.repeat(1, 2).unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_325": {
                "variable": {
                    "value": "attn",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "Call",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + self.mask(attn_weights).unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.repeat(1, 2).unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights.float(), dim=-1).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.in_proj_v(value)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, self.bias_v.repeat(1, bsz, 1)])",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "saved_state['prev_value']",
                            "Subscript"
                        ],
                        [
                            "torch.cat((saved_state['prev_value'], v), dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_34": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * self.embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_40": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, self.embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_41": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, self.embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_48": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_49": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_139": {
                "variable": {
                    "value": "k",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_140": {
                "variable": {
                    "value": "v",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_159": {
                "variable": {
                    "value": "k",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, k.new_zeros((k.size(0), 1) + k.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_160": {
                "variable": {
                    "value": "v",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, v.new_zeros((v.size(0), 1) + v.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "linear_218": {
                "input": {
                    "value": "input",
                    "type": "Variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[:end, :]",
                            "Subscript"
                        ],
                        [
                            "weight[start:, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Parameter_261": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_353": {
                "input": {
                    "value": "input",
                    "type": "Variable",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[:end, :]",
                            "Subscript"
                        ],
                        [
                            "weight[start:, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[:end]",
                            "Subscript"
                        ],
                        [
                            "bias[start:]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_142": {
                "variable": {
                    "value": "attn_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_144": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_162": {
                "variable": {
                    "value": "attn_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_164": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_126": {
                "variable": {
                    "value": "k",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(saved_state['prev_key'], k)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_131": {
                "variable": {
                    "value": "v",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(saved_state['prev_value'], v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/modules/scalar_bias.py": {
        "torch": {}
    },
    "pretraining/fairseq/modules/sinusoidal_positional_embedding.py": {
        "torch": {
            "exp_49": {
                "variable": {
                    "value": "emb",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(half_dim, dtype=torch.float) * -emb",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_51": {
                "variable": {
                    "value": "emb",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.sin(emb), torch.cos(emb)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_54": {
                "variable": {
                    "value": "emb",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[emb, torch.zeros(num_embeddings, 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_82": {
                "variable": {
                    "value": "embedding_shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(bsz.view(1), seq_len.view(1), torch.LongTensor([-1]))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "arange_50": {
                "start": {
                    "value": "num_embeddings",
                    "type": "Variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_50": {
                "input": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "arange_49": {
                "start": {
                    "value": "half_dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "embedding_dim // 2",
                            "BinOp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_54": {
                "*size": {
                    "value": "num_embeddings",
                    "type": "Variable",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sin_51": {
                "input": {
                    "value": "emb",
                    "type": "Call",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cos_51": {
                "input": {
                    "value": "emb",
                    "type": "Call",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/optim/adagrad.py": {
        "torch": {}
    },
    "pretraining/fairseq/optim/adam.py": {
        "torch": {
            "zeros_like_104": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_106": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_109": {
                "variable": {
                    "value": "state[max_exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "max_123": {
                "input": {
                    "value": "max_exp_avg_sq",
                    "type": "Name",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "max_exp_avg_sq",
                    "type": "Name",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/optim/bert_adam.py": {
        "torch": {
            "cos_56": {
                "input": {
                    "value": "math.pi * x",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_150": {
                "variable": {
                    "value": "state[next_m]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_152": {
                "variable": {
                    "value": "state[next_v]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__159": {
                "parameters": {
                    "value": "p",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/optim/fairseq_optimizer.py": {
        "torch": {
            "clip_grad_norm__86": {
                "parameters": {
                    "value": "self.params",
                    "type": "Attribute",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "max_norm",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/optim/fp16_optimizer.py": {
        "torch": {
            "Parameter_70": {
                "variable": {
                    "value": "fp32_params",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "fp32_params",
                    "type": "Call",
                    "possible_values": [
                        [
                            "params[0].new(0).float().new(total_param_size)",
                            "Call"
                        ],
                        [
                            "torch.nn.Parameter(fp32_params)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py": {
        "torch": {}
    },
    "pretraining/fairseq/optim/nag.py": {
        "torch": {}
    },
    "pretraining/fairseq/optim/sgd.py": {
        "torch": {}
    },
    "pretraining/fairseq/options.py": {
        "torch": {
            "device_count_177": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/tasks/span_bert.py": {
        "torch": {
            "ConcatDataset_189": {
                "variable": {
                    "value": "dataset",
                    "type": "Variable",
                    "possible_values": []
                },
                "datasets": {
                    "value": "loaded_datasets",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/fairseq/tokenizer.py": {
        "torch": {}
    },
    "pretraining/fairseq/trainer.py": {
        "torch": {
            "manual_seed_157": {
                "seed": {
                    "value": "seed",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "manual_seed_158": {
                "seed": {
                    "value": "seed",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "is_available_35": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_281": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "get_device_capability_98": {
                "device": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "get_device_capability_104": {
                "device": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "empty_cache_301": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/fairseq/utils.py": {
        "torch": {
            "load_67": {
                "variable": {
                    "value": "state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "filenames",
                            "Name"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "load_146": {
                "variable": {
                    "value": "state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "filenames",
                            "Name"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "load_152": {
                "variable": {
                    "value": "state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "model_arg_overrides['model_args_state']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "remainder_370": {
                "variable": {
                    "value": "index",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range - num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "Name",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "remainder_372": {
                "variable": {
                    "value": "index",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range + num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "Name",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_190": {
                "obj": {
                    "value": "maybe_tensor",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Tensor_275": {
                "variable": {
                    "value": "embed_dict[pieces[0]]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_334": {
                "start": {
                    "value": "padding_idx + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "end": {
                    "value": "max_pos",
                    "type": "Name",
                    "possible_values": [
                        [
                            "padding_idx + 1 + tensor.size(1)",
                            "BinOp"
                        ]
                    ]
                },
                "out": {
                    "value": "make_positions.range_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_350": {
                "start": {
                    "value": "max",
                    "type": "Variable",
                    "possible_values": []
                },
                "out": {
                    "value": "buffered_arange.buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "norm_385": {
                "input": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "save_21": {
                "obj": {
                    "value": "*args",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "is_tensor_35": {
                "obj": {
                    "value": "state_dict",
                    "type": "Name",
                    "possible_values": [
                        [
                            "{'args': args, 'model': model.state_dict() if model else {}, 'optimizer_history': optim_history + [{'criterion_name': criterion.__class__.__name__, 'optimizer_name': optimizer.__class__.__name__, 'lr_scheduler_state': lr_scheduler.state_dict(), 'num_updates': num_updates}], 'last_optimizer_state': convert_state_dict_type(optimizer.state_dict()), 'extra_state': extra_state}",
                            "Dict"
                        ]
                    ]
                }
            }
        }
    },
    "pretraining/multiprocessing_train.py": {
        "torch": {
            "device_count_21": {
                "variable": {
                    "value": "args.distributed_world_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "pretraining/train.py": {
        "torch": {
            "set_device_32": {
                "device": {
                    "value": "args.device_id",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_33": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}