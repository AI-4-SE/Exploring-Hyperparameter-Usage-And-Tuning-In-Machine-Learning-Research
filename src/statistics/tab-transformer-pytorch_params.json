{
    "tab_transformer_pytorch/tab_transformer_pytorch.py": {
        "torch": {
            "Residual_17": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.fn": {
                    "value": "fn",
                    "possible_values": []
                }
            },
            "PreNorm_25": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LayerNorm_28": {
                    "variable": {
                        "value": "self.norm",
                        "possible_values": []
                    },
                    "normalized_shape": {
                        "value": "dim",
                        "possible_values": []
                    }
                },
                "self.fn": {
                    "value": "fn",
                    "possible_values": []
                }
            },
            "GEGLU_36": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "FeedForward_41": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Sequential_44": {
                    "variable": {
                        "value": "self.net",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "nn.Linear(dim, dim * mult * 2)",
                        "possible_values": []
                    }
                }
            },
            "Attention_54": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.heads": {
                    "value": "heads",
                    "possible_values": [
                        [
                            "8",
                            "MethodArgument"
                        ]
                    ]
                },
                "Linear_67": {
                    "variable": {
                        "value": "self.to_qkv",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "inner_dim * 3",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "Linear_68": {
                    "variable": {
                        "value": "self.to_out",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "inner_dim",
                        "possible_values": [
                            [
                                "dim_head * heads",
                                "BinOp"
                            ]
                        ]
                    },
                    "out_features": {
                        "value": "dim",
                        "possible_values": []
                    }
                },
                "Dropout_70": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "dropout",
                        "possible_values": [
                            [
                                "0.0",
                                "MethodArgument"
                            ],
                            [
                                "0.0",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "Transformer_87": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_90": {
                    "variable": {
                        "value": "self.embeds",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "num_tokens",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "dim",
                        "possible_values": []
                    }
                },
                "ModuleList_91": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[]",
                        "possible_values": []
                    }
                }
            },
            "MLP_109": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Sequential_125": {
                    "variable": {
                        "value": "self.mlp",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "*layers",
                        "possible_values": []
                    }
                }
            },
            "TabTransformer_132": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_special_tokens": {
                    "value": "num_special_tokens",
                    "possible_values": [
                        [
                            "2",
                            "MethodArgument"
                        ]
                    ]
                },
                "pad_165": {
                    "variable": {
                        "value": "categories_offset",
                        "possible_values": []
                    },
                    "input": {
                        "value": "torch.tensor(list(categories))",
                        "possible_values": []
                    },
                    "pad": {
                        "value": "(1, 0)",
                        "possible_values": []
                    },
                    "value": {
                        "value": "num_special_tokens",
                        "possible_values": [
                            [
                                "2",
                                "MethodArgument"
                            ]
                        ]
                    }
                },
                "LayerNorm_175": {
                    "variable": {
                        "value": "self.norm",
                        "possible_values": []
                    },
                    "normalized_shape": {
                        "value": "num_continuous",
                        "possible_values": []
                    }
                },
                "self.num_continuous": {
                    "value": "num_continuous",
                    "possible_values": []
                }
            },
            "einsum_81": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "equation": {
                    "value": "b h i j, b h j d -> b h i d",
                    "possible_values": []
                },
                "*operands": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "sim.softmax(dim=-1)",
                            "Call"
                        ],
                        [
                            "self.dropout(attn)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_216": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(flat_categ, normed_cont)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_116": {
                "variable": {
                    "value": "linear",
                    "possible_values": []
                },
                "in_features": {
                    "value": "dim_in",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim_out",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "gelu_39": {
                "input": {
                    "value": "gates",
                    "possible_values": []
                }
            },
            "Linear_45": {
                "in_features": {
                    "value": "dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim * mult * 2",
                    "possible_values": []
                }
            },
            "Dropout_47": {
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.0",
                            "MethodArgument"
                        ],
                        [
                            "0.0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_48": {
                "in_features": {
                    "value": "dim * mult",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim",
                    "possible_values": []
                }
            },
            "einsum_76": {
                "equation": {
                    "value": "b h i d, b h j d -> b h i j",
                    "possible_values": []
                },
                "*operands": {
                    "value": "q",
                    "possible_values": []
                }
            },
            "tensor_165": {
                "data": {
                    "value": "list(categories)",
                    "possible_values": []
                }
            },
            "ModuleList_94": {
                "modules": {
                    "value": "[Residual(PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=attn_dropout))), Residual(PreNorm(dim, FeedForward(dim, dropout=ff_dropout)))]",
                    "possible_values": []
                }
            },
            "ReLU_122": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    }
}