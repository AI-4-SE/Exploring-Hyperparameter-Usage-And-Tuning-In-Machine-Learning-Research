{
    "Google-Landmark-Recognition-2020-3rd-Place-Solution/preprocess.py": {
        "sklearn": {
            "StratifiedKFold_13": {
                "variable": {
                    "value": "skf",
                    "possible_values": []
                },
                "n_splits": {
                    "value": "5",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "random_state": {
                    "value": "233",
                    "possible_values": []
                }
            }
        }
    },
    "Google-Landmark-Recognition-2020-3rd-Place-Solution/train.py": {
        "sklearn": {},
        "torch": {
            "DataLoader_166": {
                "variable": {
                    "value": "valid_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_valid",
                    "possible_values": [
                        [
                            "LandmarkDataset(df_valid, 'train', 'val', transform=transforms_val)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "DataParallel_172": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "ModelClass(args.enet_type, out_dim=out_dim)",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(model, device_ids=[1, 3]).to('cuda:1, 3')",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[1, 3]",
                    "possible_values": []
                }
            },
            "Adam_181": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "args.init_lr",
                    "possible_values": []
                }
            },
            "CosineAnnealingWarmRestarts_203": {
                "variable": {
                    "value": "scheduler_cosine",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "possible_values": [
                        [
                            "optim.Adam(model.parameters(), lr=args.init_lr)",
                            "Call"
                        ]
                    ]
                },
                "T_0": {
                    "value": "args.n_epochs - 1",
                    "possible_values": []
                }
            },
            "manual_seed_66": {
                "seed": {
                    "value": "seed",
                    "possible_values": [
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "manual_seed_67": {
                "seed": {
                    "value": "seed",
                    "possible_values": [
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "manual_seed_all_68": {
                "seed": {
                    "value": "seed",
                    "possible_values": [
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_123": {
                "variable": {
                    "value": "PRODS_M",
                    "possible_values": []
                },
                "tensors": {
                    "value": "PRODS_M",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(PRODS_M).numpy()",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_124": {
                "variable": {
                    "value": "PREDS_M",
                    "possible_values": []
                },
                "tensors": {
                    "value": "PREDS_M",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(PREDS_M).numpy()",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_125": {
                "variable": {
                    "value": "TARGETS",
                    "possible_values": []
                },
                "tensors": {
                    "value": "TARGETS",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(TARGETS)",
                            "Call"
                        ]
                    ]
                }
            },
            "set_device_138": {
                "device": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "load_186": {
                "variable": {
                    "value": "checkpoint",
                    "possible_values": []
                },
                "f": {
                    "value": "args.load_from",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage.cuda(3)",
                    "possible_values": []
                }
            },
            "DataLoader_212": {
                "variable": {
                    "value": "train_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset_train",
                    "possible_values": [
                        [
                            "LandmarkDataset(df_train, 'train', 'train', transform=transforms_train)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "save_237": {
                "obj": {
                    "value": "{'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(args.model_dir, f'{args.kernel_type}_fold{args.fold}_final.pth')",
                    "possible_values": []
                }
            },
            "no_grad_105": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "current_device_170": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "empty_cache_197": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "save_226": {
                "obj": {
                    "value": "{'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}",
                    "possible_values": []
                },
                "f": {
                    "value": "model_file",
                    "possible_values": [
                        [
                            "os.path.join(args.model_dir, f'{args.kernel_type}_fold{args.fold}.pth')",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "Google-Landmark-Recognition-2020-3rd-Place-Solution/dataset.py": {
        "torch": {
            "LandmarkDataset_10": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.split": {
                    "value": "split",
                    "possible_values": []
                },
                "self.mode": {
                    "value": "mode",
                    "possible_values": []
                },
                "self.transform": {
                    "value": "transform",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_34": {
                "data": {
                    "value": "image",
                    "possible_values": [
                        [
                            "cv2.imread(row.filepath)[:, :, ::-1]",
                            "Subscript"
                        ],
                        [
                            "res['image'].astype(np.float32)",
                            "Call"
                        ],
                        [
                            "image.astype(np.float32)",
                            "Call"
                        ],
                        [
                            "image.transpose(2, 0, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_36": {
                "data": {
                    "value": "row.landmark_id",
                    "possible_values": []
                }
            }
        }
    },
    "Google-Landmark-Recognition-2020-3rd-Place-Solution/models.py": {
        "torch": {
            "Swish_15": {
                "base_class_0": {
                    "value": "torch.autograd.Function",
                    "possible_values": []
                }
            },
            "Swish_module_30": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "CrossEntropyLossWithLabelSmoothing_35": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.n_dim": {
                    "value": "n_dim",
                    "possible_values": []
                },
                "self.ls_": {
                    "value": "ls_",
                    "possible_values": [
                        [
                            "0.9",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "DenseCrossEntropy_52": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "ArcMarginProduct_subcenter_63": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Parameter_66": {
                    "variable": {
                        "value": "self.weight",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.FloatTensor(out_features * k, in_features)",
                        "possible_values": []
                    }
                },
                "self.k": {
                    "value": "k",
                    "possible_values": [
                        [
                            "3",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.out_features": {
                    "value": "out_features",
                    "possible_values": []
                }
            },
            "ArcFaceLossAdaptiveMargin_82": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.s": {
                    "value": "s",
                    "possible_values": [
                        [
                            "30.0",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.margins": {
                    "value": "margins",
                    "possible_values": []
                }
            },
            "Effnet_Landmark_108": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_113": {
                    "variable": {
                        "value": "self.feat",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.enet.classifier.in_features",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "512",
                        "possible_values": []
                    }
                },
                "Identity_116": {
                    "variable": {
                        "value": "self.enet.classifier",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "RexNet20_Landmark_127": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_137": {
                    "variable": {
                        "value": "self.feat",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.enet.output[1].in_channels",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "512",
                        "possible_values": []
                    }
                },
                "Identity_140": {
                    "variable": {
                        "value": "self.enet.output",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "ResNest101_Landmark_151": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_156": {
                    "variable": {
                        "value": "self.feat",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.enet.fc.in_features",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "512",
                        "possible_values": []
                    }
                },
                "Identity_159": {
                    "variable": {
                        "value": "self.enet.fc",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "sigmoid_26": {
                "variable": {
                    "value": "sigmoid_i",
                    "possible_values": []
                },
                "input": {
                    "value": "i",
                    "possible_values": [
                        [
                            "ctx.saved_variables[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "one_hot_42": {
                "variable": {
                    "value": "target",
                    "possible_values": []
                },
                "tensor": {
                    "value": "target",
                    "possible_values": [
                        [
                            "F.one_hot(target, self.n_dim).float()",
                            "Call"
                        ],
                        [
                            "target + (1 - self.ls_) / self.n_dim",
                            "BinOp"
                        ],
                        [
                            "target.float()",
                            "Call"
                        ]
                    ]
                },
                "num_classes": {
                    "value": "self.n_dim",
                    "possible_values": []
                }
            },
            "log_softmax_46": {
                "variable": {
                    "value": "logprobs",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "x.float()",
                            "Call"
                        ],
                        [
                            "self.extract(x)",
                            "Call"
                        ],
                        [
                            "self.extract(x)",
                            "Call"
                        ],
                        [
                            "self.extract(x)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "log_softmax_56": {
                "variable": {
                    "value": "logprobs",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "x.float()",
                            "Call"
                        ],
                        [
                            "self.extract(x)",
                            "Call"
                        ],
                        [
                            "self.extract(x)",
                            "Call"
                        ],
                        [
                            "self.extract(x)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "linear_76": {
                "variable": {
                    "value": "cosine_all",
                    "possible_values": []
                },
                "input": {
                    "value": "F.normalize(features)",
                    "possible_values": []
                },
                "weight": {
                    "value": "F.normalize(self.weight)",
                    "possible_values": []
                }
            },
            "max_78": {
                "variable": {
                    "value": "(cosine, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "cosine_all",
                    "possible_values": [
                        [
                            "F.linear(F.normalize(features), F.normalize(self.weight))",
                            "Call"
                        ],
                        [
                            "cosine_all.view(-1, self.out_features, self.k)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "from_numpy_92": {
                "variable": {
                    "value": "cos_m",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.cos(ms)",
                    "possible_values": []
                }
            },
            "from_numpy_93": {
                "variable": {
                    "value": "sin_m",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.sin(ms)",
                    "possible_values": []
                }
            },
            "from_numpy_94": {
                "variable": {
                    "value": "th",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.cos(math.pi - ms)",
                    "possible_values": []
                }
            },
            "from_numpy_95": {
                "variable": {
                    "value": "mm",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.sin(math.pi - ms) * ms",
                    "possible_values": []
                }
            },
            "one_hot_96": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "tensor": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "F.one_hot(labels, out_dim).float()",
                            "Call"
                        ]
                    ]
                },
                "num_classes": {
                    "value": "out_dim",
                    "possible_values": []
                }
            },
            "sqrt_99": {
                "variable": {
                    "value": "sine",
                    "possible_values": []
                },
                "input": {
                    "value": "1.0 - torch.pow(cosine, 2)",
                    "possible_values": []
                }
            },
            "where_101": {
                "variable": {
                    "value": "phi",
                    "possible_values": []
                },
                "condition": {
                    "value": "cosine > th.view(-1, 1)",
                    "possible_values": []
                },
                "x": {
                    "value": "phi",
                    "possible_values": [
                        [
                            "cosine * cos_m.view(-1, 1) - sine * sin_m.view(-1, 1)",
                            "BinOp"
                        ],
                        [
                            "torch.where(cosine > th.view(-1, 1), phi, cosine - mm.view(-1, 1))",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "cosine - mm.view(-1, 1)",
                    "possible_values": []
                }
            },
            "load_134": {
                "variable": {
                    "value": "sd",
                    "possible_values": []
                },
                "f": {
                    "value": "pretrain_wts",
                    "possible_values": [
                        [
                            "'./weights/rexnetv1_2.0x.pth'",
                            "Constant"
                        ]
                    ]
                }
            },
            "sigmoid_19": {
                "input": {
                    "value": "i",
                    "possible_values": [
                        [
                            "ctx.saved_variables[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "normalize_76": {
                "input": {
                    "value": "self.weight",
                    "possible_values": []
                }
            },
            "pow_99": {
                "input": {
                    "value": "cosine",
                    "possible_values": [
                        [
                            "logits",
                            "Name"
                        ]
                    ]
                },
                "exponent": {
                    "value": "2",
                    "possible_values": []
                }
            }
        }
    },
    "Google-Landmark-Recognition-2020-3rd-Place-Solution/rexnetv1.py": {
        "torch": {
            "Swish_14": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Sigmoid_17": {
                    "variable": {
                        "value": "self.sigmoid",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "SE_37": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "AdaptiveAvgPool2d_40": {
                    "variable": {
                        "value": "self.avg_pool",
                        "possible_values": []
                    },
                    "output_size": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Sequential_41": {
                    "variable": {
                        "value": "self.fc",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "nn.Conv2d(in_channels, channels // se_ratio, kernel_size=1, padding=0)",
                        "possible_values": []
                    }
                }
            },
            "LinearBottleneck_55": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.in_channels": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "self.out_channels": {
                    "value": "channels",
                    "possible_values": []
                },
                "Sequential_79": {
                    "variable": {
                        "value": "self.out",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "*out",
                        "possible_values": []
                    }
                }
            },
            "ReXNetV1_89": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Sequential_139": {
                    "variable": {
                        "value": "self.features",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "*features",
                        "possible_values": []
                    }
                },
                "Sequential_140": {
                    "variable": {
                        "value": "self.output",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "nn.Dropout(dropout_ratio)",
                        "possible_values": []
                    }
                }
            },
            "Conv2d_25": {
                "in_channels": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "channels",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "pad",
                    "possible_values": [
                        [
                            "0",
                            "MethodArgument"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "groups": {
                    "value": "num_group",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "BatchNorm2d_26": {
                "num_features": {
                    "value": "channels",
                    "possible_values": []
                }
            },
            "Conv2d_32": {
                "in_channels": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "channels",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "pad",
                    "possible_values": [
                        [
                            "0",
                            "MethodArgument"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ]
                    ]
                },
                "groups": {
                    "value": "num_group",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "BatchNorm2d_33": {
                "num_features": {
                    "value": "channels",
                    "possible_values": []
                }
            },
            "Conv2d_42": {
                "in_channels": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "channels // se_ratio",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "BatchNorm2d_43": {
                "num_features": {
                    "value": "channels // se_ratio",
                    "possible_values": []
                }
            },
            "ReLU_44": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Conv2d_45": {
                "in_channels": {
                    "value": "channels // se_ratio",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "channels",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Sigmoid_46": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ReLU6_77": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_138": {
                "output_size": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Dropout_141": {
                "p": {
                    "value": "dropout_ratio",
                    "possible_values": [
                        [
                            "0.2",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Conv2d_142": {
                "in_channels": {
                    "value": "pen_channels",
                    "possible_values": [
                        [
                            "int(1280 * width_mult)",
                            "Call"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "classes",
                    "possible_values": [
                        [
                            "1000",
                            "MethodArgument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "ReLU6_28": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "ReLU_28": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    }
}