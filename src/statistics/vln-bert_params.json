{
    "scripts/matterport3D-updown-features/precompute_updown_img_features.py": {
        "sklearn": {
            "pairwise_distances_224": {
                "variable": {
                    "value": "feat_dist",
                    "possible_values": []
                },
                "X": {
                    "value": "record['features']",
                    "possible_values": []
                },
                "metric": {
                    "value": "cosine",
                    "possible_values": []
                }
            },
            "pairwise_distances_226": {
                "variable": {
                    "value": "heading_diff",
                    "possible_values": []
                },
                "X": {
                    "value": "record['featureHeading']",
                    "possible_values": []
                },
                "metric": {
                    "value": "euclidean",
                    "possible_values": []
                }
            },
            "pairwise_distances_228": {
                "variable": {
                    "value": "elevation_diff",
                    "possible_values": []
                },
                "X": {
                    "value": "record['featureElevation']",
                    "possible_values": []
                },
                "metric": {
                    "value": "euclidean",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert/vilbert.py": {
        "tensorflow": {
            "list_variables_65": {
                "variable": {
                    "value": "init_vars",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "tf_path",
                    "possible_values": [
                        [
                            "os.path.abspath(tf_checkpoint_path)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_variable_70": {
                "variable": {
                    "value": "array",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "tf_path",
                    "possible_values": [
                        [
                            "os.path.abspath(tf_checkpoint_path)",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "name",
                    "possible_values": [
                        [
                            "name.split('/')",
                            "Call"
                        ]
                    ]
                }
            }
        },
        "torch": {
            "BertEmbeddings_295": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_301": {
                    "variable": {
                        "value": "self.word_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "config.vocab_size",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "padding_idx": {
                        "value": "0",
                        "possible_values": []
                    }
                },
                "Embedding_304": {
                    "variable": {
                        "value": "self.position_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "config.max_position_embeddings",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                },
                "Embedding_307": {
                    "variable": {
                        "value": "self.token_type_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "config.type_vocab_size",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_314": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertSelfAttention_334": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_346": {
                    "variable": {
                        "value": "self.query",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_347": {
                    "variable": {
                        "value": "self.key",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_348": {
                    "variable": {
                        "value": "self.value",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Dropout_350": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.attention_probs_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertSelfOutput_390": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_393": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_395": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertAttention_404": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BertIntermediate_416": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_419": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.intermediate_size",
                        "possible_values": []
                    }
                }
            },
            "BertOutput_433": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_436": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.intermediate_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_438": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertLayer_447": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BertImageSelfAttention_461": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_475": {
                    "variable": {
                        "value": "self.query",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_476": {
                    "variable": {
                        "value": "self.key",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_477": {
                    "variable": {
                        "value": "self.value",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Dropout_479": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.v_attention_probs_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertImageSelfOutput_518": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_521": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_523": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.v_hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertImageAttention_531": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BertImageIntermediate_543": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_546": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_intermediate_size",
                        "possible_values": []
                    }
                }
            },
            "BertImageOutput_560": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_563": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_intermediate_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_565": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.v_hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertImageLayer_574": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BertBiAttention_588": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_606": {
                    "variable": {
                        "value": "self.query1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_607": {
                    "variable": {
                        "value": "self.key1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_608": {
                    "variable": {
                        "value": "self.value1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Dropout_611": {
                    "variable": {
                        "value": "self.dropout1",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.v_attention_probs_dropout_prob",
                        "possible_values": []
                    }
                },
                "Linear_613": {
                    "variable": {
                        "value": "self.query2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_614": {
                    "variable": {
                        "value": "self.key2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Linear_615": {
                    "variable": {
                        "value": "self.value2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.all_head_size",
                        "possible_values": []
                    }
                },
                "Dropout_618": {
                    "variable": {
                        "value": "self.dropout2",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.attention_probs_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertBiOutput_696": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_700": {
                    "variable": {
                        "value": "self.dense1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_702": {
                    "variable": {
                        "value": "self.dropout1",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.v_hidden_dropout_prob",
                        "possible_values": []
                    }
                },
                "Linear_704": {
                    "variable": {
                        "value": "self.q_dense1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_705": {
                    "variable": {
                        "value": "self.q_dropout1",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.v_hidden_dropout_prob",
                        "possible_values": []
                    }
                },
                "Linear_707": {
                    "variable": {
                        "value": "self.dense2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_709": {
                    "variable": {
                        "value": "self.dropout2",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.hidden_dropout_prob",
                        "possible_values": []
                    }
                },
                "Linear_711": {
                    "variable": {
                        "value": "self.q_dense2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_712": {
                    "variable": {
                        "value": "self.q_dropout2",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "BertConnectionLayer_728": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BertEncoder_757": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_778": {
                    "variable": {
                        "value": "self.layer",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                        "possible_values": []
                    }
                },
                "ModuleList_781": {
                    "variable": {
                        "value": "self.v_layer",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[copy.deepcopy(v_layer) for _ in range(config.v_num_hidden_layers)]",
                        "possible_values": []
                    }
                },
                "ModuleList_784": {
                    "variable": {
                        "value": "self.c_layer",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[copy.deepcopy(connect_layer) for _ in range(len(config.v_biattention_id))]",
                        "possible_values": []
                    }
                }
            },
            "BertTextPooler_897": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_900": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    }
                },
                "ReLU_901": {
                    "variable": {
                        "value": "self.activation",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "BertImagePooler_912": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_915": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    }
                },
                "ReLU_916": {
                    "variable": {
                        "value": "self.activation",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "BertPredictionHeadTransform_927": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_930": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    }
                }
            },
            "BertImgPredictionHeadTransform_946": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_949": {
                    "variable": {
                        "value": "self.dense",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                }
            },
            "BertLMPredictionHead_965": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_972": {
                    "variable": {
                        "value": "self.decoder",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "bert_model_embedding_weights.size(1)",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "bert_model_embedding_weights.size(0)",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "False",
                        "possible_values": []
                    }
                },
                "self.decoder.weight": {
                    "value": "bert_model_embedding_weights",
                    "possible_values": []
                },
                "Parameter_978": {
                    "variable": {
                        "value": "self.bias",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                        "possible_values": []
                    }
                }
            },
            "BertOnlyMLMHead_986": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "BertOnlyNSPHead_996": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_999": {
                    "variable": {
                        "value": "self.seq_relationship",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "2",
                        "possible_values": []
                    }
                }
            },
            "BertPreTrainingHeads_1006": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_1010": {
                    "variable": {
                        "value": "self.bi_seq_relationship",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.bi_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "2",
                        "possible_values": []
                    }
                },
                "Dropout_1013": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "0.1",
                        "possible_values": []
                    }
                }
            },
            "BertImagePredictionHead_1033": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_1040": {
                    "variable": {
                        "value": "self.decoder",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_target_size",
                        "possible_values": []
                    }
                }
            },
            "BertPreTrainedModel_1048": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.config": {
                    "value": "config",
                    "possible_values": [
                        [
                            "BertConfig(vocab_size_or_config_json_file=-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "BertImageEmbeddings_1397": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_1403": {
                    "variable": {
                        "value": "self.image_embeddings",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "config.v_feature_size",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Linear_1404": {
                    "variable": {
                        "value": "self.image_location_embeddings",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "5",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Linear_1406": {
                    "variable": {
                        "value": "self.image_orientation_embeddings",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "4",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Linear_1407": {
                    "variable": {
                        "value": "self.image_next_orientation_embeddings",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Embedding_1408": {
                    "variable": {
                        "value": "self.image_sequence_embeddings",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "32",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "config.v_hidden_size",
                        "possible_values": []
                    }
                },
                "Dropout_1411": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "config.hidden_dropout_prob",
                        "possible_values": []
                    }
                }
            },
            "SimpleClassifier_1579": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Sequential_1588": {
                    "variable": {
                        "value": "self.main",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "*layers",
                        "possible_values": []
                    }
                }
            },
            "from_numpy_108": {
                "variable": {
                    "value": "pointer.data",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "array",
                    "possible_values": [
                        [
                            "tf.train.load_variable(tf_path, name)",
                            "Call"
                        ],
                        [
                            "np.transpose(array)",
                            "Call"
                        ]
                    ]
                }
            },
            "BertLayerNorm_280": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Parameter_285": {
                    "variable": {
                        "value": "self.weight",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.ones(hidden_size)",
                        "possible_values": []
                    }
                },
                "Parameter_286": {
                    "variable": {
                        "value": "self.bias",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(hidden_size)",
                        "possible_values": []
                    }
                },
                "self.variance_epsilon": {
                    "value": "eps",
                    "possible_values": [
                        [
                            "1e-12",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "arange_318": {
                "variable": {
                    "value": "position_ids",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "possible_values": []
                }
            },
            "matmul_370": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "matmul_382": {
                "variable": {
                    "value": "context_layer",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_499": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "matmul_511": {
                "variable": {
                    "value": "context_layer",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_653": {
                "variable": {
                    "value": "attention_scores1",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer2",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer1.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "matmul_667": {
                "variable": {
                    "value": "context_layer1",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs1",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores1)",
                            "Call"
                        ],
                        [
                            "self.dropout1(attention_probs1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer1",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer1)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_673": {
                "variable": {
                    "value": "attention_scores2",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer1",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer2.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "matmul_689": {
                "variable": {
                    "value": "context_layer2",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs2",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores2)",
                            "Call"
                        ],
                        [
                            "self.dropout2(attention_probs2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer2",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer2)",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_1444": {
                "variable": {
                    "value": "self.loss_fct",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_1519": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_prob",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_1525": {
                "variable": {
                    "value": "self.vil_logit",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_1526": {
                "variable": {
                    "value": "self.vision_logit",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_1527": {
                "variable": {
                    "value": "self.linguisic_logit",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sigmoid_122": {
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_323": {
                "variable": {
                    "value": "token_type_ids",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "possible_values": []
                }
            },
            "load_1176": {
                "variable": {
                    "value": "state_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, TF_WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "ones_like_1329": {
                "variable": {
                    "value": "attention_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "input_txt",
                    "possible_values": []
                }
            },
            "zeros_like_1331": {
                "variable": {
                    "value": "token_type_ids",
                    "possible_values": []
                },
                "input": {
                    "value": "input_txt",
                    "possible_values": []
                }
            },
            "ones_1333": {
                "variable": {
                    "value": "image_attention_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_imgs.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "input_imgs.size(1)",
                    "possible_values": []
                }
            },
            "zeros_1361": {
                "variable": {
                    "value": "co_attention_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_txt.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "input_imgs.size(1)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "input_txt.size(1)",
                    "possible_values": []
                }
            },
            "MSELoss_1449": {
                "variable": {
                    "value": "self.vis_criterion",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "KLDivLoss_1451": {
                "variable": {
                    "value": "self.vis_criterion",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "erf_118": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "possible_values": []
                }
            },
            "Softmax_376": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Softmax_505": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Softmax_661": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Softmax_683": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_978": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "possible_values": []
                }
            },
            "weight_norm_1583": {
                "module": {
                    "value": "nn.Linear(in_dim, hid_dim)",
                    "possible_values": []
                },
                "dim": {
                    "value": "None",
                    "possible_values": []
                }
            },
            "ReLU_1584": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_1585": {
                "p": {
                    "value": "dropout",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "weight_norm_1586": {
                "module": {
                    "value": "nn.Linear(hid_dim, out_dim)",
                    "possible_values": []
                },
                "dim": {
                    "value": "None",
                    "possible_values": []
                }
            },
            "Linear_1583": {
                "in_features": {
                    "value": "in_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hid_dim",
                    "possible_values": []
                }
            },
            "Linear_1586": {
                "in_features": {
                    "value": "hid_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_dim",
                    "possible_values": []
                }
            },
            "ones_285": {
                "*size": {
                    "value": "hidden_size",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_286": {
                "*size": {
                    "value": "hidden_size",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sqrt_292": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "possible_values": []
                }
            },
            "no_grad_822": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_836": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_1489": {
                "input": {
                    "value": "img_loss * (image_label == 1).unsqueeze(2).float()",
                    "possible_values": []
                }
            },
            "log_softmax_1495": {
                "input": {
                    "value": "prediction_scores_v",
                    "possible_values": [
                        [
                            "self.imagePredictions(sequence_output_v)",
                            "Call"
                        ],
                        [
                            "prediction_scores_v[:, 1:]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "sum_1497": {
                "input": {
                    "value": "img_loss * (image_label == 1).unsqueeze(2).float()",
                    "possible_values": []
                }
            },
            "sum_1491": {
                "input": {
                    "value": "(image_label == 1).unsqueeze(2).expand_as(img_loss)",
                    "possible_values": []
                }
            },
            "sum_1499": {
                "input": {
                    "value": "image_label == 1",
                    "possible_values": []
                }
            }
        }
    },
    "test.py": {
        "torch": {
            "DataLoader_79": {
                "variable": {
                    "value": "data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path=f'data/task/R2R_{args.split}.json', beam_path=f'data/beamsearch/beams_{args.split}.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=False, training=False, masked_vision=False, masked_language=False, default_gpu=True)",
                            "Call"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "no_grad_100": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "train.py": {
        "torch": {
            "DataLoader_190": {
                "variable": {
                    "value": "train_data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "possible_values": [
                        [
                            "TrainDataset(vln_path=vln_path, beam_path=beam_path, tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=4, num_beams_strict=False, training=True, masked_vision=args.masked_vision, masked_language=args.masked_language, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(train_dataset, np.random.choice(range(len(train_dataset)), size=128, replace=False))",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "RandomSampler(train_dataset)",
                            "Call"
                        ],
                        [
                            "DistributedSampler(train_dataset)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "args.batch_size // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "batch_size // dist.get_world_size()",
                            "BinOp"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "DataLoader_197": {
                "variable": {
                    "value": "val_seen_data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_seen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_seen.json', beam_path='data/beamsearch/beams_val_seen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_seen_dataset, np.random.choice(range(len(val_seen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_seen_sampler",
                    "possible_values": [
                        [
                            "SequentialSampler(val_seen_dataset)",
                            "Call"
                        ],
                        [
                            "DistributedSampler(val_seen_dataset)",
                            "Call"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "args.batch_size // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "batch_size // dist.get_world_size()",
                            "BinOp"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "DataLoader_205": {
                "variable": {
                    "value": "val_unseen_data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_unseen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_unseen.json', beam_path='data/beamsearch/beams_val_unseen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_unseen_dataset, np.random.choice(range(len(val_unseen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_unseen_sampler",
                    "possible_values": [
                        [
                            "SequentialSampler(val_unseen_dataset)",
                            "Call"
                        ],
                        [
                            "DistributedSampler(val_unseen_dataset)",
                            "Call"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "args.batch_size // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "batch_size // dist.get_world_size()",
                            "BinOp"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "args.num_workers",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "zeros_507": {
                "variable": {
                    "value": "stats",
                    "possible_values": []
                },
                "*size": {
                    "value": "3",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda', args.local_rank)",
                            "Call"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "device_67": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "device_count_68": {
                "variable": {
                    "value": "n_gpu",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "device_73": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "possible_values": []
                }
            },
            "Subset_160": {
                "variable": {
                    "value": "train_dataset",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "possible_values": [
                        [
                            "TrainDataset(vln_path=vln_path, beam_path=beam_path, tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=4, num_beams_strict=False, training=True, masked_vision=args.masked_vision, masked_language=args.masked_language, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(train_dataset, np.random.choice(range(len(train_dataset)), size=128, replace=False))",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "np.random.choice(range(len(train_dataset)), size=128, replace=False)",
                    "possible_values": []
                }
            },
            "Subset_164": {
                "variable": {
                    "value": "val_seen_dataset",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_seen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_seen.json', beam_path='data/beamsearch/beams_val_seen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_seen_dataset, np.random.choice(range(len(val_seen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "np.random.choice(range(len(val_seen_dataset)), size=64, replace=False)",
                    "possible_values": []
                }
            },
            "Subset_168": {
                "variable": {
                    "value": "val_unseen_dataset",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_unseen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_unseen.json', beam_path='data/beamsearch/beams_val_unseen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_unseen_dataset, np.random.choice(range(len(val_unseen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "np.random.choice(range(len(val_unseen_dataset)), size=64, replace=False)",
                    "possible_values": []
                }
            },
            "RandomSampler_174": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_dataset",
                    "possible_values": [
                        [
                            "TrainDataset(vln_path=vln_path, beam_path=beam_path, tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=4, num_beams_strict=False, training=True, masked_vision=args.masked_vision, masked_language=args.masked_language, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(train_dataset, np.random.choice(range(len(train_dataset)), size=128, replace=False))",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_175": {
                "variable": {
                    "value": "val_seen_sampler",
                    "possible_values": []
                },
                "data_source": {
                    "value": "val_seen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_seen.json', beam_path='data/beamsearch/beams_val_seen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_seen_dataset, np.random.choice(range(len(val_seen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_176": {
                "variable": {
                    "value": "val_unseen_sampler",
                    "possible_values": []
                },
                "data_source": {
                    "value": "val_unseen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_unseen.json', beam_path='data/beamsearch/beams_val_unseen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_unseen_dataset, np.random.choice(range(len(val_unseen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_178": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "possible_values": [
                        [
                            "TrainDataset(vln_path=vln_path, beam_path=beam_path, tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=4, num_beams_strict=False, training=True, masked_vision=args.masked_vision, masked_language=args.masked_language, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(train_dataset, np.random.choice(range(len(train_dataset)), size=128, replace=False))",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_179": {
                "variable": {
                    "value": "val_seen_sampler",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_seen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_seen.json', beam_path='data/beamsearch/beams_val_seen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_seen_dataset, np.random.choice(range(len(val_seen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_180": {
                "variable": {
                    "value": "val_unseen_sampler",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_unseen_dataset",
                    "possible_values": [
                        [
                            "BeamDataset(vln_path='data/task/R2R_val_unseen.json', beam_path='data/beamsearch/beams_val_unseen.json', tokenizer=tokenizer, pano_features_reader=features_reader, max_instruction_length=args.max_instruction_length, max_path_length=args.max_path_length, max_num_boxes=args.max_num_boxes, num_beams=args.num_beams, num_beams_strict=True, training=False, masked_vision=False, masked_language=False, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "Subset(val_unseen_dataset, np.random.choice(range(len(val_unseen_dataset)), size=64, replace=False))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_410": {
                "variable": {
                    "value": "vision_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda', args.local_rank)",
                            "Call"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tensor_421": {
                "variable": {
                    "value": "linguistic_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda', args.local_rank)",
                            "Call"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tensor_428": {
                "variable": {
                    "value": "ranking_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda', args.local_rank)",
                            "Call"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "sum_445": {
                "variable": {
                    "value": "correct",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.argmax(vil_logit, 1) == target",
                    "possible_values": []
                }
            },
            "tensor_453": {
                "variable": {
                    "value": "reduced_batch_size",
                    "possible_values": []
                },
                "data": {
                    "value": "batch_size",
                    "possible_values": [
                        [
                            "args.batch_size // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "batch_size // dist.get_world_size()",
                            "BinOp"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ],
                        [
                            "get_batch_size(batch)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda', args.local_rank)",
                            "Call"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ],
                        [
                            "next(model.parameters()).device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "binary_cross_entropy_with_logits_520": {
                "variable": {
                    "value": "loss",
                    "possible_values": []
                },
                "input": {
                    "value": "vil_logit",
                    "possible_values": [
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target.float()",
                    "possible_values": []
                }
            },
            "sum_523": {
                "variable": {
                    "value": "correct",
                    "possible_values": []
                },
                "input": {
                    "value": "target.gather(1, torch.argmax(vil_logit, 1).view(-1, 1))",
                    "possible_values": []
                }
            },
            "manual_seed_61": {
                "seed": {
                    "value": "seed",
                    "possible_values": [
                        [
                            "args.seed",
                            "Attribute"
                        ],
                        [
                            "seed + args.local_rank",
                            "BinOp"
                        ]
                    ]
                }
            },
            "set_device_72": {
                "device": {
                    "value": "args.local_rank",
                    "possible_values": []
                }
            },
            "DataParallel_238": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "VLNBert(config)",
                            "Call"
                        ],
                        [
                            "VLNBert.from_pretrained(args.from_pretrained, config, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "DDP(model, delay_allreduce=True)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "kl_div_412": {
                "variable": {
                    "value": "vision_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "F.log_softmax(vision_predictions, dim=-1)",
                    "possible_values": []
                },
                "target": {
                    "value": "vision_target",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "cross_entropy_423": {
                "variable": {
                    "value": "linguistic_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "linguistic_predictions",
                    "possible_values": [
                        [
                            "output[2].view(-1, output[2].shape[-1])",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "linguistic_target",
                    "possible_values": [
                        [
                            "get_linguistic_target(batch)",
                            "Call"
                        ]
                    ]
                },
                "ignore_index": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cross_entropy_430": {
                "variable": {
                    "value": "ranking_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "vil_logit",
                    "possible_values": [
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "possible_values": [
                        [
                            "get_target(batch)",
                            "Call"
                        ],
                        [
                            "get_target(batch)",
                            "Call"
                        ]
                    ]
                },
                "ignore_index": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "save_322": {
                "obj": {
                    "value": "model_state",
                    "possible_values": [
                        [
                            "model.module.state_dict() if hasattr(model, 'module') else model.state_dict()",
                            "IfExp"
                        ]
                    ]
                },
                "f": {
                    "value": "model_path",
                    "possible_values": [
                        [
                            "os.path.join(save_folder, f'pytorch_model_{epoch + 1}.bin')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_67": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_329": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_355": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "log_softmax_413": {
                "input": {
                    "value": "vision_predictions",
                    "possible_values": [
                        [
                            "output[1].view(-1, output[1].shape[2])",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "sum_418": {
                "input": {
                    "value": "vision_target_mask",
                    "possible_values": []
                }
            },
            "argmax_445": {
                "input": {
                    "value": "vil_logit",
                    "possible_values": [
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                }
            },
            "argmax_524": {
                "input": {
                    "value": "vil_logit",
                    "possible_values": [
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "output[0].view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "utils/dataset/beam_dataset.py": {
        "torch": {
            "BeamDataset_26": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self._tokenizer": {
                    "value": "tokenizer",
                    "possible_values": []
                },
                "self._pano_features_reader": {
                    "value": "pano_features_reader",
                    "possible_values": []
                },
                "self._max_instruction_length": {
                    "value": "max_instruction_length",
                    "possible_values": []
                },
                "self._max_path_length": {
                    "value": "max_path_length",
                    "possible_values": []
                },
                "self._max_num_boxes": {
                    "value": "max_num_boxes",
                    "possible_values": []
                },
                "self._training": {
                    "value": "training",
                    "possible_values": []
                },
                "self._masked_vision": {
                    "value": "masked_vision",
                    "possible_values": []
                },
                "self._masked_language": {
                    "value": "masked_language",
                    "possible_values": []
                }
            },
            "tensor_168": {
                "variable": {
                    "value": "image_features",
                    "possible_values": []
                },
                "data": {
                    "value": "features",
                    "possible_values": []
                }
            },
            "tensor_169": {
                "variable": {
                    "value": "image_boxes",
                    "possible_values": []
                },
                "data": {
                    "value": "boxes",
                    "possible_values": []
                }
            },
            "tensor_170": {
                "variable": {
                    "value": "image_probs",
                    "possible_values": []
                },
                "data": {
                    "value": "probs",
                    "possible_values": []
                }
            },
            "tensor_171": {
                "variable": {
                    "value": "image_masks",
                    "possible_values": []
                },
                "data": {
                    "value": "masks",
                    "possible_values": []
                }
            },
            "tensor_172": {
                "variable": {
                    "value": "instr_tokens",
                    "possible_values": []
                },
                "data": {
                    "value": "[instr_tokens] * len(features)",
                    "possible_values": []
                }
            },
            "tensor_173": {
                "variable": {
                    "value": "instr_mask",
                    "possible_values": []
                },
                "data": {
                    "value": "[instr_mask] * len(features)",
                    "possible_values": []
                }
            },
            "tensor_174": {
                "variable": {
                    "value": "segment_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[segment_ids] * len(features)",
                    "possible_values": []
                }
            },
            "tensor_194": {
                "variable": {
                    "value": "target",
                    "possible_values": []
                },
                "data": {
                    "value": "target",
                    "possible_values": [
                        [
                            "success",
                            "Name"
                        ],
                        [
                            "-1",
                            "UnaryOp"
                        ],
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "torch.tensor(target).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_197": {
                "variable": {
                    "value": "co_attention_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "2",
                    "possible_values": []
                },
                "out": {
                    "value": "self._max_path_length * self._max_num_boxes",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self._max_instruction_length",
                    "possible_values": []
                }
            },
            "tensor_200": {
                "variable": {
                    "value": "instr_id",
                    "possible_values": []
                },
                "data": {
                    "value": "[path_id, instruction_index]",
                    "possible_values": []
                }
            },
            "zeros_like_183": {
                "variable": {
                    "value": "image_targets_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "image_masks",
                    "possible_values": [
                        [
                            "torch.tensor(masks).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_182": {
                "input": {
                    "value": "image_probs",
                    "possible_values": [
                        [
                            "torch.tensor(probs).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_191": {
                "input": {
                    "value": "instr_tokens",
                    "possible_values": [
                        [
                            "self._vln_data[vln_index]['instruction_tokens'][instruction_index]",
                            "Subscript"
                        ],
                        [
                            "torch.tensor([instr_tokens] * len(features)).long()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "utils/dataset/common.py": {
        "torch": {
            "randint_like_116": {
                "variable": {
                    "value": "random_tokens",
                    "possible_values": []
                },
                "input": {
                    "value": "tokens",
                    "possible_values": [
                        [
                            "tokenizer.tokenize(instruction)",
                            "Call"
                        ],
                        [
                            "['[CLS]'] + tokens + ['[SEP]']",
                            "BinOp"
                        ],
                        [
                            "[tokenizer.vocab[token] for token in tokens]",
                            "ListComp"
                        ],
                        [
                            "tokens[:max_instruction_length]",
                            "Subscript"
                        ],
                        [
                            "tokens + [pad_token] * pad_length",
                            "BinOp"
                        ]
                    ]
                },
                "low": {
                    "value": "len(tokenizer.vocab)",
                    "possible_values": []
                }
            },
            "zeros_like_153": {
                "variable": {
                    "value": "targets_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "mask",
                    "possible_values": []
                }
            },
            "ones_like_112": {
                "input": {
                    "value": "tokens",
                    "possible_values": [
                        [
                            "tokenizer.tokenize(instruction)",
                            "Call"
                        ],
                        [
                            "['[CLS]'] + tokens + ['[SEP]']",
                            "BinOp"
                        ],
                        [
                            "[tokenizer.vocab[token] for token in tokens]",
                            "ListComp"
                        ],
                        [
                            "tokens[:max_instruction_length]",
                            "Subscript"
                        ],
                        [
                            "tokens + [pad_token] * pad_length",
                            "BinOp"
                        ]
                    ]
                }
            },
            "rand_like_115": {
                "input": {
                    "value": "tokens.float()",
                    "possible_values": []
                }
            },
            "ones_like_152": {
                "input": {
                    "value": "probs",
                    "possible_values": []
                }
            },
            "rand_like_155": {
                "input": {
                    "value": "mask.float()",
                    "possible_values": []
                }
            }
        }
    },
    "utils/dataset/trajectory_dataset.py": {
        "torch": {
            "TrajectoryDataset_23": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self._pano_features_reader": {
                    "value": "pano_features_reader",
                    "possible_values": []
                },
                "self._max_instruction_length": {
                    "value": "max_instruction_length",
                    "possible_values": []
                },
                "self._max_path_length": {
                    "value": "max_path_length",
                    "possible_values": []
                },
                "self._max_num_boxes": {
                    "value": "max_num_boxes",
                    "possible_values": []
                }
            },
            "tensor_135": {
                "variable": {
                    "value": "image_features",
                    "possible_values": []
                },
                "data": {
                    "value": "[gt_features, lang_features, easy_features, hard_features]",
                    "possible_values": []
                }
            },
            "tensor_138": {
                "variable": {
                    "value": "image_boxes",
                    "possible_values": []
                },
                "data": {
                    "value": "[gt_boxes, lang_boxes, easy_boxes, hard_boxes]",
                    "possible_values": []
                }
            },
            "tensor_141": {
                "variable": {
                    "value": "image_masks",
                    "possible_values": []
                },
                "data": {
                    "value": "[gt_masks, lang_masks, easy_masks, hard_masks]",
                    "possible_values": []
                }
            },
            "tensor_144": {
                "variable": {
                    "value": "instr_tokens",
                    "possible_values": []
                },
                "data": {
                    "value": "[gt_instr_tokens, lang_instr_tokens, easy_instr_tokens, hard_instr_tokens]",
                    "possible_values": []
                }
            },
            "tensor_147": {
                "variable": {
                    "value": "instr_mask",
                    "possible_values": []
                },
                "data": {
                    "value": "[gt_instr_mask, lang_instr_mask, easy_instr_mask, hard_instr_mask]",
                    "possible_values": []
                }
            },
            "tensor_150": {
                "variable": {
                    "value": "segment_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[gt_segment_ids, lang_segment_ids, easy_segment_ids, hard_segment_ids]",
                    "possible_values": []
                }
            },
            "tensor_163": {
                "variable": {
                    "value": "target",
                    "possible_values": []
                },
                "data": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_166": {
                "variable": {
                    "value": "co_attention_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "2",
                    "possible_values": []
                },
                "out": {
                    "value": "self._max_path_length * self._max_num_boxes",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self._max_instruction_length",
                    "possible_values": []
                }
            },
            "tensor_169": {
                "variable": {
                    "value": "path_id",
                    "possible_values": []
                },
                "data": {
                    "value": "self._data[data_index]['path_id']",
                    "possible_values": []
                }
            },
            "ones_like_160": {
                "input": {
                    "value": "instr_tokens",
                    "possible_values": [
                        [
                            "torch.tensor([gt_instr_tokens, lang_instr_tokens, easy_instr_tokens, hard_instr_tokens]).long()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "vilbert/optimization.py": {
        "torch": {
            "ConstantLRSchedule_26": {
                "base_class_0": {
                    "value": "torch.optim.lr_scheduler.LambdaLR",
                    "possible_values": []
                }
            },
            "WarmupConstantSchedule_33": {
                "base_class_0": {
                    "value": "torch.optim.lr_scheduler.LambdaLR",
                    "possible_values": []
                },
                "self.warmup_steps": {
                    "value": "warmup_steps",
                    "possible_values": []
                }
            },
            "WarmupLinearSchedule_48": {
                "base_class_0": {
                    "value": "torch.optim.lr_scheduler.LambdaLR",
                    "possible_values": []
                },
                "self.warmup_steps": {
                    "value": "warmup_steps",
                    "possible_values": []
                },
                "self.t_total": {
                    "value": "t_total",
                    "possible_values": []
                }
            },
            "WarmupCosineSchedule_64": {
                "base_class_0": {
                    "value": "torch.optim.lr_scheduler.LambdaLR",
                    "possible_values": []
                },
                "self.warmup_steps": {
                    "value": "warmup_steps",
                    "possible_values": []
                },
                "self.t_total": {
                    "value": "t_total",
                    "possible_values": []
                },
                "self.cycles": {
                    "value": "cycles",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ],
                        [
                            "1.0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "WarmupCosineWithHardRestartsSchedule_84": {
                "base_class_0": {
                    "value": "torch.optim.lr_scheduler.LambdaLR",
                    "possible_values": []
                },
                "self.warmup_steps": {
                    "value": "warmup_steps",
                    "possible_values": []
                },
                "self.t_total": {
                    "value": "t_total",
                    "possible_values": []
                },
                "self.cycles": {
                    "value": "cycles",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ],
                        [
                            "1.0",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "AdamW_107": {
                "base_class_0": {
                    "value": "torch.optim.Optimizer",
                    "possible_values": []
                }
            },
            "zeros_like_155": {
                "variable": {
                    "value": "state[exp_avg]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "zeros_like_157": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            }
        }
    },
    "vln_bert.py": {
        "torch": {
            "Linear_19": {
                "variable": {
                    "value": "self.vil_logit",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Dropout_22": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_prob",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    }
}