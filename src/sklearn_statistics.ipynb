{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "SKLEARN_DATA = \"../data/sklearn/modules/sklearn_modules.json\"\n",
    "\n",
    "ALL_SKLEARN_PROJECTS = \"statistics/sklearn/statistics/*\"\n",
    "ALL_TENSORFLOW_PROJECTS = \"statistics/tensorflow/statistics/*\"\n",
    "ALL_PYTORCH_PROJECTS = \"statistics/pytorch/statistics/*\"\n",
    "SKLEARN_RESULTS = \"statistics/sklearn/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sklearn API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SKLEARN_DATA, \"r\", encoding=\"utf-8\") as sklearn_file:\n",
    "    sklearn_data = json.load(sklearn_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify projects that incorporate Scikit Learn ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projects with ML algorithms:  85\n",
      "Projects without ML algorithms:  72\n",
      "Total projects number:  157\n"
     ]
    }
   ],
   "source": [
    "projects_with_algorithms = []\n",
    "projects_without_algorithms = []\n",
    "\n",
    "for project in glob.glob(ALL_SKLEARN_PROJECTS):\n",
    "    contains_ml_algorithm = False\n",
    "    project_name = project.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    project_name = project_name.replace(\"statistics_\", \"\")\n",
    "\n",
    "    with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "        project_data = json.load(project_file)\n",
    "\n",
    "    for file in project_data:\n",
    "        file_data = project_data[file]\n",
    "\n",
    "        for module in file_data:\n",
    "            module_name = module.split(\"_\")[0]\n",
    "            sklearn_module = next(filter(lambda x: x[\"name\"] == module_name, sklearn_data))\n",
    "            contains_ml_algorithm = True\n",
    "\n",
    "        if contains_ml_algorithm:\n",
    "            projects_with_algorithms.append(project_name)\n",
    "            break\n",
    "\n",
    "    if not contains_ml_algorithm:\n",
    "        projects_without_algorithms.append(project_name)\n",
    "\n",
    "\n",
    "print(\"Projects with ML algorithms: \", len(projects_with_algorithms))\n",
    "print(\"Projects without ML algorithms: \",len(projects_without_algorithms))\n",
    "print(\"Total projects number: \",len(projects_with_algorithms) + len(projects_without_algorithms))\n",
    "\n",
    "with open(SKLEARN_RESULTS + \"projects_without_mla.txt\", \"w\", encoding=\"utf-8\") as source:\n",
    "    for project in projects_without_algorithms:\n",
    "        source.write(project + \"\\n\")\n",
    "\n",
    "with open(SKLEARN_RESULTS + \"projects_with_mla.txt\", \"w\", encoding=\"utf-8\") as source:\n",
    "    for project in projects_with_algorithms:\n",
    "        source.write(project + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify all ML algorithms used in projects with ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ML algorithms:  77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>LabelBinarizer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ParameterSampler</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MiniBatchKMeans</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 algorithm  count\n",
       "0           StandardScaler     42\n",
       "1   DecisionTreeClassifier      3\n",
       "2     KNeighborsClassifier      2\n",
       "3                      SVC      5\n",
       "4       LogisticRegression     32\n",
       "..                     ...    ...\n",
       "72            MLPRegressor      1\n",
       "73      IsotonicRegression      2\n",
       "74          LabelBinarizer      1\n",
       "75        ParameterSampler      1\n",
       "76         MiniBatchKMeans      1\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_files = [f\"statistics/sklearn/statistics/statistics_{name}.json\" for name in projects_with_algorithms]\n",
    "\n",
    "ml_algorithms = []\n",
    "\n",
    "for project in projects_files:\n",
    "    \n",
    "    # Get project data\n",
    "    with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "        project_data = json.load(project_file)\n",
    "\n",
    "    # Check each file\n",
    "    for file in project_data:\n",
    "        file_data = project_data[file]\n",
    "\n",
    "        # Extract each ML algorithm\n",
    "        for module in file_data:    \n",
    "            module_name = module.split(\"_\")[0]\n",
    "            ml_algorithms.append(module_name)\n",
    "\n",
    "data = Counter(ml_algorithms)\n",
    "df_algo = pd.DataFrame.from_dict(data, orient=\"index\").reset_index()\n",
    "df_algo = df_algo.rename(columns={'index':'algorithm', 0:'count'})\n",
    "df_aglo= df_algo.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "print(\"Number of ML algorithms: \", len(data))\n",
    "df_algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the number of options that can by set regarding the API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>count</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                algorithm  count  options\n",
       "0          StandardScaler     42        3\n",
       "1  DecisionTreeClassifier      3       12\n",
       "2    KNeighborsClassifier      2        8\n",
       "3                     SVC      5       15\n",
       "4      LogisticRegression     32       15"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_options = []\n",
    "\n",
    "algos = df_algo[\"algorithm\"].to_list()\n",
    "\n",
    "for algo in algos:\n",
    "    sklearn_module = next(filter(lambda x: x[\"name\"] == algo, sklearn_data))\n",
    "    possible_options.append(len(sklearn_module[\"params\"]))\n",
    "\n",
    "df_algo[\"options\"] = possible_options\n",
    "\n",
    "df_algo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the average number of options used per algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>count</th>\n",
       "      <th>options</th>\n",
       "      <th>avg_options_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                algorithm  count  options  avg_options_used\n",
       "0          StandardScaler     42        3              0.40\n",
       "1  DecisionTreeClassifier      3       12              1.33\n",
       "2    KNeighborsClassifier      2        8              2.50\n",
       "3                     SVC      5       15              2.00\n",
       "4      LogisticRegression     32       15              1.28"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_options_used = []\n",
    "\n",
    "for algo in algos:\n",
    "    algo_options_used = []\n",
    "    for project in projects_files:\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "        for file in project_data:\n",
    "            file_data = project_data[file]\n",
    "\n",
    "            for module in file_data:\n",
    "                module_name = module.split(\"_\")[0]\n",
    "                if algo == module_name:\n",
    "                    module_data = file_data[module]\n",
    "                    algo_options_used.append(len(module_data))\n",
    "\n",
    "\n",
    "    avg_options_used.append(round((sum(algo_options_used) / len(algo_options_used)),2))\n",
    "\n",
    "df_algo[\"avg_options_used\"] = avg_options_used\n",
    "df_algo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify most used option for each Algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>count</th>\n",
       "      <th>options</th>\n",
       "      <th>avg_options_used</th>\n",
       "      <th>Most Used HP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>defaults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1.33</td>\n",
       "      <td>criterion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2.50</td>\n",
       "      <td>n_neighbors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2.00</td>\n",
       "      <td>kernel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>1.28</td>\n",
       "      <td>solver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2.33</td>\n",
       "      <td>n_estimators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AgglomerativeClustering</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.00</td>\n",
       "      <td>n_clusters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>2.25</td>\n",
       "      <td>n_clusters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LabelEncoder</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>defaults</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 algorithm  count  options  avg_options_used  Most Used HP\n",
       "0           StandardScaler     42        3              0.40      defaults\n",
       "1   DecisionTreeClassifier      3       12              1.33     criterion\n",
       "2     KNeighborsClassifier      2        8              2.50   n_neighbors\n",
       "3                      SVC      5       15              2.00        kernel\n",
       "4       LogisticRegression     32       15              1.28        solver\n",
       "5               GaussianNB      2        2              0.00          None\n",
       "6   RandomForestClassifier      6       18              2.33  n_estimators\n",
       "7  AgglomerativeClustering      3        8              2.00    n_clusters\n",
       "8                   KMeans     32        9              2.25    n_clusters\n",
       "9             LabelEncoder     12        0              0.08      defaults"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate most used parameter for each ML algorithm\n",
    "\n",
    "most_used_options = []\n",
    "\n",
    "for algo in algos:\n",
    "    algo_options = []\n",
    "    for project in projects_files:\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "        for file in project_data:\n",
    "            file_data = project_data[file]\n",
    "\n",
    "            for module in file_data:\n",
    "                module_name = module.split(\"_\")[0]\n",
    "                if algo == module_name:\n",
    "                    module_data = file_data[module]\n",
    "                    for param, value in module_data.items():\n",
    "                        if param == \"params\" and value == \"default\":\n",
    "                            algo_options.append(\"defaults\")\n",
    "                        else:\n",
    "                            algo_options.append(param)\n",
    "    \n",
    "    data = Counter(algo_options)\n",
    "    try:\n",
    "        most_used_options.append(data.most_common(1)[0][0])\n",
    "    except IndexError:\n",
    "        most_used_options.append(\"None\")\n",
    "\n",
    "df_algo[\"Most Used HP\"] = most_used_options\n",
    "df_algo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Dataframe into Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "                 algorithm &  count &  options &  avg\\_options\\_used &         Most Used HP \\\\\n",
      "\\midrule\n",
      "            StandardScaler &     42 &        3 &              0.40 &             defaults \\\\\n",
      "    DecisionTreeClassifier &      3 &       12 &              1.33 &            criterion \\\\\n",
      "      KNeighborsClassifier &      2 &        8 &              2.50 &          n\\_neighbors \\\\\n",
      "                       SVC &      5 &       15 &              2.00 &               kernel \\\\\n",
      "        LogisticRegression &     32 &       15 &              1.28 &               solver \\\\\n",
      "                GaussianNB &      2 &        2 &              0.00 &                 None \\\\\n",
      "    RandomForestClassifier &      6 &       18 &              2.33 &         n\\_estimators \\\\\n",
      "   AgglomerativeClustering &      3 &        8 &              2.00 &           n\\_clusters \\\\\n",
      "                    KMeans &     32 &        9 &              2.25 &           n\\_clusters \\\\\n",
      "              LabelEncoder &     12 &        0 &              0.08 &             defaults \\\\\n",
      "             OneHotEncoder &      8 &        5 &              0.88 & categorical\\_features \\\\\n",
      "              MinMaxScaler &     22 &        3 &              0.77 &        feature\\_range \\\\\n",
      "                 KernelPCA &      1 &       16 &              2.00 &         n\\_components \\\\\n",
      "                       PCA &     10 &        7 &              0.90 &         n\\_components \\\\\n",
      "              GridSearchCV &     11 &       10 &              5.45 &            estimator \\\\\n",
      "           CountVectorizer &      9 &       17 &              7.89 &         max\\_features \\\\\n",
      "     DecisionTreeRegressor &      3 &       11 &              1.00 &         random\\_state \\\\\n",
      "          LinearRegression &     19 &        5 &              0.37 &             defaults \\\\\n",
      "        PolynomialFeatures &      2 &        4 &              1.00 &               degree \\\\\n",
      "     RandomForestRegressor &      3 &       17 &              1.33 &         n\\_estimators \\\\\n",
      "                       SVR &      1 &       11 &              1.00 &               kernel \\\\\n",
      "             KernelDensity &      3 &        9 &              2.00 &               kernel \\\\\n",
      "           StratifiedKFold &      5 &        3 &              3.00 &             n\\_splits \\\\\n",
      "       MultiLabelBinarizer &     10 &        2 &              1.00 &        sparse\\_output \\\\\n",
      "                      TSNE &     10 &       15 &              1.80 &         n\\_components \\\\\n",
      "                     KFold &     10 &        3 &              2.50 &             n\\_splits \\\\\n",
      "              ShuffleSplit &      1 &        4 &              3.00 &             n\\_splits \\\\\n",
      "             ParameterGrid &      2 &        1 &              1.00 &           param\\_grid \\\\\n",
      "           GaussianMixture &      5 &       14 &              3.20 &         n\\_components \\\\\n",
      "            HuberRegressor &      2 &        6 &              1.00 &              epsilon \\\\\n",
      "           TfidfVectorizer &      6 &       21 &              4.83 &               min\\_df \\\\\n",
      "                  Pipeline &     28 &        3 &              1.25 &                steps \\\\\n",
      "             SGDClassifier &      3 &       21 &              1.33 &                 loss \\\\\n",
      "               OneClassSVM &      1 &       10 &              0.00 &                 None \\\\\n",
      "            SGDOneClassSVM &      1 &       12 &              0.00 &                 None \\\\\n",
      "              SGDRegressor &      4 &       19 &              0.25 &             defaults \\\\\n",
      "                Perceptron &      2 &       16 &              0.00 &                 None \\\\\n",
      "          NearestNeighbors &      7 &        8 &              1.29 &          n\\_neighbors \\\\\n",
      "                 LinearSVC &      4 &       12 &              1.00 &             defaults \\\\\n",
      "                 MeanShift &      1 &        7 &              3.00 &            bandwidth \\\\\n",
      "                    KDTree &      3 &        4 &              2.00 &                    X \\\\\n",
      "                RBFSampler &      1 &        3 &              2.00 &                gamma \\\\\n",
      "          IterativeImputer &      1 &       14 &              2.00 &   n\\_nearest\\_features \\\\\n",
      "              TruncatedSVD &      1 &        5 &              2.00 &         n\\_components \\\\\n",
      "TransformedTargetRegressor &      1 &        5 &              3.00 &            regressor \\\\\n",
      "                GroupKFold &      4 &        1 &              1.00 &             n\\_splits \\\\\n",
      "   RepeatedStratifiedKFold &      1 &        3 &              3.00 &             n\\_splits \\\\\n",
      "         GroupShuffleSplit &      1 &        4 &              3.00 &             n\\_splits \\\\\n",
      "           TimeSeriesSplit &      3 &        4 &              1.33 &             n\\_splits \\\\\n",
      "             RepeatedKFold &      1 &        3 &              3.00 &             n\\_splits \\\\\n",
      "         ColumnTransformer &      2 &        7 &              1.50 &         transformers \\\\\n",
      "             SimpleImputer &      1 &        6 &              2.00 &       missing\\_values \\\\\n",
      "              RobustScaler &      2 &        5 &              0.00 &                 None \\\\\n",
      "           DummyClassifier &      3 &        3 &              0.67 &             strategy \\\\\n",
      "            DummyRegressor &      1 &        3 &              0.00 &                 None \\\\\n",
      "      MultiOutputRegressor &      1 &        2 &              1.00 &            estimator \\\\\n",
      "            RegressorChain &      1 &        4 &              1.00 &       base\\_estimator \\\\\n",
      "      ExtraTreesClassifier &      1 &       18 &              0.00 &                 None \\\\\n",
      "       ExtraTreesRegressor &      1 &       17 &              1.00 &     default\\_location \\\\\n",
      "                    DBSCAN &      3 &        8 &              2.00 &                  eps \\\\\n",
      " LatentDirichletAllocation &      3 &       16 &              1.00 &         n\\_components \\\\\n",
      "   BayesianGaussianMixture &      1 &       17 &              8.00 &         n\\_components \\\\\n",
      "                     Lasso &      2 &       11 &              1.00 &                alpha \\\\\n",
      "                     Ridge &      1 &        9 &              1.00 &                alpha \\\\\n",
      "          KBinsDiscretizer &      1 &        4 &              0.00 &                 None \\\\\n",
      " GradientBoostingRegressor &      1 &       21 &              3.00 &                 loss \\\\\n",
      "       FunctionTransformer &      5 &        7 &              2.00 &                 func \\\\\n",
      "          TfidfTransformer &      3 &        4 &              1.00 &           smooth\\_idf \\\\\n",
      "               BernoulliNB &      1 &        4 &              2.00 &             binarize \\\\\n",
      "             MultinomialNB &      1 &        3 &              1.00 &            fit\\_prior \\\\\n",
      "              ComplementNB &      1 &        4 &              1.00 &            fit\\_prior \\\\\n",
      "       KNeighborsRegressor &      1 &        8 &              1.00 &          n\\_neighbors \\\\\n",
      "              MLPRegressor &      1 &       23 &              6.00 &   hidden\\_layer\\_sizes \\\\\n",
      "        IsotonicRegression &      2 &        4 &              1.00 &        out\\_of\\_bounds \\\\\n",
      "            LabelBinarizer &      1 &        3 &              0.00 &                 None \\\\\n",
      "          ParameterSampler &      1 &        3 &              2.00 &  param\\_distributions \\\\\n",
      "           MiniBatchKMeans &      1 &       12 &             12.00 &           n\\_clusters \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_algo.to_latex(index=False))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify all Options used in projects with ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hyperparameter:  118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_state</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_clusters</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n_components</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>steps</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>n_splits</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>shuffle</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>param_grid</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>estimator</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_range</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>max_iter</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hyperparameter  count\n",
       "1    random_state     54\n",
       "7      n_clusters     36\n",
       "13   n_components     31\n",
       "45          steps     28\n",
       "22       n_splits     26\n",
       "23        shuffle     14\n",
       "15     param_grid     13\n",
       "14      estimator     12\n",
       "12  feature_range     12\n",
       "31       max_iter     12"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_files = [f\"statistics/sklearn/statistics/statistics_{name}.json\" for name in projects_with_algorithms]\n",
    "\n",
    "options = []\n",
    "\n",
    "for project in projects_files:\n",
    "    \n",
    "    # Get project data\n",
    "    with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "        project_data = json.load(project_file)\n",
    "\n",
    "    # Check each file\n",
    "    for file in project_data:\n",
    "        file_data = project_data[file]\n",
    "\n",
    "        # Extract each ML algorithm\n",
    "        for module in file_data:    \n",
    "            module_name = module.split(\"_\")[0]\n",
    "            module_data = file_data[module]\n",
    "            for param, value in module_data.items():\n",
    "                if param == \"params\" and value == \"default\":\n",
    "                    continue\n",
    "                options.append(param)\n",
    "\n",
    "data = Counter(options)\n",
    "df_options = pd.DataFrame.from_dict(data, orient=\"index\").reset_index()\n",
    "df_options = df_options.rename(columns={'index':'Hyperparameter', 0:'count'})\n",
    "df_options = df_options.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "print(\"Number of unique hyperparameter: \", len(data))\n",
    "df_options.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Value Range for Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th>count</th>\n",
       "      <th>num_value_range</th>\n",
       "      <th>most_common_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_state</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>[(0, 32)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_clusters</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>[(n_clusters, 8)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n_components</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>[(2, 12)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>steps</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>[(('tokenize', feature_extraction.BagOfWords(l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>n_splits</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>[(n_splits, 8)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>shuffle</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(True, 8)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>param_grid</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>[(regressor[1], 6)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>estimator</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>[(regressor[0](), 6)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feature_range</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>[((0, 1), 9)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>max_iter</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>[(100, 4)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hyperparameter  count  num_value_range  \\\n",
       "1    random_state     54               12   \n",
       "7      n_clusters     36               13   \n",
       "13   n_components     31               14   \n",
       "45          steps     28               23   \n",
       "22       n_splits     26               12   \n",
       "23        shuffle     14                3   \n",
       "15     param_grid     13                5   \n",
       "14      estimator     12                7   \n",
       "12  feature_range     12                2   \n",
       "31       max_iter     12                6   \n",
       "\n",
       "                                   most_common_values  \n",
       "1                                           [(0, 32)]  \n",
       "7                                   [(n_clusters, 8)]  \n",
       "13                                          [(2, 12)]  \n",
       "45  [(('tokenize', feature_extraction.BagOfWords(l...  \n",
       "22                                    [(n_splits, 8)]  \n",
       "23                                        [(True, 8)]  \n",
       "15                                [(regressor[1], 6)]  \n",
       "14                              [(regressor[0](), 6)]  \n",
       "12                                      [((0, 1), 9)]  \n",
       "31                                         [(100, 4)]  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate value range\n",
    "\n",
    "options = df_options[\"Hyperparameter\"]\n",
    "\n",
    "num_options_value_range = []\n",
    "most_common_option_values = []\n",
    "\n",
    "for option in options:\n",
    "    value_range = []\n",
    "    for project in projects_files:\n",
    "    \n",
    "        # Get project data\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "        # Check each file\n",
    "        for file in project_data:\n",
    "            file_data = project_data[file]\n",
    "\n",
    "            # Extract each ML algorithm\n",
    "            for module in file_data:    \n",
    "                module_name = module.split(\"_\")[0]\n",
    "                module_data = file_data[module]\n",
    "                for param, value in module_data.items():\n",
    "                    if option == param:\n",
    "                        value_range.append(value)\n",
    "\n",
    "                    #if param == \"max_features\" and value == \"None\":\n",
    "                    #    print(project)\n",
    "                    #    print(file)\n",
    "\n",
    "                    #if param == \"n_clusters\":\n",
    "                    #    print(module_name)\n",
    "\n",
    "    option_data = Counter(value_range)\n",
    "    num_options_value_range.append(option_data)\n",
    "\n",
    "    most_common_counter = option_data.most_common(1)\n",
    "\n",
    "    most_common_values = [x for x in most_common_counter]\n",
    "    most_common_option_values.append(most_common_values)\n",
    "\n",
    "num_value_range = [len(x) for x in num_options_value_range]\n",
    "\n",
    "df_options[\"num_value_range\"] = num_value_range\n",
    "df_options[\"most_common_values\"] = most_common_option_values\n",
    "df_options.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Dataframe into Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrl}\n",
      "\\toprule\n",
      "                 Hyperparameter &  count &  num\\_value\\_range &                                 most\\_common\\_values \\\\\n",
      "\\midrule\n",
      "                   random\\_state &     54 &               12 &                                          [(0, 32)] \\\\\n",
      "                     n\\_clusters &     36 &               13 &                                  [(n\\_clusters, 8)] \\\\\n",
      "                   n\\_components &     31 &               14 &                                          [(2, 12)] \\\\\n",
      "                          steps &     28 &               23 & [(('tokenize', feature\\_extraction.BagOfWords(lo... \\\\\n",
      "                       n\\_splits &     26 &               12 &                                    [(n\\_splits, 8)] \\\\\n",
      "                        shuffle &     14 &                3 &                                        [(True, 8)] \\\\\n",
      "                     param\\_grid &     13 &                5 &                                [(regressor[1], 6)] \\\\\n",
      "                      estimator &     12 &                7 &                              [(regressor[0](), 6)] \\\\\n",
      "                  feature\\_range &     12 &                2 &                                      [((0, 1), 9)] \\\\\n",
      "                       max\\_iter &     12 &                6 &                                         [(100, 4)] \\\\\n",
      "                             cv &     11 &                4 &                                           [(3, 8)] \\\\\n",
      "                   max\\_features &     11 &                5 &                                        [(None, 7)] \\\\\n",
      "                         kernel &     10 &                4 &                                         [(rbf, 5)] \\\\\n",
      "                    n\\_neighbors &     10 &                6 &                                           [(1, 3)] \\\\\n",
      "                      tokenizer &      9 &                2 &                                        [(None, 8)] \\\\\n",
      "                   decode\\_error &      9 &                3 &                                      [(strict, 6)] \\\\\n",
      "                         n\\_jobs &      9 &                4 &                                      [(n\\_jobs, 4)] \\\\\n",
      "                   preprocessor &      9 &                2 &                                        [(None, 8)] \\\\\n",
      "                          refit &      8 &                2 &                                        [(True, 6)] \\\\\n",
      "                         n\\_init &      8 &                6 &                                         [(100, 3)] \\\\\n",
      "                       encoding &      8 &                2 &                                       [(utf-8, 7)] \\\\\n",
      "                  token\\_pattern &      8 &                2 &                               [((?u)\\textbackslash b\\textbackslash w\\textbackslash w+\\textbackslash b, 7)] \\\\\n",
      "                        scoring &      8 &                2 &                      [(neg\\_mean\\_squared\\_error, 6)] \\\\\n",
      "                  sparse\\_output &      7 &                1 &                                        [(True, 7)] \\\\\n",
      "                          input &      7 &                1 &                                     [(content, 7)] \\\\\n",
      "                         solver &      7 &                4 &                                       [(lbfgs, 4)] \\\\\n",
      "                         memory &      7 &                3 &               [(('model', model(alpha=alpha)), 5)] \\\\\n",
      "                     vocabulary &      7 &                1 &                                        [(None, 7)] \\\\\n",
      "                            tol &      6 &                4 &                                      [(0.0001, 3)] \\\\\n",
      "                         min\\_df &      6 &                3 &                                           [(2, 3)] \\\\\n",
      "                            iid &      6 &                1 &                                       [(False, 6)] \\\\\n",
      "                     warm\\_start &      6 &                2 &                                        [(True, 5)] \\\\\n",
      "                   n\\_estimators &      6 &                5 &                                          [(10, 2)] \\\\\n",
      "                        verbose &      6 &                4 &                                     [(verbose, 2)] \\\\\n",
      "                       validate &      5 &                1 &                                       [(False, 5)] \\\\\n",
      "           categorical\\_features &      5 &                3 &                                         [([1], 3)] \\\\\n",
      "                    ngram\\_range &      5 &                4 &                                      [((1, 3), 2)] \\\\\n",
      "                           func &      5 &                1 &                 [(utils.concat\\_title\\_and\\_text, 5)] \\\\\n",
      "                     smooth\\_idf &      5 &                2 &                                        [(True, 3)] \\\\\n",
      "                      algorithm &      5 &                3 &                                        [(auto, 2)] \\\\\n",
      "                        penalty &      5 &                3 &                                          [(l2, 3)] \\\\\n",
      "                              C &      4 &                3 &                                        [(0.01, 2)] \\\\\n",
      "                      bandwidth &      4 &                3 &                                        [(0.25, 2)] \\\\\n",
      "                         binary &      4 &                2 &                                       [(False, 3)] \\\\\n",
      "                           init &      4 &                3 &                                   [(k-means++, 2)] \\\\\n",
      "                      with\\_mean &      4 &                2 &                                        [(True, 3)] \\\\\n",
      "                      fit\\_prior &      3 &                1 &                                        [(True, 3)] \\\\\n",
      "                       analyzer &      3 &                2 &                                        [(word, 2)] \\\\\n",
      "                            eps &      3 &                2 &                  [(CFG.POSTPROCESS.DBSCAN\\_EPS, 2)] \\\\\n",
      "                    min\\_samples &      3 &                2 &          [(CFG.POSTPROCESS.DBSCAN\\_MIN\\_SAMPLES, 2)] \\\\\n",
      "                       with\\_std &      3 &                1 &                                        [(True, 3)] \\\\\n",
      "                              X &      3 &                3 &                  [(self.train\\_x.cpu().numpy(), 1)] \\\\\n",
      "                           dual &      3 &                1 &                                       [(False, 3)] \\\\\n",
      "                          alpha &      3 &                2 &                                         [(reg, 2)] \\\\\n",
      "                     stop\\_words &      3 &                3 &                                   [(stopwords, 1)] \\\\\n",
      "                         metric &      3 &                3 &                                   [(minkowski, 1)] \\\\\n",
      "                        classes &      3 &                3 &                                     [(classes, 1)] \\\\\n",
      "                      test\\_size &      3 &                3 &                                  [(split\\_size, 1)] \\\\\n",
      "                covariance\\_type &      3 &                2 &                                        [(full, 2)] \\\\\n",
      "                  fit\\_intercept &      3 &                2 &                                       [(False, 2)] \\\\\n",
      "                       strategy &      3 &                3 &                                      [(median, 1)] \\\\\n",
      "                         max\\_df &      3 &                2 &                                        [(0.75, 2)] \\\\\n",
      "                 max\\_leaf\\_nodes &      3 &                2 &                                   [(clf\\_nodes, 2)] \\\\\n",
      "              intercept\\_scaling &      3 &                1 &                                         [(1.0, 3)] \\\\\n",
      "                  learning\\_rate &      3 &                3 &                                    [(constant, 1)] \\\\\n",
      "               min\\_samples\\_leaf &      2 &                1 &                             [(min\\_prebin\\_size, 2)] \\\\\n",
      "                      max\\_depth &      2 &                2 &                              [(self.max\\_depth, 1)] \\\\\n",
      "                         n\\_iter &      2 &                2 &                                        [(2000, 1)] \\\\\n",
      "               default\\_location &      2 &                1 &                                    [(location, 2)] \\\\\n",
      "                   transformers &      2 &                2 & [([('continuous', SimpleImputer(missing\\_values=... \\\\\n",
      "                      criterion &      2 &                1 &                                     [(entropy, 2)] \\\\\n",
      "                      n\\_repeats &      2 &                1 &                                           [(1, 2)] \\\\\n",
      "                      leaf\\_size &      2 &                2 &                                          [(40, 1)] \\\\\n",
      "                        linkage &      2 &                2 &                                        [(ward, 1)] \\\\\n",
      "                         degree &      2 &                2 &                                           [(4, 1)] \\\\\n",
      "                     perplexity &      2 &                2 &                                           [(5, 1)] \\\\\n",
      "                        epsilon &      2 &                2 &                                         [(1.5, 1)] \\\\\n",
      "                        use\\_idf &      2 &                2 &                                        [(True, 1)] \\\\\n",
      "                           norm &      2 &                1 &                                        [(None, 2)] \\\\\n",
      "                      lowercase &      2 &                2 &                                       [(False, 1)] \\\\\n",
      "                           loss &      2 &                2 &                                         [(log, 1)] \\\\\n",
      "                        n\\_folds &      2 &                1 &                                       [(folds, 2)] \\\\\n",
      "                  out\\_of\\_bounds &      2 &                1 &                                        [(clip, 2)] \\\\\n",
      "                      remainder &      1 &                1 &                                        [(drop, 1)] \\\\\n",
      "          min\\_impurity\\_decrease &      1 &                1 &                                         [(0.0, 1)] \\\\\n",
      "            param\\_distributions &      1 &                1 &                                      [(params, 1)] \\\\\n",
      "             hidden\\_layer\\_sizes &      1 &                1 &                                           [(6, 1)] \\\\\n",
      "                 compute\\_labels &      1 &                1 &                                        [(True, 1)] \\\\\n",
      "                         sparse &      1 &                1 &                                       [(False, 1)] \\\\\n",
      "                       binarize &      1 &                1 &                                        [(None, 1)] \\\\\n",
      "                      oob\\_score &      1 &                1 &                                       [(False, 1)] \\\\\n",
      "             learning\\_rate\\_init &      1 &                1 &                                       [(0.001, 1)] \\\\\n",
      "                  strip\\_accents &      1 &                1 &                                        [(None, 1)] \\\\\n",
      "                     activation &      1 &                1 &                                    [(identity, 1)] \\\\\n",
      "             max\\_no\\_improvement &      1 &                1 &                          [(max\\_no\\_improvement, 1)] \\\\\n",
      "                      init\\_size &      1 &                1 &                                   [(init\\_size, 1)] \\\\\n",
      "                     batch\\_size &      1 &                1 &                                  [(batch\\_size, 1)] \\\\\n",
      "                    bin\\_seeding &      1 &                1 &                                        [(True, 1)] \\\\\n",
      "             early\\_exaggeration &      1 &                1 &                                          [(20, 1)] \\\\\n",
      "                     means\\_init &      1 &                1 &                                   [(centroids, 1)] \\\\\n",
      "                              p &      1 &                1 &                                           [(2, 1)] \\\\\n",
      "                       affinity &      1 &                1 &                                   [(euclidean, 1)] \\\\\n",
      "                      optimizer &      1 &                1 &                          [(SGD(LEARNING\\_RATE), 1)] \\\\\n",
      "                           eta0 &      1 &                1 &                               [(LEARNING\\_RATE, 1)] \\\\\n",
      "                           seed &      1 &                1 &                                          [(42, 1)] \\\\\n",
      "                          gamma &      1 &                1 &                                       [(gamma, 1)] \\\\\n",
      "             n\\_nearest\\_features &      1 &                1 &                                          [(80, 1)] \\\\\n",
      "                      regressor &      1 &                1 &                                 [(skorch\\_nnet, 1)] \\\\\n",
      "                    transformer &      1 &                1 &                            [(StandardScaler(), 1)] \\\\\n",
      "                  check\\_inverse &      1 &                1 &                                       [(False, 1)] \\\\\n",
      "                 missing\\_values &      1 &                1 &                                      [(np.nan, 1)] \\\\\n",
      "                 base\\_estimator &      1 &                1 &    [(AutoML(task='regression', time\\_budget=1), 1)] \\\\\n",
      "                    multi\\_class &      1 &                1 &                                 [(multi\\_class, 1)] \\\\\n",
      "                    init\\_params &      1 &                1 &                                      [(method, 1)] \\\\\n",
      "weight\\_concentration\\_prior\\_type &      1 &                1 &                           [(dirichlet\\_process, 1)] \\\\\n",
      "     weight\\_concentration\\_prior &      1 &                1 &                                           [(1, 1)] \\\\\n",
      "                   weights\\_init &      1 &                1 &                                 [(gmm\\_weights, 1)] \\\\\n",
      "             reassignment\\_ratio &      1 &                1 &                          [(reassignment\\_ratio, 1)] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_options.to_latex(index=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find projects that use Scikit Learn Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics/sklearn/statistics/statistics_100DaysofMLCodeChallenge.json\n",
      "Model-Selection-&-Boosting/Model-Selection/grid_search.py\n",
      "statistics/sklearn/statistics/statistics_Conditional_Density_Estimation.json\n",
      "cde/density_estimator/BaseDensityEstimator.py\n",
      "statistics/sklearn/statistics/statistics_lua-ffi-lightGBM.json\n",
      "examples/python-guide/sklearn_example.py\n",
      "statistics/sklearn/statistics/statistics_lua-ffi-lightGBM.json\n",
      "tests/python_package_test/test_sklearn.py\n",
      "statistics/sklearn/statistics/statistics_regression_data_poisoning.json\n",
      "src/attacks.py\n",
      "statistics/sklearn/statistics/statistics_regression_data_poisoning.json\n",
      "src/main.py\n",
      "statistics/sklearn/statistics/statistics_regression_data_poisoning.json\n",
      "src/visualisation/poison_warfarin.py\n",
      "statistics/sklearn/statistics/statistics_regression_data_poisoning.json\n",
      "src/visualisation/poison_warfarin.py\n",
      "statistics/sklearn/statistics/statistics_regression_data_poisoning.json\n",
      "src/visualisation/poison_warfarin.py\n",
      "statistics/sklearn/statistics/statistics_regression_data_poisoning.json\n",
      "src/visualisation/poison_warfarin.py\n",
      "statistics/sklearn/statistics/statistics_TOCCA.json\n",
      "run_tocca.py\n",
      "Scikit Learn Projects with Hyperparameter Tuning:  5\n",
      "Scikit Learn Projects without Hyperparameter Tuning:  80\n"
     ]
    }
   ],
   "source": [
    "tuning = [\"GridSearchCV\", \"RandomizedSearchCV\", \"HalvingGridSearchCV\", \"HalvingRandomSearchCV\"]\n",
    "\n",
    "projects_with_hpo = set()\n",
    "\n",
    "for project in projects_files:\n",
    "    \n",
    "    # Get project data\n",
    "    with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "        project_data = json.load(project_file)\n",
    "\n",
    "    # Check each file\n",
    "    for file in project_data:\n",
    "        file_data = project_data[file]\n",
    "\n",
    "        # Extract each ML algorithm\n",
    "        for module in file_data:    \n",
    "            module_name = module.split(\"_\")[0]\n",
    "            module_data = file_data[module]\n",
    "            if module_name in tuning:\n",
    "                projects_with_hpo.add(project)\n",
    "                print(project)\n",
    "                print(file)\n",
    "\n",
    "print(\"Scikit Learn Projects with Hyperparameter Tuning: \", len(projects_with_hpo))\n",
    "print(\"Scikit Learn Projects without Hyperparameter Tuning: \", len(projects_with_algorithms) - len(projects_with_hpo))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b15ceb2e1c319abb5a3a14f1ef1bcbce2ee8dd1c77d2c4e6466e97ae1997d13"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
