{
    "fine-tune/model/loss.py": {
        "sklearn": {},
        "torch": {
            "ParrotLoss_13": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "L1Loss_19": {
                    "variable": {
                        "value": "self.L1Loss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "MSELoss_20": {
                    "variable": {
                        "value": "self.MSELoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "BCEWithLogitsLoss_21": {
                    "variable": {
                        "value": "self.BCEWithLogitsLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "CrossEntropyLoss_22": {
                    "variable": {
                        "value": "self.CrossEntropyLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                }
            },
            "tensor_62": {
                "variable": {
                    "value": "post_output_new",
                    "possible_values": []
                },
                "data": {
                    "value": "post_output_new",
                    "possible_values": [
                        [
                            "np.zeros((size, 3, 800, 80))",
                            "Call"
                        ],
                        [
                            "torch.tensor(post_output_new, dtype=torch.float32).to(device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_70": {
                "variable": {
                    "value": "criterion",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "tensor_89": {
                "variable": {
                    "value": "cost_valid",
                    "possible_values": []
                },
                "data": {
                    "value": "cost_valid",
                    "possible_values": [
                        [
                            "np.sum(loss) / size",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(cost_valid).to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_90": {
                "variable": {
                    "value": "emotion_embedding_high",
                    "possible_values": []
                },
                "data": {
                    "value": "emotion_embedding_high",
                    "possible_values": [
                        [
                            "torch.tensor(emotion_embedding_high).to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_91": {
                "variable": {
                    "value": "best_valid_uw",
                    "possible_values": []
                },
                "data": {
                    "value": "best_valid_uw",
                    "possible_values": [
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "valid_acc_uw",
                            "Name"
                        ],
                        [
                            "torch.tensor(best_valid_uw).to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_111": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "data": {
                    "value": "text_target.data.new(B, 1).zero_()",
                    "possible_values": []
                }
            },
            "cat_112": {
                "variable": {
                    "value": "text_target",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(text_target, padded)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ceil_150": {
                "variable": {
                    "value": "mel_step_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "max_199": {
                "variable": {
                    "value": "(_, predicted_speaker)",
                    "possible_values": []
                },
                "input": {
                    "value": "speaker_logit_from_mel",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_203": {
                "variable": {
                    "value": "(_, predicted_speaker)",
                    "possible_values": []
                },
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_213": {
                "variable": {
                    "value": "(_, predicted_text)",
                    "possible_values": []
                },
                "input": {
                    "value": "text_logit_flatten",
                    "possible_values": [
                        [
                            "text_logit_from_mel_hidden.reshape(-1, n_symbols_plus_one)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "tensor_76": {
                "variable": {
                    "value": "inputs",
                    "possible_values": []
                },
                "data": {
                    "value": "input",
                    "possible_values": []
                }
            },
            "tensor_77": {
                "variable": {
                    "value": "targets",
                    "possible_values": []
                },
                "data": {
                    "value": "target",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_168": {
                "variable": {
                    "value": "contrast_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "sum_178": {
                "variable": {
                    "value": "distance_matrix_xx",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_179": {
                "variable": {
                    "value": "distance_matrix_yy",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "bmm_183": {
                "variable": {
                    "value": "distance_matrix_xy",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed",
                    "possible_values": []
                },
                "mat2": {
                    "value": "torch.transpose(mel_hidden_normed, 1, 2)",
                    "possible_values": []
                }
            },
            "eye_187": {
                "variable": {
                    "value": "hard_alignments",
                    "possible_values": []
                },
                "n": {
                    "value": "TTEXT",
                    "possible_values": [
                        [
                            "distance_matrix.size(1)",
                            "Call"
                        ],
                        [
                            "speaker_logit_from_mel_hidden.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_69": {
                "f": {
                    "value": "LOAD_PATH",
                    "possible_values": [
                        [
                            "'/home/zhoukun/SER/Speech-Emotion-Recognition-main/checkpoint/best_model_esd.pth'",
                            "Constant"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "no_grad_75": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_157": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_164": {
                "input": {
                    "value": "stop_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_step_lengths, int(mel_target.size(2) / self.n_frames_per_step)).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_198": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_208": {
                "input": {
                    "value": "text_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_216": {
                "input": {
                    "value": "text_mask_plus_one",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths + 1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_219": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_220": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_162": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_183": {
                "input": {
                    "value": "mel_hidden_normed",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "sum_191": {
                "input": {
                    "value": "contrast_mask",
                    "possible_values": [
                        [
                            "(contrast_mask1 & contrast_mask2).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_227": {
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "text_mask.unsqueeze(2).expand(-1, -1, n_speakers).reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_174": {
                "input": {
                    "value": "text_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "norm_175": {
                "input": {
                    "value": "mel_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_189": {
                "input": {
                    "value": "1.0 - distance_matrix",
                    "possible_values": []
                }
            },
            "zeros_like_189": {
                "input": {
                    "value": "distance_matrix",
                    "possible_values": [
                        [
                            "distance_matrix_xx + distance_matrix_yy - 2 * distance_matrix_xy",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/hparams.py": {
        "tensorflow": {
            "info_162": {
                "msg": {
                    "value": "Parsing command line hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "hparams_string",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "info_166": {
                "msg": {
                    "value": "Final parsed hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "list(hparams.values())",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/hparams.py": {
        "tensorflow": {
            "info_120": {
                "msg": {
                    "value": "Parsing command line hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "hparams_string",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "info_124": {
                "msg": {
                    "value": "Final parsed hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "list(hparams.values())",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/hparams.py": {
        "tensorflow": {
            "info_116": {
                "msg": {
                    "value": "Parsing command line hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "hparams_string",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "info_120": {
                "msg": {
                    "value": "Final parsed hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "list(hparams.values())",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/distributed.py": {
        "torch": {
            "DistributedDataParallel_50": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.module": {
                    "value": "module",
                    "possible_values": []
                }
            },
            "cat_19": {
                "variable": {
                    "value": "flat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[t.contiguous().view(-1) for t in tensors]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_134": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_65": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "is_tensor_132": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_63": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/inference_A.py": {
        "torch": {
            "DataLoader_70": {
                "variable": {
                    "value": "test_loader_A",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set_A",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[hparams.speaker_D])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_75": {
                "variable": {
                    "value": "test_loader_B",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set_B",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[hparams.speaker_A])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_43": {
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "args.checkpoint_path",
                            "Attribute"
                        ]
                    ]
                }
            },
            "no_grad_120": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/inference_B.py": {
        "torch": {
            "DataLoader_70": {
                "variable": {
                    "value": "test_loader_A",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set_A",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[hparams.speaker_D])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_75": {
                "variable": {
                    "value": "test_loader_B",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set_B",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[hparams.speaker_B])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_43": {
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "args.checkpoint_path",
                            "Attribute"
                        ]
                    ]
                }
            },
            "no_grad_120": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/inference_C.py": {
        "torch": {
            "DataLoader_70": {
                "variable": {
                    "value": "test_loader_A",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set_A",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[hparams.speaker_D])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_75": {
                "variable": {
                    "value": "test_loader_B",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set_B",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[hparams.speaker_C])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_43": {
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "args.checkpoint_path",
                            "Attribute"
                        ]
                    ]
                }
            },
            "no_grad_120": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/inference_embedding.py": {
        "torch": {
            "DataLoader_41": {
                "variable": {
                    "value": "train_loader_A",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_set_A",
                    "possible_values": [
                        [
                            "TextMelIDLoader(training_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, shuffle=False, pids=[speaker])",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_26": {
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "args.checkpoint_path",
                            "Attribute"
                        ]
                    ]
                }
            },
            "no_grad_46": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/logger.py": {
        "torch": {
            "sigmoid_114": {
                "input": {
                    "value": "predicted_stop[idx]",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/logger_1.py": {
        "torch": {
            "sigmoid_114": {
                "input": {
                    "value": "predicted_stop[idx]",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/basic_layers.py": {
        "torch": {
            "LinearNorm_40": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.linear_layer",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "in_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "out_dim",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "ConvNorm_53": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv1d_61": {
                    "variable": {
                        "value": "self.conv",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "in_channels",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "out_channels",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "kernel_size",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "stride": {
                        "value": "stride",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "padding": {
                        "value": "padding",
                        "possible_values": [
                            [
                                "int(dilation * (kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "int((attention_kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "None",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "dilation": {
                        "value": "dilation",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "Prenet_74": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_78": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[LinearNorm(in_size, out_size, bias=False) for (in_size, out_size) in zip(in_sizes, sizes)]",
                        "possible_values": []
                    }
                }
            },
            "LocationLayer_88": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "Attention_107": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "ForwardAttentionV2_166": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "softmax_159": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "alignment",
                    "possible_values": [
                        [
                            "self.get_alignment_energies(attention_hidden_state, processed_memory, attention_weights_cat)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_160": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "logsumexp_236": {
                "variable": {
                    "value": "biased",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.cat(log_alpha_shift_padded, 2)",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "softmax_240": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "log_alpha_new",
                    "possible_values": [
                        [
                            "biased + log_energy",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_242": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "dropout_84": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(linear(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_233": {
                "variable": {
                    "value": "shift_padded",
                    "possible_values": []
                },
                "input": {
                    "value": "shifted",
                    "possible_values": [
                        [
                            "log_alpha[:, :max_time - sft]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "(sft, 0)",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "possible_values": []
                },
                "value": {
                    "value": "self.score_mask_value",
                    "possible_values": []
                }
            },
            "tanh_136": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "tanh_195": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "cat_236": {
                "tensors": {
                    "value": "log_alpha_shift_padded",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "relu_84": {
                "input": {
                    "value": "linear(x)",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/beam.py": {
        "torch": {
            "stack_183": {
                "tensors": {
                    "value": "hidden[::-1]",
                    "possible_values": []
                }
            },
            "min_238": {
                "input": {
                    "value": "beam.attn[-1]",
                    "possible_values": []
                }
            },
            "sum_238": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/decoder.py": {
        "torch": {
            "Decoder_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_31": {
                    "variable": {
                        "value": "self.attention_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.prenet_dim[-1] + self.hidden_cat_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.attention_rnn_dim",
                        "possible_values": []
                    }
                },
                "LSTMCell_41": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.hidden_cat_dim + hparams.attention_rnn_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "stack_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [alignment]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_152": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mel_outputs",
                    "possible_values": [
                        [
                            "torch.stack(mel_outputs).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "mel_outputs.view(mel_outputs.size(0), -1, self.n_mel_channels)",
                            "Call"
                        ],
                        [
                            "mel_outputs.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "mel_outputs + [mel_output.squeeze(1)]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_152": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_162": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "attention_weights_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weights.unsqueeze(1), self.attention_weights_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_176": {
                "variable": {
                    "value": "decoder_rnn_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_204": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "unsqueeze_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_218": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_256": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sigmoid_267": {
                "input": {
                    "value": "stop_output.data",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/layers.py": {
        "torch": {
            "SpeakerClassifier_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_36": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                }
            },
            "SpeakerEncoder_54": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_61": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.n_mel_channels",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "2",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    },
                    "dropout": {
                        "value": "hparams.speaker_encoder_dropout",
                        "possible_values": []
                    }
                }
            },
            "MergeNet_115": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_121": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioEncoder_150": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_163": {
                    "variable": {
                        "value": "self.lstm1",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "LSTM_166": {
                    "variable": {
                        "value": "self.lstm2",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.audio_encoder_hidden_dim * hparams.n_frames_per_step_encoder",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioSeq2seq_219": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_235": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.symbols_embedding_dim + hparams.audio_encoder_hidden_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "TextEncoder_465": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_483": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                },
                "LSTM_485": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "PostNet_561": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_568": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "pack_padded_sequence_80": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_86": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "tanh_91": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "tanh_106": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "argmax_110": {
                "variable": {
                    "value": "pid",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self.projection_to_A(hidden)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_130": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_136": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_183": {
                "variable": {
                    "value": "x_packed",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_189": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "total_length": {
                    "value": "x.size(1)",
                    "possible_values": []
                }
            },
            "ceil_194": {
                "variable": {
                    "value": "output_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_195": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "output_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_201": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "stack_303": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [attention_weights]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_303": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_305": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "tensors": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_305": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_306": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_306": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_312": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_318": {
                "variable": {
                    "value": "attention_weigths_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weigths.unsqueeze(1), self.attention_weigths_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_331": {
                "variable": {
                    "value": "hidden_and_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.decoder_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_356": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(start_embedding.unsqueeze(0), decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_534": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths",
                    "possible_values": [
                        [
                            "sorted_lengths.cpu().numpy()",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_540": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_614": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.convolutions[-1](x)",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_26": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(in_dim, out_dim, kernel_size=hparams.SC_kernel_size, stride=1, padding=int((hparams.SC_kernel_size - 1) / 2), dilation=1, w_init_gain='leaky_relu', param=0.2)",
                    "possible_values": []
                }
            },
            "argmax_403": {
                "variable": {
                    "value": "phone_id",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_443": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_475": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, kernel_size=hparams.encoder_kernel_size, stride=1, padding=int((hparams.encoder_kernel_size - 1) / 2), dilation=1, w_init_gain='relu')",
                    "possible_values": []
                }
            },
            "dropout_523": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_549": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_613": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tanh(self.convolutions[i](x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "sum_89": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_94": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_105": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_107": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_336": {
                "input": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_571": {
                "*args": {
                    "value": "ConvNorm(hparams.n_mel_channels, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "Sequential_598": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, out_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='linear')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_33": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "LeakyReLU_34": {
                "negative_slope": {
                    "value": "0.2",
                    "possible_values": []
                }
            },
            "Sequential_240": {
                "*args": {
                    "value": "LinearNorm(self.decoder_rnn_dim + hparams.audio_encoder_hidden_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_250": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_481": {
                "num_features": {
                    "value": "hparams.encoder_embedding_dim",
                    "possible_values": []
                }
            },
            "Sequential_493": {
                "*args": {
                    "value": "LinearNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_503": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "relu_523": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "relu_549": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "BatchNorm1d_576": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            },
            "Sequential_581": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_603": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tanh_613": {
                "input": {
                    "value": "self.convolutions[i](x)",
                    "possible_values": []
                }
            },
            "Tanh_252": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tanh_505": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_587": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/loss.py": {
        "torch": {
            "ParrotLoss_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "L1Loss_10": {
                    "variable": {
                        "value": "self.L1Loss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "MSELoss_11": {
                    "variable": {
                        "value": "self.MSELoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "BCEWithLogitsLoss_12": {
                    "variable": {
                        "value": "self.BCEWithLogitsLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "CrossEntropyLoss_13": {
                    "variable": {
                        "value": "self.CrossEntropyLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                }
            },
            "ones_174": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, 1)",
                    "possible_values": []
                }
            },
            "Linear_176": {
                "variable": {
                    "value": "net1",
                    "possible_values": []
                },
                "in_features": {
                    "value": "1",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_180": {
                "variable": {
                    "value": "net2",
                    "possible_values": []
                },
                "in_features": {
                    "value": "1",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "SGD_206": {
                "variable": {
                    "value": "opt",
                    "possible_values": []
                },
                "params": {
                    "value": "all_params",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "lr": {
                    "value": "0.1",
                    "possible_values": []
                }
            },
            "tensor_41": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "data": {
                    "value": "text_target.data.new(B, 1).zero_()",
                    "possible_values": []
                }
            },
            "cat_42": {
                "variable": {
                    "value": "text_target",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(text_target, padded)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ceil_79": {
                "variable": {
                    "value": "mel_step_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "tensor_127": {
                "variable": {
                    "value": "speaker_encoder_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "tensor_128": {
                "variable": {
                    "value": "speaker_encoder_acc",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "max_144": {
                "variable": {
                    "value": "(_, predicted_text)",
                    "possible_values": []
                },
                "input": {
                    "value": "text_logit_flatten",
                    "possible_values": [
                        [
                            "text_logit_from_mel_hidden.reshape(-1, n_symbols_plus_one)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "tensor_97": {
                "variable": {
                    "value": "contrast_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "sum_108": {
                "variable": {
                    "value": "distance_matrix_xx",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_109": {
                "variable": {
                    "value": "distance_matrix_yy",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "bmm_113": {
                "variable": {
                    "value": "distance_matrix_xy",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed",
                    "possible_values": []
                },
                "mat2": {
                    "value": "torch.transpose(mel_hidden_normed, 1, 2)",
                    "possible_values": []
                }
            },
            "eye_117": {
                "variable": {
                    "value": "hard_alignments",
                    "possible_values": []
                },
                "n": {
                    "value": "TTEXT",
                    "possible_values": [
                        [
                            "distance_matrix.size(1)",
                            "Call"
                        ],
                        [
                            "speaker_logit_from_mel_hidden.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_86": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_93": {
                "input": {
                    "value": "stop_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_step_lengths, int(mel_target.size(2) / self.n_frames_per_step)).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_139": {
                "input": {
                    "value": "text_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_147": {
                "input": {
                    "value": "text_mask_plus_one",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths + 1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_150": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sigmoid_151": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_153": {
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "text_mask.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_91": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_113": {
                "input": {
                    "value": "mel_hidden_normed",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "sum_121": {
                "input": {
                    "value": "contrast_mask",
                    "possible_values": [
                        [
                            "contrast_mask1 & contrast_mask2",
                            "BinOp"
                        ],
                        [
                            "(contrast_mask1 & contrast_mask2).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_104": {
                "input": {
                    "value": "text_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "norm_105": {
                "input": {
                    "value": "mel_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_119": {
                "input": {
                    "value": "1.0 - distance_matrix",
                    "possible_values": []
                }
            },
            "sigmoid_132": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_119": {
                "input": {
                    "value": "distance_matrix",
                    "possible_values": [
                        [
                            "distance_matrix_xx + distance_matrix_yy - 2 * distance_matrix_xy",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/model/model.py": {
        "torch": {
            "Parrot_11": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_17": {
                    "variable": {
                        "value": "self.embedding",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "hparams.n_symbols + 1",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "hparams.symbols_embedding_dim",
                        "possible_values": []
                    }
                }
            },
            "Embedding_67": {
                "variable": {
                    "value": "self.sp_embedding",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "hparams.n_speakers",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "hparams.speaker_embedding_dim",
                    "possible_values": []
                }
            },
            "cat_138": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_185": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_120": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(mel_padded, speaker_embedding.detach().unsqueeze(2).expand(-1, -1, T))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_168": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(mel_padded, speaker_embedding.unsqueeze(2).expand(-1, -1, T))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/penalties.py": {
        "torch": {
            "max_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "sum_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "min_42": {
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "log_42": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_42": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model/utils.py": {
        "torch": {
            "arange_22": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "torch.max(lengths).item()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "torch.cuda.LongTensor(max_len)",
                    "possible_values": []
                }
            },
            "max_21": {
                "variable": {
                    "value": "max_len",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([3, 5, 4])",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ceil_36": {
                "input": {
                    "value": "lengths.float() / 2",
                    "possible_values": []
                }
            },
            "L1Loss_55": {
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "sum_45": {
                "input": {
                    "value": "m",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(lengths.cuda(), data.size(1))",
                            "Call"
                        ],
                        [
                            "m.unsqueeze(2).expand(-1, -1, data.size(2)).float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/model_1/basic_layers.py": {
        "torch": {
            "LinearNorm_40": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.linear_layer",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "in_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "out_dim",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "ConvNorm_53": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv1d_61": {
                    "variable": {
                        "value": "self.conv",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "in_channels",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "out_channels",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "kernel_size",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "stride": {
                        "value": "stride",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "padding": {
                        "value": "padding",
                        "possible_values": [
                            [
                                "int(dilation * (kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "int((attention_kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "None",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "dilation": {
                        "value": "dilation",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "Prenet_74": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_78": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[LinearNorm(in_size, out_size, bias=False) for (in_size, out_size) in zip(in_sizes, sizes)]",
                        "possible_values": []
                    }
                }
            },
            "LocationLayer_88": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "Attention_107": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "ForwardAttentionV2_166": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "softmax_159": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "alignment",
                    "possible_values": [
                        [
                            "self.get_alignment_energies(attention_hidden_state, processed_memory, attention_weights_cat)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_160": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "logsumexp_236": {
                "variable": {
                    "value": "biased",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.cat(log_alpha_shift_padded, 2)",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "softmax_240": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "log_alpha_new",
                    "possible_values": [
                        [
                            "biased + log_energy",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_242": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "dropout_84": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(linear(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_233": {
                "variable": {
                    "value": "shift_padded",
                    "possible_values": []
                },
                "input": {
                    "value": "shifted",
                    "possible_values": [
                        [
                            "log_alpha[:, :max_time - sft]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "(sft, 0)",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "possible_values": []
                },
                "value": {
                    "value": "self.score_mask_value",
                    "possible_values": []
                }
            },
            "tanh_136": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "tanh_195": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "cat_236": {
                "tensors": {
                    "value": "log_alpha_shift_padded",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "relu_84": {
                "input": {
                    "value": "linear(x)",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model_1/beam.py": {
        "torch": {
            "stack_183": {
                "tensors": {
                    "value": "hidden[::-1]",
                    "possible_values": []
                }
            },
            "min_238": {
                "input": {
                    "value": "beam.attn[-1]",
                    "possible_values": []
                }
            },
            "sum_238": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model_1/decoder.py": {
        "torch": {
            "Decoder_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_31": {
                    "variable": {
                        "value": "self.attention_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.prenet_dim[-1] + self.hidden_cat_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.attention_rnn_dim",
                        "possible_values": []
                    }
                },
                "LSTMCell_41": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.hidden_cat_dim + hparams.attention_rnn_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "stack_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [alignment]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_152": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mel_outputs",
                    "possible_values": [
                        [
                            "torch.stack(mel_outputs).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "mel_outputs.view(mel_outputs.size(0), -1, self.n_mel_channels)",
                            "Call"
                        ],
                        [
                            "mel_outputs.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "mel_outputs + [mel_output.squeeze(1)]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_152": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_162": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "attention_weights_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weights.unsqueeze(1), self.attention_weights_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_176": {
                "variable": {
                    "value": "decoder_rnn_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_204": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "unsqueeze_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_218": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_256": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sigmoid_267": {
                "input": {
                    "value": "stop_output.data",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model_1/layers.py": {
        "torch": {
            "SpeakerClassifier_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_36": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                }
            },
            "SpeakerEncoder_55": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_62": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.n_mel_channels",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "2",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    },
                    "dropout": {
                        "value": "hparams.speaker_encoder_dropout",
                        "possible_values": []
                    }
                }
            },
            "MergeNet_116": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_122": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioEncoder_151": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_164": {
                    "variable": {
                        "value": "self.lstm1",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "LSTM_167": {
                    "variable": {
                        "value": "self.lstm2",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.audio_encoder_hidden_dim * hparams.n_frames_per_step_encoder",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioSeq2seq_220": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_236": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.symbols_embedding_dim + hparams.audio_encoder_hidden_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "TextEncoder_466": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_484": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                },
                "LSTM_486": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "PostNet_562": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_569": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "pack_padded_sequence_81": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_87": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "tanh_92": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "tanh_107": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "argmax_111": {
                "variable": {
                    "value": "pid",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self.projection_to_A(hidden)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_131": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_137": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_184": {
                "variable": {
                    "value": "x_packed",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_190": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "total_length": {
                    "value": "x.size(1)",
                    "possible_values": []
                }
            },
            "ceil_195": {
                "variable": {
                    "value": "output_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_196": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "output_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_202": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "stack_304": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [attention_weights]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_304": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_306": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "tensors": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_306": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_307": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_307": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_313": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_319": {
                "variable": {
                    "value": "attention_weigths_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weigths.unsqueeze(1), self.attention_weigths_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_332": {
                "variable": {
                    "value": "hidden_and_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.decoder_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_357": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(start_embedding.unsqueeze(0), decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_535": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths",
                    "possible_values": [
                        [
                            "sorted_lengths.cpu().numpy()",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_541": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_615": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.convolutions[-1](x)",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_26": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(in_dim, out_dim, kernel_size=hparams.SC_kernel_size, stride=1, padding=int((hparams.SC_kernel_size - 1) / 2), dilation=1, w_init_gain='leaky_relu', param=0.2)",
                    "possible_values": []
                }
            },
            "argmax_404": {
                "variable": {
                    "value": "phone_id",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_444": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_476": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, kernel_size=hparams.encoder_kernel_size, stride=1, padding=int((hparams.encoder_kernel_size - 1) / 2), dilation=1, w_init_gain='relu')",
                    "possible_values": []
                }
            },
            "dropout_524": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_550": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_614": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tanh(self.convolutions[i](x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "sum_90": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_95": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_106": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_108": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_337": {
                "input": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_572": {
                "*args": {
                    "value": "ConvNorm(hparams.n_mel_channels, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "Sequential_599": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, out_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='linear')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_33": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "LeakyReLU_34": {
                "negative_slope": {
                    "value": "0.2",
                    "possible_values": []
                }
            },
            "Sequential_241": {
                "*args": {
                    "value": "LinearNorm(self.decoder_rnn_dim + hparams.audio_encoder_hidden_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_251": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_482": {
                "num_features": {
                    "value": "hparams.encoder_embedding_dim",
                    "possible_values": []
                }
            },
            "Sequential_494": {
                "*args": {
                    "value": "LinearNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_504": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "relu_524": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "relu_550": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "BatchNorm1d_577": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            },
            "Sequential_582": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_604": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tanh_614": {
                "input": {
                    "value": "self.convolutions[i](x)",
                    "possible_values": []
                }
            },
            "Tanh_253": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tanh_506": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_588": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model_1/loss.py": {
        "torch": {
            "ParrotLoss_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "L1Loss_12": {
                    "variable": {
                        "value": "self.L1Loss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "MSELoss_13": {
                    "variable": {
                        "value": "self.MSELoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "BCEWithLogitsLoss_14": {
                    "variable": {
                        "value": "self.BCEWithLogitsLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "CrossEntropyLoss_15": {
                    "variable": {
                        "value": "self.CrossEntropyLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                }
            },
            "tensor_40": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "data": {
                    "value": "text_target.data.new(B, 1).zero_()",
                    "possible_values": []
                }
            },
            "cat_41": {
                "variable": {
                    "value": "text_target",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(text_target, padded)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ceil_77": {
                "variable": {
                    "value": "mel_step_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "max_126": {
                "variable": {
                    "value": "(_, predicted_speaker)",
                    "possible_values": []
                },
                "input": {
                    "value": "speaker_logit_from_mel",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_130": {
                "variable": {
                    "value": "(_, predicted_speaker)",
                    "possible_values": []
                },
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_140": {
                "variable": {
                    "value": "(_, predicted_text)",
                    "possible_values": []
                },
                "input": {
                    "value": "text_logit_flatten",
                    "possible_values": [
                        [
                            "text_logit_from_mel_hidden.reshape(-1, n_symbols_plus_one)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "tensor_95": {
                "variable": {
                    "value": "contrast_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "sum_105": {
                "variable": {
                    "value": "distance_matrix_xx",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_106": {
                "variable": {
                    "value": "distance_matrix_yy",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "bmm_110": {
                "variable": {
                    "value": "distance_matrix_xy",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed",
                    "possible_values": []
                },
                "mat2": {
                    "value": "torch.transpose(mel_hidden_normed, 1, 2)",
                    "possible_values": []
                }
            },
            "eye_114": {
                "variable": {
                    "value": "hard_alignments",
                    "possible_values": []
                },
                "n": {
                    "value": "TTEXT",
                    "possible_values": [
                        [
                            "distance_matrix.size(1)",
                            "Call"
                        ],
                        [
                            "speaker_logit_from_mel_hidden.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_84": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_91": {
                "input": {
                    "value": "stop_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_step_lengths, int(mel_target.size(2) / self.n_frames_per_step)).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_125": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_135": {
                "input": {
                    "value": "text_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_143": {
                "input": {
                    "value": "text_mask_plus_one",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths + 1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_146": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_147": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_89": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_110": {
                "input": {
                    "value": "mel_hidden_normed",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "sum_118": {
                "input": {
                    "value": "contrast_mask",
                    "possible_values": [
                        [
                            "(contrast_mask1 & contrast_mask2).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_153": {
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "text_mask.unsqueeze(2).expand(-1, -1, n_speakers).reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_101": {
                "input": {
                    "value": "text_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "norm_102": {
                "input": {
                    "value": "mel_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_116": {
                "input": {
                    "value": "1.0 - distance_matrix",
                    "possible_values": []
                }
            },
            "zeros_like_116": {
                "input": {
                    "value": "distance_matrix",
                    "possible_values": [
                        [
                            "distance_matrix_xx + distance_matrix_yy - 2 * distance_matrix_xy",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/model_1/loss_original.py": {
        "torch": {
            "ParrotLoss_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "L1Loss_10": {
                    "variable": {
                        "value": "self.L1Loss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "MSELoss_11": {
                    "variable": {
                        "value": "self.MSELoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "BCEWithLogitsLoss_12": {
                    "variable": {
                        "value": "self.BCEWithLogitsLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "CrossEntropyLoss_13": {
                    "variable": {
                        "value": "self.CrossEntropyLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                }
            },
            "ones_174": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "*size": {
                    "value": "(1, 1)",
                    "possible_values": []
                }
            },
            "Linear_176": {
                "variable": {
                    "value": "net1",
                    "possible_values": []
                },
                "in_features": {
                    "value": "1",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_180": {
                "variable": {
                    "value": "net2",
                    "possible_values": []
                },
                "in_features": {
                    "value": "1",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "SGD_206": {
                "variable": {
                    "value": "opt",
                    "possible_values": []
                },
                "params": {
                    "value": "all_params",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "lr": {
                    "value": "0.1",
                    "possible_values": []
                }
            },
            "tensor_41": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "data": {
                    "value": "text_target.data.new(B, 1).zero_()",
                    "possible_values": []
                }
            },
            "cat_42": {
                "variable": {
                    "value": "text_target",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(text_target, padded)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ceil_79": {
                "variable": {
                    "value": "mel_step_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "tensor_127": {
                "variable": {
                    "value": "speaker_encoder_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "tensor_128": {
                "variable": {
                    "value": "speaker_encoder_acc",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "max_144": {
                "variable": {
                    "value": "(_, predicted_text)",
                    "possible_values": []
                },
                "input": {
                    "value": "text_logit_flatten",
                    "possible_values": [
                        [
                            "text_logit_from_mel_hidden.reshape(-1, n_symbols_plus_one)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "tensor_97": {
                "variable": {
                    "value": "contrast_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "sum_108": {
                "variable": {
                    "value": "distance_matrix_xx",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_109": {
                "variable": {
                    "value": "distance_matrix_yy",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "bmm_113": {
                "variable": {
                    "value": "distance_matrix_xy",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed",
                    "possible_values": []
                },
                "mat2": {
                    "value": "torch.transpose(mel_hidden_normed, 1, 2)",
                    "possible_values": []
                }
            },
            "eye_117": {
                "variable": {
                    "value": "hard_alignments",
                    "possible_values": []
                },
                "n": {
                    "value": "TTEXT",
                    "possible_values": [
                        [
                            "distance_matrix.size(1)",
                            "Call"
                        ],
                        [
                            "speaker_logit_from_mel_hidden.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_86": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_93": {
                "input": {
                    "value": "stop_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_step_lengths, int(mel_target.size(2) / self.n_frames_per_step)).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_139": {
                "input": {
                    "value": "text_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_147": {
                "input": {
                    "value": "text_mask_plus_one",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths + 1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_150": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sigmoid_151": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_153": {
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "text_mask.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_91": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_113": {
                "input": {
                    "value": "mel_hidden_normed",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "sum_121": {
                "input": {
                    "value": "contrast_mask",
                    "possible_values": [
                        [
                            "contrast_mask1 & contrast_mask2",
                            "BinOp"
                        ],
                        [
                            "(contrast_mask1 & contrast_mask2).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_104": {
                "input": {
                    "value": "text_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "norm_105": {
                "input": {
                    "value": "mel_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_119": {
                "input": {
                    "value": "1.0 - distance_matrix",
                    "possible_values": []
                }
            },
            "sigmoid_132": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_119": {
                "input": {
                    "value": "distance_matrix",
                    "possible_values": [
                        [
                            "distance_matrix_xx + distance_matrix_yy - 2 * distance_matrix_xy",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/model_1/model.py": {
        "torch": {
            "Parrot_11": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_17": {
                    "variable": {
                        "value": "self.embedding",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "hparams.n_symbols + 1",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "hparams.symbols_embedding_dim",
                        "possible_values": []
                    }
                }
            },
            "Embedding_52": {
                "variable": {
                    "value": "self.sp_embedding",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "hparams.n_speakers",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "hparams.speaker_embedding_dim",
                    "possible_values": []
                }
            },
            "cat_133": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_184": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_115": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(mel_padded, speaker_embedding.detach().unsqueeze(2).expand(-1, -1, T))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(mel_padded, speaker_embedding.unsqueeze(2).expand(-1, -1, T))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model_1/penalties.py": {
        "torch": {
            "max_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "sum_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "min_42": {
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "log_42": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_42": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/model_1/utils.py": {
        "torch": {
            "arange_22": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "torch.max(lengths).item()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "torch.cuda.LongTensor(max_len)",
                    "possible_values": []
                }
            },
            "max_21": {
                "variable": {
                    "value": "max_len",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([3, 5, 4])",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ceil_36": {
                "input": {
                    "value": "lengths.float() / 2",
                    "possible_values": []
                }
            },
            "L1Loss_55": {
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "sum_45": {
                "input": {
                    "value": "m",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(lengths.cuda(), data.size(1))",
                            "Call"
                        ],
                        [
                            "m.unsqueeze(2).expand(-1, -1, data.size(2)).float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/multiproc.py": {
        "torch": {
            "device_count_7": {
                "variable": {
                    "value": "num_gpus",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/reader/reader.py": {
        "torch": {
            "TextMelIDLoader_36": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.file_path_list": {
                    "value": "file_path_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "from_numpy_113": {
                "variable": {
                    "value": "mel",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.transpose(mel)",
                    "possible_values": []
                }
            },
            "from_numpy_114": {
                "variable": {
                    "value": "spc",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.transpose(spc)",
                    "possible_values": []
                }
            },
            "max_155": {
                "variable": {
                    "value": "max_text_len",
                    "possible_values": []
                },
                "input": {
                    "value": "text_lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([len(x[0]) for x in batch])",
                            "Call"
                        ]
                    ]
                }
            },
            "max_156": {
                "variable": {
                    "value": "max_mel_len",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([x[1].size(1) for x in batch])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "conversion/train.py": {
        "torch": {
            "DataLoader_64": {
                "variable": {
                    "value": "train_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(trainset) if hparams.distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "hparams.batch_size",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_94": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(os.path.join(output_directory, log_directory), 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_102": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(os.path.join(output_directory, log_directory), 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "Adam_225": {
                "variable": {
                    "value": "optimizer_main",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "Adam_227": {
                "variable": {
                    "value": "optimizer_sc",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "is_available_37": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "set_device_41": {
                "device": {
                    "value": "rank % torch.cuda.device_count()",
                    "possible_values": []
                }
            },
            "save_116": {
                "obj": {
                    "value": "{'iteration': iteration, 'state_dict': model.state_dict(), 'optimizer_main': optimizer_main.state_dict(), 'optimizer_sc': optimizer_sc.state_dict(), 'learning_rate': learning_rate}",
                    "possible_values": []
                },
                "f": {
                    "value": "filepath",
                    "possible_values": []
                }
            },
            "DataLoader_129": {
                "variable": {
                    "value": "val_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(valset) if distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "2",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_217": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "manual_seed_218": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "DistributedSampler_61": {
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_127": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "clip_grad_norm__315": {
                "variable": {
                    "value": "grad_norm_sc",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            },
            "device_count_41": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "DistributedSampler_128": {
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__304": {
                "variable": {
                    "value": "grad_norm_main",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            }
        }
    },
    "conversion/train_src.py": {
        "torch": {
            "DataLoader_64": {
                "variable": {
                    "value": "train_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(trainset) if hparams.distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "hparams.batch_size",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_94": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(os.path.join(output_directory, log_directory), 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_102": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(os.path.join(output_directory, log_directory), 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "Adam_225": {
                "variable": {
                    "value": "optimizer_main",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "Adam_227": {
                "variable": {
                    "value": "optimizer_sc",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "is_available_37": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "set_device_41": {
                "device": {
                    "value": "rank % torch.cuda.device_count()",
                    "possible_values": []
                }
            },
            "save_116": {
                "obj": {
                    "value": "{'iteration': iteration, 'state_dict': model.state_dict(), 'optimizer_main': optimizer_main.state_dict(), 'optimizer_sc': optimizer_sc.state_dict(), 'learning_rate': learning_rate}",
                    "possible_values": []
                },
                "f": {
                    "value": "filepath",
                    "possible_values": []
                }
            },
            "DataLoader_129": {
                "variable": {
                    "value": "val_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(valset) if distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "2",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_217": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "manual_seed_218": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "DistributedSampler_61": {
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_127": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "clip_grad_norm__315": {
                "variable": {
                    "value": "grad_norm_sc",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            },
            "device_count_41": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "DistributedSampler_128": {
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std, hparams.speaker_A, hparams.speaker_B, pids=None)",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__304": {
                "variable": {
                    "value": "grad_norm_main",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/acrnn_test.py": {
        "torch": {
            "acrnn_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_classes": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "4",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.is_training": {
                    "value": "is_training",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.L1": {
                    "value": "L1",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.L2": {
                    "value": "L2",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.cell_units": {
                    "value": "cell_units",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.num_linear": {
                    "value": "num_linear",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.p": {
                    "value": "p",
                    "possible_values": [
                        [
                            "10",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.time_step": {
                    "value": "time_step",
                    "possible_values": [
                        [
                            "800",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.F1": {
                    "value": "F1",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "Conv2d_24": {
                    "variable": {
                        "value": "self.conv1",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "3",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L1",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_25": {
                    "variable": {
                        "value": "self.conv2",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L1",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_26": {
                    "variable": {
                        "value": "self.conv3",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_27": {
                    "variable": {
                        "value": "self.conv4",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_28": {
                    "variable": {
                        "value": "self.conv5",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_29": {
                    "variable": {
                        "value": "self.conv6",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Linear_31": {
                    "variable": {
                        "value": "self.linear1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.p * self.L2",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_linear",
                        "possible_values": []
                    }
                },
                "BatchNorm1d_32": {
                    "variable": {
                        "value": "self.bn",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "self.num_linear",
                        "possible_values": []
                    }
                },
                "LeakyReLU_36": {
                    "variable": {
                        "value": "self.relu",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.01",
                        "possible_values": []
                    }
                },
                "Dropout2d_37": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "self.dropout_prob",
                        "possible_values": []
                    }
                },
                "LSTM_39": {
                    "variable": {
                        "value": "self.rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.num_linear",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.cell_units",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.a_fc1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * self.cell_units",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Linear_44": {
                    "variable": {
                        "value": "self.a_fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "1",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Sigmoid_45": {
                    "variable": {
                        "value": "self.sigmoid",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "Softmax_46": {
                    "variable": {
                        "value": "self.softmax",
                        "possible_values": []
                    },
                    "dim": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Linear_49": {
                    "variable": {
                        "value": "self.fc1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * self.cell_units",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.F1",
                        "possible_values": []
                    }
                },
                "Linear_50": {
                    "variable": {
                        "value": "self.fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.F1",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_classes",
                        "possible_values": []
                    }
                }
            },
            "max_pool2d_56": {
                "variable": {
                    "value": "layer1",
                    "possible_values": []
                },
                "input": {
                    "value": "layer1",
                    "possible_values": [
                        [
                            "self.relu(self.conv1(x))",
                            "Call"
                        ],
                        [
                            "F.max_pool2d(layer1, kernel_size=(2, 4), stride=(2, 4))",
                            "Call"
                        ],
                        [
                            "self.dropout(layer1)",
                            "Call"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "(2, 4)",
                    "possible_values": []
                },
                "stride": {
                    "value": "(2, 4)",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/distributed.py": {
        "torch": {
            "DistributedDataParallel_50": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.module": {
                    "value": "module",
                    "possible_values": []
                }
            },
            "cat_19": {
                "variable": {
                    "value": "flat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[t.contiguous().view(-1) for t in tensors]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_134": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_65": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "is_tensor_132": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_63": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fine-tune/inference.py": {
        "torch": {
            "DataLoader_61": {
                "variable": {
                    "value": "test_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, shuffle=True)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_130": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "load_53": {
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "'/home/zhoukun/nonparaSeq2seqVC_code-master/pre-train/outdir/checkpoint_234000'",
                            "Constant"
                        ]
                    ]
                }
            }
        }
    },
    "fine-tune/logger.py": {
        "torch": {
            "sigmoid_114": {
                "input": {
                    "value": "predicted_stop[idx]",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/acrnn_test.py": {
        "torch": {
            "acrnn_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_classes": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "4",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.is_training": {
                    "value": "is_training",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.L1": {
                    "value": "L1",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.L2": {
                    "value": "L2",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.cell_units": {
                    "value": "cell_units",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.num_linear": {
                    "value": "num_linear",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.p": {
                    "value": "p",
                    "possible_values": [
                        [
                            "10",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.time_step": {
                    "value": "time_step",
                    "possible_values": [
                        [
                            "800",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.F1": {
                    "value": "F1",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "Conv2d_24": {
                    "variable": {
                        "value": "self.conv1",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "3",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L1",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_25": {
                    "variable": {
                        "value": "self.conv2",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L1",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_26": {
                    "variable": {
                        "value": "self.conv3",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_27": {
                    "variable": {
                        "value": "self.conv4",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_28": {
                    "variable": {
                        "value": "self.conv5",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_29": {
                    "variable": {
                        "value": "self.conv6",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Linear_31": {
                    "variable": {
                        "value": "self.linear1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.p * self.L2",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_linear",
                        "possible_values": []
                    }
                },
                "BatchNorm1d_32": {
                    "variable": {
                        "value": "self.bn",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "self.num_linear",
                        "possible_values": []
                    }
                },
                "LeakyReLU_36": {
                    "variable": {
                        "value": "self.relu",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.01",
                        "possible_values": []
                    }
                },
                "Dropout2d_37": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "self.dropout_prob",
                        "possible_values": []
                    }
                },
                "LSTM_39": {
                    "variable": {
                        "value": "self.rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.num_linear",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.cell_units",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.a_fc1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * self.cell_units",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Linear_44": {
                    "variable": {
                        "value": "self.a_fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "1",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Sigmoid_45": {
                    "variable": {
                        "value": "self.sigmoid",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "Softmax_46": {
                    "variable": {
                        "value": "self.softmax",
                        "possible_values": []
                    },
                    "dim": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Linear_49": {
                    "variable": {
                        "value": "self.fc1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * self.cell_units",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.F1",
                        "possible_values": []
                    }
                },
                "Linear_50": {
                    "variable": {
                        "value": "self.fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.F1",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_classes",
                        "possible_values": []
                    }
                }
            },
            "max_pool2d_56": {
                "variable": {
                    "value": "layer1",
                    "possible_values": []
                },
                "input": {
                    "value": "layer1",
                    "possible_values": [
                        [
                            "self.relu(self.conv1(x))",
                            "Call"
                        ],
                        [
                            "F.max_pool2d(layer1, kernel_size=(2, 4), stride=(2, 4))",
                            "Call"
                        ],
                        [
                            "self.dropout(layer1)",
                            "Call"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "(2, 4)",
                    "possible_values": []
                },
                "stride": {
                    "value": "(2, 4)",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/basic_layers.py": {
        "torch": {
            "LinearNorm_40": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.linear_layer",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "in_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "out_dim",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "ConvNorm_53": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv1d_61": {
                    "variable": {
                        "value": "self.conv",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "in_channels",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "out_channels",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "kernel_size",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "stride": {
                        "value": "stride",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "padding": {
                        "value": "padding",
                        "possible_values": [
                            [
                                "int(dilation * (kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "int((attention_kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "None",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "dilation": {
                        "value": "dilation",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "Prenet_74": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_78": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[LinearNorm(in_size, out_size, bias=False) for (in_size, out_size) in zip(in_sizes, sizes)]",
                        "possible_values": []
                    }
                }
            },
            "LocationLayer_88": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "Attention_107": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "ForwardAttentionV2_166": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "softmax_159": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "alignment",
                    "possible_values": [
                        [
                            "self.get_alignment_energies(attention_hidden_state, processed_memory, attention_weights_cat)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_160": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "logsumexp_236": {
                "variable": {
                    "value": "biased",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.cat(log_alpha_shift_padded, 2)",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "softmax_240": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "log_alpha_new",
                    "possible_values": [
                        [
                            "biased + log_energy",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_242": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "dropout_84": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(linear(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_233": {
                "variable": {
                    "value": "shift_padded",
                    "possible_values": []
                },
                "input": {
                    "value": "shifted",
                    "possible_values": [
                        [
                            "log_alpha[:, :max_time - sft]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "(sft, 0)",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "possible_values": []
                },
                "value": {
                    "value": "self.score_mask_value",
                    "possible_values": []
                }
            },
            "tanh_136": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "tanh_195": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "cat_236": {
                "tensors": {
                    "value": "log_alpha_shift_padded",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "relu_84": {
                "input": {
                    "value": "linear(x)",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/beam.py": {
        "torch": {
            "stack_183": {
                "tensors": {
                    "value": "hidden[::-1]",
                    "possible_values": []
                }
            },
            "min_238": {
                "input": {
                    "value": "beam.attn[-1]",
                    "possible_values": []
                }
            },
            "sum_238": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/decoder.py": {
        "torch": {
            "Decoder_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_31": {
                    "variable": {
                        "value": "self.attention_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.prenet_dim[-1] + self.hidden_cat_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.attention_rnn_dim",
                        "possible_values": []
                    }
                },
                "LSTMCell_41": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.hidden_cat_dim + hparams.attention_rnn_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "stack_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [alignment]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_151": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mel_outputs",
                    "possible_values": [
                        [
                            "torch.stack(mel_outputs).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "mel_outputs.view(mel_outputs.size(0), -1, self.n_mel_channels)",
                            "Call"
                        ],
                        [
                            "mel_outputs.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "mel_outputs + [mel_output.squeeze(1)]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_151": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_161": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_165": {
                "variable": {
                    "value": "attention_weights_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weights.unsqueeze(1), self.attention_weights_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_175": {
                "variable": {
                    "value": "decoder_rnn_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_203": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "unsqueeze_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_217": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_255": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sigmoid_266": {
                "input": {
                    "value": "stop_output.data",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/layers.py": {
        "torch": {
            "SpeakerClassifier_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_36": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                }
            },
            "SpeakerEncoder_53": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_60": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.n_mel_channels",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "2",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    },
                    "dropout": {
                        "value": "hparams.speaker_encoder_dropout",
                        "possible_values": []
                    }
                }
            },
            "MergeNet_113": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_119": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioEncoder_148": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_161": {
                    "variable": {
                        "value": "self.lstm1",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "LSTM_163": {
                    "variable": {
                        "value": "self.lstm2",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.audio_encoder_hidden_dim * hparams.n_frames_per_step_encoder",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioSeq2seq_216": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_232": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.symbols_embedding_dim + hparams.audio_encoder_hidden_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "TextEncoder_460": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_478": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                },
                "LSTM_480": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "PostNet_556": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_563": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "pack_padded_sequence_78": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_84": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "tanh_89": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "tanh_104": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "argmax_108": {
                "variable": {
                    "value": "pid",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self.projection(hidden)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_128": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_134": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_180": {
                "variable": {
                    "value": "x_packed",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_186": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "total_length": {
                    "value": "x.size(1)",
                    "possible_values": []
                }
            },
            "ceil_191": {
                "variable": {
                    "value": "output_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_192": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "output_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_198": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "stack_298": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [attention_weights]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_298": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_300": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "tensors": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_300": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_301": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_301": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_307": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_313": {
                "variable": {
                    "value": "attention_weigths_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weigths.unsqueeze(1), self.attention_weigths_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_326": {
                "variable": {
                    "value": "hidden_and_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.decoder_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_351": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(start_embedding.unsqueeze(0), decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_529": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths",
                    "possible_values": [
                        [
                            "sorted_lengths.cpu().numpy()",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_535": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_609": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.convolutions[-1](x)",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_26": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(in_dim, out_dim, kernel_size=hparams.SC_kernel_size, stride=1, padding=int((hparams.SC_kernel_size - 1) / 2), dilation=1, w_init_gain='leaky_relu', param=0.2)",
                    "possible_values": []
                }
            },
            "argmax_398": {
                "variable": {
                    "value": "phone_id",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_438": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_470": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, kernel_size=hparams.encoder_kernel_size, stride=1, padding=int((hparams.encoder_kernel_size - 1) / 2), dilation=1, w_init_gain='relu')",
                    "possible_values": []
                }
            },
            "dropout_518": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_544": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_608": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tanh(self.convolutions[i](x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "sum_87": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_92": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_103": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_105": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_331": {
                "input": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_566": {
                "*args": {
                    "value": "ConvNorm(hparams.n_mel_channels, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "Sequential_593": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, out_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='linear')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_33": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "LeakyReLU_34": {
                "negative_slope": {
                    "value": "0.2",
                    "possible_values": []
                }
            },
            "Sequential_237": {
                "*args": {
                    "value": "LinearNorm(self.decoder_rnn_dim + hparams.audio_encoder_hidden_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_247": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_476": {
                "num_features": {
                    "value": "hparams.encoder_embedding_dim",
                    "possible_values": []
                }
            },
            "Sequential_488": {
                "*args": {
                    "value": "LinearNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_498": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "relu_518": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "relu_544": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "BatchNorm1d_571": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            },
            "Sequential_576": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_598": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tanh_608": {
                "input": {
                    "value": "self.convolutions[i](x)",
                    "possible_values": []
                }
            },
            "Tanh_249": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tanh_500": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_582": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/model.py": {
        "torch": {
            "Parrot_10": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_16": {
                    "variable": {
                        "value": "self.embedding",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "hparams.n_symbols + 1",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "hparams.symbols_embedding_dim",
                        "possible_values": []
                    }
                }
            },
            "cat_130": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.detach().unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_181": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.detach().unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_112": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mel_padded, speaker_embedding.detach().unsqueeze(2).expand(-1, -1, T)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_164": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mel_padded, speaker_embedding.detach().unsqueeze(2).expand(-1, -1, T)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/penalties.py": {
        "torch": {
            "max_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "sum_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "min_42": {
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "log_42": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_42": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/ser.py": {
        "torch": {
            "acrnn_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_classes": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "4",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.is_training": {
                    "value": "is_training",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.L1": {
                    "value": "L1",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.L2": {
                    "value": "L2",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.cell_units": {
                    "value": "cell_units",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.num_linear": {
                    "value": "num_linear",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.p": {
                    "value": "p",
                    "possible_values": [
                        [
                            "10",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.time_step": {
                    "value": "time_step",
                    "possible_values": [
                        [
                            "800",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.F1": {
                    "value": "F1",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ]
                    ]
                },
                "Conv2d_24": {
                    "variable": {
                        "value": "self.conv1",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "3",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L1",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_25": {
                    "variable": {
                        "value": "self.conv2",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L1",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_26": {
                    "variable": {
                        "value": "self.conv3",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_27": {
                    "variable": {
                        "value": "self.conv4",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_28": {
                    "variable": {
                        "value": "self.conv5",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Conv2d_29": {
                    "variable": {
                        "value": "self.conv6",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "self.L2",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "(5, 3)",
                        "possible_values": []
                    },
                    "padding": {
                        "value": "(2, 1)",
                        "possible_values": []
                    }
                },
                "Linear_31": {
                    "variable": {
                        "value": "self.linear1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.p * self.L2",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_linear",
                        "possible_values": []
                    }
                },
                "BatchNorm1d_32": {
                    "variable": {
                        "value": "self.bn",
                        "possible_values": []
                    },
                    "num_features": {
                        "value": "self.num_linear",
                        "possible_values": []
                    }
                },
                "LeakyReLU_36": {
                    "variable": {
                        "value": "self.relu",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "0.01",
                        "possible_values": []
                    }
                },
                "Dropout2d_37": {
                    "variable": {
                        "value": "self.dropout",
                        "possible_values": []
                    },
                    "p": {
                        "value": "self.dropout_prob",
                        "possible_values": []
                    }
                },
                "LSTM_39": {
                    "variable": {
                        "value": "self.rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.num_linear",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.cell_units",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.a_fc1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * self.cell_units",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Linear_44": {
                    "variable": {
                        "value": "self.a_fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "1",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Sigmoid_45": {
                    "variable": {
                        "value": "self.sigmoid",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                },
                "Softmax_46": {
                    "variable": {
                        "value": "self.softmax",
                        "possible_values": []
                    },
                    "dim": {
                        "value": "1",
                        "possible_values": []
                    }
                },
                "Linear_49": {
                    "variable": {
                        "value": "self.fc1",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "2 * self.cell_units",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.F1",
                        "possible_values": []
                    }
                },
                "Linear_50": {
                    "variable": {
                        "value": "self.fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.F1",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_classes",
                        "possible_values": []
                    }
                }
            },
            "max_pool2d_56": {
                "variable": {
                    "value": "layer1",
                    "possible_values": []
                },
                "input": {
                    "value": "layer1",
                    "possible_values": [
                        [
                            "self.relu(self.conv1(x))",
                            "Call"
                        ],
                        [
                            "F.max_pool2d(layer1, kernel_size=(2, 4), stride=(2, 4))",
                            "Call"
                        ],
                        [
                            "self.dropout(layer1)",
                            "Call"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "(2, 4)",
                    "possible_values": []
                },
                "stride": {
                    "value": "(2, 4)",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/model/utils.py": {
        "torch": {
            "arange_22": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "torch.max(lengths).item()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "torch.cuda.LongTensor(max_len)",
                    "possible_values": []
                }
            },
            "max_21": {
                "variable": {
                    "value": "max_len",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([3, 5, 4])",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ceil_36": {
                "input": {
                    "value": "lengths.float() / 2",
                    "possible_values": []
                }
            },
            "L1Loss_55": {
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "sum_45": {
                "input": {
                    "value": "m",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(lengths.cuda(), data.size(1))",
                            "Call"
                        ],
                        [
                            "m.unsqueeze(2).expand(-1, -1, data.size(2)).float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fine-tune/multiproc.py": {
        "torch": {
            "device_count_7": {
                "variable": {
                    "value": "num_gpus",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "fine-tune/reader/reader.py": {
        "torch": {
            "TextMelIDLoader_26": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.file_path_list": {
                    "value": "file_path_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "from_numpy_109": {
                "variable": {
                    "value": "mel",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.transpose(mel)",
                    "possible_values": []
                }
            },
            "from_numpy_110": {
                "variable": {
                    "value": "spc",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.transpose(spc)",
                    "possible_values": []
                }
            },
            "max_153": {
                "variable": {
                    "value": "max_text_len",
                    "possible_values": []
                },
                "input": {
                    "value": "text_lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([len(x[0]) for x in batch])",
                            "Call"
                        ]
                    ]
                }
            },
            "max_154": {
                "variable": {
                    "value": "max_mel_len",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([x[1].size(1) for x in batch])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fine-tune/train.py": {
        "torch": {
            "DataLoader_61": {
                "variable": {
                    "value": "train_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(trainset) if hparams.distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "hparams.batch_size",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_91": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(output_directory, 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_117": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(output_directory, 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "Adam_243": {
                "variable": {
                    "value": "optimizer_main",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "Adam_245": {
                "variable": {
                    "value": "optimizer_sc",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "is_available_37": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "set_device_41": {
                "device": {
                    "value": "rank % torch.cuda.device_count()",
                    "possible_values": []
                }
            },
            "save_131": {
                "obj": {
                    "value": "{'iteration': iteration, 'state_dict': model.state_dict(), 'optimizer_main': optimizer_main.state_dict(), 'optimizer_sc': optimizer_sc.state_dict(), 'learning_rate': learning_rate}",
                    "possible_values": []
                },
                "f": {
                    "value": "filepath",
                    "possible_values": []
                }
            },
            "DataLoader_144": {
                "variable": {
                    "value": "val_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(valset) if distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_232": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "manual_seed_233": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "DistributedSampler_58": {
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_80": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_142": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_235": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "clip_grad_norm__320": {
                "variable": {
                    "value": "grad_norm_main",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            },
            "clip_grad_norm__332": {
                "variable": {
                    "value": "grad_norm_sc",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            },
            "device_count_41": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "DistributedSampler_143": {
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                }
            },
            "empty_103": {
                "*size": {
                    "value": "(4, s[1])",
                    "possible_values": []
                }
            },
            "empty_105": {
                "*size": {
                    "value": "4",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/distributed.py": {
        "torch": {
            "DistributedDataParallel_50": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.module": {
                    "value": "module",
                    "possible_values": []
                }
            },
            "cat_19": {
                "variable": {
                    "value": "flat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[t.contiguous().view(-1) for t in tensors]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_134": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_65": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "is_tensor_132": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_63": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "list(module.state_dict().values())",
                            "Call"
                        ],
                        [
                            "list(self.module.state_dict().values())",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pre-train/inference.py": {
        "torch": {
            "DataLoader_61": {
                "variable": {
                    "value": "test_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_set",
                    "possible_values": [
                        [
                            "TextMelIDLoader(test_list, hparams.mel_mean_std, shuffle=True)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "sampler": {
                    "value": "None",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_130": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "load_53": {
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "'/home/zhoukun/nonparaSeq2seqVC_code-master/pre-train/outdir/checkpoint_234000'",
                            "Constant"
                        ]
                    ]
                }
            }
        }
    },
    "pre-train/logger.py": {
        "torch": {
            "sigmoid_114": {
                "input": {
                    "value": "predicted_stop[idx]",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/basic_layers.py": {
        "torch": {
            "LinearNorm_40": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Linear_43": {
                    "variable": {
                        "value": "self.linear_layer",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "in_dim",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "out_dim",
                        "possible_values": []
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "ConvNorm_53": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Conv1d_61": {
                    "variable": {
                        "value": "self.conv",
                        "possible_values": []
                    },
                    "in_channels": {
                        "value": "in_channels",
                        "possible_values": []
                    },
                    "out_channels": {
                        "value": "out_channels",
                        "possible_values": []
                    },
                    "kernel_size": {
                        "value": "kernel_size",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "stride": {
                        "value": "stride",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "padding": {
                        "value": "padding",
                        "possible_values": [
                            [
                                "int(dilation * (kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "int((attention_kernel_size - 1) / 2)",
                                "Call"
                            ],
                            [
                                "None",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "dilation": {
                        "value": "dilation",
                        "possible_values": [
                            [
                                "1",
                                "MethodArgument"
                            ]
                        ]
                    },
                    "bias": {
                        "value": "bias",
                        "possible_values": [
                            [
                                "True",
                                "MethodArgument"
                            ],
                            [
                                "True",
                                "MethodArgument"
                            ]
                        ]
                    }
                }
            },
            "Prenet_74": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_78": {
                    "variable": {
                        "value": "self.layers",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "[LinearNorm(in_size, out_size, bias=False) for (in_size, out_size) in zip(in_sizes, sizes)]",
                        "possible_values": []
                    }
                }
            },
            "LocationLayer_88": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "Attention_107": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "ForwardAttentionV2_166": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                }
            },
            "softmax_159": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "alignment",
                    "possible_values": [
                        [
                            "self.get_alignment_energies(attention_hidden_state, processed_memory, attention_weights_cat)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_160": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "logsumexp_236": {
                "variable": {
                    "value": "biased",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.cat(log_alpha_shift_padded, 2)",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "softmax_240": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "log_alpha_new",
                    "possible_values": [
                        [
                            "biased + log_energy",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_242": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "dropout_84": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(linear(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_233": {
                "variable": {
                    "value": "shift_padded",
                    "possible_values": []
                },
                "input": {
                    "value": "shifted",
                    "possible_values": [
                        [
                            "log_alpha[:, :max_time - sft]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "(sft, 0)",
                    "possible_values": []
                },
                "mode": {
                    "value": "constant",
                    "possible_values": []
                },
                "value": {
                    "value": "self.score_mask_value",
                    "possible_values": []
                }
            },
            "tanh_136": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "tanh_195": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "cat_236": {
                "tensors": {
                    "value": "log_alpha_shift_padded",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "relu_84": {
                "input": {
                    "value": "linear(x)",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/beam.py": {
        "torch": {
            "stack_183": {
                "tensors": {
                    "value": "hidden[::-1]",
                    "possible_values": []
                }
            },
            "min_238": {
                "input": {
                    "value": "beam.attn[-1]",
                    "possible_values": []
                }
            },
            "sum_238": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/decoder.py": {
        "torch": {
            "Decoder_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_31": {
                    "variable": {
                        "value": "self.attention_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.prenet_dim[-1] + self.hidden_cat_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.attention_rnn_dim",
                        "possible_values": []
                    }
                },
                "LSTMCell_41": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "self.hidden_cat_dim + hparams.attention_rnn_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "hparams.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "stack_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [alignment]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_143": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_151": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mel_outputs",
                    "possible_values": [
                        [
                            "torch.stack(mel_outputs).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "mel_outputs.view(mel_outputs.size(0), -1, self.n_mel_channels)",
                            "Call"
                        ],
                        [
                            "mel_outputs.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "mel_outputs + [mel_output.squeeze(1)]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_151": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_161": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_165": {
                "variable": {
                    "value": "attention_weights_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weights.unsqueeze(1), self.attention_weights_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_175": {
                "variable": {
                    "value": "decoder_rnn_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_203": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "unsqueeze_146": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "stop_outputs",
                    "possible_values": [
                        [
                            "torch.stack(stop_outputs).unsqueeze(0)",
                            "Call"
                        ],
                        [
                            "torch.stack(stop_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "stop_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "stop_outputs + [stop_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_148": {
                "variable": {
                    "value": "stop_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_217": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_255": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_rnn_output, context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sigmoid_266": {
                "input": {
                    "value": "stop_output.data",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/layers.py": {
        "torch": {
            "SpeakerClassifier_9": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_36": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                }
            },
            "SpeakerEncoder_53": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_60": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.n_mel_channels",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "2",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    },
                    "dropout": {
                        "value": "hparams.speaker_encoder_dropout",
                        "possible_values": []
                    }
                }
            },
            "MergeNet_113": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_119": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioEncoder_148": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTM_161": {
                    "variable": {
                        "value": "self.lstm1",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "input_dim",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                },
                "LSTM_163": {
                    "variable": {
                        "value": "self.lstm2",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.audio_encoder_hidden_dim * hparams.n_frames_per_step_encoder",
                        "possible_values": []
                    },
                    "num_layers": {
                        "value": "1",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "AudioSeq2seq_216": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "LSTMCell_232": {
                    "variable": {
                        "value": "self.decoder_rnn",
                        "possible_values": []
                    },
                    "input_size": {
                        "value": "hparams.symbols_embedding_dim + hparams.audio_encoder_hidden_dim",
                        "possible_values": []
                    },
                    "hidden_size": {
                        "value": "self.decoder_rnn_dim",
                        "possible_values": []
                    }
                }
            },
            "TextEncoder_460": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_478": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "modules": {
                        "value": "convolutions",
                        "possible_values": [
                            [
                                "[]",
                                "List"
                            ],
                            [
                                "[]",
                                "List"
                            ]
                        ]
                    }
                },
                "LSTM_480": {
                    "variable": {
                        "value": "self.lstm",
                        "possible_values": []
                    },
                    "*args": {
                        "value": "hparams.encoder_embedding_dim",
                        "possible_values": []
                    },
                    "batch_first": {
                        "value": "True",
                        "possible_values": []
                    },
                    "bidirectional": {
                        "value": "True",
                        "possible_values": []
                    }
                }
            },
            "PostNet_556": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "ModuleList_563": {
                    "variable": {
                        "value": "self.convolutions",
                        "possible_values": []
                    },
                    "params": {
                        "value": "default",
                        "possible_values": []
                    }
                }
            },
            "pack_padded_sequence_78": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_84": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "tanh_89": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "tanh_104": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.projection1(outputs)",
                    "possible_values": []
                }
            },
            "argmax_108": {
                "variable": {
                    "value": "pid",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "self.projection(hidden)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection2(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_128": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_134": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_180": {
                "variable": {
                    "value": "x_packed",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_186": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "total_length": {
                    "value": "x.size(1)",
                    "possible_values": []
                }
            },
            "ceil_191": {
                "variable": {
                    "value": "output_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_192": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "output_lengths.cpu().numpy()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_198": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "stack_298": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [attention_weights]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_298": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_300": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "tensors": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_300": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_301": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_301": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_307": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_313": {
                "variable": {
                    "value": "attention_weigths_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weigths.unsqueeze(1), self.attention_weigths_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_326": {
                "variable": {
                    "value": "hidden_and_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.decoder_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_351": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(start_embedding.unsqueeze(0), decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_529": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x_sorted",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_lengths",
                    "possible_values": [
                        [
                            "sorted_lengths.cpu().numpy()",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_535": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_609": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.convolutions[-1](x)",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_26": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(in_dim, out_dim, kernel_size=hparams.SC_kernel_size, stride=1, padding=int((hparams.SC_kernel_size - 1) / 2), dilation=1, w_init_gain='leaky_relu', param=0.2)",
                    "possible_values": []
                }
            },
            "argmax_398": {
                "variable": {
                    "value": "phone_id",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "log_softmax_438": {
                "variable": {
                    "value": "logit",
                    "possible_values": []
                },
                "input": {
                    "value": "logit",
                    "possible_values": [
                        [
                            "torch.stack(logit).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_n_symbols(F.dropout(hidden, 0.5, self.training))",
                            "Call"
                        ],
                        [
                            "F.log_softmax(logit, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_470": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, kernel_size=hparams.encoder_kernel_size, stride=1, padding=int((hparams.encoder_kernel_size - 1) / 2), dilation=1, w_init_gain='relu')",
                    "possible_values": []
                }
            },
            "dropout_518": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_544": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_608": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tanh(self.convolutions[i](x))",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "sum_87": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_92": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_103": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "norm_105": {
                "input": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "torch.sum(outputs, dim=1) / sorted_lengths.unsqueeze(1).float()",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "torch.sum(outputs, dim=1) / float(outputs.size(1))",
                            "BinOp"
                        ],
                        [
                            "F.tanh(self.projection1(outputs))",
                            "Call"
                        ],
                        [
                            "outputs[initial_index]",
                            "Subscript"
                        ],
                        [
                            "outputs.reshape(x.size(0), -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(outputs, output_lengths.cpu().numpy(), batch_first=True)",
                            "Call"
                        ],
                        [
                            "outputs.reshape(1, -1, self.concat_hidden_dim)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ],
                        [
                            "self.projection(outputs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_331": {
                "input": {
                    "value": "hidden",
                    "possible_values": [
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "conv(hidden)",
                            "Call"
                        ],
                        [
                            "hidden.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "torch.stack(hidden).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "self.project_to_hidden(hidden_and_context)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_566": {
                "*args": {
                    "value": "ConvNorm(hparams.n_mel_channels, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "Sequential_593": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, out_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='linear')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_33": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "LeakyReLU_34": {
                "negative_slope": {
                    "value": "0.2",
                    "possible_values": []
                }
            },
            "Sequential_237": {
                "*args": {
                    "value": "LinearNorm(self.decoder_rnn_dim + hparams.audio_encoder_hidden_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_247": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_476": {
                "num_features": {
                    "value": "hparams.encoder_embedding_dim",
                    "possible_values": []
                }
            },
            "Sequential_488": {
                "*args": {
                    "value": "LinearNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, w_init_gain=hparams.hidden_activation)",
                    "possible_values": []
                }
            },
            "ReLU_498": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "relu_518": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "relu_544": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "BatchNorm1d_571": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            },
            "Sequential_576": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_dim, hparams.postnet_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_598": {
                "num_features": {
                    "value": "out_dim",
                    "possible_values": [
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.SC_hidden_dim",
                            "Attribute"
                        ],
                        [
                            "hparams.n_spc_channels",
                            "Attribute"
                        ],
                        [
                            "hparams.n_mel_channels",
                            "Attribute"
                        ]
                    ]
                }
            },
            "tanh_608": {
                "input": {
                    "value": "self.convolutions[i](x)",
                    "possible_values": []
                }
            },
            "Tanh_249": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Tanh_500": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "BatchNorm1d_582": {
                "num_features": {
                    "value": "hparams.postnet_dim",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/loss.py": {
        "torch": {
            "ParrotLoss_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "L1Loss_12": {
                    "variable": {
                        "value": "self.L1Loss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "MSELoss_13": {
                    "variable": {
                        "value": "self.MSELoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "BCEWithLogitsLoss_14": {
                    "variable": {
                        "value": "self.BCEWithLogitsLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                },
                "CrossEntropyLoss_15": {
                    "variable": {
                        "value": "self.CrossEntropyLoss",
                        "possible_values": []
                    },
                    "reduction": {
                        "value": "none",
                        "possible_values": []
                    }
                }
            },
            "tensor_40": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "data": {
                    "value": "text_target.data.new(B, 1).zero_()",
                    "possible_values": []
                }
            },
            "cat_41": {
                "variable": {
                    "value": "text_target",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(text_target, padded)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "ceil_77": {
                "variable": {
                    "value": "mel_step_lengths",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths.float() / self.n_frames_per_step",
                    "possible_values": []
                }
            },
            "max_126": {
                "variable": {
                    "value": "(_, predicted_speaker)",
                    "possible_values": []
                },
                "input": {
                    "value": "speaker_logit_from_mel",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_130": {
                "variable": {
                    "value": "(_, predicted_speaker)",
                    "possible_values": []
                },
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "max_140": {
                "variable": {
                    "value": "(_, predicted_text)",
                    "possible_values": []
                },
                "input": {
                    "value": "text_logit_flatten",
                    "possible_values": [
                        [
                            "text_logit_from_mel_hidden.reshape(-1, n_symbols_plus_one)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "tensor_95": {
                "variable": {
                    "value": "contrast_loss",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "sum_105": {
                "variable": {
                    "value": "distance_matrix_xx",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_106": {
                "variable": {
                    "value": "distance_matrix_yy",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_hidden_normed ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "bmm_110": {
                "variable": {
                    "value": "distance_matrix_xy",
                    "possible_values": []
                },
                "input": {
                    "value": "text_hidden_normed",
                    "possible_values": []
                },
                "mat2": {
                    "value": "torch.transpose(mel_hidden_normed, 1, 2)",
                    "possible_values": []
                }
            },
            "eye_114": {
                "variable": {
                    "value": "hard_alignments",
                    "possible_values": []
                },
                "n": {
                    "value": "TTEXT",
                    "possible_values": [
                        [
                            "distance_matrix.size(1)",
                            "Call"
                        ],
                        [
                            "speaker_logit_from_mel_hidden.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_84": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_91": {
                "input": {
                    "value": "stop_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_step_lengths, int(mel_target.size(2) / self.n_frames_per_step)).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_125": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_135": {
                "input": {
                    "value": "text_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_143": {
                "input": {
                    "value": "text_mask_plus_one",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(text_lengths + 1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_146": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_147": {
                "input": {
                    "value": "speaker_logit_flatten",
                    "possible_values": [
                        [
                            "speaker_logit_from_mel_hidden.reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_89": {
                "input": {
                    "value": "mel_mask",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(mel_lengths, mel_target.size(2)).unsqueeze(1).expand(-1, mel_target.size(1), -1).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "transpose_110": {
                "input": {
                    "value": "mel_hidden_normed",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "sum_118": {
                "input": {
                    "value": "contrast_mask",
                    "possible_values": [
                        [
                            "(contrast_mask1 & contrast_mask2).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_153": {
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "text_mask.unsqueeze(2).expand(-1, -1, n_speakers).reshape(-1, n_speakers)",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_101": {
                "input": {
                    "value": "text_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "norm_102": {
                "input": {
                    "value": "mel_hidden",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_116": {
                "input": {
                    "value": "1.0 - distance_matrix",
                    "possible_values": []
                }
            },
            "zeros_like_116": {
                "input": {
                    "value": "distance_matrix",
                    "possible_values": [
                        [
                            "distance_matrix_xx + distance_matrix_yy - 2 * distance_matrix_xy",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "pre-train/model/model.py": {
        "torch": {
            "Parrot_10": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "Embedding_16": {
                    "variable": {
                        "value": "self.embedding",
                        "possible_values": []
                    },
                    "num_embeddings": {
                        "value": "hparams.n_symbols + 1",
                        "possible_values": []
                    },
                    "embedding_dim": {
                        "value": "hparams.symbols_embedding_dim",
                        "possible_values": []
                    }
                }
            },
            "cat_121": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.detach().unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_172": {
                "variable": {
                    "value": "hidden",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[hidden, speaker_embedding.detach().unsqueeze(1).expand(-1, L, -1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_103": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mel_padded, speaker_embedding.detach().unsqueeze(2).expand(-1, -1, T)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_155": {
                "variable": {
                    "value": "audio_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mel_padded, speaker_embedding.detach().unsqueeze(2).expand(-1, -1, T)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/penalties.py": {
        "torch": {
            "max_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "sum_49": {
                "variable": {
                    "value": "penalty",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "min_42": {
                "input": {
                    "value": "cov",
                    "possible_values": []
                }
            },
            "log_42": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "sum_42": {
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/model/utils.py": {
        "torch": {
            "arange_22": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "torch.max(lengths).item()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "torch.cuda.LongTensor(max_len)",
                    "possible_values": []
                }
            },
            "max_21": {
                "variable": {
                    "value": "max_len",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([3, 5, 4])",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ceil_36": {
                "input": {
                    "value": "lengths.float() / 2",
                    "possible_values": []
                }
            },
            "L1Loss_55": {
                "reduction": {
                    "value": "none",
                    "possible_values": []
                }
            },
            "sum_45": {
                "input": {
                    "value": "m",
                    "possible_values": [
                        [
                            "get_mask_from_lengths(lengths.cuda(), data.size(1))",
                            "Call"
                        ],
                        [
                            "m.unsqueeze(2).expand(-1, -1, data.size(2)).float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pre-train/multiproc.py": {
        "torch": {
            "device_count_7": {
                "variable": {
                    "value": "num_gpus",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "pre-train/reader/reader.py": {
        "torch": {
            "TextMelIDLoader_36": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.file_path_list": {
                    "value": "file_path_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "from_numpy_112": {
                "variable": {
                    "value": "mel",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.transpose(mel)",
                    "possible_values": []
                }
            },
            "from_numpy_113": {
                "variable": {
                    "value": "spc",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.transpose(spc)",
                    "possible_values": []
                }
            },
            "max_154": {
                "variable": {
                    "value": "max_text_len",
                    "possible_values": []
                },
                "input": {
                    "value": "text_lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([len(x[0]) for x in batch])",
                            "Call"
                        ]
                    ]
                }
            },
            "max_155": {
                "variable": {
                    "value": "max_mel_len",
                    "possible_values": []
                },
                "input": {
                    "value": "mel_lengths",
                    "possible_values": [
                        [
                            "torch.IntTensor([x[1].size(1) for x in batch])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "pre-train/train.py": {
        "torch": {
            "DataLoader_61": {
                "variable": {
                    "value": "train_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(trainset) if hparams.distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "hparams.batch_size",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_90": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(os.path.join(output_directory, log_directory), 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_98": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(os.path.join(output_directory, log_directory), 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "Adam_221": {
                "variable": {
                    "value": "optimizer_main",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "Adam_223": {
                "variable": {
                    "value": "optimizer_sc",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ],
                        [
                            "hparams.learning_rate * hparams.decay_rate ** ((epoch - hparams.warmup) // hparams.decay_every + 1)",
                            "BinOp"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "is_available_37": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "set_device_41": {
                "device": {
                    "value": "rank % torch.cuda.device_count()",
                    "possible_values": []
                }
            },
            "save_112": {
                "obj": {
                    "value": "{'iteration': iteration, 'state_dict': model.state_dict(), 'optimizer_main': optimizer_main.state_dict(), 'optimizer_sc': optimizer_sc.state_dict(), 'learning_rate': learning_rate}",
                    "possible_values": []
                },
                "f": {
                    "value": "filepath",
                    "possible_values": []
                }
            },
            "DataLoader_125": {
                "variable": {
                    "value": "val_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(valset) if distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "2",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelIDCollate(lcm(hparams.n_frames_per_step_encoder, hparams.n_frames_per_step_decoder))",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_213": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "manual_seed_214": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "DistributedSampler_58": {
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.training_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_123": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "clip_grad_norm__311": {
                "variable": {
                    "value": "grad_norm_sc",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_sc",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            },
            "device_count_41": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "DistributedSampler_124": {
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelIDLoader(hparams.validation_list, hparams.mel_mean_std)",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__300": {
                "variable": {
                    "value": "grad_norm_main",
                    "possible_values": []
                },
                "parameters": {
                    "value": "parameters_main",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            }
        }
    }
}