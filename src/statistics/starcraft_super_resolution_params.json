{
    "run.py": {
        "tensorflow": {}
    },
    "upres/modeling/model_trainer.py": {
        "tensorflow": {
            "create_file_writer_139": {
                "variable": {
                    "value": "file_writer",
                    "possible_values": []
                },
                "logdir": {
                    "value": "str(images_path)",
                    "possible_values": []
                },
                "filename_suffix": {
                    "value": "f'_{start_epoch + epoch}.v2'",
                    "possible_values": []
                }
            },
            "TensorBoard_49": {
                "variable": {
                    "value": "tensorboard_callback",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "str(epoch_log_path)",
                    "possible_values": []
                },
                "histogram_freq": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Input_79": {
                "variable": {
                    "value": "inputs",
                    "possible_values": []
                },
                "shape": {
                    "value": "(self.sr_model.input_shape[0], self.sr_model.input_shape[1], self.sr_model.channels)",
                    "possible_values": []
                },
                "name": {
                    "value": "input",
                    "possible_values": []
                }
            },
            "Model_97": {
                "variable": {
                    "value": "upscaler",
                    "possible_values": []
                },
                "inputs": {
                    "value": "inputs",
                    "possible_values": [
                        [
                            "keras.layers.Input(shape=(self.sr_model.input_shape[0], self.sr_model.input_shape[1], self.sr_model.channels), name='input')",
                            "Call"
                        ]
                    ]
                },
                "outputs": {
                    "value": "rf_cropper",
                    "possible_values": [
                        [
                            "keras.layers.Cropping2D(cropping=self.sr_model.rf_padding)(bilin_interp)",
                            "Call"
                        ]
                    ]
                }
            },
            "image_144": {
                "name": {
                    "value": "model_name",
                    "possible_values": []
                },
                "data": {
                    "value": "images / 255",
                    "possible_values": []
                },
                "max_outputs": {
                    "value": "25",
                    "possible_values": []
                },
                "step": {
                    "value": "start_epoch + epoch",
                    "possible_values": []
                }
            },
            "UpSampling2D_88": {
                "size": {
                    "value": "(self.sr_model.scaling, self.sr_model.scaling)",
                    "possible_values": []
                },
                "interpolation": {
                    "value": "bilinear",
                    "possible_values": []
                }
            },
            "Cropping2D_93": {
                "cropping": {
                    "value": "self.sr_model.rf_padding",
                    "possible_values": []
                }
            }
        }
    },
    "upres/modeling/sr_model.py": {
        "tensorflow": {
            "load_model_100": {
                "variable": {
                    "value": "self.model",
                    "possible_values": []
                },
                "filepath": {
                    "value": "str(model_file_path)",
                    "possible_values": []
                }
            },
            "Input_132": {
                "variable": {
                    "value": "inputs",
                    "possible_values": []
                },
                "shape": {
                    "value": "(None, None, self.channels)",
                    "possible_values": []
                },
                "name": {
                    "value": "input",
                    "possible_values": []
                }
            },
            "add_151": {
                "variable": {
                    "value": "add_layer",
                    "possible_values": []
                },
                "x": {
                    "value": "[last_layer, upscaler]",
                    "possible_values": []
                },
                "name": {
                    "value": "residual_plus_upscaler",
                    "possible_values": []
                }
            },
            "Model_158": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "inputs": {
                    "value": "inputs",
                    "possible_values": [
                        [
                            "keras.layers.Input(shape=(None, None, self.channels), name='input')",
                            "Call"
                        ],
                        [
                            "keras.layers.Input(shape=(1000, 1000, self.channels), name='input')",
                            "Call"
                        ]
                    ]
                },
                "outputs": {
                    "value": "predictions",
                    "possible_values": [
                        [
                            "cropping_layer(add_layer)",
                            "Call"
                        ],
                        [
                            "self.discriminator(combined_images)",
                            "Call"
                        ],
                        [
                            "self.discriminator(self.generator(x))",
                            "Call"
                        ]
                    ]
                }
            },
            "Cropping2D_217": {
                "variable": {
                    "value": "cropping_layer",
                    "possible_values": []
                },
                "cropping": {
                    "value": "self.rf_padding",
                    "possible_values": []
                }
            },
            "Adam_222": {
                "variable": {
                    "value": "self.optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Conv2D_242": {
                "variable": {
                    "value": "keras_layer",
                    "possible_values": []
                },
                "filters": {
                    "value": "self.channels",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(conv_size, conv_size)",
                    "possible_values": []
                },
                "strides": {
                    "value": "(1, 1)",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "name": {
                    "value": "f'l_{len(self.layers) - 1}'",
                    "possible_values": []
                }
            },
            "Graph_259": {
                "variable": {
                    "value": "g",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Mean_294": {
                "variable": {
                    "value": "self.d_loss_metric",
                    "possible_values": []
                },
                "name": {
                    "value": "d_loss",
                    "possible_values": []
                }
            },
            "Mean_295": {
                "variable": {
                    "value": "self.g_loss_metric",
                    "possible_values": []
                },
                "name": {
                    "value": "g_loss",
                    "possible_values": []
                }
            },
            "cast_311": {
                "variable": {
                    "value": "y",
                    "possible_values": []
                },
                "x": {
                    "value": "y",
                    "possible_values": [
                        [
                            "tf.cast(y, 'float32')",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "float32",
                    "possible_values": []
                }
            },
            "concat_313": {
                "variable": {
                    "value": "combined_images",
                    "possible_values": []
                },
                "values": {
                    "value": "[pred, y]",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "concat_316": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "values": {
                    "value": "[tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))]",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_332": {
                "variable": {
                    "value": "misleading_labels",
                    "possible_values": []
                },
                "shape": {
                    "value": "(batch_size, 1)",
                    "possible_values": []
                }
            },
            "Input_166": {
                "variable": {
                    "value": "d_input",
                    "possible_values": []
                },
                "shape": {
                    "value": "(None, None, self.channels)",
                    "possible_values": []
                }
            },
            "Model_185": {
                "variable": {
                    "value": "discriminator",
                    "possible_values": []
                },
                "inputs": {
                    "value": "d_input",
                    "possible_values": [
                        [
                            "keras.Input(shape=(None, None, self.channels))",
                            "Call"
                        ]
                    ]
                },
                "outputs": {
                    "value": "l4",
                    "possible_values": [
                        [
                            "keras.layers.GlobalMaxPool2D()(l3)",
                            "Call"
                        ]
                    ]
                }
            },
            "Conv2D_229": {
                "variable": {
                    "value": "keras_layer",
                    "possible_values": []
                },
                "filters": {
                    "value": "num_filters",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(conv_size, conv_size)",
                    "possible_values": []
                },
                "strides": {
                    "value": "(1, 1)",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "possible_values": []
                },
                "name": {
                    "value": "f'l_{i}'",
                    "possible_values": []
                }
            },
            "Input_262": {
                "variable": {
                    "value": "inputs",
                    "possible_values": []
                },
                "shape": {
                    "value": "(1000, 1000, self.channels)",
                    "possible_values": []
                },
                "name": {
                    "value": "input",
                    "possible_values": []
                }
            },
            "Model_270": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "inputs": {
                    "value": "inputs",
                    "possible_values": [
                        [
                            "keras.layers.Input(shape=(None, None, self.channels), name='input')",
                            "Call"
                        ],
                        [
                            "keras.layers.Input(shape=(1000, 1000, self.channels), name='input')",
                            "Call"
                        ]
                    ]
                },
                "outputs": {
                    "value": "last_layer",
                    "possible_values": [
                        [
                            "self.apply_layers(keras_layers, upscaler)",
                            "Call"
                        ],
                        [
                            "self.apply_layers(keras_layers, inputs)",
                            "Call"
                        ]
                    ]
                }
            },
            "Conv2DTranspose_138": {
                "filters": {
                    "value": "self.channels",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "(self.conv_size, self.conv_size)",
                    "possible_values": []
                },
                "strides": {
                    "value": "(self.scaling, self.scaling)",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "name": {
                    "value": "upscaler",
                    "possible_values": []
                }
            },
            "shape_314": {
                "input": {
                    "value": "x",
                    "possible_values": []
                }
            },
            "uniform_320": {
                "shape": {
                    "value": "tf.shape(labels)",
                    "possible_values": []
                }
            },
            "GradientTape_323": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "GradientTape_336": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Conv2D_167": {
                "filters": {
                    "value": "64",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "strides": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "possible_values": []
                }
            },
            "Conv2D_170": {
                "filters": {
                    "value": "64",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "strides": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "possible_values": []
                }
            },
            "Conv2D_173": {
                "filters": {
                    "value": "64",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "strides": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "activation": {
                    "value": "relu",
                    "possible_values": []
                }
            },
            "Conv2D_176": {
                "filters": {
                    "value": "1",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "strides": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "same",
                    "possible_values": []
                },
                "activation": {
                    "value": "sigmoid",
                    "possible_values": []
                }
            },
            "GlobalMaxPool2D_183": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ones_317": {
                "shape": {
                    "value": "(batch_size, 1)",
                    "possible_values": []
                }
            },
            "zeros_317": {
                "shape": {
                    "value": "(batch_size, 1)",
                    "possible_values": []
                }
            },
            "shape_320": {
                "input": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)",
                            "Call"
                        ],
                        [
                            "labels + 0.05 * tf.random.uniform(tf.shape(labels))",
                            "BinOp"
                        ]
                    ]
                }
            },
            "Adam_190": {
                "learning_rate": {
                    "value": "0.0001",
                    "possible_values": []
                }
            },
            "Adam_191": {
                "learning_rate": {
                    "value": "0.0001",
                    "possible_values": []
                }
            },
            "BinaryCrossentropy_192": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    }
}