{
    "Adversarial Fine-tuning in LinkedIn/ad_model.py": {
        "torch": {
            "norm_41": {
                "variable": {
                    "value": "input1_l2_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input1.view(batch_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "norm_44": {
                "variable": {
                    "value": "input2_l2_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input2.view(batch_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "mean_47": {
                "variable": {
                    "value": "diff_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1_l2.t().mm(input2_l2).pow(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_63": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 100)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_90": {
                "variable": {
                    "value": "softmax_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "label_distirbution",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.projection(semantic_embeddings)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Sequential_98": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 64)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_109": {
                "variable": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "energy.squeeze(-1).masked_fill((1 - outputs_mask).byte(), float('-inf'))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_123": {
                "variable": {
                    "value": "self.Encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], configs['hidden_size'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_136": {
                "variable": {
                    "value": "token_embeddings_last_4_layers",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(outputs[2][-1], outputs[2][-2], outputs[2][-3], outputs[2][-4])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_195": {
                "variable": {
                    "value": "self.learning2Rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.n_bins, self.n_bins)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "exp_218": {
                "variable": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_219": {
                "variable": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_221": {
                "variable": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(torch.clamp(pooling_sum, min=1e-10)) * 0.01",
                            "BinOp"
                        ],
                        [
                            "torch.sum(log_pooling_sum, 0)",
                            "Call"
                        ],
                        [
                            "self.get_intersect_matrix(inputs_paper, inputs_author)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_226": {
                "variable": {
                    "value": "inputs_paper",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "inputs_paper",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.functional.normalize(inputs_paper, p=2, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_227": {
                "variable": {
                    "value": "inputs_author",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "inputs_author",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.functional.normalize(inputs_author, p=2, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_64": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "100",
                    "type": "int",
                    "possible_values": []
                }
            },
            "LeakyReLU_66": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_67": {
                "in_features": {
                    "value": "100",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_99": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_100": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_101": {
                "in_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_124": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Linear_201": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LeakyReLU_203": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_204": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_205": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_220": {
                "input": {
                    "value": "torch.clamp(pooling_sum, min=1e-10)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_220": {
                "input": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(pooling_value, 1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1e-10",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in LinkedIn/ad_news_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in LinkedIn/ad_paper_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in LinkedIn/linkedin_main_3_ad.py": {
        "torch": {
            "tensor_50": {
                "variable": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_51": {
                "variable": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_108": {
                "variable": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_109": {
                "variable": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "a_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_113": {
                "variable": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_114": {
                "variable": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "b_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_118": {
                "variable": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_119": {
                "variable": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "c_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_neg_sample'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_131": {
                "variable": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(total_paper_embeddings)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_313": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_314": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_336": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_337": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_339": {
                "variable": {
                    "value": "b_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_340": {
                "variable": {
                    "value": "b_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "device_415": {
                "variable": {
                    "value": "bert_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_416": {
                "variable": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:1",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_460": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../paper_level/l2_model/l2_checkpoints/model_2_266'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:1",
                    "type": "str",
                    "possible_values": []
                }
            },
            "MarginRankingLoss_481": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "margin": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_482": {
                "variable": {
                    "value": "rank_y",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[-1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_486": {
                "variable": {
                    "value": "crossEntropyLoss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Adam_497": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "[{'params': shared_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': private_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': adversarial_model.parameters(), 'lr': configs['adversarial_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['knrm_learning_rate']}]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_326": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_327": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_349": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_350": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_271": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_363": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_573": {
                "variable": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(matching_batch_loss)",
                            "Call"
                        ],
                        [
                            "torch.mean(matching_batch_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_575": {
                "variable": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(matching_batch_loss)",
                            "Call"
                        ],
                        [
                            "torch.mean(matching_batch_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_588": {
                "variable": {
                    "value": "paper_label",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "sample_paper_embeddings.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_589": {
                "variable": {
                    "value": "news_label",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "news_batch_embeddings.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "argmax_594": {
                "variable": {
                    "value": "paper_predict",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "paper_softmax_prob",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_604": {
                "variable": {
                    "value": "news_predict",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "news_softmax_prob",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_609": {
                "variable": {
                    "value": "fake_news_label",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "private_news_embeddings.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_686": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "file_name + 'best_model_' + str(epoch) + '_' + str(batch_num + 1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "save_692": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "file_name + 'common_model_' + str(epoch) + '_' + str(batch_num + 1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in LinkedIn/paper_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in LinkedIn/paper_model.py": {
        "torch": {
            "Sequential_21": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 64)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_32": {
                "variable": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "energy.squeeze(-1).masked_fill((1 - outputs_mask).byte(), float('-inf'))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_47": {
                "variable": {
                    "value": "self.Encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['bert_size'], configs['hidden_size'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_60": {
                "variable": {
                    "value": "token_embeddings_last_4_layers",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(outputs[2][-1], outputs[2][-2], outputs[2][-3], outputs[2][-4])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_119": {
                "variable": {
                    "value": "self.learning2Rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.n_bins, self.n_bins)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tanh_151": {
                "variable": {
                    "value": "sim_vec",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.pairwise_distance(paper_embed, author_embed)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "exp_157": {
                "variable": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_158": {
                "variable": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_160": {
                "variable": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(torch.clamp(pooling_sum, min=1e-10)) * 0.01",
                            "BinOp"
                        ],
                        [
                            "torch.sum(log_pooling_sum, 0)",
                            "Call"
                        ],
                        [
                            "self.get_intersect_matrix(inputs_paper, inputs_author)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_22": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_23": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_24": {
                "in_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_48": {
                "in_features": {
                    "value": "configs['bert_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Linear_125": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LeakyReLU_128": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_129": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_130": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "pairwise_distance_151": {
                "x1": {
                    "value": "paper_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "paper_embed.view(paper_shape[0], 1, configs['hidden_size'])",
                            "Call"
                        ],
                        [
                            "paper_embed.repeat(1, author_shape[0], 1).view(paper_shape[0] * author_shape[0], configs['hidden_size'])",
                            "Call"
                        ]
                    ]
                },
                "x2": {
                    "value": "author_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "author_embed.repeat(paper_shape[0], 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_159": {
                "input": {
                    "value": "torch.clamp(pooling_sum, min=1e-10)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_159": {
                "input": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(pooling_value, 1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1e-10",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in LinkedIn/test_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in LinkedIn/test_l2_adver.py": {
        "torch": {
            "tensor_50": {
                "variable": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_51": {
                "variable": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_108": {
                "variable": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_109": {
                "variable": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "a_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_113": {
                "variable": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_114": {
                "variable": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "b_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_118": {
                "variable": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_119": {
                "variable": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "c_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_neg_sample'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_131": {
                "variable": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(total_paper_embeddings)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_313": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_314": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_336": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_337": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_339": {
                "variable": {
                    "value": "b_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_340": {
                "variable": {
                    "value": "b_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "device_415": {
                "variable": {
                    "value": "bert_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_416": {
                "variable": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "MarginRankingLoss_476": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "margin": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_477": {
                "variable": {
                    "value": "rank_y",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[-1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:0')",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_481": {
                "variable": {
                    "value": "crossEntropyLoss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Adam_492": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "[{'params': shared_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': private_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': adversarial_model.parameters(), 'lr': configs['adversarial_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['knrm_learning_rate']}]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "load_506": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../paper_level/l2_model/l2_checkpoints/model_2_266'",
                            "str"
                        ],
                        [
                            "'./fake_news_checkpoints/best_model_3_1600'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_516": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../paper_level/l2_model/l2_checkpoints/model_2_266'",
                            "str"
                        ],
                        [
                            "'./fake_news_checkpoints/best_model_3_1600'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "tensor_326": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_327": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_349": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_350": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_271": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_363": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/ad_model.py": {
        "torch": {
            "norm_41": {
                "variable": {
                    "value": "input1_l2_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input1.view(batch_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "norm_44": {
                "variable": {
                    "value": "input2_l2_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input2.view(batch_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "mean_47": {
                "variable": {
                    "value": "diff_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1_l2.t().mm(input2_l2).pow(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_63": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 100)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_90": {
                "variable": {
                    "value": "softmax_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "label_distirbution",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.projection(semantic_embeddings)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Sequential_98": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 64)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_109": {
                "variable": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "energy.squeeze(-1).masked_fill((1 - outputs_mask).byte(), float('-inf'))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_123": {
                "variable": {
                    "value": "self.Encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], configs['hidden_size'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_136": {
                "variable": {
                    "value": "token_embeddings_last_4_layers",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(outputs[2][-1], outputs[2][-2], outputs[2][-3], outputs[2][-4])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_195": {
                "variable": {
                    "value": "self.learning2Rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.n_bins, self.n_bins)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "exp_218": {
                "variable": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_219": {
                "variable": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_221": {
                "variable": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(torch.clamp(pooling_sum, min=1e-10)) * 0.01",
                            "BinOp"
                        ],
                        [
                            "torch.sum(log_pooling_sum, 0)",
                            "Call"
                        ],
                        [
                            "self.get_intersect_matrix(inputs_paper, inputs_author)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_226": {
                "variable": {
                    "value": "inputs_paper",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "inputs_paper",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.functional.normalize(inputs_paper, p=2, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "normalize_227": {
                "variable": {
                    "value": "inputs_author",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "inputs_author",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.functional.normalize(inputs_author, p=2, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_64": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "100",
                    "type": "int",
                    "possible_values": []
                }
            },
            "LeakyReLU_66": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_67": {
                "in_features": {
                    "value": "100",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_99": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_100": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_101": {
                "in_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_124": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Linear_201": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LeakyReLU_203": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_204": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_205": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_220": {
                "input": {
                    "value": "torch.clamp(pooling_sum, min=1e-10)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_220": {
                "input": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(pooling_value, 1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1e-10",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/ad_news_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in News/ad_paper_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in News/expert_linking_chinese/coad_model.py": {
        "torch": {
            "Sequential_23": {
                "variable": {
                    "value": "self.Encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(bert_size, hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_113": {
                "variable": {
                    "value": "self.learning2Rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.n_bins, self.n_bins)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Tanh_127": {
                "variable": {
                    "value": "self.relu_fnc",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "exp_155": {
                "variable": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_156": {
                "variable": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_158": {
                "variable": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(torch.clamp(pooling_sum, min=1e-10)) * 0.01",
                            "BinOp"
                        ],
                        [
                            "torch.sum(log_pooling_sum, 0)",
                            "Call"
                        ],
                        [
                            "self.get_intersect_matrix(inputs_paper, inputs_author)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_24": {
                "in_features": {
                    "value": "bert_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "768",
                            "int"
                        ]
                    ]
                },
                "out_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "512",
                            "int"
                        ]
                    ]
                }
            },
            "Tanh_26": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_119": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LeakyReLU_120": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_121": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_122": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "pairwise_distance_146": {
                "x1": {
                    "value": "paper_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "paper_embed.view(paper_shape[0], 1, 512)",
                            "Call"
                        ],
                        [
                            "paper_embed.repeat(1, author_shape[0], 1).view(paper_shape[0] * author_shape[0], 512)",
                            "Call"
                        ]
                    ]
                },
                "x2": {
                    "value": "author_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "author_embed.repeat(paper_shape[0], 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_157": {
                "input": {
                    "value": "torch.clamp(pooling_sum, min=1e-10)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_157": {
                "input": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(pooling_value, 1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1e-10",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/expert_linking_chinese/data_processer.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in News/expert_linking_chinese/expert_linking.py": {
        "torch": {
            "device_49": {
                "variable": {
                    "value": "local_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_49": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/expert_linking_chinese/model_init.py": {
        "torch": {
            "load_20": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "self.savedModel",
                    "type": "Attribute",
                    "possible_values": []
                },
                "map_location": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_54": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_55": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_64": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_65": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_31": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/l2_main_adversarial.py": {
        "torch": {
            "tensor_50": {
                "variable": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_51": {
                "variable": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_108": {
                "variable": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_109": {
                "variable": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "a_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_113": {
                "variable": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_114": {
                "variable": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "b_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_118": {
                "variable": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_119": {
                "variable": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "c_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_neg_sample'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_131": {
                "variable": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(total_paper_embeddings)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_313": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_314": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_336": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_337": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_339": {
                "variable": {
                    "value": "b_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_340": {
                "variable": {
                    "value": "b_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "device_415": {
                "variable": {
                    "value": "bert_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_416": {
                "variable": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:1",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_460": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../paper_level/l2_model/l2_checkpoints/model_2_266'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:1",
                    "type": "str",
                    "possible_values": []
                }
            },
            "MarginRankingLoss_481": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "margin": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_482": {
                "variable": {
                    "value": "rank_y",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[-1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_486": {
                "variable": {
                    "value": "crossEntropyLoss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Adam_497": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "[{'params': shared_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': private_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': adversarial_model.parameters(), 'lr': configs['adversarial_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['knrm_learning_rate']}]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_326": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_327": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_349": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_350": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_271": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_363": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_573": {
                "variable": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(matching_batch_loss)",
                            "Call"
                        ],
                        [
                            "torch.mean(matching_batch_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_575": {
                "variable": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "matching_batch_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(matching_batch_loss)",
                            "Call"
                        ],
                        [
                            "torch.mean(matching_batch_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_588": {
                "variable": {
                    "value": "paper_label",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "sample_paper_embeddings.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_589": {
                "variable": {
                    "value": "news_label",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "news_batch_embeddings.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "argmax_594": {
                "variable": {
                    "value": "paper_predict",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "paper_softmax_prob",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_604": {
                "variable": {
                    "value": "news_predict",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "news_softmax_prob",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_609": {
                "variable": {
                    "value": "fake_news_label",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "private_news_embeddings.size()[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:1')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_686": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "file_name + 'best_model_' + str(epoch) + '_' + str(batch_num + 1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "save_692": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'matching_model': matching_model.state_dict(), 'shared_embedding_model': shared_embedding_model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "file_name + 'common_model_' + str(epoch) + '_' + str(batch_num + 1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/paper_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in News/paper_model.py": {
        "torch": {
            "Sequential_21": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 64)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_32": {
                "variable": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "energy.squeeze(-1).masked_fill((1 - outputs_mask).byte(), float('-inf'))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_47": {
                "variable": {
                    "value": "self.Encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['bert_size'], configs['hidden_size'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_60": {
                "variable": {
                    "value": "token_embeddings_last_4_layers",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(outputs[2][-1], outputs[2][-2], outputs[2][-3], outputs[2][-4])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_119": {
                "variable": {
                    "value": "self.learning2Rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.n_bins, self.n_bins)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tanh_151": {
                "variable": {
                    "value": "sim_vec",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.pairwise_distance(paper_embed, author_embed)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "exp_157": {
                "variable": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_158": {
                "variable": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_160": {
                "variable": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(torch.clamp(pooling_sum, min=1e-10)) * 0.01",
                            "BinOp"
                        ],
                        [
                            "torch.sum(log_pooling_sum, 0)",
                            "Call"
                        ],
                        [
                            "self.get_intersect_matrix(inputs_paper, inputs_author)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_22": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_23": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_24": {
                "in_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_48": {
                "in_features": {
                    "value": "configs['bert_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Linear_125": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LeakyReLU_128": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_129": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_130": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "pairwise_distance_151": {
                "x1": {
                    "value": "paper_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "paper_embed.view(paper_shape[0], 1, configs['hidden_size'])",
                            "Call"
                        ],
                        [
                            "paper_embed.repeat(1, author_shape[0], 1).view(paper_shape[0] * author_shape[0], configs['hidden_size'])",
                            "Call"
                        ]
                    ]
                },
                "x2": {
                    "value": "author_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "author_embed.repeat(paper_shape[0], 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_159": {
                "input": {
                    "value": "torch.clamp(pooling_sum, min=1e-10)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_159": {
                "input": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(pooling_value, 1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1e-10",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Adversarial Fine-tuning in News/test_data_process.py": {
        "torch": {}
    },
    "Adversarial Fine-tuning in News/test_l2_adver.py": {
        "torch": {
            "tensor_50": {
                "variable": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_51": {
                "variable": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "news_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(news_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_108": {
                "variable": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_109": {
                "variable": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "a_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(a_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "a_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_113": {
                "variable": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_114": {
                "variable": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "b_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(b_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "b_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_118": {
                "variable": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_input_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_input_ids).to(device, non_blocking=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_119": {
                "variable": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "c_paper_batch_attention_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(c_paper_batch_attention_masks).to(device, non_blocking=True)",
                            "Call"
                        ],
                        [
                            "c_paper_batch_attention_masks.view(configs['domain_paper_batch_size'], configs['train_neg_sample'], configs['train_max_papers_each_author'], configs['train_max_paper_length'])",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_131": {
                "variable": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "total_paper_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(total_paper_embeddings)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_313": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_314": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_336": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_337": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_339": {
                "variable": {
                    "value": "b_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_340": {
                "variable": {
                    "value": "b_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "device_415": {
                "variable": {
                    "value": "bert_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_416": {
                "variable": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "MarginRankingLoss_476": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "margin": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_477": {
                "variable": {
                    "value": "rank_y",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[-1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "domain_device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:0')",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_481": {
                "variable": {
                    "value": "crossEntropyLoss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Adam_492": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "[{'params': shared_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': private_embedding_model.parameters(), 'lr': configs['bert_learning_rate']}, {'params': adversarial_model.parameters(), 'lr': configs['adversarial_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['knrm_learning_rate']}]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "load_506": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../paper_level/l2_model/l2_checkpoints/model_2_266'",
                            "str"
                        ],
                        [
                            "'./fake_news_checkpoints/best_model_3_1600'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_516": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'../paper_level/l2_model/l2_checkpoints/model_2_266'",
                            "str"
                        ],
                        [
                            "'./fake_news_checkpoints/best_model_3_1600'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "tensor_326": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_327": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_349": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_350": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_271": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_363": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "Contrastive Pre-training in AMiner/margin_main_paper_l2.py": {
        "torch": {
            "tensor_61": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_62": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_64": {
                "variable": {
                    "value": "b_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_65": {
                "variable": {
                    "value": "b_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "device_157": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_184": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'./l2_checkpoints/model_2_266'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "MarginRankingLoss_195": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "margin": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_196": {
                "variable": {
                    "value": "rank_y",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[-1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:0')",
                            "Call"
                        ]
                    ]
                }
            },
            "Adam_198": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "[{'params': embedding_model.parameters(), 'lr': configs['train_bert_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['train_knrm_learning_rate']}]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "ExponentialLR_202": {
                "variable": {
                    "value": "my_lr_scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.optim.Adam([{'params': embedding_model.parameters(), 'lr': configs['train_bert_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['train_knrm_learning_rate']}])",
                            "Call"
                        ]
                    ]
                },
                "gamma": {
                    "value": "decayRate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.96",
                            "float"
                        ]
                    ]
                }
            },
            "tensor_74": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_75": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_88": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_247": {
                "variable": {
                    "value": "instance_mean_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "instance_mean_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(instance_mean_loss)",
                            "Call"
                        ],
                        [
                            "torch.mean(instance_mean_loss)",
                            "Call"
                        ],
                        [
                            "instance_mean_loss / len(batch_data)",
                            "BinOp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "np.mean(instance_mean_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "mean_249": {
                "variable": {
                    "value": "instance_mean_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "instance_mean_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(instance_mean_loss)",
                            "Call"
                        ],
                        [
                            "torch.mean(instance_mean_loss)",
                            "Call"
                        ],
                        [
                            "instance_mean_loss / len(batch_data)",
                            "BinOp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "np.mean(instance_mean_loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "save_282": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'matching_model': matching_model.state_dict(), 'embedding_model': embedding_model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "file_name + 'model_' + str(epoch_num) + '_' + str(batch_num + 1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "Contrastive Pre-training in AMiner/paper_data_process.py": {
        "torch": {}
    },
    "Contrastive Pre-training in AMiner/paper_model.py": {
        "torch": {
            "Sequential_21": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['hidden_size'], 64)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_32": {
                "variable": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "energy.squeeze(-1).masked_fill((1 - outputs_mask).byte(), float('-inf'))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_46": {
                "variable": {
                    "value": "self.Encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(configs['bert_size'], configs['hidden_size'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_59": {
                "variable": {
                    "value": "token_embeddings_last_4_layers",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(outputs[2][-1], outputs[2][-2], outputs[2][-3], outputs[2][-4])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_118": {
                "variable": {
                    "value": "self.learning2Rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.n_bins, self.n_bins)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tanh_144": {
                "variable": {
                    "value": "sim_vec",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.pairwise_distance(paper_embed, author_embed)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "exp_150": {
                "variable": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_151": {
                "variable": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "pooling_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(-(sim_vec - self.mu) ** 2 / self.sigma ** 2 / 2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_153": {
                "variable": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(torch.clamp(pooling_sum, min=1e-10)) * 0.01",
                            "BinOp"
                        ],
                        [
                            "torch.sum(log_pooling_sum, 0)",
                            "Call"
                        ],
                        [
                            "self.get_intersect_matrix(inputs_paper, inputs_author)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_22": {
                "in_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_23": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_24": {
                "in_features": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_47": {
                "in_features": {
                    "value": "configs['bert_size']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "configs['hidden_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Linear_124": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LeakyReLU_125": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_126": {
                "in_features": {
                    "value": "self.n_bins",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_127": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "pairwise_distance_144": {
                "x1": {
                    "value": "paper_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "paper_embed.view(paper_shape[0], 1, configs['hidden_size'])",
                            "Call"
                        ],
                        [
                            "paper_embed.repeat(1, author_shape[0], 1).view(paper_shape[0] * author_shape[0], configs['hidden_size'])",
                            "Call"
                        ]
                    ]
                },
                "x2": {
                    "value": "author_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "author_embed.repeat(paper_shape[0], 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_152": {
                "input": {
                    "value": "torch.clamp(pooling_sum, min=1e-10)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_152": {
                "input": {
                    "value": "pooling_sum",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(pooling_value, 1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1e-10",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Contrastive Pre-training in AMiner/test_data_process.py": {
        "torch": {}
    },
    "Contrastive Pre-training in AMiner/test_paper_main.py": {
        "torch": {
            "tensor_61": {
                "variable": {
                    "value": "a_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_62": {
                "variable": {
                    "value": "a_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[0][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_64": {
                "variable": {
                    "value": "b_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_65": {
                "variable": {
                    "value": "b_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "instance[1][1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "device_157": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_184": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "load_name",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'./l2_checkpoints/model_2_266'",
                            "str"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cuda:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "MarginRankingLoss_195": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "margin": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "tensor_196": {
                "variable": {
                    "value": "rank_y",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[-1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:0')",
                            "Call"
                        ]
                    ]
                }
            },
            "Adam_198": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "[{'params': embedding_model.parameters(), 'lr': configs['train_bert_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['train_knrm_learning_rate']}]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "ExponentialLR_202": {
                "variable": {
                    "value": "my_lr_scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.optim.Adam([{'params': embedding_model.parameters(), 'lr': configs['train_bert_learning_rate']}, {'params': matching_model.parameters(), 'lr': configs['train_knrm_learning_rate']}])",
                            "Call"
                        ]
                    ]
                },
                "gamma": {
                    "value": "decayRate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.96",
                            "float"
                        ]
                    ]
                }
            },
            "tensor_74": {
                "variable": {
                    "value": "c_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_paper_inputs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_75": {
                "variable": {
                    "value": "c_paper_attention_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "each_attention_masks",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_88": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}