{
    "data/ava_dataset.py": {
        "torch": {
            "AVADataset_11": {
                "base_class_0": {
                    "value": "torch.utils.data.Dataset",
                    "possible_values": []
                },
                "self.split": {
                    "value": "split",
                    "possible_values": [
                        [
                            "'train'",
                            "MethodArgument"
                        ]
                    ]
                },
                "self.objectsfile": {
                    "value": "objectsfile",
                    "possible_values": [
                        [
                            "'./ava_objects_fasterrcnn.hdf5'",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "from_numpy_31": {
                "variable": {
                    "value": "actors_features",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "hf_actors.get('features').value",
                    "possible_values": []
                }
            },
            "from_numpy_32": {
                "variable": {
                    "value": "actors_labels",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "hf_actors.get('labels').value",
                    "possible_values": []
                }
            },
            "from_numpy_33": {
                "variable": {
                    "value": "actors_boxes",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "hf_actors.get('boxes').value",
                    "possible_values": []
                }
            },
            "from_numpy_36": {
                "variable": {
                    "value": "objects_features",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "hf_objects.get(clip_id + '_' + timestamp.lstrip('0') + '_' + 'features').value",
                    "possible_values": []
                }
            },
            "from_numpy_37": {
                "variable": {
                    "value": "objects_boxes",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "hf_objects.get(clip_id + '_' + timestamp.lstrip('0') + '_' + 'boxes').value",
                    "possible_values": []
                }
            }
        }
    },
    "data/collate_batch.py": {
        "torch": {
            "cat_9": {
                "variable": {
                    "value": "actors_features",
                    "possible_values": []
                },
                "tensors": {
                    "value": "transposed_batch[0]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_10": {
                "variable": {
                    "value": "actors_labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "transposed_batch[1]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_11": {
                "variable": {
                    "value": "actors_boxes",
                    "possible_values": []
                },
                "tensors": {
                    "value": "transposed_batch[2]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_14": {
                "variable": {
                    "value": "objects_features",
                    "possible_values": []
                },
                "tensors": {
                    "value": "transposed_batch[4]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_15": {
                "variable": {
                    "value": "objects_boxes",
                    "possible_values": []
                },
                "tensors": {
                    "value": "transposed_batch[5]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_21": {
                "variable": {
                    "value": "adj",
                    "possible_values": []
                },
                "*size": {
                    "value": "(num_actor_proposals + num_object_proposals, num_actor_proposals + num_object_proposals)",
                    "possible_values": []
                }
            },
            "t_47": {
                "variable": {
                    "value": "adj[num_actor_proposals:, :num_actor_proposals]",
                    "possible_values": []
                },
                "input": {
                    "value": "adj[:num_actor_proposals, num_actor_proposals:]",
                    "possible_values": []
                }
            }
        }
    },
    "models/attention_layer.py": {
        "torch": {
            "GraphAttentionLayer_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.dropout": {
                    "value": "dropout",
                    "possible_values": []
                },
                "self.in_features": {
                    "value": "in_features",
                    "possible_values": []
                },
                "self.out_features": {
                    "value": "out_features",
                    "possible_values": []
                },
                "self.alpha": {
                    "value": "alpha",
                    "possible_values": []
                },
                "Parameter_14": {
                    "variable": {
                        "value": "self.W",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(size=(in_features, out_features))",
                        "possible_values": []
                    }
                },
                "Parameter_16": {
                    "variable": {
                        "value": "self.a",
                        "possible_values": []
                    },
                    "data": {
                        "value": "torch.zeros(size=(2 * out_features, 1))",
                        "possible_values": []
                    }
                },
                "LeakyReLU_19": {
                    "variable": {
                        "value": "self.leakyrelu",
                        "possible_values": []
                    },
                    "negative_slope": {
                        "value": "self.alpha",
                        "possible_values": []
                    }
                }
            },
            "mm_22": {
                "variable": {
                    "value": "h",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "possible_values": []
                },
                "mat2": {
                    "value": "self.W",
                    "possible_values": []
                }
            },
            "cat_25": {
                "variable": {
                    "value": "a_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "where_29": {
                "variable": {
                    "value": "attention",
                    "possible_values": []
                },
                "condition": {
                    "value": "adj > 0",
                    "possible_values": []
                },
                "x": {
                    "value": "e * adj",
                    "possible_values": []
                },
                "y": {
                    "value": "zero_vec",
                    "possible_values": [
                        [
                            "-9000000000000000.0 * torch.ones_like(e)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "softmax_31": {
                "variable": {
                    "value": "attention",
                    "possible_values": []
                },
                "input": {
                    "value": "attention / tau",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "matmul_32": {
                "variable": {
                    "value": "h_prime",
                    "possible_values": []
                },
                "input": {
                    "value": "attention",
                    "possible_values": [
                        [
                            "torch.where(adj > 0, e * adj, zero_vec)",
                            "Call"
                        ],
                        [
                            "F.softmax(attention / tau, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "h",
                    "possible_values": [
                        [
                            "torch.mm(input, self.W)",
                            "Call"
                        ]
                    ]
                }
            },
            "dropout_33": {
                "variable": {
                    "value": "h_prime",
                    "possible_values": []
                },
                "input": {
                    "value": "h_prime",
                    "possible_values": [
                        [
                            "torch.matmul(attention, h)",
                            "Call"
                        ],
                        [
                            "F.dropout(h_prime, self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "elu_35": {
                "input": {
                    "value": "h_prime",
                    "possible_values": [
                        [
                            "torch.matmul(attention, h)",
                            "Call"
                        ],
                        [
                            "F.dropout(h_prime, self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_14": {
                "size": {
                    "value": "(in_features, out_features)",
                    "possible_values": []
                }
            },
            "zeros_16": {
                "size": {
                    "value": "(2 * out_features, 1)",
                    "possible_values": []
                }
            },
            "matmul_26": {
                "input": {
                    "value": "a_input",
                    "possible_values": [
                        [
                            "torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.a",
                    "possible_values": []
                }
            },
            "squeeze_26": {
                "input": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "ones_like_28": {
                "input": {
                    "value": "e",
                    "possible_values": [
                        [
                            "self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models/gat.py": {
        "torch": {
            "GAT_7": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.dropout": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "dropout_17": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "F.dropout(x, self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.cat([v(x, adj) for (k, v) in self._modules.items() if k.startswith('attention')], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "cat_18": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v(x, adj) for (k, v) in self._modules.items() if k.startswith('attention')]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "models/model.py": {
        "torch": {
            "Stage_6": {
                "base_class_0": {
                    "value": "torch.nn.Module",
                    "possible_values": []
                },
                "self.num_classes": {
                    "value": "num_classes",
                    "possible_values": []
                },
                "self.actors_features_size": {
                    "value": "actors_features_size",
                    "possible_values": []
                },
                "self.objects_features_size": {
                    "value": "objects_features_size",
                    "possible_values": []
                },
                "self.n_heads": {
                    "value": "n_heads",
                    "possible_values": []
                },
                "Linear_20": {
                    "variable": {
                        "value": "self.gat_fc",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    }
                },
                "LayerNorm_21": {
                    "variable": {
                        "value": "self.l_norm",
                        "possible_values": []
                    },
                    "normalized_shape": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    }
                },
                "Linear_24": {
                    "variable": {
                        "value": "self.gat_fc2",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    }
                },
                "LayerNorm_25": {
                    "variable": {
                        "value": "self.l_norm2",
                        "possible_values": []
                    },
                    "normalized_shape": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    }
                },
                "Linear_27": {
                    "variable": {
                        "value": "self.logits",
                        "possible_values": []
                    },
                    "in_features": {
                        "value": "self.actors_features_size + 4",
                        "possible_values": []
                    },
                    "out_features": {
                        "value": "self.num_classes",
                        "possible_values": []
                    }
                }
            },
            "cat_43": {
                "variable": {
                    "value": "actors_features",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(actors_features, actors_h.unsqueeze(1), actors_w.unsqueeze(1), actors_centers_x.unsqueeze(1), actors_centers_y.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_48": {
                "variable": {
                    "value": "objects_features",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(objects_features, objects_h.unsqueeze(1), objects_w.unsqueeze(1), objects_centers_x.unsqueeze(1), objects_centers_y.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_50": {
                "variable": {
                    "value": "all_features",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(actors_features, objects_features)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_62": {
                "variable": {
                    "value": "loss",
                    "possible_values": []
                },
                "input": {
                    "value": "pred",
                    "possible_values": [
                        [
                            "self.logits(all_features[:actors_features.shape[0], :])",
                            "Call"
                        ],
                        [
                            "torch.sigmoid(pred)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "actors_labels",
                    "possible_values": []
                }
            },
            "sigmoid_64": {
                "variable": {
                    "value": "pred",
                    "possible_values": []
                },
                "input": {
                    "value": "pred",
                    "possible_values": [
                        [
                            "self.logits(all_features[:actors_features.shape[0], :])",
                            "Call"
                        ],
                        [
                            "torch.sigmoid(pred)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_17": {
                "variable": {
                    "value": "self.obj_reducer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.objects_features_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.actors_features_size",
                    "possible_values": []
                }
            },
            "mean_42": {
                "input": {
                    "value": "actors_features",
                    "possible_values": [
                        [
                            "torch.mean(torch.mean(torch.mean(actors_features, dim=2), dim=-1), dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.cat((actors_features, actors_h.unsqueeze(1), actors_w.unsqueeze(1), actors_centers_x.unsqueeze(1), actors_centers_y.unsqueeze(1)), dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "relu_46": {
                "variable": {
                    "value": "objects_features",
                    "possible_values": []
                },
                "input": {
                    "value": "self.obj_reducer(objects_features)",
                    "possible_values": []
                }
            },
            "no_grad_41": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "test.py": {
        "torch": {
            "device_31": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "DataLoader_36": {
                "variable": {
                    "value": "data_loader_val",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ava_val",
                    "possible_values": [
                        [
                            "AVADataset(split='val', videodir=args.actors_dir, objectsfile=args.objects_dir)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.n_workers",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "BatchCollator()",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "no_grad_49": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_31": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "nonzero_64": {
                "variable": {
                    "value": "classes",
                    "possible_values": []
                },
                "input": {
                    "value": "prop",
                    "possible_values": []
                }
            }
        }
    },
    "train.py": {
        "torch": {
            "device_37": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "DataLoader_46": {
                "variable": {
                    "value": "data_loader_train",
                    "possible_values": []
                },
                "dataset": {
                    "value": "ava_train",
                    "possible_values": [
                        [
                            "AVADataset(split='train', videodir=args.actors_dir, objectsfile=args.objects_file)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "args.n_workers",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "BatchCollator()",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Adam_55": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "args.lr",
                    "possible_values": []
                }
            },
            "mean_83": {
                "variable": {
                    "value": "loss",
                    "possible_values": []
                },
                "input": {
                    "value": "loss",
                    "possible_values": [
                        [
                            "torch.mean(loss)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_37": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/boxlist_ops.py": {
        "torch": {
            "max_24": {
                "variable": {
                    "value": "lt",
                    "possible_values": []
                },
                "input": {
                    "value": "boxlist1[:, None, :2]",
                    "possible_values": []
                }
            },
            "min_25": {
                "variable": {
                    "value": "rb",
                    "possible_values": []
                },
                "input": {
                    "value": "boxlist1[:, None, 2:]",
                    "possible_values": []
                }
            },
            "cat_42": {
                "variable": {
                    "value": "center1",
                    "possible_values": []
                },
                "tensors": {
                    "value": "((boxlist1[:, None, 2] - boxlist1[:, None, 0]) / 2 + boxlist1[:, None, 0], (boxlist1[:, None, 3] - boxlist1[:, None, 1]) / 2 + boxlist1[:, None, 1])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_43": {
                "variable": {
                    "value": "center2",
                    "possible_values": []
                },
                "tensors": {
                    "value": "((boxlist2[:, None, 2] - boxlist2[:, None, 0]) / 2 + boxlist2[:, None, 0], (boxlist2[:, None, 3] - boxlist2[:, None, 1]) / 2 + boxlist2[:, None, 1])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sqrt_48": {
                "variable": {
                    "value": "d",
                    "possible_values": []
                },
                "input": {
                    "value": "(center1[:, :, 0] - center2[:, :, 0]) ** 2 + (center1[:, :, 1] - center2[:, :, 1]) ** 2",
                    "possible_values": []
                }
            },
            "exp_50": {
                "input": {
                    "value": "-1 * tau * d",
                    "possible_values": []
                }
            }
        }
    },
    "utils/checkpoints.py": {
        "torch": {
            "load_44": {
                "variable": {
                    "value": "checkpoint",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "possible_values": [
                        [
                            "get_checkpoint_file(output_dir)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "torch.device('cpu')",
                    "possible_values": []
                }
            },
            "save_34": {
                "obj": {
                    "value": "data",
                    "possible_values": [
                        [
                            "{'optimizer_state': optimizer_state, 'epoch': epoch, 'iteration': iteration}",
                            "Dict"
                        ],
                        [
                            "{}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "save_file",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, 'last_checkpoint')",
                            "Call"
                        ],
                        [
                            "os.path.join(output_dir, 'last_checkpoint')",
                            "Call"
                        ],
                        [
                            "os.path.join(output_dir, '{}.pth'.format(name))",
                            "Call"
                        ]
                    ]
                }
            },
            "device_44": {
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            }
        }
    }
}