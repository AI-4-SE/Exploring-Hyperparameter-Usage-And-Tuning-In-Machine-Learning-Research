{
    "moses_baselines/aae_distribution_learning.py": {
        "torch": {
            "load_19": {
                "variable": {
                    "value": "model_config",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.config_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_20": {
                "variable": {
                    "value": "model_vocab",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.vocab_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_21": {
                "variable": {
                    "value": "model_state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.model_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_24": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "config.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "moses_baselines/aae_train.py": {
        "torch": {
            "device_28": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "config.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_25": {
                "obj": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parser.parse_known_args()[0]",
                            "Subscript"
                        ]
                    ]
                },
                "f": {
                    "value": "config.config_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_26": {
                "obj": {
                    "value": "vocab",
                    "type": "variable",
                    "possible_values": [
                        [
                            "CharVocab.from_data(train)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "config.vocab_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_37": {
                "obj": {
                    "value": "model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "config.model_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "moses_baselines/organ_distribution_learning.py": {
        "torch": {
            "load_28": {
                "variable": {
                    "value": "model_config",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.config_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_29": {
                "variable": {
                    "value": "model_vocab",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.vocab_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_30": {
                "variable": {
                    "value": "model_state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.model_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_33": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "config.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "moses_baselines/organ_train.py": {
        "torch": {
            "device_34": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "config.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_44": {
                "obj": {
                    "value": "model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "config.model_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_45": {
                "obj": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parser.parse_known_args()[0]",
                            "Subscript"
                        ]
                    ]
                },
                "f": {
                    "value": "config.config_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_46": {
                "obj": {
                    "value": "vocab",
                    "type": "variable",
                    "possible_values": [
                        [
                            "CharVocab.from_data(train)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "config.vocab_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "moses_baselines/vae_distribution_learning.py": {
        "torch": {
            "load_29": {
                "variable": {
                    "value": "model_config",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.config_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_31": {
                "variable": {
                    "value": "model_state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "config.model_load",
                    "type": "Attribute",
                    "possible_values": []
                },
                "map_location": {
                    "value": "map_location",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'cpu' if config.device == 'cpu' else None",
                            "IfExp"
                        ]
                    ]
                }
            },
            "load_32": {
                "variable": {
                    "value": "self.model_vocab",
                    "type": "Attribute",
                    "possible_values": []
                },
                "f": {
                    "value": "config.vocab_load",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_35": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "config.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_39": {
                "device": {
                    "value": "device.index or 0",
                    "type": "BoolOp",
                    "possible_values": []
                }
            }
        }
    },
    "moses_baselines/vae_train.py": {
        "torch": {
            "device_23": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "config.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_36": {
                "obj": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parser.parse_known_args()[0]",
                            "Subscript"
                        ]
                    ]
                },
                "f": {
                    "value": "config.config_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_37": {
                "obj": {
                    "value": "corpus.vocab",
                    "type": "Attribute",
                    "possible_values": []
                },
                "f": {
                    "value": "config.vocab_save",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_27": {
                "device": {
                    "value": "device.index or 0",
                    "type": "BoolOp",
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/action_sampler.py": {
        "torch": {
            "zeros_83": {
                "variable": {
                    "value": "actions",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, self.max_seq_length)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_88": {
                "variable": {
                    "value": "prob",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/distribution_learning.py": {
        "torch": {
            "is_available_28": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/rnn_generator.py": {
        "torch": {
            "Adam_53": {
                "variable": {
                    "value": "self.optimizer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "self.model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "lr",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.001",
                            "Constant"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_54": {
                "variable": {
                    "value": "self.criterion",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/rnn_model.py": {
        "torch": {
            "Embedding_24": {
                "variable": {
                    "value": "self.encoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_25": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "output_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LSTM_27": {
                "variable": {
                    "value": "self.rnn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "n_layers",
                    "type": "variable",
                    "possible_values": []
                },
                "dropout": {
                    "value": "rnn_dropout",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_56": {
                "*size": {
                    "value": "self.n_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_57": {
                "*size": {
                    "value": "self.n_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "self.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/rnn_sampler.py": {
        "torch": {
            "no_grad_38": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/rnn_trainer.py": {
        "torch": {
            "DataLoader_141": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "self.training_data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "self.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "self.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_212": {
                "variable": {
                    "value": "test_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "self.test_data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "self.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "self.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "clip_grad_norm__55": {
                "parameters": {
                    "value": "self.model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "no_grad_73": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/rnn_utils.py": {
        "torch": {
            "from_numpy_28": {
                "variable": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "numpy_array",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "TensorDataset_33": {
                "*tensors": {
                    "value": "inp",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "save_79": {
                "obj": {
                    "value": "model.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "model_params",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(base_dir, base_name + '.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_187": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "load_69": {
                "f": {
                    "value": "model_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "map_location",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lambda storage, loc: storage if copy_to_cpu else None",
                            "Lambda"
                        ]
                    ]
                }
            },
            "manual_seed_189": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/smiles_rnn_directed_generator.py": {
        "torch": {
            "is_available_57": {
                "variable": {
                    "value": "cuda_available",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_hc/smiles_rnn_distribution_learner.py": {
        "torch": {
            "is_available_33": {
                "variable": {
                    "value": "cuda_available",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_35": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "device_str",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'cuda' if cuda_available else 'cpu'",
                            "IfExp"
                        ]
                    ]
                }
            },
            "Adam_58": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "smiles_model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "self.lr",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_59": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "sd.pad_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_ppo/action_replay.py": {
        "torch": {
            "zeros_52": {
                "variable": {
                    "value": "log_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_samples",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "max_seq_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "action_batch.size()[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_53": {
                "variable": {
                    "value": "values",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_samples",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "max_seq_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "action_batch.size()[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_54": {
                "variable": {
                    "value": "entropies",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_samples",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "max_seq_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "action_batch.size()[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_55": {
                "variable": {
                    "value": "kl_divs",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_samples",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "max_seq_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "action_batch.size()[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_98": {
                "variable": {
                    "value": "log_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "action_batch.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_99": {
                "variable": {
                    "value": "values",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "action_batch.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_100": {
                "variable": {
                    "value": "entropies",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "action_batch.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_101": {
                "variable": {
                    "value": "kl_divs",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "action_batch.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_105": {
                "variable": {
                    "value": "prob",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "actor_output",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_114": {
                "variable": {
                    "value": "prob_prior",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "actor_output_prior",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_112": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_ppo/ppo_directed_generator.py": {
        "torch": {
            "is_available_32": {
                "variable": {
                    "value": "cuda_available",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_ppo/ppo_trainer.py": {
        "torch": {
            "Adam_67": {
                "variable": {
                    "value": "self.optimizer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "0.0001",
                    "type": "float",
                    "possible_values": []
                }
            },
            "BatchSampler_97": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "sampler": {
                    "value": "SubsetRandomSampler(range(self.episode_size))",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "self.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_209": {
                "variable": {
                    "value": "rewards",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "actions.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "actions.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "exp_113": {
                "variable": {
                    "value": "ratio",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "log_probs_batch - old_log_probs_batch",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "SubsetRandomSampler_97": {
                "indices": {
                    "value": "range(self.episode_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_147": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clamp_115": {
                "input": {
                    "value": "ratio",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.exp(log_probs_batch - old_log_probs_batch)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1.0 - self.clip_param",
                    "type": "BinOp",
                    "possible_values": []
                },
                "max": {
                    "value": "1.0 + self.clip_param",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "min_117": {
                "input": {
                    "value": "surr1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ratio * advantages_batch",
                            "BinOp"
                        ]
                    ]
                }
            },
            "mean_117": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "smiles_lstm_ppo/rnn_model.py": {
        "torch": {
            "Linear_16": {
                "variable": {
                    "value": "self.critic_decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.smiles_rnn.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    }
}