{
    "code/m2p_finetune.py": {
        "sklearn": {
            "accuracy_score_52": {
                "variable": {
                    "value": "acc_2class",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "true_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(true_label[nonzero_index] > 0).astype(int)",
                            "Call"
                        ]
                    ]
                },
                "y_pred": {
                    "value": "pred_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(pred_label[nonzero_index] > 0).astype(int)",
                            "Call"
                        ]
                    ]
                }
            },
            "f1_score_53": {
                "variable": {
                    "value": "f1_2class",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "true_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(true_label[nonzero_index] > 0).astype(int)",
                            "Call"
                        ]
                    ]
                },
                "y_pred": {
                    "value": "pred_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(pred_label[nonzero_index] > 0).astype(int)",
                            "Call"
                        ]
                    ]
                },
                "average": {
                    "value": "weighted",
                    "type": "str",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "pad_sequence_88": {
                "variable": {
                    "value": "pad_batch_audio",
                    "type": "Variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "batch_audio",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[x['audio_input'] for x in sample_list]",
                            "ListComp"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "tensor_100": {
                "variable": {
                    "value": "batch_label",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[x['label'] for x in sample_list]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "DataLoader_122": {
                "variable": {
                    "value": "train_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "DownstreamDataset(train_data, tokenizer, audio_length)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "config['dataloader']['batch_size']",
                            "Subscript"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer, config['upstream']['acoustic'])",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "config['dataloader']['n_jobs']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "DataLoader_128": {
                "variable": {
                    "value": "valid_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valid_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "DownstreamDataset(valid_data, tokenizer, audio_length)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "config['dataloader']['batch_size']",
                            "Subscript"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer, config['upstream']['acoustic'])",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "config['dataloader']['n_jobs']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "DataLoader_137": {
                "variable": {
                    "value": "test_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "DownstreamDataset(test_data, tokenizer, audio_length)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "config['dataloader']['batch_size']",
                            "Subscript"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer, config['upstream']['acoustic'])",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "config['dataloader']['n_jobs']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "CosineAnnealingLR_154": {
                "variable": {
                    "value": "scheduler",
                    "type": "Variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "AdamW(optimizer_grouped_parameters, lr=1e-05)",
                            "Call"
                        ]
                    ]
                },
                "T_max": {
                    "value": "epochs",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "args.epochs",
                            "Attribute"
                        ]
                    ]
                }
            },
            "mean_230": {
                "variable": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tensor(epoch_train_loss)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_191": {
                "variable": {
                    "value": "acc_train_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tensor(epoch_train_loss)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_196": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_243": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "argmax_222": {
                "variable": {
                    "value": "prediction",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "Variable",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "argmax_268": {
                "variable": {
                    "value": "prediction",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "Variable",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_230": {
                "data": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.mean(torch.tensor(epoch_train_loss)).cpu().detach().numpy()",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_191": {
                "data": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.mean(torch.tensor(epoch_train_loss)).cpu().detach().numpy()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/run_s-reg-mosei.py": {
        "sklearn": {
            "accuracy_score_72": {
                "variable": {
                    "value": "acc_2class",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "true_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "true_label[nonzero_index] > 0",
                            "Compare"
                        ]
                    ]
                },
                "y_pred": {
                    "value": "pred_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "pred_label[nonzero_index] > 0",
                            "Compare"
                        ]
                    ]
                }
            },
            "f1_score_73": {
                "variable": {
                    "value": "f1_2class",
                    "type": "Variable",
                    "possible_values": []
                },
                "y_true": {
                    "value": "true_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "true_label[nonzero_index] > 0",
                            "Compare"
                        ]
                    ]
                },
                "y_pred": {
                    "value": "pred_2class",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "pred_label[nonzero_index] > 0",
                            "Compare"
                        ]
                    ]
                },
                "average": {
                    "value": "weighted",
                    "type": "str",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "tensor_41": {
                "variable": {
                    "value": "batch_label",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[x['label'] for x in sample_list]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_118": {
                "variable": {
                    "value": "train_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "EmotionDataset(train_data, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "32",
                            "Constant"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "4",
                            "Constant"
                        ]
                    ]
                }
            },
            "DataLoader_123": {
                "variable": {
                    "value": "valid_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valid_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "EmotionDataset(valid_data, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "32",
                            "Constant"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "4",
                            "Constant"
                        ]
                    ]
                }
            },
            "DataLoader_128": {
                "variable": {
                    "value": "test_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "EmotionDataset(test_data, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "32",
                            "Constant"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "4",
                            "Constant"
                        ]
                    ]
                }
            },
            "mean_153": {
                "variable": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tensor(epoch_train_loss)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_153": {
                "data": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.mean(torch.tensor(epoch_train_loss)).cpu().detach().numpy()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/calculate_eer.py": {
        "torch": {
            "cosine_similarity_59": {
                "variable": {
                    "value": "cos_same",
                    "type": "Variable",
                    "possible_values": []
                },
                "x1": {
                    "value": "embeddings_flat",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "embeddings.reshape(embeddings.shape[0] * num_utterances, -1)",
                            "Call"
                        ]
                    ]
                },
                "x2": {
                    "value": "utterance_centroids_flat",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "utterance_centroids.view(utterance_centroids.shape[0] * utterance_centroids.shape[1], -1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cosine_similarity_73": {
                "variable": {
                    "value": "cos_diff",
                    "type": "Variable",
                    "possible_values": []
                },
                "x1": {
                    "value": "embeddings_expand",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "embeddings_flat.unsqueeze(1).repeat(1, embeddings.shape[0], 1)",
                            "Call"
                        ],
                        [
                            "embeddings_expand.view(embeddings_expand.shape[0] * embeddings_expand.shape[1], embeddings_expand.shape[-1])",
                            "Call"
                        ]
                    ]
                },
                "x2": {
                    "value": "centroids_expand",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "centroids.repeat((num_utterances * embeddings.shape[0], 1))",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_124": {
                "variable": {
                    "value": "all_utterances",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "all_utterances",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "np.stack(all_utterances, axis=0)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(all_utterances)",
                            "Call"
                        ]
                    ]
                }
            },
            "split_126": {
                "variable": {
                    "value": "(enrollment_embeddings, verification_embeddings)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "tensor": {
                    "value": "all_utterances",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "np.stack(all_utterances, axis=0)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(all_utterances)",
                            "Call"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "int(M / 2)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/m2p_dataloader.py": {
        "torch": {
            "nonzero_91": {
                "variable": {
                    "value": "s_valid_batchid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.sum(s_labels != -100, dim=1)",
                    "type": "Call",
                    "possible_values": []
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_93": {
                "variable": {
                    "value": "a_valid",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "a_labels.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_95": {
                "variable": {
                    "value": "s_valid",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "s_labels.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "nonzero_98": {
                "variable": {
                    "value": "valid_batchid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "valid_batchid",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "a_valid.long() & s_valid.long()",
                            "BinOp"
                        ],
                        [
                            "torch.nonzero(valid_batchid, as_tuple=False).view(-1)",
                            "Call"
                        ],
                        [
                            "a_valid.long() & s_valid.long()",
                            "BinOp"
                        ],
                        [
                            "torch.nonzero(valid_batchid, as_tuple=False).view(-1)",
                            "Call"
                        ]
                    ]
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pad_sequence_115": {
                "variable": {
                    "value": "x_a_pad_batch",
                    "type": "Variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "acoustic_batch",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[load_acoustic_data(x_file, self.root) for x_file in self.X_a[index]]",
                            "ListComp"
                        ],
                        [
                            "[load_acoustic_data(x_file, self.root) for x_file in self.X_a[index]]",
                            "ListComp"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "nonzero_174": {
                "variable": {
                    "value": "s_valid_batchid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.sum(s_labels != -100, dim=1)",
                    "type": "Call",
                    "possible_values": []
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_176": {
                "variable": {
                    "value": "a_valid",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "a_labels.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_178": {
                "variable": {
                    "value": "s_valid",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "s_labels.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "nonzero_181": {
                "variable": {
                    "value": "valid_batchid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "valid_batchid",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "a_valid.long() & s_valid.long()",
                            "BinOp"
                        ],
                        [
                            "torch.nonzero(valid_batchid, as_tuple=False).view(-1)",
                            "Call"
                        ],
                        [
                            "a_valid.long() & s_valid.long()",
                            "BinOp"
                        ],
                        [
                            "torch.nonzero(valid_batchid, as_tuple=False).view(-1)",
                            "Call"
                        ]
                    ]
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "pad_sequence_198": {
                "variable": {
                    "value": "x_a_pad_batch",
                    "type": "Variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "acoustic_batch",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[load_acoustic_data(x_file, self.root) for x_file in self.X_a[index]]",
                            "ListComp"
                        ],
                        [
                            "[load_acoustic_data(x_file, self.root) for x_file in self.X_a[index]]",
                            "ListComp"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_91": {
                "input": {
                    "value": "s_labels != -100",
                    "type": "Compare",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sum_174": {
                "input": {
                    "value": "s_labels != -100",
                    "type": "Compare",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/m2p_mask.py": {
        "torch": {
            "ones_62": {
                "variable": {
                    "value": "attn_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, seq_len)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "nonzero_142": {
                "variable": {
                    "value": "valid_batchid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_label.view(batch_size, -1).sum(dim=-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "ones_162": {
                "variable": {
                    "value": "attn_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, seq_len)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "ones_192": {
                "variable": {
                    "value": "attn_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, seq_len)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "no_grad_40": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_154": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_180": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_like_60": {
                "input": {
                    "value": "spec_stacked",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "spec.view(spec.shape[0], spec.shape[1] // dr, spec.shape[2] * dr)",
                            "Call"
                        ],
                        [
                            "down_sample_frames(target_spec, dr)",
                            "Call"
                        ],
                        [
                            "spec_stacked.to(dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "spec[:, :, -1]",
                            "Subscript"
                        ],
                        [
                            "spec_stacked.to(dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "down_sample_frames(spec[0], dr)",
                            "Call"
                        ],
                        [
                            "spec_stacked.to(dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_like_61": {
                "input": {
                    "value": "spec_stacked",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "spec.view(spec.shape[0], spec.shape[1] // dr, spec.shape[2] * dr)",
                            "Call"
                        ],
                        [
                            "down_sample_frames(target_spec, dr)",
                            "Call"
                        ],
                        [
                            "spec_stacked.to(dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "spec[:, :, -1]",
                            "Subscript"
                        ],
                        [
                            "spec_stacked.to(dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "down_sample_frames(spec[0], dr)",
                            "Call"
                        ],
                        [
                            "spec_stacked.to(dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_74": {
                "variable": {
                    "value": "offset",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "consecutive",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "masked_select_114": {
                "variable": {
                    "value": "zero_intervals",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "chosen_intervals",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "starts_to_intervals(chosen_starts, rand_bandwidth)",
                            "Call"
                        ],
                        [
                            "starts_to_intervals(chosen_starts, mask_consecutive)",
                            "Call"
                        ]
                    ]
                },
                "mask": {
                    "value": "zero_intervals",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.BoolTensor(dice < 0.8)",
                            "Call"
                        ],
                        [
                            "torch.masked_select(chosen_intervals, zero_intervals)",
                            "Call"
                        ]
                    ]
                }
            },
            "masked_select_116": {
                "variable": {
                    "value": "rand_intervals",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "chosen_intervals",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "starts_to_intervals(chosen_starts, rand_bandwidth)",
                            "Call"
                        ],
                        [
                            "starts_to_intervals(chosen_starts, mask_consecutive)",
                            "Call"
                        ]
                    ]
                },
                "mask": {
                    "value": "rand_intervals",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.BoolTensor((dice >= 0.8) * (dice < 0.9))",
                            "Call"
                        ],
                        [
                            "torch.masked_select(chosen_intervals, rand_intervals)",
                            "Call"
                        ]
                    ]
                }
            },
            "Normal_139": {
                "variable": {
                    "value": "noise_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "loc": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "scale": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                }
            },
            "arange_89": {
                "variable": {
                    "value": "valid_starts",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "rand_start",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "random.randint(0, min(mask_consecutive, valid_start_max))",
                            "Call"
                        ]
                    ]
                },
                "end": {
                    "value": "valid_start_max + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "step": {
                    "value": "mask_bucket_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "round(mask_consecutive * mask_bucket_ratio)",
                            "Call"
                        ]
                    ]
                }
            },
            "randperm_128": {
                "n": {
                    "value": "spec_masked.shape[2] - rand_bandwidth",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "randperm_85": {
                "n": {
                    "value": "valid_start_max + 1",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "randperm_120": {
                "n": {
                    "value": "spec_len[idx]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "randperm_90": {
                "n": {
                    "value": "len(valid_starts)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/m2p_model.py": {
        "torch": {
            "Embedding_19": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_20": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_21": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim * config.downsample_rate",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LayerNorm_23": {
                "variable": {
                    "value": "self.LayerNorm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "eps": {
                    "value": "config.layer_norm_eps",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_24": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_36": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_shape",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "inputs_embeds.size()[:-1]",
                            "Subscript"
                        ],
                        [
                            "inputs_embeds.size()[:-1]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "inputs_embeds.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "LayerNorm_64": {
                "variable": {
                    "value": "self.layer_norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "eps": {
                    "value": "config.layer_norm_eps",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_65": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.output_dim * config.downsample_rate",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Parameter_66": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(self.output_dim * config.downsample_rate)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_55": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_57": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_129": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_shape",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "inputs_embeds.size()[:-1]",
                            "Subscript"
                        ],
                        [
                            "inputs_embeds.size()[:-1]",
                            "Subscript"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "inputs_embeds.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_131": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_shape",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "inputs_embeds.size()[:-1]",
                            "Subscript"
                        ],
                        [
                            "inputs_embeds.size()[:-1]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "inputs_embeds.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "L1Loss_228": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "arange_27": {
                "start": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_66": {
                "*size": {
                    "value": "self.output_dim * config.downsample_rate",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_143": {
                "variable": {
                    "value": "encoder_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "encoder_hidden_shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "inputs_embeds.device",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "code/m2p_optimization.py": {
        "torch": {
            "zeros_like_263": {
                "variable": {
                    "value": "state[next_m]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_265": {
                "variable": {
                    "value": "state[next_v]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_395": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_397": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__272": {
                "parameters": {
                    "value": "p",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "code/m2p_runner.py": {
        "torch": {
            "load_138": {
                "variable": {
                    "value": "ckpt",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "ckptpth",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "is_available_19": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_54": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_158": {
                "obj": {
                    "value": "all_states",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "{'semantic_model': self.model.semantic_model.state_dict() if not self.args.multi_gpu else self.model.module.semantic_model.state_dict(), 'acoustic_model': self.model.acoustic_model.state_dict() if not self.args.multi_gpu else self.model.module.acoustic_model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "new_model_path",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "'{}/{}-{}.ckpt'.format(self.ckpdir, name, self.global_step)",
                            "Call"
                        ],
                        [
                            "to_path",
                            "Name"
                        ]
                    ]
                }
            },
            "device_18": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "no_grad_108": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_125": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_18": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clip_grad_norm__214": {
                "variable": {
                    "value": "grad_norm",
                    "type": "Variable",
                    "possible_values": []
                },
                "parameters": {
                    "value": "self.model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "self.gradient_clipping",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_count_55": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "empty_cache_240": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/m2p_transfer.py": {
        "torch": {
            "load_13": {
                "variable": {
                    "value": "ckpt_states",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "ckpt_path",
                    "type": "Variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Linear_134": {
                "variable": {
                    "value": "self.fuse_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.acoustic_config.hidden_size + self.semantic_config.hidden_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.acoustic_config.hidden_size + self.semantic_config.hidden_size",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_137": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.acoustic_config.hidden_size + self.semantic_config.hidden_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.label_num",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_140": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "drop_rate",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "0.2",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tanh_230": {
                "variable": {
                    "value": "fuse_encode_act",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "fuse_encode",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.cat([att_feats, max_feats], dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.cat([semantic_pool, acoustic_pool], dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.cat([semantic_pool, semantic_max], dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.cat([acoustic_pool, acoustic_max], dim=-1)",
                            "Call"
                        ],
                        [
                            "self.fuse_linear(fuse_encode)",
                            "Call"
                        ]
                    ]
                }
            },
            "norm_255": {
                "variable": {
                    "value": "acoustic_norm",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "acoustic_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "norm_256": {
                "variable": {
                    "value": "semantic_norm",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "acoustic_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "p": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "diag_258": {
                "variable": {
                    "value": "orth_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.matmul(acoustic_state, semantic_state.permute(1, 0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_259": {
                "variable": {
                    "value": "orth_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.abs(orth_loss / (acoustic_norm * semantic_norm))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_129": {
                "variable": {
                    "value": "self.acoustic_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.acoustic_config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.acoustic_config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_130": {
                "variable": {
                    "value": "self.acoustic_attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.acoustic_config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_132": {
                "variable": {
                    "value": "self.semantic_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.semantic_config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.semantic_config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "L1Loss_143": {
                "variable": {
                    "value": "self.loss_fct",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_145": {
                "variable": {
                    "value": "self.loss_fct",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tanh_197": {
                "variable": {
                    "value": "semantic_encode",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "semantic_encode",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "semantic_outputs[0]",
                            "Subscript"
                        ],
                        [
                            "self.semantic_linear(semantic_encode)",
                            "Call"
                        ],
                        [
                            "torch.tanh(semantic_encode)",
                            "Call"
                        ],
                        [
                            "semantic_encode * s_attention_mask[:, :, None] - 10000.0 * (1.0 - s_attention_mask[:, :, None])",
                            "BinOp"
                        ]
                    ]
                }
            },
            "tanh_206": {
                "variable": {
                    "value": "acoustic_encode",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "acoustic_encode",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "acoustic_outputs[0]",
                            "Subscript"
                        ],
                        [
                            "self.acoustic_linear(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "torch.tanh(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "acoustic_encode * a_attention_mask[:, :, None] - 10000.0 * (1.0 - a_attention_mask[:, :, None])",
                            "BinOp"
                        ]
                    ]
                }
            },
            "softmax_210": {
                "variable": {
                    "value": "acoustic_pool",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "acoustic_pool",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "self.acoustic_attention(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "acoustic_pool * a_attention_mask[:, :, None] - 10000.0 * (1.0 - a_attention_mask[:, :, None])",
                            "BinOp"
                        ],
                        [
                            "F.softmax(acoustic_pool, dim=1)",
                            "Call"
                        ],
                        [
                            "torch.matmul(acoustic_pool.permute(0, 2, 1), acoustic_encode).squeeze(1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "matmul_211": {
                "variable": {
                    "value": "acoustic_pool",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "acoustic_pool.permute(0, 2, 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "other": {
                    "value": "acoustic_encode",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "acoustic_outputs[0]",
                            "Subscript"
                        ],
                        [
                            "self.acoustic_linear(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "torch.tanh(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "acoustic_encode * a_attention_mask[:, :, None] - 10000.0 * (1.0 - a_attention_mask[:, :, None])",
                            "BinOp"
                        ]
                    ]
                }
            },
            "squeeze_211": {
                "variable": {
                    "value": "acoustic_pool",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_220": {
                "variable": {
                    "value": "fuse_encode",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[att_feats, max_feats]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_222": {
                "variable": {
                    "value": "fuse_encode",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[semantic_pool, acoustic_pool]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_225": {
                "variable": {
                    "value": "fuse_encode",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[semantic_pool, semantic_max]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_227": {
                "variable": {
                    "value": "fuse_encode",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[acoustic_pool, acoustic_max]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "matmul_258": {
                "input": {
                    "value": "acoustic_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "other": {
                    "value": "semantic_state.permute(1, 0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "abs_259": {
                "input": {
                    "value": "orth_loss / (acoustic_norm * semantic_norm)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "no_grad_164": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_202": {
                "input": {
                    "value": "semantic_encode[:, 1:, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "max_214": {
                "input": {
                    "value": "acoustic_encode",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "acoustic_outputs[0]",
                            "Subscript"
                        ],
                        [
                            "self.acoustic_linear(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "torch.tanh(acoustic_encode)",
                            "Call"
                        ],
                        [
                            "acoustic_encode * a_attention_mask[:, :, None] - 10000.0 * (1.0 - a_attention_mask[:, :, None])",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/run_m2pretrain.py": {
        "torch": {
            "DataLoader_89": {
                "variable": {
                    "value": "dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "MultiModalDataset(file_path=config['dataloader']['data_path'], sets=config['dataloader']['train_set'], bucket_size=config['dataloader']['batch_size'], max_timestep=config['dataloader']['max_timestep'], drop=True, acoustic_config=config['acoustic'], semantic_config=config['semantic'], tokenizer=tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "config['dataloader']['n_jobs']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "yaml.load(open(args.config, 'r'), Loader=yaml.FullLoader)",
                            "Call"
                        ],
                        [
                            "ckpt['Settings']['Config']",
                            "Subscript"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "load_65": {
                "variable": {
                    "value": "ckpt",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "resume_ckpt",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "args.resume",
                            "Attribute"
                        ],
                        [
                            "ckpts[-1]",
                            "Subscript"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "code/run_s-iemocap.py": {
        "torch": {
            "tensor_38": {
                "variable": {
                    "value": "batch_label",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[x['label'] for x in sample_list]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_99": {
                "variable": {
                    "value": "train_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "EmotionDataset(train_data, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "16",
                            "Constant"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "4",
                            "Constant"
                        ]
                    ]
                }
            },
            "DataLoader_104": {
                "variable": {
                    "value": "valid_loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valid_dataset",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "EmotionDataset(valid_data, tokenizer)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "16",
                            "Constant"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda x: collate(x, tokenizer)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "4",
                            "Constant"
                        ]
                    ]
                }
            },
            "mean_128": {
                "variable": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tensor(epoch_train_loss)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "argmax_139": {
                "variable": {
                    "value": "label_outputs",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs.logits",
                    "type": "Attribute",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_128": {
                "data": {
                    "value": "epoch_train_loss",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.mean(torch.tensor(epoch_train_loss)).cpu().detach().numpy()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    }
}