{
    "Language model/char_lang_model.py": {
        "sklearn": {},
        "tensorflow": {
            "set_verbosity_43": {
                "level": {
                    "value": "tf.logging.INFO",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Input_98": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "name": {
                    "value": "seed",
                    "type": "str",
                    "possible_values": []
                },
                "shape": {
                    "value": "(seq_len,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "128",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Model_105": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "inputs": {
                    "value": "[source]",
                    "type": "List",
                    "possible_values": []
                },
                "outputs": {
                    "value": "[predicted_char]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "clear_session_116": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "info_64": {
                "msg": {
                    "value": "Input text [%d] %s",
                    "type": "str",
                    "possible_values": []
                },
                "*args": {
                    "value": "len(txt)",
                    "type": "Call",
                    "possible_values": []
                },
                "**kwargs": {
                    "value": "txt[:50]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "GFile_61": {
                "name": {
                    "value": "SHAKESPEARE_TXT",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'/media/raid6/shivam/langmodels/data/new_persona.txt'",
                            "Constant"
                        ]
                    ]
                },
                "mode": {
                    "value": "r",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Embedding_101": {
                "input_dim": {
                    "value": "max_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "output_dim": {
                    "value": "EMBEDDING_DIM",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ]
                    ]
                }
            },
            "LSTM_102": {
                "units": {
                    "value": "EMBEDDING_DIM",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ]
                    ]
                },
                "stateful": {
                    "value": "stateful",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                },
                "return_sequences": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "LSTM_103": {
                "units": {
                    "value": "EMBEDDING_DIM",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ]
                    ]
                },
                "stateful": {
                    "value": "stateful",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                },
                "return_sequences": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "TimeDistributed_104": {
                "layer": {
                    "value": "tf.keras.layers.Dense(max_tokens, activation='softmax')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Dense_104": {
                "units": {
                    "value": "max_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "activation": {
                    "value": "softmax",
                    "type": "str",
                    "possible_values": []
                }
            },
            "RMSPropOptimizer_107": {
                "learning_rate": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "Multi-label image classification/train2.py": {
        "sklearn": {}
    },
    "Show, attend and Tell (Soft Attention)/tensorflow_attention.py": {
        "sklearn": {
            "train_test_split_163": {
                "variable": {
                    "value": "(img_name_train, img_name_val, cap_train, cap_val)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "*arrays_0": {
                    "value": "img_name_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "*arrays_1": {
                    "value": "cap_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "test_size": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                },
                "random_state": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        },
        "tensorflow": {
            "ConfigProto_30": {
                "variable": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": []
                },
                "device_count": {
                    "value": "{'GPU': 1}",
                    "type": "Dict",
                    "possible_values": []
                }
            },
            "Session_31": {
                "variable": {
                    "value": "sess",
                    "type": "variable",
                    "possible_values": []
                },
                "config": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.ConfigProto(device_count={'GPU': 1})",
                            "Call"
                        ]
                    ]
                }
            },
            "enable_eager_execution_26": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "InceptionV3_102": {
                "variable": {
                    "value": "image_model",
                    "type": "variable",
                    "possible_values": []
                },
                "include_top": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "weights": {
                    "value": "imagenet",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Model_107": {
                "variable": {
                    "value": "image_features_extract_model",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "new_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "image_model.input",
                            "Attribute"
                        ]
                    ]
                },
                "**kwargs": {
                    "value": "hidden_layer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "image_model.layers[-1].output",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Tokenizer_137": {
                "variable": {
                    "value": "tokenizer",
                    "type": "variable",
                    "possible_values": []
                },
                "num_words": {
                    "value": "top_k",
                    "type": "variable",
                    "possible_values": [
                        [
                            "5000",
                            "Constant"
                        ]
                    ]
                },
                "oov_token": {
                    "value": "<unk>",
                    "type": "str",
                    "possible_values": []
                },
                "filters": {
                    "value": "!\"#$%&()*+.,-/:;=?@[\\\\]^_`{|}~ ",
                    "type": "str",
                    "possible_values": []
                }
            },
            "pad_sequences_156": {
                "variable": {
                    "value": "cap_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "train_seqs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tokenizer.texts_to_sequences(train_captions)",
                            "Call"
                        ],
                        [
                            "tokenizer.texts_to_sequences(train_captions)",
                            "Call"
                        ]
                    ]
                },
                "padding": {
                    "value": "post",
                    "type": "str",
                    "possible_values": []
                }
            },
            "AdamOptimizer_316": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Checkpoint_330": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.train.AdamOptimizer()",
                            "Call"
                        ]
                    ]
                },
                "encoder": {
                    "value": "encoder",
                    "type": "variable",
                    "possible_values": [
                        [
                            "CNN_Encoder(embedding_dim)",
                            "Call"
                        ]
                    ]
                },
                "decoder": {
                    "value": "decoder",
                    "type": "variable",
                    "possible_values": [
                        [
                            "RNN_Decoder(embedding_dim, units, vocab_size)",
                            "Call"
                        ]
                    ]
                }
            },
            "read_file_96": {
                "variable": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": []
                },
                "filename": {
                    "value": "image_path",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "decode_jpeg_97": {
                "variable": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.read_file(image_path)",
                            "Call"
                        ],
                        [
                            "tf.image.decode_jpeg(img, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize_images(img, (299, 299))",
                            "Call"
                        ],
                        [
                            "tf.keras.applications.inception_v3.preprocess_input(img)",
                            "Call"
                        ]
                    ]
                },
                "channels": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "preprocess_input_99": {
                "variable": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.read_file(image_path)",
                            "Call"
                        ],
                        [
                            "tf.image.decode_jpeg(img, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize_images(img, (299, 299))",
                            "Call"
                        ],
                        [
                            "tf.keras.applications.inception_v3.preprocess_input(img)",
                            "Call"
                        ]
                    ]
                }
            },
            "exp_406": {
                "variable": {
                    "value": "perplex_per_epoch[epoch + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "x": {
                    "value": "total_loss / len(cap_vector)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "expand_dims_434": {
                "variable": {
                    "value": "temp_input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "load_image(image)[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "reshape_436": {
                "variable": {
                    "value": "img_tensor_val",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "img_tensor_val",
                    "type": "variable",
                    "possible_values": [
                        [
                            "image_features_extract_model(temp_input)",
                            "Call"
                        ],
                        [
                            "tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "(img_tensor_val.shape[0], -1, img_tensor_val.shape[3])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "expand_dims_440": {
                "variable": {
                    "value": "dec_input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "[tokenizer.word_index['<start>']]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_gpu_available_214": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dense_233": {
                "variable": {
                    "value": "self.W1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "units": {
                    "value": "units",
                    "type": "variable",
                    "possible_values": [
                        [
                            "512",
                            "Constant"
                        ]
                    ]
                }
            },
            "Dense_234": {
                "variable": {
                    "value": "self.W2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "units": {
                    "value": "units",
                    "type": "variable",
                    "possible_values": [
                        [
                            "512",
                            "Constant"
                        ]
                    ]
                }
            },
            "Dense_235": {
                "variable": {
                    "value": "self.V",
                    "type": "Attribute",
                    "possible_values": []
                },
                "units": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "expand_dims_242": {
                "variable": {
                    "value": "hidden_with_time_axis",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder.reset_state(batch_size=target.shape[0])",
                            "Call"
                        ],
                        [
                            "decoder.reset_state(batch_size=1)",
                            "Call"
                        ]
                    ]
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tanh_245": {
                "variable": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": []
                },
                "x": {
                    "value": "self.W1(features) + self.W2(hidden_with_time_axis)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "softmax_249": {
                "variable": {
                    "value": "attention_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "self.V(score)",
                    "type": "Call",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "reduce_sum_253": {
                "variable": {
                    "value": "context_vector",
                    "type": "variable",
                    "possible_values": []
                },
                "input_tensor": {
                    "value": "context_vector",
                    "type": "variable",
                    "possible_values": [
                        [
                            "attention_weights * features",
                            "BinOp"
                        ],
                        [
                            "tf.reduce_sum(context_vector, axis=1)",
                            "Call"
                        ]
                    ]
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Dense_264": {
                "variable": {
                    "value": "self.fc",
                    "type": "Attribute",
                    "possible_values": []
                },
                "units": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "Constant"
                        ]
                    ]
                }
            },
            "relu_268": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "features": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.fc(x)",
                            "Call"
                        ],
                        [
                            "tf.nn.relu(x)",
                            "Call"
                        ],
                        [
                            "self.embedding(x)",
                            "Call"
                        ],
                        [
                            "tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)",
                            "Call"
                        ],
                        [
                            "self.fc1(output)",
                            "Call"
                        ],
                        [
                            "tf.reshape(x, (-1, x.shape[2]))",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "Embedding_277": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input_dim": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(tokenizer.word_index)",
                            "Call"
                        ]
                    ]
                },
                "output_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "Constant"
                        ]
                    ]
                }
            },
            "Dense_279": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "units": {
                    "value": "self.units",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dense_280": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "units": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(tokenizer.word_index)",
                            "Call"
                        ]
                    ]
                }
            },
            "concat_292": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "values": {
                    "value": "[tf.expand_dims(context_vector, 1), x]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "reshape_301": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.fc(x)",
                            "Call"
                        ],
                        [
                            "tf.nn.relu(x)",
                            "Call"
                        ],
                        [
                            "self.embedding(x)",
                            "Call"
                        ],
                        [
                            "tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)",
                            "Call"
                        ],
                        [
                            "self.fc1(output)",
                            "Call"
                        ],
                        [
                            "tf.reshape(x, (-1, x.shape[2]))",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "(-1, x.shape[2])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "reduce_mean_322": {
                "input_tensor": {
                    "value": "loss_",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask",
                            "BinOp"
                        ]
                    ]
                }
            },
            "latest_checkpoint_342": {
                "checkpoint_dir": {
                    "value": "/media/raid6/shivam/imagecaption/colab_attention/40training_checkpoints",
                    "type": "str",
                    "possible_values": []
                }
            },
            "expand_dims_357": {
                "variable": {
                    "value": "dec_input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "[tokenizer.word_index['<start>']] * BATCH_SIZE",
                    "type": "BinOp",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "reshape_446": {
                "variable": {
                    "value": "attention_plot[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensor": {
                    "value": "attention_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tf.nn.softmax(self.V(score), axis=1)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "(-1,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "argmax_448": {
                "variable": {
                    "value": "predicted_id",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "predictions[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "expand_dims_454": {
                "variable": {
                    "value": "dec_input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "[predicted_id]",
                    "type": "List",
                    "possible_values": []
                },
                "axis": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "py_func_201": {
                "func": {
                    "value": "map_func",
                    "type": "variable",
                    "possible_values": []
                },
                "inp": {
                    "value": "[item1, item2]",
                    "type": "List",
                    "possible_values": []
                },
                "Tout": {
                    "value": "[tf.float32, tf.int32]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "CuDNNGRU_217": {
                "units": {
                    "value": "units",
                    "type": "variable",
                    "possible_values": [
                        [
                            "512",
                            "Constant"
                        ]
                    ]
                },
                "return_sequences": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "return_state": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "recurrent_initializer": {
                    "value": "glorot_uniform",
                    "type": "str",
                    "possible_values": []
                }
            },
            "GRU_222": {
                "units": {
                    "value": "units",
                    "type": "variable",
                    "possible_values": [
                        [
                            "512",
                            "Constant"
                        ]
                    ]
                },
                "return_sequences": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "return_state": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "recurrent_activation": {
                    "value": "sigmoid",
                    "type": "str",
                    "possible_values": []
                },
                "recurrent_initializer": {
                    "value": "glorot_uniform",
                    "type": "str",
                    "possible_values": []
                }
            },
            "zeros_309": {
                "shape": {
                    "value": "(batch_size, self.units)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "sparse_softmax_cross_entropy_with_logits_321": {
                "labels": {
                    "value": "real",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "pred",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "GradientTape_359": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "expand_dims_369": {
                "variable": {
                    "value": "dec_input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "target[:, i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "get_or_create_global_step_377": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "expand_dims_292": {
                "input": {
                    "value": "context_vector",
                    "type": "variable",
                    "possible_values": [
                        [
                            "attention_weights * features",
                            "BinOp"
                        ],
                        [
                            "tf.reduce_sum(context_vector, axis=1)",
                            "Call"
                        ]
                    ]
                },
                "axis": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_382": {
                "x": {
                    "value": "loss.numpy() / int(target.shape[1])",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "preprocess.py": {
        "sklearn": {
            "train_test_split_38": {
                "variable": {
                    "value": "(img_train, img_val, tags_train, tags_val)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "*arrays_0": {
                    "value": "path_perImg",
                    "type": "variable",
                    "possible_values": []
                },
                "*arrays_1": {
                    "value": "tags_perImg",
                    "type": "variable",
                    "possible_values": []
                },
                "test_size": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "random_state": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "train_test_split_44": {
                "variable": {
                    "value": "(img_vald, img_test, tags_vald, tags_test)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "*arrays_0": {
                    "value": "img_val",
                    "type": "variable",
                    "possible_values": []
                },
                "*arrays_1": {
                    "value": "tags_val",
                    "type": "variable",
                    "possible_values": []
                },
                "test_size": {
                    "value": "0.5",
                    "type": "float",
                    "possible_values": []
                },
                "random_state": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "Show and tell/data_loader.py": {
        "torch": {
            "stack_81": {
                "variable": {
                    "value": "images",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "images",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.stack(images, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_87": {
                "variable": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(captions)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "max(lengths)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "DataLoader_106": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "coco",
                    "type": "variable",
                    "possible_values": [
                        [
                            "CocoDataset(root=root, json=json, vocab=vocab, transform=transform)",
                            "Call"
                        ],
                        [
                            "self.coco",
                            "Attribute"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "shuffle",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "variable",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Tensor_54": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sort_76": {
                "key": {
                    "value": "lambda x: len(x[1])",
                    "type": "Lambda",
                    "possible_values": []
                },
                "reverse": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "Show and tell/model.py": {
        "torch": {
            "Sequential_13": {
                "variable": {
                    "value": "self.resnet",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*modules",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Linear_14": {
                "variable": {
                    "value": "self.linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "resnet.fc.in_features",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "BatchNorm1d_15": {
                "variable": {
                    "value": "self.bn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_features": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Embedding_30": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LSTM_31": {
                "variable": {
                    "value": "self.lstm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_32": {
                "variable": {
                    "value": "self.linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_38": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(features.unsqueeze(1), embeddings)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_39": {
                "variable": {
                    "value": "packed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed(captions)",
                            "Call"
                        ],
                        [
                            "torch.cat((features.unsqueeze(1), embeddings), 1)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "stack_55": {
                "variable": {
                    "value": "sampled_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "sampled_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(sampled_ids, 1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_19": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "Show and tell/sample.py": {
        "torch": {
            "device_17": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_available_17": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_46": {
                "f": {
                    "value": "args.encoder_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_47": {
                "f": {
                    "value": "args.decoder_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "Show and tell/train.py": {
        "torch": {
            "device_15": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_46": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Adam_48": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "params",
                    "type": "variable",
                    "possible_values": [
                        [
                            "list(decoder.parameters()) + list(encoder.linear.parameters()) + list(encoder.bn.parameters())",
                            "BinOp"
                        ]
                    ]
                },
                "lr": {
                    "value": "args.learning_rate",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_15": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "pack_padded_sequence_69": {
                "input": {
                    "value": "captions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "captions.to(device)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "save_99": {
                "obj": {
                    "value": "decoder.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(args.model_path, 'decoder-{}-{}.ckpt'.format(epoch + 1, i + 1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "save_101": {
                "obj": {
                    "value": "encoder.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(args.model_path, 'encoder-{}-{}.ckpt'.format(epoch + 1, i + 1))",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "flask/app.py": {
        "torch": {
            "device_29": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_58": {
                "f": {
                    "value": "args.encoder_path",
                    "type": "Attribute",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "load_59": {
                "f": {
                    "value": "args.decoder_path",
                    "type": "Attribute",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage",
                    "type": "Lambda",
                    "possible_values": []
                }
            }
        }
    },
    "flask/data_loader.py": {
        "torch": {
            "stack_81": {
                "variable": {
                    "value": "images",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "images",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.stack(images, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_87": {
                "variable": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "len(captions)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "max(lengths)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "DataLoader_106": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "coco",
                    "type": "variable",
                    "possible_values": [
                        [
                            "CocoDataset(root=root, json=json, vocab=vocab, transform=transform)",
                            "Call"
                        ],
                        [
                            "self.coco",
                            "Attribute"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "shuffle",
                    "type": "variable",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "variable",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Tensor_54": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "sort_76": {
                "key": {
                    "value": "lambda x: len(x[1])",
                    "type": "Lambda",
                    "possible_values": []
                },
                "reverse": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "flask/model.py": {
        "torch": {
            "Sequential_13": {
                "variable": {
                    "value": "self.resnet",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*modules",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Linear_14": {
                "variable": {
                    "value": "self.linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "resnet.fc.in_features",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "BatchNorm1d_15": {
                "variable": {
                    "value": "self.bn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_features": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "momentum": {
                    "value": "0.01",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Embedding_30": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LSTM_31": {
                "variable": {
                    "value": "self.lstm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "embed_size",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_32": {
                "variable": {
                    "value": "self.linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_38": {
                "variable": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(features.unsqueeze(1), embeddings)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_39": {
                "variable": {
                    "value": "packed",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed(captions)",
                            "Call"
                        ],
                        [
                            "torch.cat((features.unsqueeze(1), embeddings), 1)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "stack_55": {
                "variable": {
                    "value": "sampled_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "sampled_ids",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(sampled_ids, 1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_19": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}