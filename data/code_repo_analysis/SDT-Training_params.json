{
    "eval_lm.py": {
        "torch": {
            "is_available_56": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/bleu.py": {
        "torch": {}
    },
    "fairseq/criterions/adaptive_loss.py": {
        "torch": {
            "cross_entropy_60": {
                "input": {
                    "value": "logits[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "target": {
                    "value": "target[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/criterions/composite_loss.py": {
        "torch": {}
    },
    "fairseq/criterions/cross_entropy.py": {
        "torch": {
            "nll_loss_45": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_normalized_probs(net_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "lprobs.view(-1, lprobs.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, net_output).view(-1)",
                            "Call"
                        ]
                    ]
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/criterions/fairseq_criterion.py": {
        "torch": {}
    },
    "fairseq/criterions/label_smoothed_adaptive_loss.py": {
        "torch": {
            "cross_entropy_70": {
                "input": {
                    "value": "logits[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "target": {
                    "value": "target[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduce": {
                    "value": "reduce",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/backtranslation_dataset.py": {
        "torch": {
            "is_available_90": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/dictionary.py": {
        "torch": {
            "Tensor_216": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "is_tensor_56": {
                "obj": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/fairseq_dataset.py": {
        "torch": {}
    },
    "fairseq/data/indexed_dataset.py": {
        "torch": {
            "from_numpy_92": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "a",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "from_numpy_149": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "a",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/iterators.py": {
        "torch": {
            "DataLoader_184": {
                "dataset": {
                    "value": "self.dataset",
                    "type": "Attribute",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "self.collate_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_sampler": {
                    "value": "batches",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(list(batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "list(ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[]))",
                            "Call"
                        ],
                        [
                            "shuffle_batches(list(self.frozen_batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(batches, self.seed + epoch + self.shard_id)",
                            "Call"
                        ],
                        [
                            "ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[])",
                            "Call"
                        ],
                        [
                            "batches",
                            "Method Argument"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "self.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/language_pair_dataset.py": {
        "torch": {
            "cat_137": {
                "variable": {
                    "value": "tgt_item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.tgt[index], torch.LongTensor([eos])]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/lm_context_window_dataset.py": {
        "torch": {
            "from_numpy_59": {
                "variable": {
                    "value": "sample[net_input][src_tokens]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_toks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty([bsz, tsz + self.context_window], dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_60": {
                "variable": {
                    "value": "sample[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_tgt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.full([bsz, tsz + self.context_window], pad, dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/monolingual_dataset.py": {
        "torch": {
            "cat_98": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[source, source.new([self.vocab.eos()])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_101": {
                "variable": {
                    "value": "future_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[future_target, future_target.new([self.vocab.pad()])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_105": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[past_target.new([self.vocab.pad()]), past_target[1:], source[-2, None]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/noising.py": {
        "torch": {
            "t_65": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.t(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "t_289": {
                "variable": {
                    "value": "src_tokens_t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.src_dataset[index]",
                            "Subscript"
                        ],
                        [
                            "src_tokens.unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "t_296": {
                "variable": {
                    "value": "noisy_src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "noisy_src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.word_shuffle.noising(x=x, lengths=lengths, max_shuffle_distance=self.max_word_shuffle_distance)",
                            "Call"
                        ],
                        [
                            "self.word_dropout.noising(x=noisy_src_tokens, lengths=noisy_src_lengths, dropout_prob=self.word_dropout_prob)",
                            "Call"
                        ],
                        [
                            "self.word_dropout.noising(x=noisy_src_tokens, lengths=noisy_src_lengths, dropout_prob=self.word_blanking_prob, blank_idx=self.dictionary.unk())",
                            "Call"
                        ],
                        [
                            "self.noiser.noising(src_tokens_t, src_lengths)",
                            "Call"
                        ],
                        [
                            "torch.t(noisy_src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_178": {
                "ndarray": {
                    "value": "permutation",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.argsort()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/data/token_block_dataset.py": {
        "torch": {
            "cat_105": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.dataset[idx] for idx in range(start_ds_idx, end_ds_idx + 1)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "cat_118": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.eos]), buffer[0:e - 1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_119": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.pad, self.eos]), buffer[0:e - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_123": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.eos]), buffer[0:e - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/data/transform_eos_dataset.py": {
        "torch": {
            "cat_84": {
                "variable": {
                    "value": "item[source]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item['source'], self.eos]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_90": {
                "variable": {
                    "value": "item[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item['target'], self.eos]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/distributed_utils.py": {
        "torch": {}
    },
    "fairseq/legacy_distributed_data_parallel.py": {
        "torch": {
            "zeros_like_144": {
                "variable": {
                    "value": "param.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "param",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_111": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ],
                        [
                            "params[0]",
                            "Subscript"
                        ],
                        [
                            "params",
                            "variable"
                        ],
                        [
                            "params",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/models/distributed_fairseq_model.py": {
        "torch": {}
    },
    "fairseq/models/dlcl_transformer.py": {
        "torch": {
            "Embedding_715": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_722": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_200": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_231": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_347": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_414": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_539": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for i in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_554": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_560": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_561": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_563": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_662": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_691": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_692": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_694": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "triu_471": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_473": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_685": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_369": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_456": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_458": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_297": {},
            "Tensor_497": {}
        }
    },
    "fairseq/models/fairseq_decoder.py": {
        "torch": {}
    },
    "fairseq/models/fairseq_encoder.py": {
        "torch": {}
    },
    "fairseq/models/fairseq_model.py": {
        "torch": {
            "ModuleDict_197": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "{key: FairseqModel(encoders[key], decoders[key]) for key in self.keys}",
                    "type": "DictComp",
                    "possible_values": []
                }
            },
            "is_tensor_42": {
                "obj": {
                    "value": "net_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output",
                            "Method Argument"
                        ],
                        [
                            "net_output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "remove_weight_norm_104": {
                "module": {
                    "value": "module",
                    "type": "variable",
                    "possible_values": [
                        [
                            "module",
                            "Method Argument"
                        ],
                        [
                            "module",
                            "Method Argument"
                        ],
                        [
                            "module",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_45": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_47": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/fconv.py": {
        "torch": {
            "Embedding_613": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_628": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_211": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_212": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_256": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_360": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x.view(sz[0] * sz[1], sz[2])",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_425": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_426": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_427": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_485": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "weight_norm_631": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx, left_pad)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_640": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx, left_pad)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "weight_norm_650": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx, left_pad)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_282": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_291": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_506": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_508": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_536": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_289": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, padding_r)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Linear_461": {
                "variable": {
                    "value": "self.fc3",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "out_embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "weight_norm_558": {
                "variable": {
                    "value": "self.convolutions[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "module": {
                    "value": "conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "zip(self.projections, self.convolutions, self.residuals)",
                            "Call"
                        ],
                        [
                            "zip(self.projections, self.convolutions, self.attention, self.residuals)",
                            "Call"
                        ],
                        [
                            "conv in enumerate(self.convolutions)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "remove_weight_norm_557": {
                "module": {
                    "value": "conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "zip(self.projections, self.convolutions, self.residuals)",
                            "Call"
                        ],
                        [
                            "zip(self.projections, self.convolutions, self.attention, self.residuals)",
                            "Call"
                        ],
                        [
                            "conv in enumerate(self.convolutions)",
                            "Call"
                        ]
                    ]
                }
            },
            "Tensor_553": {}
        }
    },
    "fairseq/models/fconv_self_att.py": {
        "torch": {
            "Embedding_485": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_498": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_170": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_171": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_172": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_173": {
                "variable": {
                    "value": "self.attproj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_192": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_308": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_309": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_310": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_311": {
                "variable": {
                    "value": "self.selfattention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_312": {
                "variable": {
                    "value": "self.attproj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_385": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_426": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_212": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_215": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, padding_r)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "glu_217": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_349": {
                "variable": {
                    "value": "self.gate1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_350": {
                "variable": {
                    "value": "self.gate2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_352": {
                "variable": {
                    "value": "self.joining",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim * 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_401": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_403": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_433": {
                "variable": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x, self.pretrained_outputs['out']]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_438": {
                "variable": {
                    "value": "fusion",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[gated_x1, gated_x2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Sigmoid_349": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sigmoid_350": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_355": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_358": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/lightconv.py": {
        "torch": {
            "Embedding_767": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_774": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_314": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_343": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_429": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_494": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_585": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for _ in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_599": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_607": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_613": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_614": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_616": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_708": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_714": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_743": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_744": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_746": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "triu_539": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_541": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "GLU_561": {
                "variable": {
                    "value": "self.act",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_649": {
                "variable": {
                    "value": "self.act",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_737": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_451": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_524": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_526": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/lstm.py": {
        "torch": {
            "Embedding_470": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(task.source_dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "LSTM_477": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LSTMCell_485": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "input_size": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size",
                            "Method Argument"
                        ],
                        [
                            "input_size",
                            "Method Argument"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hidden_size",
                            "Method Argument"
                        ],
                        [
                            "hidden_size",
                            "Method Argument"
                        ],
                        [
                            "512",
                            "Method Argument"
                        ],
                        [
                            "512",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_494": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_220": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "F.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_in",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_226": {
                "variable": {
                    "value": "packed_x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "F.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "src_lengths.data.tolist()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_238": {
                "variable": {
                    "value": "(x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "sequence": {
                    "value": "packed_outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.lstm(packed_x, (h0, c0))",
                            "Call"
                        ]
                    ]
                },
                "padding_value": {
                    "value": "self.padding_value",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_239": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "F.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_297": {
                "variable": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(source_hids * x.unsqueeze(0)).sum(dim=2)",
                            "Call"
                        ],
                        [
                            "attn_scores.float().masked_fill_(encoder_padding_mask, float('-inf')).type_as(attn_scores)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_scores, dim=0)",
                            "Call"
                        ],
                        [
                            "x.new_zeros(srclen, seqlen, bsz)",
                            "Call"
                        ],
                        [
                            "attn_scores.transpose(0, 2)",
                            "Call"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tanh_302": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.output_proj(torch.cat((x, input), dim=1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_335": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LSTMCell(input_size=hidden_size + embed_dim if layer == 0 else hidden_size, hidden_size=hidden_size) for layer in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_370": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "F.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_in",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_425": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "outs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_392": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x[j, :, :], input_feed)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_410": {
                "variable": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()",
                            "Call"
                        ],
                        [
                            "self.attention(hidden, encoder_outs, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "hidden",
                            "variable"
                        ],
                        [
                            "F.dropout(out, p=self.dropout_out, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_399": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "rnn(input, (prev_hiddens[i], prev_cells[i]))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_440": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "F.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_442": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "F.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_302": {
                "tensors": {
                    "value": "(x, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/models/sdt_transformer.py": {
        "torch": {
            "Embedding_802": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_809": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_211": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_246": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_429": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_497": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_623": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for i in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_638": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_645": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_646": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_648": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_749": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_778": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_779": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_781": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CosineSimilarity_308": {
                "variable": {
                    "value": "cos",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-06",
                    "type": "float",
                    "possible_values": []
                }
            },
            "CosineSimilarity_325": {
                "variable": {
                    "value": "cos",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-06",
                    "type": "float",
                    "possible_values": []
                }
            },
            "triu_554": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_556": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_772": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_451": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_539": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_541": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "self.history.pop()",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_380": {},
            "Tensor_580": {}
        }
    },
    "fairseq/models/transformer.py": {
        "torch": {
            "Embedding_780": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_787": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_291": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_320": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_423": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_488": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_603": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for i in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_618": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_624": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_625": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_627": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_727": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_756": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_757": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_759": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "triu_534": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_536": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_750": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_445": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_519": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_521": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state, self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.self_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_375": {},
            "Tensor_560": {}
        }
    },
    "fairseq/modules/adaptive_input.py": {
        "torch": {
            "ModuleList_38": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_43": {
                "variable": {
                    "value": "seq",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Embedding(size, dim, padding_idx)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_44": {
                "num_embeddings": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.cutoff[i] - prev",
                            "BinOp"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_45": {
                "in_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/adaptive_softmax.py": {
        "torch": {
            "Linear_39": {
                "variable": {
                    "value": "self.class_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_classes",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "LogSoftmax_76": {
                "variable": {
                    "value": "self.lsm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_94": {
                "variable": {
                    "value": "self.tail",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_159": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_23": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight.t() if self.transpose else self.weight",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Sequential_34": {
                "variable": {
                    "value": "self.word_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(input_dim, emb_dim, bias=False)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_81": {
                "variable": {
                    "value": "self.head",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cutoff[0] + len(cutoff) - 1",
                            "BinOp"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Sequential_109": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_107": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + 1))",
                            "Call"
                        ],
                        [
                            "input.size()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_35": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "emb_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tied_emb.size()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_105": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "tied_proj.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "tied_proj.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_111": {
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_112": {
                "in_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + 1))",
                            "Call"
                        ],
                        [
                            "input.size()",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.cutoff[i + 1] - self.cutoff[i]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/bak.py": {
        "torch": {
            "Parameter_32": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_37": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_49": {
                "variable": {
                    "value": "self.relative_position_keys",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(2 * self.max_relative_length + 1, self.head_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_50": {
                "variable": {
                    "value": "self.relative_position_values",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(2 * self.max_relative_length + 1, self.head_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "embedding_176": {
                "variable": {
                    "value": "relation_keys",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_positions_matrix.long().cuda()",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.relative_position_keys",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "embedding_177": {
                "variable": {
                    "value": "relation_values",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_positions_matrix.long().cuda()",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.relative_position_values",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_206": {
                "variable": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._relative_attention_inner(q, k, relation_keys, transpose=True)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "relative_attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(relative_attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(relative_attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), relative_attn_weights.float()).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clamp_282": {
                "variable": {
                    "value": "distance_mat_clipped",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "distance_mat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "range_mat - range_mat.transpose(0, 1)",
                            "BinOp"
                        ],
                        [
                            "torch.range(-length + 1, 0).view(1, -1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "-max_relative_length",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "max": {
                    "value": "max_relative_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_relative_length",
                            "Method Argument"
                        ],
                        [
                            "max_relative_length",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_313": {
                "variable": {
                    "value": "xy_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "mat2": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "y.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "y",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_319": {
                "variable": {
                    "value": "x_tz_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "z",
                    "type": "variable",
                    "possible_values": [
                        [
                            "z.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "z",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "transpose_319": {
                "variable": {
                    "value": "x_tz_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_34": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_40": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_41": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_121": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_122": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_162": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, k.new_zeros((k.size(0), 1) + k.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_163": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, v.new_zeros((v.size(0), 1) + v.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "linear_248": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_276": {
                "variable": {
                    "value": "range_vec",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "z.size()[0]",
                            "Subscript"
                        ],
                        [
                            "length",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "range_280": {
                "variable": {
                    "value": "distance_mat",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "-length + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "end": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_124": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_126": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_165": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_167": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, torch.zeros(key_padding_mask.size(0), 1).type_as(key_padding_mask)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "where_191": {
                "variable": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "key_padding_mask.unsqueeze(1).unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "torch.Tensor([float('-Inf')])",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "relative_attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_142": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_key, k)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_148": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_value, v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_168": {
                "*size": {
                    "value": "key_padding_mask.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/beamable_mm.py": {
        "torch": {
            "mm_41": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mat2": {
                    "value": "input2[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/character_token_embedder.py": {
        "torch": {
            "Embedding_38": {
                "variable": {
                    "value": "self.char_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "257",
                    "type": "int",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "char_embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "variable": {
                    "value": "self.symbol_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(2, word_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_43": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_53": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "last_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sum((f[1] for f in filters))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "word_embed_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_154": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "conv_result",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "max_150": {
                "variable": {
                    "value": "(x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv(char_embs)",
                            "Call"
                        ],
                        [
                            "torch.max(x, -1)",
                            "Call"
                        ],
                        [
                            "F.relu(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(conv_result, dim=-1)",
                            "Call"
                        ],
                        [
                            "self.highway(x)",
                            "Call"
                        ],
                        [
                            "self.projection(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_151": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv(char_embs)",
                            "Call"
                        ],
                        [
                            "torch.max(x, -1)",
                            "Call"
                        ],
                        [
                            "F.relu(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(conv_result, dim=-1)",
                            "Call"
                        ],
                        [
                            "self.highway(x)",
                            "Call"
                        ],
                        [
                            "self.projection(x)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_124": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "pads.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "word_embs.new_zeros(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_126": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "eos.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "self.symbol_embeddings[self.eos_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_128": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "unk.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "self.symbol_embeddings[self.unk_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "Conv1d_46": {
                "in_channels": {
                    "value": "char_embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_c",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filters",
                            "variable"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "width",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filters",
                            "variable"
                        ]
                    ]
                }
            },
            "where_109": {
                "variable": {
                    "value": "chars",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "eos.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "chars.new_zeros(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "chars",
                    "type": "variable",
                    "possible_values": [
                        [
                            "vocab[i].encode()",
                            "Call"
                        ],
                        [
                            "input.view(-1, self.max_char_len)",
                            "Call"
                        ],
                        [
                            "self.word_to_char[flat_words.type_as(self.word_to_char)].type_as(input)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), chars.new_zeros(1), chars)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/conv_tbc.py": {
        "torch": {
            "Parameter_25": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.kernel_size[0], in_channels, out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_27": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/downsampled_multihead_attention.py": {
        "torch": {
            "Linear_244": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ],
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ],
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Sequential_54": {
                "variable": {
                    "value": "self.in_proj_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*k_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Sequential_55": {
                "variable": {
                    "value": "self.in_proj_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*v_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "bmm_108": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query",
                            "variable"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "q.view(tgt_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "q.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_138": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_139": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_141": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "value",
                            "variable"
                        ],
                        [
                            "self.in_proj_v(v)",
                            "Call"
                        ],
                        [
                            "v.view(src_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "v.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "scalar_bias(v, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_247": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Linear(in_features, out_features, bias=bias)",
                            "Call"
                        ]
                    ]
                }
            },
            "Sequential_252": {
                "*args": {
                    "value": "Linear(in_features, out_features * 4, dropout, bias)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_214": {
                "variable": {
                    "value": "full_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_223": {
                "variable": {
                    "value": "full_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_224": {
                "variable": {
                    "value": "full_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "GLU_254": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_256": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "unsqueeze_112": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_116": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tril_112": {
                "input": {
                    "value": "attn_weights.data.new([1]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "triu_116": {
                "input": {
                    "value": "attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/dynamic_convolution.py": {
        "torch": {
            "Linear_17": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_151": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "bmm_153": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "unfold1d(x, K, padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight.unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_200": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, 0, self.input_size).contiguous()",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, 0, self.input_size).contiguous()",
                            "Call"
                        ],
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_67": {
                "variable": {
                    "value": "self.conv_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_127": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_141": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_149": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_176": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_187": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_188": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_175": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/grad_multiply.py": {
        "torch": {}
    },
    "fairseq/modules/highway.py": {
        "torch": {
            "ModuleList_27": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ReLU_29": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sigmoid_53": {
                "variable": {
                    "value": "gate",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "gate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "projection.chunk(2, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.sigmoid(gate)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_27": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/layer_history.py": {
        "torch": {
            "ModuleList_31": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "(LayerNorm(dim) for _ in range(layers))",
                    "type": "GeneratorExp",
                    "possible_values": []
                }
            },
            "Parameter_54": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.layer_num, self.layer_num).fill_(1.0).tril()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tril_54": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "stack_84": {
                "tensors": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/layer_norm.py": {
        "torch": {
            "is_available_12": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "LayerNorm_18": {
                "normalized_shape": {
                    "value": "normalized_shape",
                    "type": "variable",
                    "possible_values": [
                        [
                            "normalized_shape",
                            "Method Argument"
                        ]
                    ]
                },
                "eps": {
                    "value": "eps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1e-05",
                            "Method Argument"
                        ]
                    ]
                },
                "elementwise_affine": {
                    "value": "elementwise_affine",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/learned_positional_embedding.py": {
        "torch": {}
    },
    "fairseq/modules/lightweight_convolution.py": {
        "torch": {
            "Parameter_47": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, 1, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_73": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "conv1d_79": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.view(-1, H, T)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "groups": {
                    "value": "self.num_heads",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_117": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, 1, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_184": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_185": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "unfold1d(x, self.kernel_size, self.padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                }
            },
            "dropout_214": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_216": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_50": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_71": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Parameter_119": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/linearized_convolution.py": {
        "torch": {
            "linear_65": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._get_linearized_weight()",
                            "Call"
                        ],
                        [
                            "self.weight.transpose(2, 1).transpose(1, 0).contiguous()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_64": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/logsumexp_moe.py": {
        "torch": {
            "logsumexp_22": {
                "input": {
                    "value": "logp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "logp",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-1",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/mean_pool_gating_network.py": {
        "torch": {
            "Linear_25": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_27": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_experts",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_experts",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "tanh_49": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "sum_44": {
                "variable": {
                    "value": "ntokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1 - encoder_padding_mask",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "mean_47": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out['encoder_out'].transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "encoder_out.clone()",
                            "Call"
                        ],
                        [
                            "encoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_53": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.sum(encoder_out, dim=1) / ntokens.type_as(encoder_out)",
                            "BinOp"
                        ],
                        [
                            "torch.mean(encoder_out, dim=1)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "self.dropout(x)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_26": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "sum_45": {
                "input": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out['encoder_out'].transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "encoder_out.clone()",
                            "Call"
                        ],
                        [
                            "encoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/multihead_attention.py": {
        "torch": {
            "Parameter_31": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_36": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_162": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_qkv(query)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_q(query)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_190": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), attn_weights.float()).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_192": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), attn_weights.float()).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(attn_weights)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_qkv(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_v(value)",
                            "Call"
                        ],
                        [
                            "self.in_proj_kv(key)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, self.bias_v.repeat(1, bsz, 1)])",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(-1, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)",
                            "Call"
                        ],
                        [
                            "prev_value",
                            "variable"
                        ],
                        [
                            "torch.cat((prev_value, v), dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_33": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_40": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_113": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_114": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_154": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, k.new_zeros((k.size(0), 1) + k.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_155": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, v.new_zeros((v.size(0), 1) + v.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "linear_232": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_116": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_118": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_157": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_159": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, torch.zeros(key_padding_mask.size(0), 1).type_as(key_padding_mask)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "where_175": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "key_padding_mask.unsqueeze(1).unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "torch.Tensor([float('-Inf')])",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_134": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_key, k)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_140": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_value, v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_160": {
                "*size": {
                    "value": "key_padding_mask.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/relative_multihead_attention.py": {
        "torch": {
            "Parameter_33": {
                "variable": {
                    "value": "self.in_proj_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_38": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_48": {
                "variable": {
                    "value": "self.relative_position_keys",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(2 * self.max_relative_length + 1, self.head_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_209": {
                "variable": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._relative_attention_inner(q, k, relation_keys, transpose=True)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "relative_attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(relative_attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(relative_attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), relative_attn_weights.float()).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clamp_291": {
                "variable": {
                    "value": "distance_mat_clipped",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "distance_mat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "range_mat - range_mat.transpose(0, 1)",
                            "BinOp"
                        ],
                        [
                            "torch.range(-length + 1, 0).view(1, -1)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "-max_relative_length",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "max": {
                    "value": "max_relative_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_relative_length",
                            "Method Argument"
                        ],
                        [
                            "max_relative_length",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_322": {
                "variable": {
                    "value": "xy_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "mat2": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "y.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "y",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_328": {
                "variable": {
                    "value": "x_tz_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "z",
                    "type": "variable",
                    "possible_values": [
                        [
                            "z.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "z",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "transpose_328": {
                "variable": {
                    "value": "x_tz_matmul",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_35": {
                "variable": {
                    "value": "self.in_proj_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(3 * embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_41": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_42": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_50": {
                "variable": {
                    "value": "self.relative_position_values",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(2 * self.max_relative_length + 1, self.head_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_122": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_123": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_163": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, k.new_zeros((k.size(0), 1) + k.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_164": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, v.new_zeros((v.size(0), 1) + v.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "embedding_176": {
                "variable": {
                    "value": "relation_keys",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_positions_matrix.long().cuda()",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.relative_position_keys",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "embedding_178": {
                "variable": {
                    "value": "relation_keys",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_positions_matrix.long().cuda()",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.relative_position_keys",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "embedding_179": {
                "variable": {
                    "value": "relation_values",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_positions_matrix.long().cuda()",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.relative_position_values",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_212": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._relative_attention_inner(q, k, relation_keys, transpose=True)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights + attn_mask",
                            "BinOp"
                        ],
                        [
                            "relative_attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "utils.softmax(relative_attn_weights, dim=-1, onnx_trace=self.onnx_trace).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(relative_attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "torch.where(key_padding_mask.unsqueeze(1).unsqueeze(2), torch.Tensor([float('-Inf')]), relative_attn_weights.float()).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.float().masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf')).type_as(relative_attn_weights)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.view(bsz, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "relative_attn_weights.sum(dim=1) / self.num_heads",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_qkv(query)",
                            "Call"
                        ],
                        [
                            "self.in_proj_v(value)",
                            "Call"
                        ],
                        [
                            "self.in_proj_kv(key)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, self.bias_v.repeat(1, bsz, 1)])",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(-1, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)",
                            "Call"
                        ],
                        [
                            "prev_value",
                            "variable"
                        ],
                        [
                            "torch.cat((prev_value, v), dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "linear_257": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_weight",
                            "Attribute"
                        ],
                        [
                            "weight[start:end, :]",
                            "Subscript"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.in_proj_bias",
                            "Attribute"
                        ],
                        [
                            "bias[start:end]",
                            "Subscript"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_285": {
                "variable": {
                    "value": "range_vec",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "z.size()[0]",
                            "Subscript"
                        ],
                        [
                            "length",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "range_289": {
                "variable": {
                    "value": "distance_mat",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "-length + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "end": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_125": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_127": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_166": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_168": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, torch.zeros(key_padding_mask.size(0), 1).type_as(key_padding_mask)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "where_194": {
                "variable": {
                    "value": "relative_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "key_padding_mask.unsqueeze(1).unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "torch.Tensor([float('-Inf')])",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "relative_attn_weights.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_143": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_key, k)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_149": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(prev_value, v)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_169": {
                "*size": {
                    "value": "key_padding_mask.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/modules/scalar_bias.py": {
        "torch": {}
    },
    "fairseq/modules/sinusoidal_positional_embedding.py": {
        "torch": {
            "exp_49": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(half_dim, dtype=torch.float) * -emb",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_51": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.sin(emb), torch.cos(emb)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_54": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[emb, torch.zeros(num_embeddings, 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_82": {
                "variable": {
                    "value": "embedding_shape",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(bsz.view(1), seq_len.view(1), torch.LongTensor([-1]))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "arange_50": {
                "start": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_50": {
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_49": {
                "start": {
                    "value": "half_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim // 2",
                            "BinOp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_54": {
                "*size": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sin_51": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cos_51": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/modules/unfold1d.py": {
        "torch": {
            "pad_15": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, kernel_size - 1 - padding_l), value=pad_value)",
                            "Call"
                        ],
                        [
                            "x.as_strided((T, B, C, kernel_size), (B * C, C, 1, B * C))",
                            "Call"
                        ],
                        [
                            "x.unsqueeze(3)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, kernel_size - 1 - padding_l)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "pad_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/adadelta.py": {
        "torch": {}
    },
    "fairseq/optim/adafactor.py": {
        "torch": {
            "mul_120": {
                "input": {
                    "value": "r_factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(exp_avg_sq_row / exp_avg_sq_row.mean(dim=-1)).rsqrt_().unsqueeze(-1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "c_factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "exp_avg_sq_col.unsqueeze(-2).rsqrt()",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_like_151": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "grad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data",
                            "Attribute"
                        ]
                    ]
                }
            },
            "zeros_153": {
                "variable": {
                    "value": "state[exp_avg_sq_row]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "*size": {
                    "value": "grad_shape[:-1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_154": {
                "variable": {
                    "value": "state[exp_avg_sq_col]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "*size": {
                    "value": "grad_shape[:-2] + grad_shape[-1:]",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_156": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "grad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data",
                            "Attribute"
                        ]
                    ]
                }
            },
            "rsqrt_180": {
                "input": {
                    "value": "exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "update",
                    "type": "variable",
                    "possible_values": [
                        [
                            "grad ** 2 + group['eps'][0]",
                            "BinOp"
                        ],
                        [
                            "exp_avg",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/adagrad.py": {
        "torch": {}
    },
    "fairseq/optim/adam.py": {
        "torch": {
            "zeros_like_110": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_112": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_115": {
                "variable": {
                    "value": "state[max_exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "max_129": {
                "input": {
                    "value": "max_exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "max_exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/fairseq_optimizer.py": {
        "torch": {
            "clip_grad_norm__85": {
                "parameters": {
                    "value": "self.params",
                    "type": "Attribute",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "max_norm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max_norm",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/fp16_optimizer.py": {
        "torch": {
            "Parameter_99": {
                "variable": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params[0].new(0).float().new(total_param_size)",
                            "Call"
                        ],
                        [
                            "torch.nn.Parameter(fp32_params)",
                            "Call"
                        ],
                        [
                            "fp32_params",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py": {
        "torch": {}
    },
    "fairseq/optim/nag.py": {
        "torch": {}
    },
    "fairseq/optim/sgd.py": {
        "torch": {}
    },
    "fairseq/options.py": {
        "torch": {
            "device_count_256": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/search.py": {
        "torch": {
            "stack_163": {
                "variable": {
                    "value": "self.scores_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "scores_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.scores_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_164": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "indices_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_165": {
                "variable": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "tensors": {
                    "value": "beams_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "topk_73": {
                "input": {
                    "value": "lprobs.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "k": {
                    "value": "min(beam_size * 2, lprobs.view(bsz, -1).size(1) - 1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "(self.scores_buf, self.indices_buf)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "div_83": {
                "input": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "other": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_135": {
                "*size": {
                    "value": "lprobs[:, 0, :].size()",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "self.diversity_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "multinomial_200": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_nopad.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "beam_size",
                            "Method Argument"
                        ]
                    ]
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "multinomial_207": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_nopad.view(bsz * beam_size, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "gather_219": {
                "input": {
                    "value": "probs_nopad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs_nopad.exp_()",
                            "Call"
                        ],
                        [
                            "probs_nopad.expand(bsz, beam_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "self.indices_buf.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "self.scores_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "gather_229": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "topk_indices.expand(bsz, beam_size, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "self.indices_buf.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "squeeze_229": {
                "variable": {
                    "value": "self.indices_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_241": {
                "variable": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "beam_size",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "add_144": {
                "variable": {
                    "value": "lprobs_g",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs_g",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs[:, g::self.num_groups, :]",
                            "Subscript"
                        ],
                        [
                            "torch.add(lprobs_g, self.diversity_strength, self.diversity_buf.unsqueeze(1))",
                            "Call"
                        ],
                        [
                            "lprobs_g.contiguous()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.diversity_strength",
                    "type": "Attribute",
                    "possible_values": []
                },
                "alpha": {
                    "value": "self.diversity_buf.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_244": {
                "input": {
                    "value": "scores[:, :, step - 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "self.beams_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/sequence_generator.py": {
        "torch": {
            "arange_147": {
                "variable": {
                    "value": "new_order",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size[0]",
                            "Subscript"
                        ],
                        [
                            "new_bsz",
                            "variable"
                        ]
                    ]
                }
            },
            "arange_171": {
                "variable": {
                    "value": "cand_offsets",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "cand_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2 * beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "no_grad_100": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_532": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "models",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_543": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_549": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "gather_477": {
                "variable": {
                    "value": "active_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1)).view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores[:, step].view(bsz, beam_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "add_458": {
                "input": {
                    "value": "eos_mask.type_as(cand_offsets) * cand_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "cand_offsets[:eos_mask.size(1)]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                }
            },
            "topk_467": {
                "input": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.beam_size",
                            "Attribute"
                        ],
                        [
                            "1",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "largest": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(_ignore, active_hypos)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "gather_473": {
                "input": {
                    "value": "cand_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ],
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_486": {
                "input": {
                    "value": "tokens[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "tokens.clone()",
                            "Call"
                        ],
                        [
                            "tokens",
                            "variable"
                        ]
                    ]
                }
            },
            "gather_490": {
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf.view(bsz, beam_size, -1)[:, :, step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "gather_499": {
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.gather(probs_slice, dim=1, index=prefix_tokens[:, step].view(-1, 1)).view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf.view(bsz, beam_size, -1)[:, :, step]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "logsumexp_570": {
                "input": {
                    "value": "torch.stack(log_probs, dim=0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "gather_353": {
                "variable": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs_slice",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.view(bsz, -1, lprobs.size(-1))[:, 0, :]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "prefix_tokens[:, step].view(-1, 1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_like_361": {
                "variable": {
                    "value": "cand_beams",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "prefix_tokens[:, step].view(-1, 1).repeat(1, cand_size)",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "sort_386": {
                "input": {
                    "value": "lprobs[:, self.eos]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(eos_scores, eos_bbsz_idx)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "masked_select_406": {
                "input": {
                    "value": "cand_bbsz_idx[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "cand_indices.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_bbsz_idx')",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_495": {
                "input": {
                    "value": "scores[:, :step]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf[:, :step]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "scores.clone()",
                            "Call"
                        ],
                        [
                            "scores_buf.type_as(lprobs)",
                            "Call"
                        ],
                        [
                            "scores",
                            "variable"
                        ]
                    ]
                }
            },
            "index_select_506": {
                "input": {
                    "value": "attn[:, :, :step + 2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "attn_buf[:, :, :step + 2]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "attn.clone()",
                            "Call"
                        ],
                        [
                            "attn",
                            "variable"
                        ]
                    ]
                }
            },
            "stack_570": {
                "tensors": {
                    "value": "log_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "log_probs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "masked_select_412": {
                "input": {
                    "value": "cand_scores[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "cand_indices.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "eos_scores / (step + 1) ** self.len_penalty",
                            "BinOp"
                        ],
                        [
                            "eos_scores",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_302": {
                "start": {
                    "value": "batch_idxs.numel()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_170": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size[0]",
                            "Subscript"
                        ],
                        [
                            "new_bsz",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/sequence_scorer.py": {
        "torch": {
            "no_grad_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_tensor_82": {
                "obj": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out[1]",
                            "Subscript"
                        ],
                        [
                            "attn.data",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "fairseq/tasks/fairseq_task.py": {
        "torch": {
            "no_grad_236": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_241": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/tasks/language_modeling.py": {
        "torch": {
            "no_grad_216": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/tasks/multilingual_translation.py": {
        "torch": {
            "no_grad_206": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/tasks/translation_moe.py": {
        "torch": {
            "cat_160": {
                "variable": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "lprob_y",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "get_lprob_y(encoder_out, prev_output_tokens_k)",
                            "Call"
                        ],
                        [
                            "torch.cat(lprob_y, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_180": {
                "variable": {
                    "value": "prob_z_xy",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprob_yz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "get_lprob_yz()",
                            "Call"
                        ],
                        [
                            "get_lprob_yz()",
                            "Call"
                        ],
                        [
                            "lprob_y",
                            "variable"
                        ],
                        [
                            "lprob_y + lprob_z.type_as(lprob_y)",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_211": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_217": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_178": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/trainer.py": {
        "torch": {
            "manual_seed_408": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "is_available_39": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_297": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_410": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "get_device_capability_102": {
                "device": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "get_device_capability_110": {
                "device": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_cache_319": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "fairseq/utils.py": {
        "torch": {
            "load_71": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "filename",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filenames",
                            "variable"
                        ],
                        [
                            "filename",
                            "Method Argument"
                        ],
                        [
                            "filename",
                            "Method Argument"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "load_155": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "path",
                            "Method Argument"
                        ],
                        [
                            "path",
                            "Method Argument"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "Parameter_80": {
                "variable": {
                    "value": "state[model][encoder.history.weight]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(new_layer, new_layer).fill_(1.0).tril()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_89": {
                "variable": {
                    "value": "state[model][encoder.history.layer_norms. + str(iternum) + .weight]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_91": {
                "variable": {
                    "value": "state[model][encoder.history.layer_norms. + str(iternum) + .bias]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "remainder_387": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range - num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "remainder_389": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range + num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_207": {
                "obj": {
                    "value": "maybe_tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "maybe_tensor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_351": {
                "start": {
                    "value": "padding_idx + 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "end": {
                    "value": "max_pos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "padding_idx + 1 + tensor.size(1)",
                            "BinOp"
                        ]
                    ]
                },
                "out": {
                    "value": "make_positions.range_buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_367": {
                "start": {
                    "value": "max",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "buffered_arange.buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "norm_402": {
                "input": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ],
                        [
                            "tensor",
                            "Method Argument"
                        ],
                        [
                            "tensor",
                            "Method Argument"
                        ],
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "softmax_473": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['args'].encoder_embed_dim",
                            "Attribute"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "softmax_475": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['args'].encoder_embed_dim",
                            "Attribute"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "log_softmax_480": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['args'].encoder_embed_dim",
                            "Attribute"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_482": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['args'].encoder_embed_dim",
                            "Attribute"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_25": {
                "obj": {
                    "value": "*args",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "is_tensor_39": {
                "obj": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'args': args, 'model': model_state_dict if model_state_dict else {}, 'optimizer_history': optim_history + [{'criterion_name': criterion.__class__.__name__, 'optimizer_name': optimizer.__class__.__name__, 'lr_scheduler_state': lr_scheduler.state_dict(), 'num_updates': num_updates}], 'last_optimizer_state': convert_state_dict_type(optimizer.state_dict()), 'extra_state': extra_state}",
                            "Dict"
                        ],
                        [
                            "state_dict",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "tril_80": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Tensor_91": {}
        }
    },
    "generate.py": {
        "torch": {
            "is_available_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "interactive.py": {
        "torch": {
            "is_available_73": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "scripts/average_checkpoints.py": {
        "torch": {
            "load_25": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "inputs",
                            "variable"
                        ],
                        [
                            "files",
                            "variable"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, _: torch.serialization.default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "save_130": {
                "obj": {
                    "value": "new_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "state",
                            "variable"
                        ],
                        [
                            "average_checkpoints(args.inputs)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "args.output",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "stack.py": {
        "torch": {
            "load_11": {
                "variable": {
                    "value": "ckpt",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "sys.argv[1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "save_97": {
                "obj": {
                    "value": "ckpt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.load(sys.argv[1])",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "sys.argv[2]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_average_checkpoints.py": {
        "torch": {
            "save_46": {
                "obj": {
                    "value": "collections.OrderedDict([('model', params_0)])",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "path_0",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tempfile.mkstemp()",
                            "Call"
                        ]
                    ]
                }
            },
            "save_47": {
                "obj": {
                    "value": "collections.OrderedDict([('model', params_1)])",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "path_1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tempfile.mkstemp()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "tests/test_backtranslation_dataset.py": {
        "torch": {
            "is_available_32": {
                "variable": {
                    "value": "self.cuda",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_75": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "backtranslation_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "BacktranslationDataset(tgt_dataset=TransformEosDataset(dataset=tgt_dataset, eos=self.tgt_dict.eos(), remove_eos_from_src=remove_eos_from_input_src), backtranslation_fn=lambda net_input: generator.generate([self.model], {'net_input': net_input}), output_collater=TransformEosDataset(dataset=tgt_dataset, eos=self.tgt_dict.eos(), append_eos_to_tgt=remove_eos_from_input_src, remove_eos_from_src=remove_eos_from_output_src).collater, cuda=self.cuda)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "backtranslation_dataset.collater",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_binaries.py": {
        "torch": {
            "rand_249": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_examples * maxlen",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "floor_250": {
                "input": {
                    "value": "26 * data",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_character_token_embedder.py": {
        "torch": {}
    },
    "tests/test_convtbc.py": {
        "torch": {
            "Conv1d_20": {
                "variable": {
                    "value": "conv1d",
                    "type": "variable",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_25": {
                "variable": {
                    "value": "input_tbc",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "7",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "randn_34": {
                "variable": {
                    "value": "grad_tbc",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "output_tbc.size()",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_dictionary.py": {
        "torch": {}
    },
    "tests/test_label_smoothing.py": {
        "torch": {
            "unsqueeze_43": {
                "variable": {
                    "value": "self.args.probs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_noising.py": {
        "torch": {
            "DataLoader_442": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "language_pair_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "LanguagePairDataset(src=noising_dataset, tgt=tgt, src_sizes=None, src_dict=src_dict)",
                            "Call"
                        ],
                        [
                            "TransformEosDataset(language_pair_dataset, src_dict.eos(), append_eos_to_tgt=append_eos_to_tgt)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "language_pair_dataset.collater",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "t_456": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[['he@@', 'llo', 'n@@', 'ew', 'y@@', 'or@@', 'k'], ['how', 'are', 'y@@', 'ou']]",
                            "List"
                        ],
                        [
                            "[['he', 'llo_EOW', 'n', 'ew_EOW', 'y', 'or', 'k_EOW'], ['how_EOW', 'are_EOW', 'y', 'ou_EOW']]",
                            "List"
                        ],
                        [
                            "[['hello', 'new', 'york', 'you'], ['how', 'are', 'you', 'new', 'york']]",
                            "List"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=True)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=False)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "t_493": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[['he@@', 'llo', 'n@@', 'ew', 'y@@', 'or@@', 'k'], ['how', 'are', 'y@@', 'ou']]",
                            "List"
                        ],
                        [
                            "[['he', 'llo_EOW', 'n', 'ew_EOW', 'y', 'or', 'k_EOW'], ['how_EOW', 'are_EOW', 'y', 'ou_EOW']]",
                            "List"
                        ],
                        [
                            "[['hello', 'new', 'york', 'you'], ['how', 'are', 'you', 'new', 'york']]",
                            "List"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=True)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=False)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "tests/test_sequence_generator.py": {
        "torch": {
            "log_140": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_239": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_sequence_scorer.py": {
        "torch": {
            "log_99": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "tests/test_token_block_dataset.py": {
        "torch": {}
    },
    "tests/test_train.py": {
        "torch": {}
    },
    "tests/test_utils.py": {
        "torch": {}
    },
    "tests/utils.py": {
        "torch": {
            "DataLoader_47": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TestDataset(samples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(samples)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda samples: collate(samples, padding_idx, eos_idx)",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "rand_222": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bbsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "prev_output_tokens.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tgt_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "prev_output_tokens.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "src_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out.size(1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "train.py": {
        "torch": {
            "manual_seed_36": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_34": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "set_device_35": {
                "device": {
                    "value": "args.device_id",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    }
}