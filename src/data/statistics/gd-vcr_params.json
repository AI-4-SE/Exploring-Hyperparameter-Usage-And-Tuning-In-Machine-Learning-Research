{
    "vilbert_beta/vilbert/vilbert.py": {
        "tensorflow": {
            "list_variables_66": {
                "variable": {
                    "value": "init_vars",
                    "type": "Variable",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "tf_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.abspath(tf_checkpoint_path)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_variable_71": {
                "variable": {
                    "value": "array",
                    "type": "Variable",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "tf_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.abspath(tf_checkpoint_path)",
                            "Call"
                        ]
                    ]
                },
                "name": {
                    "value": "name",
                    "type": "Name",
                    "possible_values": [
                        [
                            "name.split('/')",
                            "Call"
                        ]
                    ]
                }
            }
        },
        "torch": {
            "from_numpy_109": {
                "variable": {
                    "value": "pointer.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "array",
                    "type": "Call",
                    "possible_values": [
                        [
                            "tf.train.load_variable(tf_path, name)",
                            "Call"
                        ],
                        [
                            "np.transpose(array)",
                            "Call"
                        ]
                    ]
                }
            },
            "Embedding_302": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Embedding_305": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_308": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_315": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_319": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Name",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_347": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_348": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_349": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_351": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_371": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_383": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_394": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_396": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_420": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_437": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_439": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_476": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_477": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_478": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_480": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.v_attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_500": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_512": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_522": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_524": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.v_hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_547": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_564": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_566": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.v_hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_607": {
                "variable": {
                    "value": "self.query1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_608": {
                "variable": {
                    "value": "self.key1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_609": {
                "variable": {
                    "value": "self.value1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_612": {
                "variable": {
                    "value": "self.dropout1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.v_attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_614": {
                "variable": {
                    "value": "self.query2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_615": {
                "variable": {
                    "value": "self.key2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_616": {
                "variable": {
                    "value": "self.value2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_619": {
                "variable": {
                    "value": "self.dropout2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_654": {
                "variable": {
                    "value": "attention_scores1",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer2",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer1.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_668": {
                "variable": {
                    "value": "context_layer1",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs1",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores1)",
                            "Call"
                        ],
                        [
                            "self.dropout1(attention_probs1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer1",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer1)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_674": {
                "variable": {
                    "value": "attention_scores2",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer1",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer2.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_690": {
                "variable": {
                    "value": "context_layer2",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs2",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores2)",
                            "Call"
                        ],
                        [
                            "self.dropout2(attention_probs2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer2",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer2)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_701": {
                "variable": {
                    "value": "self.dense1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_703": {
                "variable": {
                    "value": "self.dropout1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.v_hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_705": {
                "variable": {
                    "value": "self.q_dense1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_706": {
                "variable": {
                    "value": "self.q_dropout1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.v_hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_708": {
                "variable": {
                    "value": "self.dense2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_710": {
                "variable": {
                    "value": "self.dropout2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_712": {
                "variable": {
                    "value": "self.q_dense2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_713": {
                "variable": {
                    "value": "self.q_dropout2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_779": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_782": {
                "variable": {
                    "value": "self.v_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(v_layer) for _ in range(config.v_num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_785": {
                "variable": {
                    "value": "self.c_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(connect_layer) for _ in range(len(config.v_biattention_id))]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_901": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReLU_902": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_916": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReLU_917": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_931": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_950": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_973": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_979": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_1000": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_1011": {
                "variable": {
                    "value": "self.bi_seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_1014": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "0.1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_1041": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_target_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1404": {
                "variable": {
                    "value": "self.image_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_feature_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1405": {
                "variable": {
                    "value": "self.image_location_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "5",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_1407": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1433": {
                "variable": {
                    "value": "self.loss_fct",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Dropout_1508": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_prob",
                    "type": "Name",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_1514": {
                "variable": {
                    "value": "self.vil_logit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.bi_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_1515": {
                "variable": {
                    "value": "self.vision_logit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.v_hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_1516": {
                "variable": {
                    "value": "self.linguisic_logit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Sequential_1577": {
                "variable": {
                    "value": "self.main",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*layers",
                    "type": null,
                    "possible_values": []
                }
            },
            "sigmoid_123": {
                "input": {
                    "value": "x",
                    "type": "Call",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_324": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "load_1177": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, TF_WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ones_like_1330": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_txt",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_like_1332": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_txt",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "ones_1334": {
                "variable": {
                    "value": "image_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_imgs.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "input_imgs.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_1362": {
                "variable": {
                    "value": "co_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_txt.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "input_imgs.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "input_txt.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "MSELoss_1438": {
                "variable": {
                    "value": "self.vis_criterion",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "KLDivLoss_1440": {
                "variable": {
                    "value": "self.vis_criterion",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "erf_119": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Parameter_286": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_287": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Softmax_377": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_506": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_662": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Softmax_684": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_979": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "weight_norm_1572": {
                "module": {
                    "value": "nn.Linear(in_dim, hid_dim)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "None",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ReLU_1573": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_1574": {
                "p": {
                    "value": "dropout",
                    "type": "Variable",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "weight_norm_1575": {
                "module": {
                    "value": "nn.Linear(hid_dim, out_dim)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "None",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_1572": {
                "in_features": {
                    "value": "in_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hid_dim",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Linear_1575": {
                "in_features": {
                    "value": "hid_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_dim",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "ones_286": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_287": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sqrt_293": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "no_grad_823": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_837": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "sum_1478": {
                "input": {
                    "value": "img_loss * (image_label == 1).unsqueeze(2).float()",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "log_softmax_1484": {
                "input": {
                    "value": "prediction_scores_v",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.imagePredictions(sequence_output_v)",
                            "Call"
                        ],
                        [
                            "prediction_scores_v[:, 1:]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sum_1486": {
                "input": {
                    "value": "img_loss * (image_label == 1).unsqueeze(2).float()",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_1480": {
                "input": {
                    "value": "(image_label == 1).unsqueeze(2).expand_as(img_loss)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "sum_1488": {
                "input": {
                    "value": "image_label == 1",
                    "type": "Compare",
                    "possible_values": []
                }
            }
        }
    },
    "build_dataset/question_cluster.py": {
        "torch": {
            "device_76": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "build_dataset/relevance_model.py": {
        "torch": {
            "CrossEntropyLoss_107": {
                "variable": {
                    "value": "loss_fn",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_14": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_15": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "device_21": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "tensor_60": {
                "variable": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "input_ids",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(input_ids)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_61": {
                "variable": {
                    "value": "attention_masks",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "attention_masks",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(attention_masks)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_178": {
                "variable": {
                    "value": "all_logits",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "all_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(all_logits, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "softmax_179": {
                "variable": {
                    "value": "probs",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "all_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(all_logits, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "tensor_227": {
                "variable": {
                    "value": "train_labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "y_train",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "np.array(y_train)",
                            "Call"
                        ]
                    ]
                }
            },
            "TensorDataset_231": {
                "variable": {
                    "value": "train_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "train_inputs",
                    "type": null,
                    "possible_values": []
                }
            },
            "RandomSampler_232": {
                "variable": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(train_inputs, train_masks, train_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_233": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(train_inputs, train_masks, train_labels)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "Name",
                    "possible_values": [
                        [
                            "RandomSampler(train_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "32",
                            "Constant"
                        ]
                    ]
                }
            },
            "Sequential_72": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(D_in, H)",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_112": {
                "seed": {
                    "value": "seed_value",
                    "type": "Name",
                    "possible_values": [
                        [
                            "42",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "manual_seed_all_113": {
                "seed": {
                    "value": "seed_value",
                    "type": "Name",
                    "possible_values": [
                        [
                            "42",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "save_163": {
                "obj": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "'relevance_model_repro.th'",
                            "Constant"
                        ]
                    ]
                }
            },
            "get_device_name_17": {
                "device": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_73": {
                "in_features": {
                    "value": "D_in",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "H",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "ReLU_74": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_75": {
                "in_features": {
                    "value": "H",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "D_out",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "clip_grad_norm__138": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "1.0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "no_grad_174": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_16": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "build_dataset/similarity.py": {
        "torch": {
            "load_208": {
                "variable": {
                    "value": "relevance_model",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "relevance_model.th",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "device_249": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "tensor_232": {
                "variable": {
                    "value": "val_inputs",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "val_inputs_1",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[val_input[:64] if len(val_input) > 64 else val_input + [0] * (64 - len(val_input)) for val_input in val_inputs]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "tensor_233": {
                "variable": {
                    "value": "val_masks",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "val_masks_1",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[val_mask[:64] if len(val_mask) > 64 else val_mask + [0] * (64 - len(val_mask)) for val_mask in val_masks]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "tensor_234": {
                "variable": {
                    "value": "val_labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "np.array([0] * len(answers))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "TensorDataset_235": {
                "variable": {
                    "value": "val_data",
                    "type": "Variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "val_inputs",
                    "type": null,
                    "possible_values": []
                }
            },
            "SequentialSampler_236": {
                "variable": {
                    "value": "val_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "val_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(val_inputs, val_masks, val_labels)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_237": {
                "variable": {
                    "value": "val_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_data",
                    "type": "Name",
                    "possible_values": [
                        [
                            "TensorDataset(val_inputs, val_masks, val_labels)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_sampler",
                    "type": "Name",
                    "possible_values": [
                        [
                            "SequentialSampler(val_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "64",
                            "Constant"
                        ]
                    ]
                }
            }
        }
    },
    "generate_tsv.py": {
        "torch": {}
    },
    "generate_tsv_gt.py": {
        "torch": {}
    },
    "vilbert_beta/eval_retrieval.py": {
        "torch": {
            "manual_seed_122": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_147": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_148": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_151": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_150": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_163": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_198": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForMultiModalPreTraining.from_pretrained(args.from_pretrained, config)",
                            "Call"
                        ],
                        [
                            "VILBertForVLTasks.from_pretrained(args.from_pretrained, config, num_labels=num_labels, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "DDP(model, deay_allreduce=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_226": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_147": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "softmax_230": {
                "input": {
                    "value": "vil_logit",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/eval_tasks.py": {
        "torch": {
            "manual_seed_174": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_197": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_198": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_201": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_200": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_212": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_250": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BaseBertForVLTasks.from_pretrained(args.from_pretrained, config, num_labels=num_labels, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "VILBertForVLTasks.from_pretrained(args.from_pretrained, config, num_labels=num_labels, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "DDP(model, delay_allreduce=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_197": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/train_baseline.py": {
        "torch": {
            "device_224": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_227": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_230": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_251": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_229": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_253": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataParallel_321": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForMultiModalPreTraining.from_pretrained(args.bert_model, config)",
                            "Call"
                        ],
                        [
                            "BertForMultiModalPreTraining(config)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "DDP(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "set_grad_enabled_524": {
                "mode": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "set_grad_enabled_589": {
                "mode": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "save_606": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(savePath, 'pytorch_model_' + str(epochId) + '.bin')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_225": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/train_concap.py": {
        "torch": {
            "device_235": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_238": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_241": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_262": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_240": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_264": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_311": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_344": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForMultiModalPreTraining.from_pretrained(args.from_pretrained, config)",
                            "Call"
                        ],
                        [
                            "BertForMultiModalPreTraining(config)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "DDP(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "set_grad_enabled_577": {
                "mode": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "set_grad_enabled_641": {
                "mode": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "save_658": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(savePath, 'pytorch_model_' + str(epochId) + '.bin')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_509": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_236": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/train_tasks.py": {
        "torch": {
            "device_198": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_199": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_202": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReduceLROnPlateau_353": {
                "variable": {
                    "value": "lr_scheduler",
                    "type": "Variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertAdam(optimizer_grouped_parameters, lr=args.learning_rate, warmup=args.warmup_proportion, t_total=num_train_optimization_steps, schedule='warmup_constant')",
                            "Call"
                        ],
                        [
                            "Adam(optimizer_grouped_parameters, lr=base_lr, warmup=args.warmup_proportion, t_total=num_train_optimization_steps, schedule='warmup_constant')",
                            "Call"
                        ],
                        [
                            "Adamax(optimizer_grouped_parameters, lr=base_lr, warmup=args.warmup_proportion, t_total=num_train_optimization_steps, schedule='warmup_constant')",
                            "Call"
                        ]
                    ]
                },
                "mode": {
                    "value": "max",
                    "type": "Constant",
                    "possible_values": []
                },
                "factor": {
                    "value": "0.2",
                    "type": "Constant",
                    "possible_values": []
                },
                "patience": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "cooldown": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "threshold": {
                    "value": "0.001",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "set_device_201": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_214": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_274": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BaseBertForVLTasks.from_pretrained(args.from_pretrained, config, num_labels=num_labels, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "VILBertForVLTasks.from_pretrained(args.from_pretrained, config, num_labels=num_labels, default_gpu=default_gpu)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "DDP(model, delay_allreduce=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "LambdaLR_364": {
                "variable": {
                    "value": "lr_scheduler",
                    "type": "Variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertAdam(optimizer_grouped_parameters, lr=args.learning_rate, warmup=args.warmup_proportion, t_total=num_train_optimization_steps, schedule='warmup_constant')",
                            "Call"
                        ],
                        [
                            "Adam(optimizer_grouped_parameters, lr=base_lr, warmup=args.warmup_proportion, t_total=num_train_optimization_steps, schedule='warmup_constant')",
                            "Call"
                        ],
                        [
                            "Adamax(optimizer_grouped_parameters, lr=base_lr, warmup=args.warmup_proportion, t_total=num_train_optimization_steps, schedule='warmup_constant')",
                            "Call"
                        ]
                    ]
                },
                "lr_lambda": {
                    "value": "lr_lambda_fun",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "save_426": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(savePath, 'pytorch_model_' + str(epochId) + '.bin')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_198": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/basebert.py": {
        "torch": {
            "Embedding_282": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Embedding_283": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Embedding_284": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_289": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_293": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Call",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ],
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_312": {
                "variable": {
                    "value": "self.image_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "2048",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_314": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_315": {
                "variable": {
                    "value": "self.image_location_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "5",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_320": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_353": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_354": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_355": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_357": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_374": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_386": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_396": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_398": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_422": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_437": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_439": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_466": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_482": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tanh_483": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_497": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_518": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_522": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_543": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_552": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_573": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_577": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_591": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1601",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_604": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ones_681": {
                "variable": {
                    "value": "image_token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_imgs.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "input_imgs.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_708": {
                "variable": {
                    "value": "embedding_output",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[embedding_output, img_embeding_output]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_709": {
                "variable": {
                    "value": "extended_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[extended_attention_mask, extended_image_attention_mask]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "KLDivLoss_777": {
                "variable": {
                    "value": "self.vis_criterion",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_778": {
                "variable": {
                    "value": "self.loss_fct",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Dropout_836": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout_prob",
                    "type": "Name",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_842": {
                "variable": {
                    "value": "self.vil_logit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_843": {
                "variable": {
                    "value": "self.vision_logit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_844": {
                "variable": {
                    "value": "self.linguisic_logit",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Sequential_897": {
                "variable": {
                    "value": "self.main",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*layers",
                    "type": null,
                    "possible_values": []
                }
            },
            "sigmoid_51": {
                "input": {
                    "value": "x",
                    "type": "Name",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_201": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, TF_WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_like_296": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_like_327": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "ones_like_673": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_txt",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_like_675": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_txt",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "ones_677": {
                "variable": {
                    "value": "image_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_imgs.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "input_imgs.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "erf_47": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Parameter_65": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_66": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Softmax_380": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_522": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_577": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "weight_norm_892": {
                "module": {
                    "value": "nn.Linear(in_dim, hid_dim)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "None",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ReLU_893": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_894": {
                "p": {
                    "value": "dropout",
                    "type": "Variable",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "weight_norm_895": {
                "module": {
                    "value": "nn.Linear(hid_dim, out_dim)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "None",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "log_softmax_812": {
                "input": {
                    "value": "prediction_scores_v",
                    "type": "Name",
                    "possible_values": [
                        [
                            "prediction_scores_v[:, 1:]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sum_814": {
                "input": {
                    "value": "img_loss * (image_label == 1).unsqueeze(2).float()",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_892": {
                "in_features": {
                    "value": "in_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hid_dim",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Linear_895": {
                "in_features": {
                    "value": "hid_dim",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_dim",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "ones_65": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_66": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sqrt_72": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "sum_816": {
                "input": {
                    "value": "image_label == 1",
                    "type": "Compare",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/datasets/concept_cap_dataset.py": {
        "torch": {
            "is_available_118": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_714": {
                "data": {
                    "value": "data",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "tensor_179": {
                "data": {
                    "value": "data",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "tensor_274": {
                "data": {
                    "value": "data",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/datasets/refer_expression_dataset.py": {
        "torch": {
            "tensor_208": {
                "variable": {
                    "value": "features",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_features_pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros((self.max_region_num, 2048))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_209": {
                "variable": {
                    "value": "image_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "image_mask",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[1] * mix_num_boxes",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(image_mask).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_210": {
                "variable": {
                    "value": "spatials",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_boxes_pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros((self.max_region_num, 5))",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_212": {
                "variable": {
                    "value": "target",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(self.max_region_num, 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "tensor_215": {
                "variable": {
                    "value": "spatials_ori",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_boxes_ori",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.concatenate((boxes_ori, gt_boxes_ori), axis=0)",
                            "Call"
                        ],
                        [
                            "boxes_ori",
                            "Name"
                        ]
                    ]
                }
            },
            "zeros_216": {
                "variable": {
                    "value": "co_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(self.max_region_num, self._max_seq_length)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "from_numpy_150": {
                "variable": {
                    "value": "token",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['token'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_153": {
                "variable": {
                    "value": "input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['input_mask'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_156": {
                "variable": {
                    "value": "segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['segment_ids'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "min_36": {
                "input": {
                    "value": "boxes[:, :, 2]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "max_37": {
                "input": {
                    "value": "boxes[:, :, 0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "min_40": {
                "input": {
                    "value": "boxes[:, :, 3]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "max_41": {
                "input": {
                    "value": "boxes[:, :, 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_187": {
                "data": {
                    "value": "[ref_box]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_195": {
                "data": {
                    "value": "[ref_box]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/datasets/retreival_dataset.py": {
        "torch": {
            "tensor_146": {
                "variable": {
                    "value": "features1",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_features_pad",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 2048))",
                            "Call"
                        ],
                        [
                            "np.zeros((self._max_region_num, 2048))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_147": {
                "variable": {
                    "value": "image_mask1",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "image_mask",
                    "type": "BinOp",
                    "possible_values": [
                        [
                            "[1] * int(mix_num_boxes)",
                            "BinOp"
                        ],
                        [
                            "torch.stack([image_mask1, image_mask2, image_mask3, image_mask4], dim=0)",
                            "Call"
                        ],
                        [
                            "[1] * int(mix_num_boxes)",
                            "BinOp"
                        ]
                    ]
                }
            },
            "tensor_148": {
                "variable": {
                    "value": "spatials1",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_boxes_pad",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 5))",
                            "Call"
                        ],
                        [
                            "np.zeros((self._max_region_num, 5))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_190": {
                "variable": {
                    "value": "features3",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_features_pad",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 2048))",
                            "Call"
                        ],
                        [
                            "np.zeros((self._max_region_num, 2048))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_191": {
                "variable": {
                    "value": "image_mask3",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "image_mask3",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[1] * int(num_boxes3)",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(image_mask3).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_192": {
                "variable": {
                    "value": "spatials3",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_boxes_pad",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 5))",
                            "Call"
                        ],
                        [
                            "np.zeros((self._max_region_num, 5))",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_219": {
                "variable": {
                    "value": "features",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[features1, features2, features3, features4]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "stack_220": {
                "variable": {
                    "value": "spatials",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[spatials1, spatials2, spatials3, spatials4]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "stack_221": {
                "variable": {
                    "value": "image_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[image_mask1, image_mask2, image_mask3, image_mask4]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "stack_222": {
                "variable": {
                    "value": "caption",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[caption1, caption2, caption3, caption4]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "stack_223": {
                "variable": {
                    "value": "input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_mask1, input_mask2, input_mask3, input_mask4]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "stack_224": {
                "variable": {
                    "value": "segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[segment_ids1, segment_ids2, segment_ids3, segment_ids4]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_225": {
                "variable": {
                    "value": "co_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(4, self._max_region_num, self._max_seq_length)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Tensor_317": {
                "variable": {
                    "value": "self.features_all",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_318": {
                "variable": {
                    "value": "self.image_mask_all",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_319": {
                "variable": {
                    "value": "self.spatials_all",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_385": {
                "variable": {
                    "value": "target_all",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "500",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "from_numpy_119": {
                "variable": {
                    "value": "token",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['token'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_122": {
                "variable": {
                    "value": "input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['input_mask'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_125": {
                "variable": {
                    "value": "segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['segment_ids'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_353": {
                "variable": {
                    "value": "token",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['token'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_356": {
                "variable": {
                    "value": "input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['input_mask'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_359": {
                "variable": {
                    "value": "segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['segment_ids'])",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/datasets/vcr_dataset.py": {
        "torch": {
            "tensor_323": {
                "variable": {
                    "value": "features",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_features_pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 2048))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_324": {
                "variable": {
                    "value": "image_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "image_mask",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[1] * mix_num_boxes",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(image_mask).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_325": {
                "variable": {
                    "value": "spatials",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_boxes_pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 5))",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_339": {
                "variable": {
                    "value": "co_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(len(entry['co_attention_mask']), self._max_region_num, self._max_caption_length)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "from_numpy_221": {
                "variable": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['input_ids'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_224": {
                "variable": {
                    "value": "input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['input_mask'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_227": {
                "variable": {
                    "value": "segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['segment_ids'])",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/datasets/vqa_dataset.py": {
        "torch": {
            "tensor_206": {
                "variable": {
                    "value": "features",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_features_pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 2048))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_207": {
                "variable": {
                    "value": "image_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "image_mask",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[1] * int(mix_num_boxes)",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(image_mask).long()",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_208": {
                "variable": {
                    "value": "spatials",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mix_boxes_pad",
                    "type": "Name",
                    "possible_values": [
                        [
                            "np.zeros((self._max_region_num, 5))",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_214": {
                "variable": {
                    "value": "co_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(self._max_region_num, self._max_seq_length)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_215": {
                "variable": {
                    "value": "target",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "self.num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_161": {
                "variable": {
                    "value": "question",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['q_token'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_164": {
                "variable": {
                    "value": "q_input_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['q_input_mask'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_167": {
                "variable": {
                    "value": "q_segment_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['q_segment_ids'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_175": {
                "variable": {
                    "value": "labels",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "labels",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.array(answer['labels'])",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(labels)",
                            "Call"
                        ],
                        [
                            "answer['labels']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "from_numpy_176": {
                "variable": {
                    "value": "scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "scores",
                    "type": "Call",
                    "possible_values": [
                        [
                            "np.array(answer['scores'], dtype=np.float32)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(scores)",
                            "Call"
                        ],
                        [
                            "answer['scores']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "vilbert_beta/vilbert/optimization.py": {
        "torch": {
            "cat_543": {
                "variable": {
                    "value": "norm_buf",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[exp_inf.mul_(beta2).unsqueeze(0), grad.abs().add_(eps).unsqueeze_(0)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_like_265": {
                "variable": {
                    "value": "state[next_m]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_267": {
                "variable": {
                    "value": "state[next_v]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_398": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_400": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_520": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_521": {
                "variable": {
                    "value": "state[exp_inf]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "max_547": {
                "input": {
                    "value": "norm_buf",
                    "type": "Name",
                    "possible_values": [
                        [
                            "torch.cat([exp_inf.mul_(beta2).unsqueeze(0), grad.abs().add_(eps).unsqueeze_(0)], 0)",
                            "Call"
                        ]
                    ]
                },
                "keepdim": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "out": {
                    "value": "(exp_inf, exp_inf.new().long())",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "clip_grad_norm__274": {
                "parameters": {
                    "value": "p",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_like_403": {
                "variable": {
                    "value": "state[max_exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__412": {
                "parameters": {
                    "value": "p",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "max_428": {
                "input": {
                    "value": "max_exp_avg_sq",
                    "type": "Name",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "max_exp_avg_sq",
                    "type": "Name",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "clip_grad_norm__529": {
                "parameters": {
                    "value": "p",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "vilbert_beta/vilbert/task_utils.py": {
        "torch": {
            "zeros_334": {
                "variable": {
                    "value": "one_hots",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "*labels.size()",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_20": {
                "reduction": {
                    "value": "mean",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_21": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_318": {
                "variable": {
                    "value": "task_dataloader_val[task]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dataset": {
                    "value": "task_datasets_val[task]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Call",
                    "possible_values": [
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "task_cfg[task]['batch_size'] // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "int(batch_size / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "args.batch_size",
                            "Attribute"
                        ],
                        [
                            "int(batch_size / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Call",
                    "possible_values": [
                        [
                            "args.num_workers",
                            "Attribute"
                        ],
                        [
                            "int(num_workers / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "int(args.num_workers / len(ids))",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sort_373": {
                "variable": {
                    "value": "(sorted_score, sorted_idx)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "-vil_prediction",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "max_63": {
                "variable": {
                    "value": "(_, preds)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "vil_logit",
                    "type": "Call",
                    "possible_values": [
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                }
            },
            "max_124": {
                "variable": {
                    "value": "(_, preds)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "vil_logit",
                    "type": "Call",
                    "possible_values": [
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_237": {
                "variable": {
                    "value": "task_dataloader_train[task]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dataset": {
                    "value": "task_datasets_train[task]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "Call",
                    "possible_values": [
                        [
                            "RandomSampler(task_datasets_train[task])",
                            "Call"
                        ],
                        [
                            "DistributedSampler(task_datasets_train[task])",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Call",
                    "possible_values": [
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "task_cfg[task]['batch_size'] // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "int(batch_size / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "args.batch_size",
                            "Attribute"
                        ],
                        [
                            "int(batch_size / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Call",
                    "possible_values": [
                        [
                            "args.num_workers",
                            "Attribute"
                        ],
                        [
                            "int(num_workers / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "int(args.num_workers / len(ids))",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "DataLoader_249": {
                "variable": {
                    "value": "task_dataloader_val[task]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dataset": {
                    "value": "task_datasets_val[task]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Call",
                    "possible_values": [
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "task_cfg[task]['batch_size'] // args.gradient_accumulation_steps",
                            "BinOp"
                        ],
                        [
                            "int(batch_size / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "args.batch_size",
                            "Attribute"
                        ],
                        [
                            "int(batch_size / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ],
                        [
                            "features.size(0)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Call",
                    "possible_values": [
                        [
                            "args.num_workers",
                            "Attribute"
                        ],
                        [
                            "int(num_workers / dist.get_world_size())",
                            "Call"
                        ],
                        [
                            "int(args.num_workers / len(ids))",
                            "Call"
                        ]
                    ]
                },
                "pin_memory": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "no_grad_367": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_389": {
                "variable": {
                    "value": "(_, preds)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "vil_logit",
                    "type": "Call",
                    "possible_values": [
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_392": {
                "variable": {
                    "value": "probs",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "vil_logit",
                    "type": "Call",
                    "possible_values": [
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ],
                        [
                            "vil_logit.view(batch_size, num_options)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "max_69": {
                "variable": {
                    "value": "(_, select_idx)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "vision_logit",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sum_71": {
                "variable": {
                    "value": "batch_score",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "select_target > 0.5",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "max_131": {
                "variable": {
                    "value": "(_, select_idx)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "vision_logit",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "RandomSampler_230": {
                "variable": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "task_datasets_train[task]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "DistributedSampler_234": {
                "variable": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "task_datasets_train[task]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "max_333": {
                "input": {
                    "value": "logits",
                    "type": "Attribute",
                    "possible_values": [
                        [
                            "torch.max(logits, 1)[1].data",
                            "Attribute"
                        ],
                        [
                            "torch.max(vil_prediction, 1)[1].data",
                            "Attribute"
                        ]
                    ]
                }
            },
            "max_399": {
                "variable": {
                    "value": "(_, select_idx)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "vision_logit",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "sum_401": {
                "variable": {
                    "value": "batch_score",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "select_target > 0.5",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "max_372": {
                "input": {
                    "value": "vil_prediction",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sum_133": {
                "input": {
                    "value": "select_target > 0.5",
                    "type": "Compare",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/bert_data_utils.py": {
        "torch": {
            "tensor_265": {
                "variable": {
                    "value": "self.input_ids_field",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.input_ids",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_266": {
                "variable": {
                    "value": "self.input_mask_field",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.input_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_267": {
                "variable": {
                    "value": "self.input_type_ids_field",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.segment_ids",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_270": {
                "variable": {
                    "value": "self.masked_lm_labels_field",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.lm_label_ids",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_274": {
                "variable": {
                    "value": "self.is_random_next_field",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[int(self.is_next)]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/bert_field.py": {
        "torch": {
            "from_numpy_54": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_arr",
                    "type": "Name",
                    "possible_values": [
                        [
                            "numpy.ones((num_tokens, self.embs.shape[1]), dtype=numpy.float32) * self.padding_value",
                            "BinOp"
                        ]
                    ]
                }
            },
            "from_numpy_108": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "return_array",
                    "type": "BinOp",
                    "possible_values": [
                        [
                            "numpy.asarray(numpy.ones(max_shape, 'int64') * self.padding_value)",
                            "Call"
                        ],
                        [
                            "torch.ones(max_shape, dtype=torch.int64) * self.padding_value",
                            "BinOp"
                        ],
                        [
                            "torch.ones(max_shape, dtype=torch.float) * self.padding_value",
                            "BinOp"
                        ]
                    ]
                }
            },
            "ones_146": {
                "*size": {
                    "value": "max_shape",
                    "type": "ListComp",
                    "possible_values": [
                        [
                            "[padding_lengths['dimension_{}'.format(i)] for i in range(len(padding_lengths))]",
                            "ListComp"
                        ],
                        [
                            "[padding_lengths['dimension_{}'.format(i)] for i in range(len(padding_lengths))]",
                            "ListComp"
                        ],
                        [
                            "[padding_lengths['dimension_{}'.format(i)] for i in range(len(padding_lengths))]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_182": {
                "*size": {
                    "value": "max_shape",
                    "type": "ListComp",
                    "possible_values": [
                        [
                            "[padding_lengths['dimension_{}'.format(i)] for i in range(len(padding_lengths))]",
                            "ListComp"
                        ],
                        [
                            "[padding_lengths['dimension_{}'.format(i)] for i in range(len(padding_lengths))]",
                            "ListComp"
                        ],
                        [
                            "[padding_lengths['dimension_{}'.format(i)] for i in range(len(padding_lengths))]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/coco_dataset.py": {
        "torch": {
            "load_60": {
                "variable": {
                    "value": "self.chunk",
                    "type": "Attribute",
                    "possible_values": []
                },
                "f": {
                    "value": "args.chunk_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_348": {
                "variable": {
                    "value": "masks",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_root, 'mask_train.th')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_349": {
                "variable": {
                    "value": "mask_val",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_root, 'mask_val.th')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "stack_454": {
                "variable": {
                    "value": "images",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "images",
                    "type": "Name",
                    "possible_values": [
                        [
                            "torch.stack(images, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "all_458": {
                "variable": {
                    "value": "td[box_mask]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "td['boxes'] >= 0",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "load_391": {
                "variable": {
                    "value": "chunk",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "chunk_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(data_root, 'trainval/resnet101_genome.th')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_389": {
                "obj": {
                    "value": "chunk",
                    "type": "Name",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.load(chunk_file)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "chunk_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(data_root, 'trainval/resnet101_genome.th')",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_386": {
                "variable": {
                    "value": "item[features]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "item['features']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "from_numpy_387": {
                "variable": {
                    "value": "item[boxes]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "item['boxes']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/flickr_ban/dataset.py": {
        "torch": {}
    },
    "visualbert/dataloaders/flickr_ban/utils.py": {
        "torch": {
            "save_107": {
                "obj": {
                    "value": "model_dict",
                    "type": "Name",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'model_state': model.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "path",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "is_tensor_126": {
                "obj": {
                    "value": "batch[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "load_76": {
                "f": {
                    "value": "net_file",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "stack_137": {
                "tensors": {
                    "value": "[F.pad(x, (0, 0, 0, max_num_boxes - x.size(0))).data for x in batch]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                },
                "out": {
                    "value": "out",
                    "type": "Call",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "batch[0].new(storage)",
                            "Call"
                        ],
                        [
                            "batch[0].new(storage)",
                            "Call"
                        ],
                        [
                            "t.gather(dim, dummy)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_145": {
                "tensors": {
                    "value": "batch",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                },
                "out": {
                    "value": "out",
                    "type": "Call",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "batch[0].new(storage)",
                            "Call"
                        ],
                        [
                            "batch[0].new(storage)",
                            "Call"
                        ],
                        [
                            "t.gather(dim, dummy)",
                            "Call"
                        ]
                    ]
                }
            },
            "abs_35": {
                "input": {
                    "value": "real - expected",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "stack_154": {
                "tensors": {
                    "value": "[torch.from_numpy(b) for b in batch]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "pad_137": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "pad": {
                    "value": "(0, 0, 0, max_num_boxes - x.size(0))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "from_numpy_154": {
                "ndarray": {
                    "value": "b",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/flickr_dataset.py": {
        "torch": {
            "from_numpy_163": {
                "variable": {
                    "value": "self.features",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "self.features",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_164": {
                "variable": {
                    "value": "self.spatials",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "self.spatials",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_167": {
                "variable": {
                    "value": "phrase",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['p_token'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_188": {
                "variable": {
                    "value": "entry[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "target_tensors",
                    "type": "Name",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_175": {
                "variable": {
                    "value": "target_tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "out": {
                    "value": "max_box",
                    "type": "Name",
                    "possible_values": [
                        [
                            "100",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_182": {
                "variable": {
                    "value": "target_tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "out": {
                    "value": "max_box",
                    "type": "Name",
                    "possible_values": [
                        [
                            "100",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "from_numpy_177": {
                "variable": {
                    "value": "target_idx",
                    "type": "Variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.array(entry['target_indices'][i])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_178": {
                "variable": {
                    "value": "target_tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "max_box",
                    "type": "Name",
                    "possible_values": [
                        [
                            "100",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "unsqueeze_178": {
                "variable": {
                    "value": "target_tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/nlvr_dataset.py": {
        "torch": {
            "load_56": {
                "variable": {
                    "value": "self.chunk",
                    "type": "Attribute",
                    "possible_values": []
                },
                "f": {
                    "value": "args.chunk_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_107": {
                "variable": {
                    "value": "image_feat_variable",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/vcr.py": {
        "torch": {
            "stack_474": {
                "variable": {
                    "value": "images",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "images",
                    "type": "Name",
                    "possible_values": [
                        [
                            "torch.stack(images, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "all_485": {
                "variable": {
                    "value": "td[box_mask]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "td['boxes'] >= 0",
                    "type": "Compare",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/dataloaders/vqa_dataset.py": {
        "torch": {}
    },
    "visualbert/models/model.py": {
        "torch": {
            "CrossEntropyLoss_63": {
                "variable": {
                    "value": "self._loss",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clamp_73": {
                "variable": {
                    "value": "span_tags_fixed",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "span_tags",
                    "type": "Variable",
                    "possible_values": []
                },
                "min": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_94": {
                "variable": {
                    "value": "span_rep",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(span['bert'], retrieved_feats)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_313": {
                "variable": {
                    "value": "one_hots",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "*labels.size()",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "arange_264": {
                "variable": {
                    "value": "image_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "image_feat_variable.size(-2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_75": {
                "start": {
                    "value": "0",
                    "type": "Constant",
                    "possible_values": []
                },
                "end": {
                    "value": "row_id.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "step": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "device": {
                    "value": "row_id.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "max_312": {
                "input": {
                    "value": "logits",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "output_dict['logits']",
                            "Subscript"
                        ],
                        [
                            "logits.detach().float()",
                            "Call"
                        ],
                        [
                            "output_dict['logits']",
                            "Subscript"
                        ],
                        [
                            "masked_unk_softmax(logits, 1, 0)",
                            "Call"
                        ],
                        [
                            "torch.max(logits, 1)[1].data",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "visualbert/models/model_wrapper.py": {
        "torch": {
            "DataParallel_146": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Name",
                    "possible_values": [
                        [
                            "Model.from_params(vocab=None, params=Params(args.model))",
                            "Call"
                        ]
                    ]
                }
            },
            "load_203": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "restore_bin",
                    "type": "Variable",
                    "possible_values": []
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "save_167": {
                "obj": {
                    "value": "model_state",
                    "type": "IfExp",
                    "possible_values": [
                        [
                            "self.model.module.state_dict() if isinstance(self.model, DataParallel) else self.model.state_dict()",
                            "IfExp"
                        ],
                        [
                            "self.model.module.state_dict() if isinstance(self.model, DataParallel) else self.model.state_dict()",
                            "IfExp"
                        ]
                    ]
                },
                "f": {
                    "value": "model_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'model_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'model_step_{}_epoch_{}.th'.format(step, epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_175": {
                "obj": {
                    "value": "training_state",
                    "type": "Dict",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'val_metric_per_epoch': val_metric_per_epoch, 'optimizer': self.optimizer.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'step': step, 'epoch': epoch, 'val_metric_per_epoch': None, 'optimizer': self.optimizer.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "training_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'training_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'training_step_{}_epoch_{}.th'.format(step, epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_186": {
                "obj": {
                    "value": "model_state",
                    "type": "IfExp",
                    "possible_values": [
                        [
                            "self.model.module.state_dict() if isinstance(self.model, DataParallel) else self.model.state_dict()",
                            "IfExp"
                        ],
                        [
                            "self.model.module.state_dict() if isinstance(self.model, DataParallel) else self.model.state_dict()",
                            "IfExp"
                        ]
                    ]
                },
                "f": {
                    "value": "model_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'model_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'model_step_{}_epoch_{}.th'.format(step, epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_195": {
                "obj": {
                    "value": "training_state",
                    "type": "Dict",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'val_metric_per_epoch': val_metric_per_epoch, 'optimizer': self.optimizer.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'step': step, 'epoch': epoch, 'val_metric_per_epoch': None, 'optimizer': self.optimizer.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "training_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'training_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'training_step_{}_epoch_{}.th'.format(step, epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_54": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/models/train.py": {
        "torch": {
            "device_count_267": {
                "variable": {
                    "value": "NUM_GPUS",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_536": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Tensor_579": {
                "variable": {
                    "value": "val_probs",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Tensor_587": {
                "variable": {
                    "value": "val_probs",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Tensor_588": {
                "variable": {
                    "value": "val_labels",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sum_590": {
                "input": {
                    "value": "compute_score_with_logits(val_probs, val_labels)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/pytorch_pretrained_bert/fine_tuning.py": {
        "torch": {
            "device_483": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_484": {
                "variable": {
                    "value": "n_gpu",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_487": {
                "variable": {
                    "value": "device",
                    "type": "Variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_502": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_584": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "Name",
                    "possible_values": [
                        [
                            "BERTDataset(args.train_file, tokenizer, seq_len=args.max_seq_length, corpus_lines=None, on_memory=args.on_memory)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "Call",
                    "possible_values": [
                        [
                            "RandomSampler(train_dataset)",
                            "Call"
                        ],
                        [
                            "DistributedSampler(train_dataset)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_486": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_504": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataParallel_539": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Call",
                    "possible_values": [
                        [
                            "BertForPreTraining.from_pretrained(args.bert_model)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "DDP(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "RandomSampler_579": {
                "variable": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_dataset",
                    "type": "Name",
                    "possible_values": [
                        [
                            "BERTDataset(args.train_file, tokenizer, seq_len=args.max_seq_length, corpus_lines=None, on_memory=args.on_memory)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_583": {
                "variable": {
                    "value": "train_sampler",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "Name",
                    "possible_values": [
                        [
                            "BERTDataset(args.train_file, tokenizer, seq_len=args.max_seq_length, corpus_lines=None, on_memory=args.on_memory)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_138": {
                "data": {
                    "value": "cur_features.input_ids",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_139": {
                "data": {
                    "value": "cur_features.input_mask",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_140": {
                "data": {
                    "value": "cur_features.segment_ids",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_141": {
                "data": {
                    "value": "cur_features.lm_label_ids",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_142": {
                "data": {
                    "value": "cur_features.is_next",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_621": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(args.output_dir, 'pytorch_model.bin')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_483": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/pytorch_pretrained_bert/modeling.py": {
        "torch": {
            "gather_1674": {
                "variable": {
                    "value": "scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "labels",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "torch.ones_like(labels) * labels_mask",
                            "BinOp"
                        ],
                        [
                            "labels.data.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "logits",
                    "type": "Call",
                    "possible_values": [
                        [
                            "logits.topk(k=recall, dim=-1)[1].data.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "torch.max(logits, -1)[1].data",
                            "Attribute"
                        ],
                        [
                            "logits.unsqueeze(-1)",
                            "Call"
                        ],
                        [
                            "masked_unk_softmax(logits, 1, 0)",
                            "Call"
                        ],
                        [
                            "torch.max(logits, 1)[1].data",
                            "Attribute"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.qa_outputs(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_1699": {
                "variable": {
                    "value": "x1",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Call",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sum_1701": {
                "variable": {
                    "value": "x1_sum",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x1",
                    "type": "Name",
                    "possible_values": [
                        [
                            "F.softmax(x, dim=dim)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_like_1708": {
                "variable": {
                    "value": "one_hots",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "labels",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "torch.ones_like(labels) * labels_mask",
                            "BinOp"
                        ],
                        [
                            "labels.data.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Embedding_182": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_183": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_184": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_189": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_193": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Call",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ],
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_218": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_219": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_220": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_222": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_241": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_253": {
                "variable": {
                    "value": "context_layer",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "type": "Call",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_266": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_268": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_298": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_311": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_313": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_348": {
                "variable": {
                    "value": "self.layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_377": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tanh_378": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_392": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_411": {
                "variable": {
                    "value": "self.decoder",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_model_embedding_weights.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_415": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(bert_model_embedding_weights.size(0))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_436": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_447": {
                "variable": {
                    "value": "self.seq_relationship",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_930": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_931": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_labels",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "2",
                            "MethodArgument"
                        ],
                        [
                            "2",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Dropout_995": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_996": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_1065": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1066": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_labels",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "2",
                            "MethodArgument"
                        ],
                        [
                            "2",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_1134": {
                "variable": {
                    "value": "self.qa_outputs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Embedding_1174": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_1175": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_1176": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_1181": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_1186": {
                "variable": {
                    "value": "self.token_type_embeddings_visual",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_1187": {
                "variable": {
                    "value": "self.position_embeddings_visual",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1189": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.visual_embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_1194": {
                "variable": {
                    "value": "self.token_type_embeddings_visual.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "deepcopy(self.token_type_embeddings.weight.data)",
                    "type": "Call",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Parameter_1195": {
                "variable": {
                    "value": "self.position_embeddings_visual.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "deepcopy(self.position_embeddings.weight.data)",
                    "type": "Call",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "arange_1208": {
                "variable": {
                    "value": "position_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "Call",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ],
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1613": {
                "variable": {
                    "value": "self.query",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1614": {
                "variable": {
                    "value": "self.key",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1615": {
                "variable": {
                    "value": "self.value",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_1617": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "matmul_1639": {
                "variable": {
                    "value": "attention_scores",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ],
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Tensor_1669": {
                "variable": {
                    "value": "counter",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sigmoid_65": {
                "input": {
                    "value": "x",
                    "type": "Call",
                    "possible_values": [
                        [
                            "(x - u) / torch.sqrt(s + self.variance_epsilon)",
                            "BinOp"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ],
                        [
                            "x.view(*new_x_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_196": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "load_554": {
                "variable": {
                    "value": "state_dict",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "weights_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_like_652": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_like_654": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_744": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_812": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_874": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_940": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1009": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1075": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1155": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "ignored_index",
                    "type": "Name",
                    "possible_values": [
                        [
                            "start_logits.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_1211": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cat_1253": {
                "variable": {
                    "value": "embeddings",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(embeddings, v_embeddings)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "ones_like_1277": {
                "variable": {
                    "value": "attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "zeros_like_1279": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cat_1311": {
                "variable": {
                    "value": "new_input",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(sequence_output, visual_part)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_1417": {
                "variable": {
                    "value": "flat_attention_mask",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(flat_input_mask, flat_image_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ones_like_1653": {
                "input": {
                    "value": "labels",
                    "type": "MethodArgument",
                    "possible_values": [
                        [
                            "torch.ones_like(labels) * labels_mask",
                            "BinOp"
                        ],
                        [
                            "labels.data.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "erf_61": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Parameter_167": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_168": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(hidden_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Softmax_247": {
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_415": {
                "*size": {
                    "value": "bert_model_embedding_weights.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_750": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_1238": {
                "variable": {
                    "value": "position_ids_visual",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "*visual_embeddings.size()[:-1]",
                    "type": "Starred",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_1247": {
                "variable": {
                    "value": "position_ids_visual",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "*visual_embeddings.size()[:-1]",
                    "type": "Starred",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_1355": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1356": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_like_1412": {
                "variable": {
                    "value": "visual_embeddings_type",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "flat_image_mask",
                    "type": "Name",
                    "possible_values": [
                        [
                            "transform_to_batch_sequence(image_mask)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1472": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1480": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "max_1672": {
                "input": {
                    "value": "logits",
                    "type": "Call",
                    "possible_values": [
                        [
                            "logits.topk(k=recall, dim=-1)[1].data.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "torch.max(logits, -1)[1].data",
                            "Attribute"
                        ],
                        [
                            "logits.unsqueeze(-1)",
                            "Call"
                        ],
                        [
                            "masked_unk_softmax(logits, 1, 0)",
                            "Call"
                        ],
                        [
                            "torch.max(logits, 1)[1].data",
                            "Attribute"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.qa_outputs(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ]
                    ]
                }
            },
            "max_1707": {
                "input": {
                    "value": "logits",
                    "type": "Call",
                    "possible_values": [
                        [
                            "logits.topk(k=recall, dim=-1)[1].data.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "torch.max(logits, -1)[1].data",
                            "Attribute"
                        ],
                        [
                            "logits.unsqueeze(-1)",
                            "Call"
                        ],
                        [
                            "masked_unk_softmax(logits, 1, 0)",
                            "Call"
                        ],
                        [
                            "torch.max(logits, 1)[1].data",
                            "Attribute"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.qa_outputs(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ],
                        [
                            "self.classifier(pooled_output)",
                            "Call"
                        ]
                    ]
                }
            },
            "Dropout_1360": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1361": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "3129",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1497": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "gather_1505": {
                "variable": {
                    "value": "pooled_output",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "sequence_output",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "encoded_layers[-1]",
                            "Subscript"
                        ],
                        [
                            "self.dropout(sequence_output)",
                            "Call"
                        ],
                        [
                            "encoded_layers[-1]",
                            "Subscript"
                        ],
                        [
                            "encoded_layers[-1]",
                            "Subscript"
                        ],
                        [
                            "encoded_layers[-1]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "index_to_gather.unsqueeze(-1).unsqueeze(-1).expand(index_to_gather.size(0), 1, sequence_output.size(-1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_1507": {
                "variable": {
                    "value": "flat_input_ids",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "flat_input_ids",
                    "type": "Call",
                    "possible_values": [
                        [
                            "input_ids.view(-1, input_ids.size(-1))",
                            "Call"
                        ],
                        [
                            "transform_to_batch_sequence(input_ids)",
                            "Call"
                        ],
                        [
                            "torch.gather(flat_input_ids, 1, index_to_gather.unsqueeze(-1).expand(index_to_gather.size(0), 1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "index": {
                    "value": "index_to_gather.unsqueeze(-1).expand(index_to_gather.size(0), 1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ones_167": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "zeros_168": {
                "*size": {
                    "value": "hidden_size",
                    "type": "Name",
                    "possible_values": [
                        [
                            "768",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sqrt_174": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_like_1422": {
                "input": {
                    "value": "flat_attention_mask",
                    "type": "Name",
                    "possible_values": [
                        [
                            "attention_mask.view(-1, attention_mask.size(-1))",
                            "Call"
                        ],
                        [
                            "torch.cat((flat_input_mask, flat_image_mask), dim=-1)",
                            "Call"
                        ],
                        [
                            "flat_input_mask",
                            "Name"
                        ]
                    ]
                }
            },
            "KLDivLoss_1518": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "batchmean",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "LogSoftmax_1519": {
                "variable": {
                    "value": "log_softmax",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1533": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Dropout_1365": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_1366": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "2",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_1368": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sum_1523": {
                "input": {
                    "value": "compute_score_with_logits(reshaped_logits, label)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_1564": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "KLDivLoss_1587": {
                "variable": {
                    "value": "loss_fct",
                    "type": "Variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "batchmean",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "LogSoftmax_1588": {
                "variable": {
                    "value": "log_softmax",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "max_1538": {
                "input": {
                    "value": "prediction_scores",
                    "type": "Call",
                    "possible_values": [
                        [
                            "self.predictions(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.predictions(sequence_output)",
                            "Call"
                        ],
                        [
                            "self.cls(sequence_output)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "visualbert/pytorch_pretrained_bert/optimization.py": {
        "torch": {
            "zeros_like_264": {
                "variable": {
                    "value": "state[next_m]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_266": {
                "variable": {
                    "value": "state[next_v]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__273": {
                "parameters": {
                    "value": "p",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/utils/detector.py": {
        "torch": {
            "Sequential_60": {
                "variable": {
                    "value": "self.backbone",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "backbone.conv1",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_90": {
                "variable": {
                    "value": "self.after_roi_align",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*after_roi_align",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_92": {
                "variable": {
                    "value": "self.obj_downsample",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "torch.nn.Dropout(p=0.1)",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_97": {
                "variable": {
                    "value": "self.regularizing_predictor",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "2048",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_features": {
                    "value": "81",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_116": {
                "variable": {
                    "value": "rois",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(box_inds[:, 0, None].type(boxes.dtype), boxes[box_inds[:, 0], box_inds[:, 1]])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Embedding_77": {
                "variable": {
                    "value": "self.object_embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "81",
                    "type": "Constant",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "128",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Conv2d_78": {
                "variable": {
                    "value": "self.mask_upsample",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "self.mask_dims",
                    "type": "Attribute",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "2 if USE_IMAGENET_PRETRAINED else 1",
                    "type": "IfExp",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Dropout_93": {
                "p": {
                    "value": "0.1",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "Linear_94": {
                "in_features": {
                    "value": "2048 + (128 if semantic else 0)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "final_dim",
                    "type": "Name",
                    "possible_values": [
                        [
                            "1024",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_95": {
                "inplace": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cross_entropy_131": {
                "input": {
                    "value": "obj_logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "self.regularizing_predictor(post_roialign)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "obj_labels",
                    "type": "Name",
                    "possible_values": [
                        [
                            "classes[box_inds[:, 0], box_inds[:, 1]]",
                            "Subscript"
                        ]
                    ]
                },
                "size_average": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "cat_133": {
                "tensors": {
                    "value": "(post_roialign, self.object_embed(obj_labels))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "AvgPool2d_88": {
                "kernel_size": {
                    "value": "7",
                    "type": "Constant",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/utils/get_image_features/extract_image_features_nlvr.py": {
        "torch": {
            "load_298": {
                "variable": {
                    "value": "giant_file",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.existing",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_341": {
                "obj": {
                    "value": "giant_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ],
                        [
                            "torch.load(args.existing)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "one_giant_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "args.one_giant_file",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Tensor_329": {
                "variable": {
                    "value": "box_features",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Tensor_330": {
                "variable": {
                    "value": "cls_boxes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "Tensor_331": {
                "variable": {
                    "value": "max_conf",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "visualbert/utils/get_image_features/get_mask.py": {
        "torch": {
            "save_386": {
                "obj": {
                    "value": "giant_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "one_giant_file",
                    "type": "Name",
                    "possible_values": [
                        [
                            "args.one_giant_file",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "visualbert/utils/pytorch_misc.py": {
        "torch": {
            "load_228": {
                "variable": {
                    "value": "model_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fn",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'best.th')",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_236": {
                "variable": {
                    "value": "model_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fn",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'best.th')",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_296": {
                "variable": {
                    "value": "model_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "model_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'model_state_epoch_{}.th'.format(epoch_to_load))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'model_step_{}_epoch_{}.th'.format(max_step, max_epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'model_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_297": {
                "variable": {
                    "value": "training_state",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "training_state_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'training_state_epoch_{}.th'.format(epoch_to_load))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'training_step_{}_epoch_{}.th'.format(max_step, max_epoch))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "device_mapping(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_393": {
                "variable": {
                    "value": "x1",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sum_395": {
                "variable": {
                    "value": "x1_sum",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x1",
                    "type": "Name",
                    "possible_values": [
                        [
                            "F.softmax(x, dim=dim)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "Constant",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "Constant",
                    "possible_values": []
                }
            },
            "zeros_like_402": {
                "variable": {
                    "value": "one_hots",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "labels",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "save_209": {
                "obj": {
                    "value": "model_state",
                    "type": "Call",
                    "possible_values": [
                        [
                            "model.module.state_dict() if isinstance(model, DataParallel) else model.state_dict()",
                            "IfExp"
                        ],
                        [
                            "torch.load(fn, map_location=device_mapping(-1))",
                            "Call"
                        ],
                        [
                            "torch.load(fn, map_location=device_mapping(-1))",
                            "Call"
                        ],
                        [
                            "torch.load(model_path, map_location=device_mapping(-1))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "model_path",
                    "type": "Call",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'model_state_epoch_{}.th'.format(epoch_to_load))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'model_step_{}_epoch_{}.th'.format(max_step, max_epoch))",
                            "Call"
                        ],
                        [
                            "os.path.join(serialization_dir, 'model_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_220": {
                "obj": {
                    "value": "training_state",
                    "type": "Name",
                    "possible_values": [
                        [
                            "{'epoch': epoch, 'val_metric_per_epoch': val_metric_per_epoch, 'optimizer': optimizer.state_dict()}",
                            "Dict"
                        ],
                        [
                            "torch.load(training_state_path, map_location=device_mapping(-1))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "training_path",
                    "type": "Name",
                    "possible_values": [
                        [
                            "os.path.join(serialization_dir, 'training_state_epoch_{}.th'.format(epoch))",
                            "Call"
                        ]
                    ]
                }
            },
            "max_401": {
                "input": {
                    "value": "logits",
                    "type": "Name",
                    "possible_values": [
                        [
                            "masked_unk_softmax(logits, 1, 0)",
                            "Call"
                        ],
                        [
                            "torch.max(logits, 1)[1].data",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    }
}