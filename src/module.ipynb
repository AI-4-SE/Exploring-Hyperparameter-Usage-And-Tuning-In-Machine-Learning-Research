{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "SKLEARN_DATA = \"../data/sklearn/modules/sklearn_modules.json\"\n",
    "\n",
    "ALL_SKLEARN_PROJECTS = \"statistics/sklearn/statistics/*\"\n",
    "ALL_TENSORFLOW_PROJECTS = \"statistics/tensorflow/statistics/*\"\n",
    "ALL_PYTORCH_PROJECTS = \"statistics/pytorch/statistics/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len projects:  2\n"
     ]
    }
   ],
   "source": [
    "projects = glob.glob(ALL_SKLEARN_PROJECTS)\n",
    "print(\"Len projects: \", len(projects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'statistics/sklearn\\\\results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-05f971a39d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mproject_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"statistics_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mproject_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mproject_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'statistics/sklearn\\\\results'"
     ]
    }
   ],
   "source": [
    "with open(SKLEARN_DATA, \"r\", encoding=\"utf-8\") as sklearn_file:\n",
    "    sklearn_data = json.load(sklearn_file)\n",
    "\n",
    "data = []\n",
    "\n",
    "for project in glob.glob(ALL_SKLEARN_PROJECTS):\n",
    "    project_name = project.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    project_name = project_name.replace(\"statistics_\", \"\")\n",
    "\n",
    "    with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "        project_data = json.load(project_file)\n",
    "\n",
    "    for file in project_data:\n",
    "        file_data = project_data[file]\n",
    "\n",
    "        for module in file_data:\n",
    "            module_name = module.split(\"_\")[0]\n",
    "            module_data = file_data[module]\n",
    "\n",
    "            sklearn_module = next(filter(lambda x: x[\"name\"] == module_name, sklearn_data))\n",
    "\n",
    "            total_options = len(sklearn_module[\"params\"])\n",
    "\n",
    "            if module_name == \"KMeans\":\n",
    "                data.append({\n",
    "                    \"project\": project_name,\n",
    "                    \"total_options\": total_options,\n",
    "                    \"options_used\": len(module_data),\n",
    "                    \"portion\": len(module_data)/total_options\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules:  {'TruncatedSVD', 'KDTree', 'OneClassSVM', 'ShuffleSplit', 'IsotonicRegression', 'OneHotEncoder', 'GaussianMixture', 'SimpleImputer', 'SVR', 'RandomForestClassifier', 'MultinomialNB', 'PCA', 'LinearRegression', 'ExtraTreesClassifier', 'LabelEncoder', 'TfidfVectorizer', 'TransformedTargetRegressor', 'CountVectorizer', 'MLPRegressor', 'AgglomerativeClustering', 'BayesianGaussianMixture', 'ParameterSampler', 'RFE', 'SVC', 'SGDOneClassSVM', 'LabelBinarizer', 'GridSearchCV', 'DBSCAN', 'HuberRegressor', 'KFold', 'RBFSampler', 'TfidfTransformer', 'GroupKFold', 'MultiLabelBinarizer', 'ExtraTreesRegressor', 'OneVsRestClassifier', 'Perceptron', 'BernoulliNB', 'KBinsDiscretizer', 'DecisionTreeRegressor', 'ComplementNB', 'LatentDirichletAllocation', 'KNeighborsClassifier', 'RepeatedStratifiedKFold', 'KMeans', 'GroupShuffleSplit', 'TSNE', 'RANSACRegressor', 'RobustScaler', 'StratifiedKFold', 'MultiOutputRegressor', 'GradientBoostingRegressor', 'DummyRegressor', 'SGDRegressor', 'RepeatedKFold', 'PolynomialFeatures', 'ColumnTransformer', 'KernelPCA', 'LogisticRegression', 'MeanShift', 'IterativeImputer', 'MiniBatchKMeans', 'FunctionTransformer', 'DecisionTreeClassifier', 'LinearSVC', 'GaussianNB', 'RegressorChain', 'MinMaxScaler', 'DummyClassifier', 'KernelDensity', 'ParameterGrid', 'TimeSeriesSplit', 'RandomForestRegressor', 'Pipeline', 'StandardScaler', 'Lasso', 'KNeighborsRegressor', 'NearestNeighbors', 'SGDClassifier', 'Ridge'}\n",
      "Len modules:  80\n"
     ]
    }
   ],
   "source": [
    "modules = set()\n",
    "\n",
    "for project in glob.glob(ALL_SKLEARN_PROJECTS):\n",
    "    project_name = project.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    project_name = project_name.replace(\"statistics_\", \"\")\n",
    "\n",
    "    with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "        project_data = json.load(project_file)\n",
    "\n",
    "    for file in project_data:\n",
    "        file_data = project_data[file]\n",
    "\n",
    "        for module in file_data:\n",
    "            module_name = module.split(\"_\")[0]\n",
    "            modules.add(module_name)\n",
    "\n",
    "\n",
    "print(\"Modules: \", modules)\n",
    "print(\"Len modules: \", len(modules))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "for name in modules:\n",
    "    data = []\n",
    "\n",
    "    for project in glob.glob(ALL_SKLEARN_PROJECTS):\n",
    "        project_name = project.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        project_name = project_name.replace(\"statistics_\", \"\")\n",
    "\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "        for file in project_data:\n",
    "            file_data = project_data[file]\n",
    "\n",
    "            for module in file_data:\n",
    "                default_counter = 0\n",
    "                custom_counter = 0\n",
    "                module_name = module.split(\"_\")[0]\n",
    "                module_data = file_data[module]\n",
    "\n",
    "                sklearn_module = next(filter(lambda x: x[\"name\"] == module_name, sklearn_data))\n",
    "\n",
    "                total_options = len(sklearn_module[\"params\"])\n",
    "\n",
    "                if module_name == name:\n",
    "                    if module_data:\n",
    "                        for option in module_data:\n",
    "                            try:\n",
    "                                param = next(filter(lambda x: x[0] == option, sklearn_module[\"params\"]))\n",
    "                                default_value = param[1].split(\"=\")[-1]\n",
    "                                option_value = module_data[option]   \n",
    "                                if default_value == option_value:\n",
    "                                    default_counter += 1\n",
    "                                else:\n",
    "                                    custom_counter +=1\n",
    "                            except:\n",
    "                                custom_counter +=1\n",
    "\n",
    "                    data.append({\n",
    "                        \"project\": project_name,\n",
    "                        \"file\": file,\n",
    "                        \"total_options\": total_options,\n",
    "                        \"options_used\": len(module_data),\n",
    "                        \"default_options_used\": default_counter,\n",
    "                        \"custom_options_used\": custom_counter\n",
    "                    })\n",
    "\n",
    "    all_data[name] = data\n",
    "\n",
    "\n",
    "with open(\"sklearn_modules_data.json\", \"w\") as outfile:\n",
    "    json.dump(all_data, outfile, sort_keys=True, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b15ceb2e1c319abb5a3a14f1ef1bcbce2ee8dd1c77d2c4e6466e97ae1997d13"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
