{
    "datasets.py": {
        "torch": {
            "load_139": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_dir, pt_name)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_153": {
                "variable": {
                    "value": "train_data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_dir, 'train_data.pt')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_154": {
                "variable": {
                    "value": "test_data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_dir, 'test_data.pt')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_190": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_dir, pt_file)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "DataLoader_284": {
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "MemoryDataset(data)",
                            "Call"
                        ],
                        [
                            "DiskDataset(img_paths, img_loader)",
                            "Call"
                        ],
                        [
                            "DiskDataset(img_paths, img_loader)",
                            "Call"
                        ],
                        [
                            "MemoryDataset(data)",
                            "Call"
                        ],
                        [
                            "dataset",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "tensor_39": {
                "variable": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "img_loader(os.path.join(data_dir, 'lfw-deepfunneled', celeb_name, fname))",
                            "Call"
                        ],
                        [
                            "img_loader(fname)",
                            "Call"
                        ],
                        [
                            "cv2.imread(path)",
                            "Call"
                        ],
                        [
                            "cv2.cvtColor(img, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "center_crop(img, self.center_crop_size)",
                            "Call"
                        ],
                        [
                            "cv2.resize(img, (self.resize, self.resize))",
                            "Call"
                        ],
                        [
                            "img.transpose(2, 0, 1)",
                            "Call"
                        ],
                        [
                            "img / 127.5 - 1",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(img, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "img.astype(self.dtype)",
                            "Call"
                        ],
                        [
                            "img",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "self.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_272": {
                "variable": {
                    "value": "batch_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "batch",
                    "type": "variable",
                    "possible_values": [
                        [
                            "batch",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "save_81": {
                "obj": {
                    "value": "training_set",
                    "type": "variable",
                    "possible_values": [
                        [
                            "read_image_file(os.path.join(raw_folder, 'train-images-idx3-ubyte'))",
                            "Call"
                        ],
                        [
                            "training_set.reshape(-1, 1, MNIST_WORKING_DIM, MNIST_WORKING_DIM) / 127.5 - 1",
                            "BinOp"
                        ]
                    ]
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tarfile.open(os.path.join(data_dir, 'lfw-deepfunneled.tgz'), 'r:gz')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_83": {
                "obj": {
                    "value": "test_set",
                    "type": "variable",
                    "possible_values": [
                        [
                            "read_image_file(os.path.join(raw_folder, 't10k-images-idx3-ubyte'))",
                            "Call"
                        ],
                        [
                            "test_set.reshape(-1, 1, MNIST_WORKING_DIM, MNIST_WORKING_DIM) / 127.5 - 1",
                            "BinOp"
                        ]
                    ]
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tarfile.open(os.path.join(data_dir, 'lfw-deepfunneled.tgz'), 'r:gz')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_137": {
                "obj": {
                    "value": "torch.stack(imgs)",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tarfile.open(os.path.join(data_dir, 'lfw-deepfunneled.tgz'), 'r:gz')",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_269": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "interpolate_274": {
                "variable": {
                    "value": "batch_tensor",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "batch_tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.stack(batch).to(self.device).float()",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.interpolate(batch_tensor, (self.resize, self.resize))",
                            "Call"
                        ]
                    ]
                },
                "size": {
                    "value": "(self.resize, self.resize)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "stack_137": {
                "tensors": {
                    "value": "imgs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "save_188": {
                "obj": {
                    "value": "torch.stack(imgs)",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tarfile.open(os.path.join(data_dir, 'lfw-deepfunneled.tgz'), 'r:gz')",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_135": {
                "data": {
                    "value": "img",
                    "type": "variable",
                    "possible_values": [
                        [
                            "img_loader(os.path.join(data_dir, 'lfw-deepfunneled', celeb_name, fname))",
                            "Call"
                        ],
                        [
                            "img_loader(fname)",
                            "Call"
                        ],
                        [
                            "cv2.imread(path)",
                            "Call"
                        ],
                        [
                            "cv2.cvtColor(img, cv2.COLOR_BGR2RGB)",
                            "Call"
                        ],
                        [
                            "center_crop(img, self.center_crop_size)",
                            "Call"
                        ],
                        [
                            "cv2.resize(img, (self.resize, self.resize))",
                            "Call"
                        ],
                        [
                            "img.transpose(2, 0, 1)",
                            "Call"
                        ],
                        [
                            "img / 127.5 - 1",
                            "BinOp"
                        ],
                        [
                            "torch.tensor(img, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "img.astype(self.dtype)",
                            "Call"
                        ],
                        [
                            "img",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_188": {
                "tensors": {
                    "value": "imgs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            }
        }
    },
    "dnn/costume_layers.py": {
        "torch": {
            "interpolate_13": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.instance_norm(x)",
                            "Call"
                        ],
                        [
                            "F.conv2d(x, weight=self.weight, groups=self.groups, padding=1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "scale_factor": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "mode": {
                    "value": "bilinear",
                    "type": "str",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "avg_pool2d_18": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.instance_norm(x)",
                            "Call"
                        ],
                        [
                            "F.conv2d(x, weight=self.weight, groups=self.groups, padding=1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "InstanceNorm2d_33": {
                "variable": {
                    "value": "self.instance_norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_features": {
                    "value": "channels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "channels",
                            "Method Argument"
                        ],
                        [
                            "channels",
                            "Method Argument"
                        ]
                    ]
                },
                "affine": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "mean_38": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.instance_norm(x)",
                            "Call"
                        ],
                        [
                            "F.conv2d(x, weight=self.weight, groups=self.groups, padding=1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "[2, 3]",
                    "type": "List",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "sqrt_39": {
                "variable": {
                    "value": "std",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.mean((x - m) ** 2, dim=[2, 3], keepdim=True)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_40": {
                "variable": {
                    "value": "style",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(m, std)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "conv2d_64": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.instance_norm(x)",
                            "Call"
                        ],
                        [
                            "F.conv2d(x, weight=self.weight, groups=self.groups, padding=1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "groups": {
                    "value": "self.groups",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_102": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros((1, n_channel, 1, 1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "InstanceNorm2d_117": {
                "variable": {
                    "value": "self.norm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_features": {
                    "value": "n_channel",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_channel",
                            "Method Argument"
                        ],
                        [
                            "n_channel",
                            "Method Argument"
                        ],
                        [
                            "n_channel",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_152": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(out_channels, in_channels, *self.kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "grad_22": {
                "outputs": {
                    "value": "d_result_real.sum()",
                    "type": "Call",
                    "possible_values": []
                },
                "inputs": {
                    "value": "real_images",
                    "type": "variable",
                    "possible_values": [
                        [
                            "real_images",
                            "Method Argument"
                        ]
                    ]
                },
                "create_graph": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "retain_graph": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "sum_26": {
                "input": {
                    "value": "real_grads.pow(2.0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "[1, 2, 3]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "rsqrt_69": {
                "input": {
                    "value": "torch.mean(x.pow(2.0), dim=1, keepdim=True) + epsilon",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "linear_135": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight * self.c",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_155": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "conv2d_167": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.instance_norm(x)",
                            "Call"
                        ],
                        [
                            "F.conv2d(x, weight=self.weight, groups=self.groups, padding=1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight * self.c",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "stride": {
                    "value": "self.stride",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dilation": {
                    "value": "self.dilation",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "mean_39": {
                "input": {
                    "value": "(x - m) ** 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "[2, 3]",
                    "type": "List",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_102": {
                "*size": {
                    "value": "(1, n_channel, 1, 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "mean_69": {
                "input": {
                    "value": "x.pow(2.0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Tensor_155": {}
        }
    },
    "dnn/models/StyleGan.py": {
        "torch": {
            "Adam_31": {
                "variable": {
                    "value": "self.G_optimizer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "list(self.F.parameters()) + list(self.G.parameters())",
                    "type": "BinOp",
                    "possible_values": []
                },
                "lr": {
                    "value": "self.cfg['lr']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "betas": {
                    "value": "(0.0, 0.99)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Adam_32": {
                "variable": {
                    "value": "self.D_optimizer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "self.D.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "self.cfg['lr']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "betas": {
                    "value": "(0.0, 0.99)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_35": {
                "variable": {
                    "value": "batch_z",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_real_data.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "self.cfg['z_dim']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randn_51": {
                "variable": {
                    "value": "batch_z",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_real_data.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "self.cfg['z_dim']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softplus_54": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-fake_images_dicriminator_outputs",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "mean_54": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_58": {
                "obj": {
                    "value": "{'F': self.F.state_dict(), 'G': self.G.state_dict(), 'D': self.D.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "save_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "save_path",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "interpolate_107": {
                "variable": {
                    "value": "generated_images",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "generated_images",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.G(self.F(samples_z), res_idx, alpha)",
                            "Call"
                        ],
                        [
                            "torch.nn.functional.interpolate(generated_images, size=self.cfg['resolutions'][-1])",
                            "Call"
                        ],
                        [
                            "generated_images * 0.5 + 0.5",
                            "BinOp"
                        ]
                    ]
                },
                "size": {
                    "value": "self.cfg['resolutions'][-1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "no_grad_36": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "softplus_40": {
                "input": {
                    "value": "-real_images_dicriminator_outputs",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "no_grad_105": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "train_MlpALAE.py": {
        "torch": {
            "device_19": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() and args.device == cuda:0 else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "randn_47": {
                "variable": {
                    "value": "test_samples_z",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "args.num_debug_images",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "config['z_dim']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_19": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "train_StyleALAE.py": {
        "torch": {
            "device_18": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() and args.device == cuda:0 else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "randn_62": {
                "variable": {
                    "value": "test_samples_z",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "args.num_debug_images",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "config['z_dim']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_45": {
                "variable": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "cfg_file_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, 'checkpoints', 'cfg.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "save_46": {
                "obj": {
                    "value": "config",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'z_dim': 256, 'w_dim': 256, 'image_dim': 64, 'mapping_layers': 8, 'resolutions': [4, 8, 16, 32, 64, 64], 'channels': [256, 256, 128, 128, 64, 32, 16], 'learning_rates': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], 'phase_lengths': [600000, 600000, 600000, 600000, 600000, 1000000], 'batch_sizes': [128, 128, 128, 64, 32, 32], 'n_critic': 1, 'dump_imgs_freq': 5000, 'checkpoint_freq': 10000}",
                            "Dict"
                        ],
                        [
                            "torch.load(cfg_file_path)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "cfg_file_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, 'checkpoints', 'cfg.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_18": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "train_StyleGan.py": {
        "torch": {
            "device_18": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() and args.device == cuda:0 else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "randn_51": {
                "variable": {
                    "value": "test_samples_z",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "args.num_debug_images",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out": {
                    "value": "config['z_dim']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_18": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}