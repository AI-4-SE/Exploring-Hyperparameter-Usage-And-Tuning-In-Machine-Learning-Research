{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length task paper:  1537\n",
      "Length tasks:  800\n",
      "[('General Classification', 160), ('Semantic Segmentation', 137), ('Image Classification', 121), ('Object Detection', 97), ('Translation', 89), ('Representation Learning', 77), ('Question Answering', 65), ('Language Modelling', 62), ('Data Augmentation', 51), ('Image Generation', 50)]\n"
     ]
    }
   ],
   "source": [
    "def get_task_paper():\n",
    "    task_paper = []\n",
    "    tasks = []\n",
    "\n",
    "    with open(\"final_metadata.json\", \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    for item in data:\n",
    "        paper = item[\"paper\"]\n",
    "        if paper:\n",
    "            task = paper[\"tasks\"]\n",
    "            if task:\n",
    "                for x in task:\n",
    "                    tasks.append(x)\n",
    "\n",
    "                x = {\n",
    "                    \"abstract\": paper[\"abstract\"],\n",
    "                    \"body\": paper[\"body\"],\n",
    "                    \"file_name\": paper[\"filename\"],\n",
    "                    \"title\": paper[\"title\"],\n",
    "                    \"tasks\": task\n",
    "                }\n",
    "                task_paper.append(x)\n",
    "\n",
    "    with open(\"task_paper.json\", \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(task_paper, dest, sort_keys=True, indent=4)\n",
    "\n",
    "    task_counter = Counter(tasks)\n",
    "    print(\"Length task paper: \", len(task_paper))\n",
    "    print(\"Length tasks: \", len(task_counter))\n",
    "    print(task_counter.most_common(10))\n",
    "\n",
    "get_task_paper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length method papers:  644\n",
      "Len methods:  7\n",
      "[('General', 3659), ('Computer Vision', 1865), ('Natural Language Processing', 330), ('Reinforcement Learning', 120), ('Sequential', 105), ('Graphs', 63), ('Audio', 10)]\n"
     ]
    }
   ],
   "source": [
    "def get_methods_paper():\n",
    "    area_papers = []\n",
    "    areas = []\n",
    "\n",
    "    with open(\"final_metadata.json\", \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    for item in data:\n",
    "        paper = item[\"paper\"]\n",
    "        methods_areas = []\n",
    "        if paper:\n",
    "            methods = paper[\"methods\"]\n",
    "            if methods:\n",
    "                for method in methods:\n",
    "                    main_collection = method[\"main_collection\"]\n",
    "                    if main_collection:\n",
    "                        areas.append(main_collection[\"area\"])\n",
    "                        methods_areas.append(main_collection[\"area\"])\n",
    "\n",
    "                x = {\n",
    "                    \"abstract\": paper[\"abstract\"],\n",
    "                    \"body\": paper[\"body\"],\n",
    "                    \"file_name\": paper[\"filename\"],\n",
    "                    \"title\": paper[\"title\"],\n",
    "                    \"method_areas\": methods_areas\n",
    "                }\n",
    "                area_papers.append(x)\n",
    "\n",
    "    with open(\"method_paper.json\", \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(area_papers, dest, sort_keys=True, indent=4)\n",
    "\n",
    "    area_counter = Counter(areas)\n",
    "    print(\"Length method papers: \", len(area_papers))\n",
    "    print(\"Len methods: \", len(area_counter))\n",
    "    print(area_counter.most_common(10))\n",
    "\n",
    "get_methods_paper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwc_methods = [\"General\", \"Computer Vision\", \"Natural Language Processing\", \"Reinforcement Learning\", \"Audio\", \"Sequential\", \"Graphs\"]\n",
    "pwc_sota = [\"Computer Vison\", \"Natural Language Processing\", \"Medical\", \"Miscellaneous\", \"Methodology\", \"Time Series\", \"Graphs\", \"Speech\", \"Reasoning\", \"Playing Games\", \"Computer Code\", \"Robots\", \"Adversarial\", \"Knowledge Base\", \"Music\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
