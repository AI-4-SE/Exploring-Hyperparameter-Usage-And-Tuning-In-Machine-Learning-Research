{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def df_to_latex(df: pd.DataFrame) -> None:\n",
    "    print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find:  TestKFold sklearn\n",
      "Could not find:  ConditionalDensity sklearn\n",
      "Could not find:  River2SKLBase sklearn\n",
      "Could not find:  River2SKLRegressor sklearn\n",
      "Could not find:  River2SKLClassifier sklearn\n",
      "Could not find:  River2SKLTransformer sklearn\n",
      "Could not find:  River2SKLClusterer sklearn\n",
      "Could not find:  AutoML sklearn\n",
      "Could not find:  ResidualBlock tensorflow\n",
      "Could not find:  TFAttention tensorflow\n",
      "Could not find:  TFMLP tensorflow\n",
      "Could not find:  TFBlock tensorflow\n",
      "Could not find:  PreprocessLayer tensorflow\n",
      "Could not find:  TFMultiHeadAttention tensorflow\n",
      "Could not find:  GenCallback tensorflow\n",
      "Could not find:  MessagerCallback tensorflow\n",
      "Could not find:  TFAdaptiveEmbedding tensorflow\n",
      "Could not find:  TFT5LayerSelfAttention tensorflow\n",
      "Could not find:  TFT5LayerNorm tensorflow\n",
      "Could not find:  TFT5DenseReluDense tensorflow\n",
      "Could not find:  TFT5LayerFF tensorflow\n",
      "Could not find:  TFTransfoXLLMHead tensorflow\n",
      "Could not find:  TFTransfoXLMainLayer tensorflow\n",
      "Could not find:  TFT5Attention tensorflow\n",
      "Could not find:  TFT5Block tensorflow\n",
      "Could not find:  TFT5LayerCrossAttention tensorflow\n",
      "Could not find:  TFT5MainLayer tensorflow\n",
      "Could not find:  TFPositionalEmbedding tensorflow\n",
      "Could not find:  TFPositionwiseFF tensorflow\n",
      "Could not find:  TFRelPartialLearnableMultiHeadAttn tensorflow\n",
      "Could not find:  TFRelPartialLearnableDecoderLayer tensorflow\n",
      "Could not find:  TFRobertaClassificationHead tensorflow\n",
      "Could not find:  TCN tensorflow\n",
      "Could not find:  TFRobertaLMHead tensorflow\n",
      "Could not find:  TFDistilBertMainLayer tensorflow\n",
      "Could not find:  TFEncoderLayer tensorflow\n",
      "Could not find:  TFCTRLMainLayer tensorflow\n",
      "Could not find:  TFCTRLLMHead tensorflow\n",
      "Could not find:  TFEmbeddings tensorflow\n",
      "Could not find:  TFMultiHeadSelfAttention tensorflow\n",
      "Could not find:  TFFFN tensorflow\n",
      "Could not find:  TFTransformerBlock tensorflow\n",
      "Could not find:  TFTransformer tensorflow\n",
      "Could not find:  TFDistilBertLMHead tensorflow\n",
      "Could not find:  TFOpenAIGPTMainLayer tensorflow\n",
      "Could not find:  TFElectraEmbeddings tensorflow\n",
      "Could not find:  TFElectraDiscriminatorPredictions tensorflow\n",
      "Could not find:  TFElectraGeneratorPredictions tensorflow\n",
      "Could not find:  TFElectraMaskedLMHead tensorflow\n",
      "Could not find:  WaveNetModel tensorflow\n",
      "Could not find:  TFPreTrainedModel tensorflow\n",
      "Could not find:  TFGPT2MainLayer tensorflow\n",
      "Could not find:  TFAdaptiveSoftmaxMask tensorflow\n",
      "Could not find:  ModulesTest tensorflow\n",
      "Could not find:  TFConv1D tensorflow\n",
      "Could not find:  CausalConvolution tensorflow\n",
      "Could not find:  TFBertMainLayer tensorflow\n",
      "Could not find:  SelfLayer tensorflow\n",
      "Could not find:  ConvolutionsTest tensorflow\n",
      "Could not find:  MaskLayerTriangular tensorflow\n",
      "Could not find:  MaskLayerRight tensorflow\n",
      "Could not find:  MaskLayerLeft tensorflow\n",
      "Could not find:  TFSharedEmbeddings tensorflow\n",
      "Could not find:  MetricsSaver tensorflow\n",
      "Could not find:  TFSequenceSummary tensorflow\n",
      "Could not find:  TFTransformerFFN tensorflow\n",
      "Could not find:  PositionLayer tensorflow\n",
      "Could not find:  TFXLMMainLayer tensorflow\n",
      "Could not find:  ProbabilityParameterEstimator tensorflow\n",
      "Could not find:  ConditionProjection tensorflow\n",
      "Could not find:  TFXLMPredLayer tensorflow\n",
      "Could not find:  TFXLNetRelativeAttention tensorflow\n",
      "Could not find:  TFXLNetFeedForward tensorflow\n",
      "Could not find:  TFXLNetLayer tensorflow\n",
      "Could not find:  TFXLNetLMHead tensorflow\n",
      "Could not find:  TFXLNetMainLayer tensorflow\n",
      "Could not find:  WarmUp tensorflow\n",
      "Could not find:  AdamWeightDecay tensorflow\n",
      "Could not find:  PostProcessing tensorflow\n",
      "Could not find:  TestCallback tensorflow\n",
      "Could not find:  EncoderTest tensorflow\n",
      "Could not find:  TFBertNSPHead tensorflow\n",
      "Could not find:  BridgeTest tensorflow\n",
      "Could not find:  AdafactorOptimizer tensorflow\n",
      "Could not find:  MultistepAdamOptimizer tensorflow\n",
      "Could not find:  ConfigTest tensorflow\n",
      "Could not find:  TokenizerTest tensorflow\n",
      "Could not find:  DataTest tensorflow\n",
      "Could not find:  DecoderTest tensorflow\n",
      "Could not find:  EvaluatorTest tensorflow\n",
      "Could not find:  HooksTest tensorflow\n",
      "Could not find:  InputterTest tensorflow\n",
      "Could not find:  OptimTest tensorflow\n",
      "Could not find:  PositionTest tensorflow\n",
      "Could not find:  ReducerTest tensorflow\n",
      "Could not find:  SequenceClassifierTest tensorflow\n",
      "Could not find:  SequenceTaggerTest tensorflow\n",
      "Could not find:  CustomizedAdamOptimizer tensorflow\n",
      "Could not find:  CapsLayerTest tensorflow\n",
      "Could not find:  LayersTest tensorflow\n",
      "Could not find:  LossTest tensorflow\n",
      "Could not find:  RoutingTest tensorflow\n",
      "Could not find:  SquashTest tensorflow\n",
      "Could not find:  CIFAR10InputTest tensorflow\n",
      "Could not find:  PartitionedMultiRNNCell tensorflow\n",
      "Could not find:  MomentumWOptimizer tensorflow\n",
      "Could not find:  AdamWOptimizer tensorflow\n",
      "Could not find:  LossHistory tensorflow\n",
      "Could not find:  DataLoader tensorflow\n",
      "Could not find:  UpConvBlock tensorflow\n",
      "Could not find:  SingleConvBlock tensorflow\n",
      "Could not find:  DoubleConvBlock tensorflow\n",
      "Could not find:  DexiNed tensorflow\n",
      "Could not find:  SequenceToSequenceTest tensorflow\n",
      "Could not find:  TransformerTest tensorflow\n",
      "Could not find:  TFBertMLMHead tensorflow\n",
      "Could not find:  TFAlbertSOPHead tensorflow\n",
      "Could not find:  ResUpdate tensorflow\n",
      "Could not find:  PiNet tensorflow\n",
      "Could not find:  TFAlbertEmbeddings tensorflow\n",
      "Could not find:  TFAlbertSelfAttention tensorflow\n",
      "Could not find:  TFAlbertSelfOutput tensorflow\n",
      "Could not find:  TFAlbertLayer tensorflow\n",
      "Could not find:  TFAlbertLayerGroup tensorflow\n",
      "Could not find:  TFAlbertTransformer tensorflow\n",
      "Could not find:  TFAlbertMLMHead tensorflow\n",
      "Could not find:  TFAlbertMainLayer tensorflow\n",
      "Could not find:  TFBertEmbeddings tensorflow\n",
      "Could not find:  VocabTest tensorflow\n",
      "Could not find:  TFBertSelfAttention tensorflow\n",
      "Could not find:  TFBertSelfOutput tensorflow\n",
      "Could not find:  TFBertAttention tensorflow\n",
      "Could not find:  TFBertIntermediate tensorflow\n",
      "Could not find:  TFBertOutput tensorflow\n",
      "Could not find:  TFBertLayer tensorflow\n",
      "Could not find:  TFBertEncoder tensorflow\n",
      "Could not find:  TFBertPooler tensorflow\n",
      "Could not find:  TFBertPredictionHeadTransform tensorflow\n",
      "Could not find:  TFBertLMPredictionHead tensorflow\n",
      "Could not find:  GCBlock tensorflow\n",
      "Could not find:  OutLayer tensorflow\n",
      "Could not find:  IPLayer tensorflow\n",
      "Could not find:  PILayer tensorflow\n",
      "Could not find:  LogParametersCountHook tensorflow\n",
      "Could not find:  CountersHook tensorflow\n",
      "Could not find:  LogPredictionTimeHook tensorflow\n",
      "Could not find:  SaveEvaluationPredictionHook tensorflow\n",
      "Could not find:  CellListNL tensorflow\n",
      "Could not find:  CutoffFunc tensorflow\n",
      "Could not find:  GaussianBasis tensorflow\n",
      "Could not find:  PolynomialBasis tensorflow\n",
      "Could not find:  AtomicOnehot tensorflow\n",
      "Could not find:  ANNOutput tensorflow\n",
      "Could not find:  BPSymmFunc tensorflow\n",
      "Could not find:  BPFingerprint tensorflow\n",
      "Could not find:  BPFeedForward tensorflow\n",
      "Could not find:  BPNN tensorflow\n",
      "Could not find:  LJ tensorflow\n",
      "Could not find:  FFLayer tensorflow\n",
      "Could not find:  Bottleneck torch\n",
      "Could not find:  ResNet torch\n",
      "Could not find:  BasicBlock torch\n",
      "Could not find:  Net torch\n",
      "Could not find:  BertEmbeddings torch\n",
      "Could not find:  BertPooler torch\n",
      "Could not find:  Attention torch\n",
      "Could not find:  Block torch\n",
      "Could not find:  BertPreTrainingHeads torch\n",
      "Could not find:  BertOnlyNSPHead torch\n",
      "Could not find:  BertOnlyMLMHead torch\n",
      "Could not find:  BertLMPredictionHead torch\n",
      "Could not find:  BertPredictionHeadTransform torch\n",
      "Could not find:  BertOutput torch\n",
      "Could not find:  BertIntermediate torch\n",
      "Could not find:  BertLayer torch\n",
      "Could not find:  BertSelfAttention torch\n",
      "Could not find:  BertEncoder torch\n",
      "Could not find:  BertSelfOutput torch\n",
      "Could not find:  BertAttention torch\n",
      "Could not find:  Decoder torch\n",
      "Could not find:  Encoder torch\n",
      "Could not find:  GCN torch\n",
      "Could not find:  AllReduce torch\n",
      "Could not find:  BertLayerNorm torch\n",
      "Could not find:  BertPreTrainedModel torch\n",
      "Could not find:  LocalizedSpatialTransformer torch\n",
      "Could not find:  LocalizedSpatialTransformerFn torch\n",
      "Could not find:  PINN torch\n",
      "Could not find:  LearnedTanh torch\n",
      "Could not find:  ResnetBlock torch\n",
      "Could not find:  GANLoss torch\n",
      "Could not find:  MLP torch\n",
      "Could not find:  HeadAttention torch\n",
      "Could not find:  SPADEResnetBlock torch\n",
      "Could not find:  SPADE torch\n",
      "Could not find:  Mask torch\n",
      "Could not find:  PruningMethod torch\n",
      "Could not find:  BaseDataset torch\n",
      "Could not find:  ModelNetDataset torch\n",
      "Could not find:  WeightedSmoothL1Loss torch\n",
      "Could not find:  Head torch\n",
      "Could not find:  RPN torch\n",
      "Could not find:  FocalLoss torch\n",
      "Could not find:  InPlaceABN torch\n",
      "Could not find:  CSDataTestSet torch\n",
      "Could not find:  ProGANDiscriminator torch\n",
      "Could not find:  ProGANGeneratorBlock torch\n",
      "Could not find:  Accuracy torch\n",
      "Could not find:  BaseActivation torch\n",
      "Could not find:  ProGANGenerator torch\n",
      "Could not find:  ModulatedDeformConv torch\n",
      "Could not find:  DeformConv torch\n",
      "Could not find:  SpMiddleResNetFHD torch\n",
      "Could not find:  SpMiddleFHDNobn torch\n",
      "Could not find:  ImgModel torch\n",
      "Could not find:  OhemCrossEntropy2d torch\n",
      "Could not find:  InPlaceABNSync torch\n",
      "Could not find:  DataParallelCriterion torch\n",
      "Could not find:  DataParallelModel torch\n",
      "Could not find:  ProGANDiscriminatorBlock torch\n",
      "Could not find:  CriterionOhemDSN torch\n",
      "Could not find:  CriterionDSN torch\n",
      "Could not find:  ASPPModule torch\n",
      "Could not find:  VGGLoss torch\n",
      "Could not find:  SpMiddleFHD torch\n",
      "Could not find:  VGG19 torch\n",
      "Could not find:  MultiHeadAttention torch\n",
      "Could not find:  BaseNetwork torch\n",
      "Could not find:  Reduce torch\n",
      "Could not find:  CondRCUBlock torch\n",
      "Could not find:  SegModel torch\n",
      "Could not find:  ConstantInput torch\n",
      "Could not find:  Blur torch\n",
      "Could not find:  DRN torch\n",
      "Could not find:  CondJoint torch\n",
      "Could not find:  EqualizedConv2d torch\n",
      "Could not find:  EqualizedLinear torch\n",
      "Could not find:  FusedUpsample torch\n",
      "Could not find:  FusedDownsample torch\n",
      "Could not find:  DiscreteImprovedWGANLoss torch\n",
      "Could not find:  GANSampler torch\n",
      "Could not find:  RegHead torch\n",
      "Could not find:  DNN torch\n",
      "Could not find:  Mclr torch\n",
      "Could not find:  MultiGroupHead torch\n",
      "Could not find:  NearestInterpolate torch\n",
      "Could not find:  BilinearInterpolate torch\n",
      "Could not find:  NoiseInjection torch\n",
      "Could not find:  AdaptiveInstanceNorm torch\n",
      "Could not find:  PixelNorm torch\n",
      "Could not find:  EncoderLayer torch\n",
      "Could not find:  Memory torch\n",
      "Could not find:  BlurFunction torch\n",
      "Could not find:  BlurFunctionBackward torch\n",
      "Could not find:  BaseDetector torch\n",
      "Could not find:  BertAdam torch\n",
      "Could not find:  RCNNSpMiddleFHD torch\n",
      "Could not find:  GroupedBatchSampler torch\n",
      "Could not find:  AssistedBlock torch\n",
      "Could not find:  InceptionV3 torch\n",
      "Could not find:  PyConvBlock torch\n",
      "Could not find:  CondMSFBlock torch\n",
      "Could not find:  MODEL torch\n",
      "Could not find:  G torch\n",
      "Could not find:  CondCRPBlock torch\n",
      "Could not find:  CRPBlock torch\n",
      "Could not find:  SigmoidFocalLoss torch\n",
      "Could not find:  ConditionalBatchNorm2d torch\n",
      "Could not find:  UNet256 torch\n",
      "Could not find:  ImageFolder torch\n",
      "Could not find:  NumDiffAutoGradFn torch\n",
      "Could not find:  D torch\n",
      "Could not find:  ResnetGenerator torch\n",
      "Could not find:  PixelDiscriminator torch\n",
      "Could not find:  ConvMeanPool torch\n",
      "Could not find:  CondRefineBlock torch\n",
      "Could not find:  FPN torch\n",
      "Could not find:  PyConv3 torch\n",
      "Could not find:  FCN torch\n",
      "Could not find:  SubstituteNet torch\n",
      "Could not find:  UNet torch\n",
      "Could not find:  SELayer torch\n",
      "Could not find:  MeanPoolConv torch\n",
      "Could not find:  FBNet torch\n",
      "Could not find:  PyConv4 torch\n",
      "Could not find:  PyConv2d torch\n",
      "Could not find:  PyConv2 torch\n",
      "Could not find:  ConditionalResidualBlock torch\n",
      "Could not find:  RetinaNetHead torch\n",
      "Could not find:  MyDataSet torch\n",
      "Could not find:  UpsampleConv torch\n",
      "Could not find:  NLayerDiscriminator torch\n",
      "Could not find:  ReformerOnlyLMHead torch\n",
      "Could not find:  ReformerEncoder torch\n",
      "Could not find:  ReformerLayer torch\n",
      "Could not find:  ChunkReformerFeedForward torch\n",
      "Could not find:  ReformerFeedForwardDense torch\n",
      "Could not find:  RobertaLMHead torch\n",
      "Could not find:  RobertaClassificationHead torch\n",
      "Could not find:  ReformerFeedForwardOutput torch\n",
      "Could not find:  ProjectedAdaptiveLogSoftmax torch\n",
      "Could not find:  PositionEmbeddings torch\n",
      "Could not find:  ReformerAttention torch\n",
      "Could not find:  ReformerSelfOutput torch\n",
      "Could not find:  TransformerBlock torch\n",
      "Could not find:  MultiHeadSelfAttention torch\n",
      "Could not find:  Embeddings torch\n",
      "Could not find:  LongformerSelfAttention torch\n",
      "Could not find:  ModalEmbeddings torch\n",
      "Could not find:  MMBTForClassification torch\n",
      "Could not find:  AxialPositionEmbeddings torch\n",
      "Could not find:  SinusoidalPositionalEmbedding torch\n",
      "Could not find:  LearnedPositionalEmbedding torch\n",
      "Could not find:  BartClassificationHead torch\n",
      "Could not find:  SelfAttention torch\n",
      "Could not find:  BartDecoder torch\n",
      "Could not find:  ReformerEmbeddings torch\n",
      "Could not find:  LSHSelfAttention torch\n",
      "Could not find:  DecoderLayer torch\n",
      "Could not find:  ReverseSort torch\n",
      "Could not find:  LocalSelfAttention torch\n",
      "Could not find:  FFN torch\n",
      "Could not find:  XLNetRelativeAttention torch\n",
      "Could not find:  BartEncoder torch\n",
      "Could not find:  GRNN torch\n",
      "Could not find:  AEC torch\n",
      "Could not find:  ClusteringLayer torch\n",
      "Could not find:  DEC torch\n",
      "Could not find:  SeismicDataset torch\n",
      "Could not find:  EstimatorNetwork torch\n",
      "Could not find:  AveragePolicyNetwork torch\n",
      "Could not find:  Baller2VecDataset torch\n",
      "Could not find:  QuantileNetworkModule torch\n",
      "Could not find:  Baller2VecSeq2Seq torch\n",
      "Could not find:  Baller2Vec torch\n",
      "Could not find:  SqErrNetworkModule torch\n",
      "Could not find:  QecSiaNet torch\n",
      "Could not find:  LineByLineTextDataset torch\n",
      "Could not find:  PyConvResNet torch\n",
      "Could not find:  ChaosLiverMR torch\n",
      "Could not find:  EncoderBlock torch\n",
      "Could not find:  DecoderBlock torch\n",
      "Could not find:  PyConvHGResNet torch\n",
      "Could not find:  PyConvBasicBlock1 torch\n",
      "Could not find:  PyConvBasicBlock2 torch\n",
      "Could not find:  ContentLoss torch\n",
      "Could not find:  QecNet torch\n",
      "Could not find:  GramMatrix torch\n",
      "Could not find:  StyleLoss torch\n",
      "Could not find:  BasicSymeig torch\n",
      "Could not find:  BatchSymeig torch\n",
      "Could not find:  GeneralizedSymeig torch\n",
      "Could not find:  QecModule torch\n",
      "Could not find:  AHNet torch\n",
      "Could not find:  PVP torch\n",
      "Could not find:  Pseudo3DLayer torch\n",
      "Could not find:  RelPartialLearnableDecoderLayer torch\n",
      "Could not find:  T5LayerSelfAttention torch\n",
      "Could not find:  T5LayerCrossAttention torch\n",
      "Could not find:  T5Block torch\n",
      "Could not find:  PositionalEmbedding torch\n",
      "Could not find:  PositionwiseFF torch\n",
      "Could not find:  RelPartialLearnableMultiHeadAttn torch\n",
      "Could not find:  AdaptiveEmbedding torch\n",
      "Could not find:  Final torch\n",
      "Could not find:  Conv1D torch\n",
      "Could not find:  XLNetFeedForward torch\n",
      "Could not find:  XLNetLayer torch\n",
      "Could not find:  BasicBlock3x3x1 torch\n",
      "Could not find:  GlueDataset torch\n",
      "Could not find:  TextDataset torch\n",
      "Could not find:  T5Attention torch\n",
      "Could not find:  T5LayerFF torch\n",
      "Could not find:  T5DenseReluDense torch\n",
      "Could not find:  T5LayerNorm torch\n",
      "Could not find:  ElectraClassificationHead torch\n",
      "Could not find:  ElectraGeneratorPredictions torch\n",
      "Could not find:  ElectraDiscriminatorPredictions torch\n",
      "Could not find:  AlbertSOPHead torch\n",
      "Could not find:  AlbertMLMHead torch\n",
      "Could not find:  AlbertTransformer torch\n",
      "Could not find:  AlbertLayerGroup torch\n",
      "Could not find:  AlbertLayer torch\n",
      "Could not find:  BasicBlock3x3x3 torch\n",
      "Could not find:  Bottleneck3x3x1 torch\n",
      "Could not find:  Projection torch\n",
      "Could not find:  DenseBlock torch\n",
      "Could not find:  UpTransition torch\n",
      "Could not find:  PreTrainedModel torch\n",
      "Could not find:  GeneratorPointer torch\n",
      "Could not find:  PoolerStartLogits torch\n",
      "Could not find:  DeepAttention torch\n",
      "Could not find:  Prenet torch\n",
      "Could not find:  LocationLayer torch\n",
      "Could not find:  Tacotron2Loss torch\n",
      "Could not find:  Tacotron2Logger torch\n",
      "Could not find:  TacotronSTFT torch\n",
      "Could not find:  ConvNorm torch\n",
      "Could not find:  LinearNorm torch\n",
      "Could not find:  TextMelLoader torch\n",
      "Could not find:  Detect torch\n",
      "Could not find:  L2Norm torch\n",
      "Could not find:  Tokenizer torch\n",
      "Could not find:  Tagger torch\n",
      "Could not find:  Parser torch\n",
      "Could not find:  LSTMAttention torch\n",
      "Could not find:  LinearAttention torch\n",
      "Could not find:  Tacotron2 torch\n",
      "Could not find:  SoftDotAttention torch\n",
      "Could not find:  BasicAttention torch\n",
      "Could not find:  Seq2SeqModel torch\n",
      "Could not find:  LSTMwRecDropout torch\n",
      "Could not find:  PackedLSTM torch\n",
      "Could not find:  MaxEntropySequenceLoss torch\n",
      "Could not find:  MixLoss torch\n",
      "Could not find:  HighwayLSTM torch\n",
      "Could not find:  WordDropout torch\n",
      "Could not find:  MultiBoxLoss torch\n",
      "Could not find:  CharacterModel torch\n",
      "Could not find:  DeepBiaffineScorer torch\n",
      "Could not find:  PairwiseBiaffineScorer torch\n",
      "Could not find:  BiaffineScorer torch\n",
      "Could not find:  Postnet torch\n",
      "Could not find:  STFT torch\n",
      "Could not find:  PoolerEndLogits torch\n",
      "Could not find:  ModelPool torch\n",
      "Could not find:  VLight torch\n",
      "Could not find:  InvBasicBlockPxsh torch\n",
      "Could not find:  InvBasicBlockBilinear torch\n",
      "Could not find:  DWBasicBlock torch\n",
      "Could not find:  OutConv torch\n",
      "Could not find:  Up torch\n",
      "Could not find:  Down torch\n",
      "Could not find:  DoubleConv torch\n",
      "Could not find:  RepeatDataset torch\n",
      "Could not find:  LeNet torch\n",
      "Could not find:  AdamNormGrad torch\n",
      "Could not find:  SpatialTransformer torch\n",
      "Could not find:  Saccader torch\n",
      "Could not find:  RelationalNetwork torch\n",
      "Could not find:  NumericalDifferentiator torch\n",
      "Could not find:  Actor torch\n",
      "Could not find:  VOCDetection torch\n",
      "Could not find:  ImageStateProjector torch\n",
      "Could not find:  MultiBatchModule torch\n",
      "Could not find:  BasicDropoutBlock torch\n",
      "Could not find:  BWtoRGB torch\n",
      "Could not find:  DropoutBottleneck torch\n",
      "Could not find:  MulticlassBCELoss2d torch\n",
      "Could not find:  MulticlassBCELoss torch\n",
      "Could not find:  SoftDiceLoss torch\n",
      "Could not find:  BCELoss2d torch\n",
      "Could not find:  CrossEntropyLoss2d torch\n",
      "Could not find:  ImageLoader torch\n",
      "Could not find:  TwinCritic torch\n",
      "Could not find:  Critic torch\n",
      "Could not find:  PairwiseBilinear torch\n",
      "Could not find:  Stage torch\n",
      "Could not find:  GAT torch\n",
      "Could not find:  EncoderDecoderModel torch\n",
      "Could not find:  StateTransition torch\n",
      "Could not find:  RNNEmbeddings torch\n",
      "Could not find:  DualLearning torch\n",
      "Could not find:  RNNDecoderPointer torch\n",
      "Could not find:  RNNDecoder torch\n",
      "Could not find:  Tail torch\n",
      "Could not find:  ImageSuperResolutionDataset torch\n",
      "Could not find:  Refine torch\n",
      "Could not find:  V torch\n",
      "Could not find:  H torch\n",
      "Could not find:  Q torch\n",
      "Could not find:  GatedTrans torch\n",
      "Could not find:  DynamicRNN torch\n",
      "Could not find:  RvAEncoder torch\n",
      "Could not find:  GraphAttentionLayer torch\n",
      "Could not find:  RvA torch\n",
      "Could not find:  INFER torch\n",
      "Could not find:  PAIR torch\n",
      "Could not find:  ATT torch\n",
      "Could not find:  LateFusionEncoder torch\n",
      "Could not find:  GenerativeDecoder torch\n",
      "Could not find:  DiscriminativeDecoder torch\n",
      "Could not find:  VisDialDataset torch\n",
      "Could not find:  SequentialDistributedSampler torch\n",
      "Could not find:  XLMPredLayer torch\n",
      "Could not find:  TransformerFFN torch\n",
      "Could not find:  SequenceSummary torch\n",
      "Could not find:  SQuADHead torch\n",
      "Could not find:  PoolerAnswerClass torch\n",
      "Could not find:  RNNEncoder torch\n",
      "Could not find:  EncoderDecoder torch\n",
      "Could not find:  DWConv torch\n",
      "Could not find:  LanguageModel torch\n",
      "Could not find:  AVADataset torch\n",
      "Could not find:  DataParallelWithCallback torch\n",
      "Could not find:  Segmentor torch\n",
      "Could not find:  PSPModule torch\n",
      "Could not find:  ResNetMulti torch\n",
      "Could not find:  ClassifierModule torch\n",
      "Could not find:  StableBCELoss torch\n",
      "Could not find:  CriterionOhemDSN2 torch\n",
      "Could not find:  SegImgModel torch\n",
      "Could not find:  UpFirDn2d torch\n",
      "Could not find:  UpFirDn2dBackward torch\n",
      "Could not find:  FusedLeakyReLU torch\n",
      "Could not find:  FusedLeakyReLUFunction torch\n",
      "Could not find:  FusedLeakyReLUFunctionBackward torch\n",
      "Could not find:  CondMask torch\n",
      "Could not find:  Alpha torch\n",
      "Could not find:  StyleGANGeneratorBlock torch\n",
      "Could not find:  StyleGANGenerator torch\n",
      "Could not find:  ACE torch\n",
      "Could not find:  Zencoder torch\n",
      "Could not find:  SSD torch\n",
      "Could not find:  KLDLoss torch\n",
      "Could not find:  DepthConv torch\n",
      "Could not find:  SAE torch\n",
      "Could not find:  DepthsepCCBlock torch\n",
      "Could not find:  SyntheticDataset torch\n",
      "Could not find:  SemiSyntheticDataset torch\n",
      "Could not find:  MyAdam torch\n",
      "Could not find:  MyNLLLoss torch\n",
      "Could not find:  PolypDataset torch\n",
      "Could not find:  VFELayer torch\n",
      "Could not find:  PyramidVisionTransformerImpr torch\n",
      "Could not find:  LianjiaAffiliationDataset torch\n",
      "Could not find:  CIFARDataset torch\n",
      "Could not find:  MNIST torch\n",
      "Could not find:  CifarModel torch\n",
      "Could not find:  MNISTModel torch\n",
      "Could not find:  MySGD torch\n",
      "Could not find:  FEDLOptimizer torch\n",
      "Could not find:  LianjiaCornerDataset torch\n",
      "Could not find:  ContentAddressing torch\n",
      "Could not find:  LianjiaRoomDataset torch\n",
      "Could not find:  CornerNet torch\n",
      "Could not find:  CornerEdgeNet torch\n",
      "Could not find:  CornerRoomAssociate torch\n",
      "Could not find:  CornerCornerAssociate torch\n",
      "Could not find:  ResidualModule torch\n",
      "Could not find:  ClozeModel torch\n",
      "Could not find:  SimplifiedDNC torch\n",
      "Could not find:  DeformConvFunction torch\n",
      "Could not find:  CoFusion torch\n",
      "Could not find:  DeformRoIPoolingFunction torch\n",
      "Could not find:  DeformRoIPooling torch\n",
      "Could not find:  BalancedL1Loss torch\n",
      "Could not find:  TestDataset torch\n",
      "Could not find:  BipedDataset torch\n",
      "Could not find:  UpConvBlock torch\n",
      "Could not find:  WOZDataSet torch\n",
      "Could not find:  SingleConvBlock torch\n",
      "Could not find:  DoubleConvBlock torch\n",
      "Could not find:  DexiNed torch\n",
      "Could not find:  DecoderRNN torch\n",
      "Could not find:  EncoderRNN torch\n",
      "Could not find:  Model torch\n",
      "Could not find:  ResidualBlock torch\n",
      "Could not find:  SamePad2d torch\n",
      "Could not find:  TopDownLayer torch\n",
      "Could not find:  PointCloudDataset torch\n",
      "Could not find:  GroupSampler torch\n",
      "Could not find:  InterDiscriminator torch\n",
      "Could not find:  LogReg torch\n",
      "Could not find:  ClassBalancedSampler torch\n",
      "Could not find:  DistributedSamplerV2 torch\n",
      "Could not find:  Gate torch\n",
      "Could not find:  Classifier torch\n",
      "Could not find:  DoubleGate torch\n",
      "Could not find:  Normalization torch\n",
      "Could not find:  SimpleNormalization torch\n",
      "Could not find:  Dense torch\n",
      "Could not find:  ConvNd torch\n",
      "Could not find:  Convolution torch\n",
      "Could not find:  DistributedGroupSampler torch\n",
      "Could not find:  GNN torch\n",
      "Could not find:  TextSamplerDataset torch\n",
      "Could not find:  SpatialGatingUnit torch\n",
      "Could not find:  PreNorm torch\n",
      "Could not find:  PreShiftTokens torch\n",
      "Could not find:  Residual torch\n",
      "Could not find:  AutoregressiveWrapper torch\n",
      "Could not find:  RoIAlign torch\n",
      "Could not find:  CropAndResize torch\n",
      "Could not find:  CropAndResizeFunction torch\n",
      "Could not find:  MaskRCNN torch\n",
      "Could not find:  Relation torch\n",
      "Could not find:  Orientation torch\n",
      "Could not find:  ModulatedDeformConvFunction torch\n",
      "Could not find:  SoftHistogram torch\n",
      "Could not find:  TransposedConvolution torch\n",
      "Could not find:  ThreeInterpolate torch\n",
      "Could not find:  PointnetFPModule torch\n",
      "Could not find:  PointnetLFPModuleMSG torch\n",
      "Could not find:  RandomDropout torch\n",
      "Could not find:  FurthestPointSampling torch\n",
      "Could not find:  GatherOperation torch\n",
      "Could not find:  ThreeNN torch\n",
      "Could not find:  GroupingOperation torch\n",
      "Could not find:  PointnetSAModuleVotes torch\n",
      "Could not find:  BallQuery torch\n",
      "Could not find:  QueryAndGroup torch\n",
      "Could not find:  GroupAll torch\n",
      "Could not find:  SharedMLP torch\n",
      "Could not find:  FC torch\n",
      "Could not find:  RoIFunction torch\n",
      "Could not find:  PointnetSAModuleMSGVotes torch\n",
      "Could not find:  Correlation torch\n",
      "Could not find:  IdentityResidualBlock torch\n",
      "Could not find:  Empty torch\n",
      "Could not find:  VoxelFeatureExtractorV2 torch\n",
      "Could not find:  VFEV3 torch\n",
      "Could not find:  VoxelFeatureExtractorV3 torch\n",
      "Could not find:  SimpleVoxel torch\n",
      "Could not find:  ConvModule torch\n",
      "Could not find:  ConvWS2d torch\n",
      "Could not find:  PointPillarsScatter torch\n",
      "Could not find:  CorrelationFunction torch\n",
      "Could not find:  NaiveSyncBatchNorm torch\n",
      "Could not find:  Scale torch\n",
      "Could not find:  Align torch\n",
      "Could not find:  AlignFeatureFunction torch\n",
      "Could not find:  AlignFeature torch\n",
      "Could not find:  RotateRoIAlign torch\n",
      "Could not find:  SigmoidFocalLossFunction torch\n",
      "Could not find:  DistributedSyncBNFucntion torch\n",
      "Could not find:  VOCDataSet torch\n",
      "Could not find:  Class torch\n",
      "Could not find:  BaseHead torch\n",
      "Could not find:  WeightedSoftmaxClassificationLoss torch\n",
      "Could not find:  DirectTemporalNeRF torch\n",
      "Could not find:  NeRFOriginal torch\n",
      "Could not find:  IoULoss torch\n",
      "Could not find:  VOCDataTestSet torch\n",
      "Could not find:  AlexNet torch\n",
      "Could not find:  CSDataSet torch\n",
      "Could not find:  ABN torch\n",
      "Could not find:  InPlaceABNWrapper torch\n",
      "Could not find:  InPlaceABNSyncWrapper torch\n",
      "Could not find:  DenseModule torch\n",
      "Could not find:  GlobalAvgPool2d torch\n",
      "Could not find:  MixedOp torch\n",
      "Could not find:  ResNetBottleneck torch\n",
      "Could not find:  ResNetBasicBlock torch\n",
      "Could not find:  Shufv2Unit torch\n",
      "Could not find:  Scalar torch\n",
      "Could not find:  PyTorchLogReg torch\n",
      "Could not find:  Precision torch\n",
      "Could not find:  Recall torch\n",
      "Could not find:  PrecisionRecall torch\n",
      "Could not find:  PointModule torch\n",
      "Could not find:  MegDistributedDataParallel torch\n",
      "Could not find:  MegDataParallel torch\n",
      "Could not find:  VGG torch\n",
      "Could not find:  SSFA torch\n",
      "Could not find:  PFNLayer torch\n",
      "Could not find:  PillarFeatureNet torch\n",
      "Could not find:  ConvTransposeNd torch\n",
      "Could not find:  BasicReadout torch\n",
      "Could not find:  OverlapPatchEmbed torch\n",
      "Could not find:  PanopticFPN torch\n",
      "Could not find:  RotatedAnchorGenerator torch\n",
      "Could not find:  Backbone torch\n",
      "Could not find:  LastLevelMaxPool torch\n",
      "Could not find:  LastLevelP6P7 torch\n",
      "Could not find:  ResNetBlockBase torch\n",
      "Could not find:  BasicStem torch\n",
      "Could not find:  GeneralizedRCNN torch\n",
      "Could not find:  BufferList torch\n",
      "Could not find:  ProposalNetwork torch\n",
      "Could not find:  RetinaNet torch\n",
      "Could not find:  RetinaNetNoisy torch\n",
      "Could not find:  SemanticSegmentor torch\n",
      "Could not find:  SemSegFPNHead torch\n",
      "Could not find:  ROIPooler torch\n",
      "Could not find:  DefaultAnchorGenerator torch\n",
      "Could not find:  ROIAlignRotated torch\n",
      "Could not find:  SubsetSampler torch\n",
      "Could not find:  TrainingSampler torch\n",
      "Could not find:  NTM torch\n",
      "Could not find:  BinaySeqDataset torch\n",
      "Could not find:  DGLGraphDataLoader torch\n",
      "Could not find:  MapDataset torch\n",
      "Could not find:  DatasetFromList torch\n",
      "Could not find:  AspectRatioGroupedDataset torch\n",
      "Could not find:  RepeatFactorTrainingSampler torch\n",
      "Could not find:  ROIAlign torch\n",
      "Could not find:  InferenceSampler torch\n",
      "Could not find:  Caffe2Model torch\n",
      "Could not find:  ProtobufModel torch\n",
      "Could not find:  ProtobufDetectionModel torch\n",
      "Could not find:  Caffe2MetaArch torch\n",
      "Could not find:  FrozenBatchNorm2d torch\n",
      "Could not find:  StandardRPNHead torch\n",
      "Could not find:  FastRCNNConvFCHead torch\n",
      "Could not find:  FastRCNNOutputLayers torch\n",
      "Could not find:  HoiClassifier torch\n",
      "Could not find:  ScatterVerbsToHois torch\n",
      "Could not find:  VerbGivenBoxesAndObjectLabel torch\n",
      "Could not find:  VerbGivenHumanPose torch\n",
      "Could not find:  VerbGivenObjectAppearance torch\n",
      "Could not find:  DGLGraphDataset torch\n",
      "Could not find:  BasicConv2d torch\n",
      "Could not find:  BaseKeypointRCNNHead torch\n",
      "Could not find:  CFM torch\n",
      "Could not find:  SAM torch\n",
      "Could not find:  ChannelAttention torch\n",
      "Could not find:  SpatialAttention torch\n",
      "Could not find:  PolypPVT torch\n",
      "Could not find:  Mlp torch\n",
      "Could not find:  Features torch\n",
      "Could not find:  TridentConv torch\n",
      "Could not find:  SwapAlign2Nat torch\n",
      "Could not find:  TensorMaskHead torch\n",
      "Could not find:  TensorMask torch\n",
      "Could not find:  StandardPointHead torch\n",
      "Could not find:  CoarseMaskHead torch\n",
      "Could not find:  DensePosePredictor torch\n",
      "Could not find:  DensePoseV1ConvXHead torch\n",
      "Could not find:  ASPP torch\n",
      "Could not find:  VoxelFeatureExtractor torch\n",
      "Could not find:  ASPPConv torch\n",
      "Could not find:  DensePoseDeepLabHead torch\n",
      "Could not find:  WrapModel torch\n",
      "Could not find:  GeneralizedRCNNWithTTA torch\n",
      "Could not find:  ROIHeads torch\n",
      "Could not find:  BaseMaskRCNNHead torch\n",
      "Could not find:  Controller torch\n",
      "Could not find:  PostProcess torch\n",
      "Could not find:  DirectIntrinsicsSN torch\n",
      "Could not find:  MobileNetV2 torch\n",
      "Could not find:  SSE torch\n",
      "Could not find:  ImageNet32Dataset torch\n",
      "Could not find:  Multiception torch\n",
      "Could not find:  MixConv torch\n",
      "Could not find:  ConvBNReLU torch\n",
      "Could not find:  InvertedResidual torch\n",
      "Could not find:  CifarSEBasicBlock torch\n",
      "Could not find:  BayesRNN torch\n",
      "Could not find:  CifarSEResNet torch\n",
      "Could not find:  ShakeBlock torch\n",
      "Could not find:  ShakeResNet torch\n",
      "Could not find:  ShakeShake torch\n",
      "Could not find:  Shortcut torch\n",
      "Could not find:  ImplicitGraph torch\n",
      "Could not find:  VAELoss torch\n",
      "Could not find:  ZincDataset torch\n",
      "Could not find:  Loss torch\n",
      "Could not find:  LettuceDataset torch\n",
      "Could not find:  OlivettiFaces torch\n",
      "Could not find:  MPNNLayer torch\n",
      "Could not find:  RNNModel torch\n",
      "Could not find:  AttnMPNN torch\n",
      "Could not find:  LeMoNADe torch\n",
      "Could not find:  VideoDataset torch\n",
      "Could not find:  DictIndexDataset torch\n",
      "Could not find:  SSELayer torch\n",
      "Could not find:  FlattenLayer torch\n",
      "Could not find:  LioDataset torch\n",
      "Could not find:  IndexDataset torch\n",
      "Could not find:  InfiniteSampler torch\n",
      "Could not find:  StackGNN torch\n",
      "Could not find:  ImplicitFunction torch\n",
      "Could not find:  JointpostGenerator torch\n",
      "Could not find:  ContextGenerator torch\n",
      "Could not find:  UNetScore torch\n",
      "Could not find:  RefineNetDilated torch\n",
      "Could not find:  ConvResBlock torch\n",
      "Could not find:  DeconvResBlock torch\n",
      "Could not find:  ResScore torch\n",
      "Could not find:  ResNetScore torch\n",
      "Could not find:  UNetResScore torch\n",
      "Could not find:  ResEnergy torch\n",
      "Could not find:  IGNN torch\n",
      "Could not find:  MLPScore torch\n",
      "Could not find:  LargeScore torch\n",
      "Could not find:  Score torch\n",
      "Could not find:  SmallScore torch\n",
      "Could not find:  NightDataSet torch\n",
      "Could not find:  SSD640 torch\n",
      "Could not find:  InstanceNorm2dPlus torch\n",
      "Could not find:  UnetSkipConnectionBlock torch\n",
      "Could not find:  UnetSkipConnectionBlockWithResNet torch\n",
      "Could not find:  UnetGenerator torch\n",
      "Could not find:  Gaussian4SVI torch\n",
      "Could not find:  Gaussian torch\n",
      "Could not find:  GMM torch\n",
      "Could not find:  CondRefineNetDeeperDilated torch\n",
      "Could not find:  CondRefineNetDilated torch\n",
      "Could not find:  ConditionalInstanceNorm2dPlus torch\n",
      "Could not find:  ConditionalInstanceNorm2d torch\n",
      "Could not find:  VisionDataset torch\n",
      "Could not find:  CGS torch\n",
      "Could not find:  GraphTaskCGS torch\n",
      "Could not find:  FixedPointLayer torch\n",
      "Could not find:  STN torch\n",
      "Could not find:  ASPPPooling torch\n",
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "             Class &  Count &  \\#HP &  AvgOptionsUsed &           Most Used HP \\\\\n",
      "\\midrule\n",
      "    StandardScaler &     44 &    3 &            0.20 &                default \\\\\n",
      "LogisticRegression &     40 &   15 &            1.12 &                default \\\\\n",
      "            KMeans &     30 &    9 &            2.30 &             n\\_clusters \\\\\n",
      "      MinMaxScaler &     25 &    3 &            0.52 & feature\\_range, default \\\\\n",
      "          Pipeline &     21 &    3 &            1.00 &                  steps \\\\\n",
      "      LabelEncoder &     17 &    0 &            0.00 &                default \\\\\n",
      "  LinearRegression &     13 &    5 &            0.08 &                default \\\\\n",
      "               PCA &     12 &    9 &            1.00 &           n\\_components \\\\\n",
      "     OneHotEncoder &     11 &    7 &            0.73 &   categorical\\_features \\\\\n",
      "             KFold &     10 &    3 &            2.50 &               n\\_splits \\\\\n",
      "            DEFINE &    524 &    9 &            3.00 &    name, default, help \\\\\n",
      "          Variable &    384 &   12 &            2.44 &          initial\\_value \\\\\n",
      "           Session &    312 &    3 &            0.54 &                default \\\\\n",
      "             Dense &    271 &   11 &            2.69 &                  units \\\\\n",
      "             Input &    233 &    9 &            1.38 &                  shape \\\\\n",
      "             Model &    205 &    2 &            1.89 &        inputs, outputs \\\\\n",
      "            Conv2D &    190 &   17 &            4.74 &   filters, kernel\\_size \\\\\n",
      "             Saver &    163 &   15 &            0.61 &                default \\\\\n",
      "           Dropout &    161 &    4 &            1.02 &                   rate \\\\\n",
      "       ConfigProto &    146 &   17 &            0.73 &                default \\\\\n",
      "            Conv2d &   2125 &   11 &            4.86 &            in\\_channels \\\\\n",
      "            Linear &   2097 &    5 &            2.17 &            in\\_features \\\\\n",
      "        Sequential &   1658 &    1 &            0.92 &                  *args \\\\\n",
      "              ReLU &   1454 &    1 &            0.64 &                inplace \\\\\n",
      "        DataLoader &    888 &   15 &            4.04 &                dataset \\\\\n",
      "       BatchNorm2d &    868 &    7 &            1.29 &           num\\_features \\\\\n",
      "        ModuleList &    750 &    1 &            0.43 &                default \\\\\n",
      "         Parameter &    600 &    2 &            1.19 &                   data \\\\\n",
      "           Dropout &    489 &    2 &            0.99 &                      p \\\\\n",
      "  CrossEntropyLoss &    369 &    6 &            0.37 &                default \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_library_classes(library_name: str, library_dir: str, project_dir: str) -> pd.DataFrame:\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "\n",
    "    # Get Most used Class\n",
    "    classes = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, _ in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name = key.split(\"_\")[0]\n",
    "                                classes.append(class_name)\n",
    "\n",
    "    class_data = Counter(classes)\n",
    "    df_classes = pd.DataFrame.from_dict(class_data, orient=\"index\").reset_index()\n",
    "    df_classes = df_classes.rename(columns={'index':'Class', 0:'Count'})\n",
    "    df_classes = df_classes.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "    # Get Number of API Options\n",
    "    class_options = []\n",
    "    classes = df_classes[\"Class\"].to_list()\n",
    "\n",
    "    for ml_class in classes:\n",
    "        try:\n",
    "            class_data = next(filter(lambda x: x[\"name\"] == ml_class, library_data))\n",
    "            class_options.append(len(class_data[\"params\"]))\n",
    "        except StopIteration:\n",
    "            print(\"Could not find: \", ml_class, library_name)\n",
    "            class_options.append(0)\n",
    "            continue\n",
    "\n",
    "    df_classes[\"#HP\"] = class_options\n",
    "\n",
    "    # Compute average number of options used per class and most used option\n",
    "    avg_class_options = []\n",
    "    most_used_class_option = []\n",
    "\n",
    "    for ml_class in classes:\n",
    "        avg_class_options_used = []\n",
    "        class_options = []\n",
    "        for project in glob.glob(project_dir):\n",
    "            with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                project_data = json.load(project_file)\n",
    "\n",
    "                for file in project_data.keys():\n",
    "                    file_data = project_data[file]\n",
    "                    for library in file_data.keys():\n",
    "                        if library == library_name:\n",
    "                            module_data = file_data[library]\n",
    "                            for module_name, data in module_data.items():\n",
    "                                if module_name[0].isupper():\n",
    "                                    name = module_name.split(\"_\")[0]\n",
    "                                    if ml_class == name:\n",
    "                                        counter = 0\n",
    "                                        for param in data.keys():\n",
    "                                            if param == \"variable\":\n",
    "                                                continue\n",
    "\n",
    "                                            if  param not in (\"variable\", \"params\", \"class\"):\n",
    "                                                counter += 1\n",
    "\n",
    "                                            if param == \"params\":\n",
    "                                                class_options.append(\"default\")\n",
    "                                            else:\n",
    "                                                class_options.append(param)\n",
    "            \n",
    "                                        avg_class_options_used.append(counter)\n",
    "                                \n",
    "        avg_class_options.append(round((sum(avg_class_options_used) / len(avg_class_options_used)),2))\n",
    "        class_option_data = Counter(class_options)\n",
    "        try:\n",
    "            most_common_number = class_option_data.most_common(1)[0][1]\n",
    "            options = [elem[0] for elem in class_option_data.most_common() if elem[1] == most_common_number]\n",
    "            option_str = \", \".join(options)\n",
    "            most_used_class_option.append(option_str)\n",
    "        except IndexError:\n",
    "            most_used_class_option.append(\"None\")\n",
    "\n",
    "    df_classes[\"AvgOptionsUsed\"] = avg_class_options\n",
    "    df_classes[\"Most Used HP\"] = most_used_class_option\n",
    "    \n",
    "    return df_classes\n",
    "\n",
    "\n",
    "df_sklearn_classes = get_library_classes(\"sklearn\", \"modules/sklearn_default_values.json\" , \"statistics/*\")\n",
    "df_sklearn_classes = df_sklearn_classes[:10]\n",
    "df_tf_classes = get_library_classes(\"tensorflow\", \"modules/tensorflow_default_values.json\" , \"statistics/*\")\n",
    "df_tf_classes = df_tf_classes[:10]\n",
    "df_pytorch_classes = get_library_classes(\"torch\", \"modules/torch_default_values.json\" , \"statistics/*\")\n",
    "df_pytorch_classes = df_pytorch_classes[:10]\n",
    "df_all_classes = pd.concat([df_sklearn_classes, df_tf_classes, df_pytorch_classes])\n",
    "\n",
    "df_to_latex(df=df_all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find:  detection torch\n",
      "Could not find:  modeler torch\n",
      "Could not find:  depthwise_conv torch\n",
      "Could not find:  gMLPVision torch\n",
      "Could not find:  shufv2DownsampleUnit torch\n",
      "Could not find:  pz_BasicUnit torch\n",
      "Could not find:  pz_DownsampleUnit torch\n",
      "Could not find:  timenet torch\n",
      "Could not find:  pFedMeOptimizer torch\n",
      "Could not find:  gMLPBlock torch\n",
      "Could not find:  gMLP torch\n",
      "Could not find:  depthwise_separable_conv torch\n",
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "             Method &  Count &  \\#Args &  AvgArgsUsed &          Most Used Args \\\\\n",
      "\\midrule\n",
      "   train\\_test\\_split &    143 &      6 &         3.68 &               *arrays\\_0 \\\\\n",
      "   confusion\\_matrix &     68 &      5 &         2.10 &          y\\_true, y\\_pred \\\\\n",
      "           f1\\_score &     68 &      7 &         2.79 &          y\\_true, y\\_pred \\\\\n",
      " mean\\_squared\\_error &     65 &      5 &         2.51 &          y\\_true, y\\_pred \\\\\n",
      " load\\_breast\\_cancer &     43 &      2 &         0.51 &                 default \\\\\n",
      "      roc\\_auc\\_score &     41 &      7 &         2.22 &         y\\_true, y\\_score \\\\\n",
      "        check\\_array &     41 &     13 &         4.66 & array, force\\_all\\_finite \\\\\n",
      "mean\\_absolute\\_error &     39 &      4 &         2.05 &          y\\_true, y\\_pred \\\\\n",
      "          load\\_iris &     28 &      2 &         1.21 &              return\\_X\\_y \\\\\n",
      "     accuracy\\_score &     26 &      4 &         2.04 &          y\\_true, y\\_pred \\\\\n",
      "            reshape &   1491 &      3 &         2.01 &           tensor, shape \\\\\n",
      "     variable\\_scope &   1314 &     13 &         1.30 &           name\\_or\\_scope \\\\\n",
      "               cast &   1052 &      3 &         2.00 &                x, dtype \\\\\n",
      "         reduce\\_sum &    750 &      4 &         1.79 &            input\\_tensor \\\\\n",
      "        placeholder &    707 &      3 &         2.36 &                   dtype \\\\\n",
      "             concat &    701 &      3 &         2.03 &                  values \\\\\n",
      "              shape &    694 &      3 &         1.00 &                   input \\\\\n",
      "           constant &    620 &      4 &         1.75 &                   value \\\\\n",
      "        expand\\_dims &    560 &      3 &         2.00 &                   input \\\\\n",
      "          transpose &    501 &      4 &         1.81 &                       a \\\\\n",
      "                cat &   3067 &      3 &         1.82 &                 tensors \\\\\n",
      "             tensor &   1501 &      5 &         1.70 &                    data \\\\\n",
      "         from\\_numpy &   1473 &      1 &         1.00 &                 ndarray \\\\\n",
      "              zeros &   1411 &      6 &         2.11 &                   *size \\\\\n",
      "                sum &   1078 &      2 &         1.54 &                   input \\\\\n",
      "            no\\_grad &   1016 &      0 &         0.00 &                 default \\\\\n",
      "               load &    908 &      4 &         1.30 &                       f \\\\\n",
      "               save &    776 &      5 &         2.00 &                     obj \\\\\n",
      "              stack &    745 &      3 &         1.64 &                 tensors \\\\\n",
      "       is\\_available &    729 &      0 &         0.00 &                 default \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_library_methods(library_name: str, library_dir: str, project_dir: str) -> pd.DataFrame:\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "\n",
    "    methods = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, _ in module_data.items():\n",
    "                            if key[0].islower():\n",
    "                                method_name_parts = key.split(\"_\")[:-1]\n",
    "                                method_name = \"_\".join(method_name_parts)\n",
    "                                #for item in library_data:\n",
    "                                #    if item[\"name\"] == method_name:\n",
    "                                methods.append(method_name)\n",
    "\n",
    "    method_data = Counter(methods)\n",
    "    df_methods = pd.DataFrame.from_dict(method_data, orient=\"index\").reset_index()\n",
    "    df_methods = df_methods.rename(columns={'index':'Method', 0:'Count'})\n",
    "    df_methods = df_methods.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "    # Compute number of args that can be set regarding the API data\n",
    "    method_options = []\n",
    "    methods = df_methods[\"Method\"].to_list()\n",
    "\n",
    "    for method in methods:\n",
    "        try:\n",
    "            method_data = next(filter(lambda x: x[\"name\"] == method, library_data))\n",
    "            method_options.append(len(method_data[\"params\"]))\n",
    "        except StopIteration:\n",
    "            print(\"Could not find: \", method, library_name)\n",
    "            method_options.append(0)\n",
    "            continue\n",
    "\n",
    "    df_methods[\"#Args\"] = method_options\n",
    "\n",
    "    # Compute average number of args used per method\n",
    "    avg_method_args = []\n",
    "    most_used_method_args = []\n",
    "\n",
    "    for method in methods:\n",
    "        avg_method_args_used = []\n",
    "        method_args = []\n",
    "        for project in glob.glob(project_dir):\n",
    "            with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                project_data = json.load(project_file)\n",
    "\n",
    "                for file in project_data.keys():\n",
    "                    file_data = project_data[file]\n",
    "                    for library in file_data.keys():\n",
    "                        if library == library_name:\n",
    "                            module_data = file_data[library]\n",
    "                            for module_name, data in module_data.items():\n",
    "                                if module_name[0].islower():\n",
    "                                    method_name_parts = module_name.split(\"_\")[:-1]\n",
    "                                    method_name = \"_\".join(method_name_parts)\n",
    "                                    if method == method_name:\n",
    "                                        counter = 0\n",
    "                                        for arg in data.keys():\n",
    "                                            if arg == \"variable\":\n",
    "                                                continue\n",
    "\n",
    "                                            if arg not in (\"variable\", \"params\", \"class\"):\n",
    "                                                counter += 1\n",
    "\n",
    "                                            if arg == \"params\":\n",
    "                                                method_args.append(\"default\")\n",
    "                                            else:\n",
    "                                                method_args.append(arg)\n",
    "                                        \n",
    "                                        avg_method_args_used.append(counter)\n",
    "                                \n",
    "        avg_method_args.append(round((sum(avg_method_args_used) / len(avg_method_args_used)),2))\n",
    "        method_arg_data = Counter(method_args)\n",
    "        try:\n",
    "            most_common_num = method_arg_data.most_common(1)[0][1]\n",
    "            args = [x[0] for x in method_arg_data.most_common() if x[1] == most_common_num]\n",
    "            arg_str = \", \".join(args)\n",
    "            most_used_method_args.append(arg_str)\n",
    "        except IndexError:\n",
    "            most_used_method_args.append(\"None\")\n",
    "\n",
    "    df_methods[\"AvgArgsUsed\"] = avg_method_args\n",
    "    df_methods[\"Most Used Args\"] = most_used_method_args\n",
    "\n",
    "    return df_methods\n",
    "\n",
    "df_sklearn_methods = get_library_methods(\"sklearn\", \"modules/sklearn_default_values.json\", \"statistics/*\")\n",
    "df_sklearn_methods = df_sklearn_methods[:10]\n",
    "df_tf_methods = get_library_methods(\"tensorflow\", \"modules/tensorflow_default_values.json\", \"statistics/*\")\n",
    "df_tf_methods = df_tf_methods[:10]\n",
    "df_torch_methods = get_library_methods(\"torch\", \"modules/torch_default_values.json\", \"statistics/*\")\n",
    "df_torch_methods = df_torch_methods[:10]\n",
    "df_all_methods = pd.concat([df_sklearn_methods, df_tf_methods, df_torch_methods])\n",
    "\n",
    "df_to_latex(df=df_all_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "ML Library &  API Class Count &  Project Class Count \\\\\n",
      "\\midrule\n",
      "   sklearn &              262 &                   81 \\\\\n",
      "tensorflow &             2273 &                  192 \\\\\n",
      "     torch &              384 &                  144 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_api_and_project_classes(library_names: List, library_data_dirs: List, project_dir: str):\n",
    "    api_class_count = []\n",
    "    project_class_count = []\n",
    "\n",
    "    for library_data_dir in library_data_dirs:\n",
    "        class_counter = 0\n",
    "        with open(library_data_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "            library_data = json.load(library_file)\n",
    "\n",
    "        for module in library_data:\n",
    "            if module[\"name\"][0].isupper():\n",
    "                class_counter += 1\n",
    "\n",
    "        api_class_count.append(class_counter)\n",
    "\n",
    "\n",
    "    for library_name in library_names:\n",
    "        class_counter = 0\n",
    "        classes_visited = []\n",
    "        for project in glob.glob(project_dir):\n",
    "            with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                project_data = json.load(project_file)\n",
    "\n",
    "                for file in project_data.keys():\n",
    "                    file_data = project_data[file]\n",
    "                    for library in file_data.keys():\n",
    "                        if library == library_name:\n",
    "                            module_data = file_data[library]\n",
    "                            for key, value in module_data.items():\n",
    "                                if key[0].isupper():\n",
    "                                    class_name = key.split(\"_\")[0]\n",
    "                                    if \"base_class_0\" in value:\n",
    "                                        continue\n",
    "                                    if class_name not in classes_visited:\n",
    "                                        class_counter += 1\n",
    "                                        classes_visited.append(class_name)\n",
    "        \n",
    "        project_class_count.append(class_counter)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"ML Library\"] = library_names\n",
    "    df[\"API Class Count\"] = api_class_count\n",
    "    df[\"Project Class Count\"] = project_class_count\n",
    "    return df     \n",
    "\n",
    "library_data_dirs = [\"modules/sklearn_default_values.json\", \"modules/tensorflow_default_values.json\",  \"modules/torch_default_values.json\"]\n",
    "library_names = [\"sklearn\", \"tensorflow\", \"torch\"]\n",
    "df_class_count = compare_api_and_project_classes(library_names, library_data_dirs, \"statistics/*\")\n",
    "df_class_count.head()\n",
    "df_to_latex(df=df_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "   Library &  Total Count &  Default Count &  Customized Count &  Not API Match Count \\\\\n",
      "\\midrule\n",
      "   sklearn &          625 &            110 &               474 &                   41 \\\\\n",
      "tensorflow &         9403 &            163 &              8096 &                 1144 \\\\\n",
      "     torch &        32227 &           1974 &             29923 &                  330 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_hyperparameter_count(library_name: str, library_dir: str, project_dir: str) -> pd.DataFrame:\n",
    "    total_count = 0\n",
    "    default_count = 0\n",
    "    customized_count = 0\n",
    "    not_match_api_count = 0\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for module_name, module_value in module_data.items():\n",
    "                            if module_name[0].isupper():\n",
    "                                class_name = module_name.split(\"_\")[0]\n",
    "                                if \"base_class_0\" in module_value:\n",
    "                                    continue\n",
    "                                #print(\"Module Name: \", class_name)\n",
    "                                for param, param_value in module_value.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        total_count += 1\n",
    "\n",
    "                                        api_module = next(filter(lambda x: x[\"name\"] == class_name, library_data))\n",
    "\n",
    "                                        if param in api_module[\"params\"]:\n",
    "                                            api_param_value = api_module[\"params\"].get(param)\n",
    "                                            if api_param_value == param_value[\"value\"]:\n",
    "                                                default_count +=1\n",
    "                                            else:\n",
    "                                                customized_count += 1\n",
    "                                        else:\n",
    "                                            not_match_api_count += 1\n",
    "\n",
    "    #assert total_count == default_count + customized_count + not_match_api_count                                        \n",
    "\n",
    "    data = {\n",
    "        \"Library\": [library_name],\n",
    "        \"Total Count\": [total_count],\n",
    "        \"Default Count\": [default_count],\n",
    "        \"Customized Count\": [customized_count],\n",
    "        \"Not API Match Count\": [not_match_api_count]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sklearn = get_hyperparameter_count(\"sklearn\", \"modules/sklearn_default_values.json\", \"statistics/*\")\n",
    "df_tf = get_hyperparameter_count(\"tensorflow\", \"modules/tensorflow_default_values.json\", \"statistics/*\")\n",
    "df_torch = get_hyperparameter_count(\"torch\", \"modules/torch_default_values.json\", \"statistics/*\")\n",
    "\n",
    "df_all = pd.concat([df_sklearn, df_tf, df_torch])\n",
    "df_all.head()\n",
    "df_to_latex(df=df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "                        Class &  Count &  \\#HP &  AvgOptionsUsed &                                                                 Most Used HP \\\\\n",
      "\\midrule\n",
      "           LogisticRegression &     40 &   15 &            1.12 &                                                                      default \\\\\n",
      "                       KMeans &     30 &    9 &            2.30 &                                                                   n\\_clusters \\\\\n",
      "             LinearRegression &     13 &    5 &            0.08 &                                                                      default \\\\\n",
      "                          PCA &     12 &    9 &            1.00 &                                                                 n\\_components \\\\\n",
      "                          SVC &      7 &   15 &            2.00 &                                                                       kernel \\\\\n",
      "             NearestNeighbors &      7 &    8 &            1.29 &                                                                  n\\_neighbors \\\\\n",
      "       RandomForestClassifier &      6 &   18 &            2.33 &                                                                 n\\_estimators \\\\\n",
      "        DecisionTreeRegressor &      5 &   11 &            0.80 &                                                                      default \\\\\n",
      "       DecisionTreeClassifier &      4 &   12 &            1.25 & criterion, random\\_state, default, min\\_samples\\_leaf, max\\_leaf\\_nodes, **kwargs \\\\\n",
      "         KNeighborsClassifier &      4 &    8 &            1.50 &                                                          n\\_neighbors, metric \\\\\n",
      "                 SGDRegressor &      4 &   19 &            0.75 &                                                                     **kwargs \\\\\n",
      "              RANSACRegressor &      4 &   13 &            1.00 &                                                               base\\_estimator \\\\\n",
      "                       DBSCAN &      3 &    8 &            2.00 &                                                             eps, min\\_samples \\\\\n",
      "          KNeighborsRegressor &      3 &    8 &            0.67 &                                               default, **kwargs, n\\_neighbors \\\\\n",
      "                SGDClassifier &      3 &   21 &            2.00 &                                                                     **kwargs \\\\\n",
      "    LatentDirichletAllocation &      3 &   16 &            1.00 &                                                                 n\\_components \\\\\n",
      "                KernelDensity &      3 &    9 &            2.00 &                                                            kernel, bandwidth \\\\\n",
      "                    KernelPCA &      3 &   16 &            1.00 &                                      n\\_components, kernel, default, **kwargs \\\\\n",
      "      AgglomerativeClustering &      3 &    8 &            2.00 &                                                                   n\\_clusters \\\\\n",
      "                   GaussianNB &      3 &    2 &            0.00 &                                                                      default \\\\\n",
      "            ColumnTransformer &      2 &    7 &            1.50 &                                                                 transformers \\\\\n",
      "                        Lasso &      2 &   11 &            1.00 &                                                                        alpha \\\\\n",
      "QuadraticDiscriminantAnalysis &      2 &    4 &            0.50 &                                                            default, **kwargs \\\\\n",
      "   LinearDiscriminantAnalysis &      2 &    7 &            0.50 &                                                            default, **kwargs \\\\\n",
      "                      FastICA &      2 &    9 &            0.50 &                                                            default, **kwargs \\\\\n",
      "              IsolationForest &      2 &    9 &            0.50 &                                                            default, **kwargs \\\\\n",
      "                       KDTree &      2 &    4 &            1.50 &                                                                            X \\\\\n",
      "                        Ridge &      2 &    9 &            1.00 &                                                                        alpha \\\\\n",
      "                  BernoulliNB &      2 &    4 &            1.00 &                                                 default, binarize, fit\\_prior \\\\\n",
      "        RandomForestRegressor &      2 &   17 &            1.50 &                                                                 n\\_estimators \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_ml_algorithms(library_name: str, library_dir: str, project_dir: str) -> pd.DataFrame:\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "\n",
    "    # Get Most used Class\n",
    "    classes = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, value in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name = key.split(\"_\")[0]\n",
    "                                for item in library_data:\n",
    "                                    if item[\"name\"] == class_name:\n",
    "                                        classes.append(class_name)\n",
    "\n",
    "    class_data = Counter(classes)\n",
    "    df_classes = pd.DataFrame.from_dict(class_data, orient=\"index\").reset_index()\n",
    "    df_classes = df_classes.rename(columns={'index':'Class', 0:'Count'})\n",
    "    df_classes = df_classes.sort_values(by=['Count'], ascending=False)\n",
    "\n",
    "    # Get Number of API Options\n",
    "    class_options = []\n",
    "    classes = df_classes[\"Class\"].to_list()\n",
    "\n",
    "    for ml_class in classes:\n",
    "        try:\n",
    "            class_data = next(filter(lambda x: x[\"name\"] == ml_class, library_data))\n",
    "            class_options.append(len(class_data[\"params\"]))\n",
    "        except StopIteration:\n",
    "            print(\"Could not find: \", ml_class)\n",
    "            continue\n",
    "            #raise StopIteration()\n",
    "\n",
    "    df_classes[\"#HP\"] = class_options\n",
    "\n",
    "    # Compute average number of options used per class and most used option\n",
    "    avg_class_options = []\n",
    "    most_used_class_option = []\n",
    "\n",
    "    for ml_class in classes:\n",
    "        avg_class_options_used = []\n",
    "        class_options = []\n",
    "        for project in glob.glob(project_dir):\n",
    "            with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                project_data = json.load(project_file)\n",
    "\n",
    "                for file in project_data.keys():\n",
    "                    file_data = project_data[file]\n",
    "                    for library in file_data.keys():\n",
    "                        if library == library_name:\n",
    "                            module_data = file_data[library]\n",
    "                            for module_name, data in module_data.items():\n",
    "                                if module_name[0].isupper():\n",
    "                                    name = module_name.split(\"_\")[0]\n",
    "                                    if ml_class == name:\n",
    "                                        counter = 0\n",
    "\n",
    "                                        for param in data.keys():\n",
    "                                            if param == \"variable\":\n",
    "                                                continue\n",
    "\n",
    "                                            if param not in (\"variable\", \"params\", \"class\"):\n",
    "                                                counter += 1\n",
    "\n",
    "                                            if param == \"params\":\n",
    "                                                class_options.append(\"default\")\n",
    "                                            else:\n",
    "                                                class_options.append(param)\n",
    "            \n",
    "                                        avg_class_options_used.append(counter)\n",
    "                                \n",
    "        avg_class_options.append(round((sum(avg_class_options_used) / len(avg_class_options_used)),2))\n",
    "        class_option_data = Counter(class_options)\n",
    "        try:\n",
    "            most_common_number = class_option_data.most_common(1)[0][1]\n",
    "            options = [elem[0] for elem in class_option_data.most_common() if elem[1] == most_common_number]\n",
    "            option_str = \", \".join(options)\n",
    "            most_used_class_option.append(option_str)\n",
    "        except IndexError:\n",
    "            most_used_class_option.append(\"None\")\n",
    "\n",
    "    df_classes[\"AvgOptionsUsed\"] = avg_class_options\n",
    "    df_classes[\"Most Used HP\"] = most_used_class_option\n",
    "\n",
    "    return df_classes\n",
    "\n",
    "\n",
    "\n",
    "df_sklearn_ml_algo = get_ml_algorithms(\"sklearn\", \"modules/sklearn_ml_algorithms.json\", \"statistics/*\")\n",
    "df_sklearn_ml_algo = df_sklearn_ml_algo[:30]\n",
    "\n",
    "df_to_latex(df=df_sklearn_ml_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression default\n",
      "KMeans n_clusters\n",
      "KMeans n_clusters n_clusters {'value': '5', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'i', 'possible_values': [[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': '5', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'i', 'possible_values': [[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'len(np.unique(self.y))', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'len(np.unique(self.y))', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'ncenters', 'possible_values': [['min(len(X), ncenters)', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'k', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['10', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['10', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['10', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['10', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'self.n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['np.ceil(label_patch.size / (args.tile_w * args.tile_h) + 1).astype(np.int)', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['np.ceil(np.prod(label_patch.size) / (args.tile_w * args.tile_h) + 1).astype(np.int)', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['np.ceil(np.prod(label_patch.size) / (args.tile_w * args.tile_h) + 1).astype(np.int)', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_colors', 'possible_values': [['0', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['min_clusters', 'Name']]}\n",
      "KMeans n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['min_clusters', 'Name']]}\n",
      "KMeans n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['5', 'Constant']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters == cluster_num', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': 'cluster_num', 'possible_values': [['new_width[int(i / 4) + 1]', 'Subscript']]}\n",
      "KMeans n_clusters n_clusters {'value': 'mpi_size', 'possible_values': [['mpi_comm.Get_size()', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'mpi_size', 'possible_values': [['mpi_comm.Get_size()', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['len(label_list)', 'Call'], ['config.n_clusters', 'Attribute'], [\"hpkwargs.get('n_clusters')\", 'Call'], ['None', 'MethodArgument']]}\n",
      "KMeans n_clusters n_clusters {'value': 'n_clusters', 'possible_values': [['opt.n_clusters', 'Attribute'], ['min(feat.shape[0], opt.n_clusters)', 'Call']]}\n",
      "KMeans n_clusters n_clusters {'value': '2 ** num_bits', 'possible_values': []}\n",
      "KMeans n_clusters n_clusters {'value': '2 ** num_bits', 'possible_values': []}\n",
      "LinearRegression default\n",
      "PCA n_components\n",
      "PCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "PCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "PCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "PCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "PCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'n_components', 'possible_values': [['4', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'n_components', 'possible_values': [['4', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'mle', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'n_components', 'possible_values': [[\"config['n_components']\", 'Subscript']]}\n",
      "PCA n_components n_components {'value': 'n_components', 'possible_values': [[\"config['n_components']\", 'Subscript']]}\n",
      "PCA n_components n_components {'value': 'n_components', 'possible_values': [[\"config['n_components']\", 'Subscript']]}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'k', 'possible_values': [['8', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'k', 'possible_values': [['8', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'k', 'possible_values': [['8', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'k', 'possible_values': [['8', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "PCA n_components n_components {'value': 'pca_dim', 'possible_values': [['50', 'MethodArgument']]}\n",
      "PCA n_components n_components {'value': 'feat_dim', 'possible_values': []}\n",
      "SVC kernel\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'rbf', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "SVC kernel kernel {'value': 'linear', 'possible_values': []}\n",
      "NearestNeighbors n_neighbors\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': 'n_neighbors', 'possible_values': [['6', 'MethodArgument']]}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': '1', 'possible_values': []}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': 'n_neighbors', 'possible_values': [['6', 'MethodArgument']]}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': '1', 'possible_values': []}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': '1', 'possible_values': []}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': 'num', 'possible_values': [['min(n_objs, len(Archive))', 'Call']]}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': 'num', 'possible_values': [['min(n_objs, len(W))', 'Call']]}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': 'num', 'possible_values': [['min(n_objs, len(W))', 'Call'], ['int(len(W_) - len(W_) * delete_ratio)', 'Call']]}\n",
      "NearestNeighbors n_neighbors n_neighbors {'value': 'numberOfNeighbor', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '10', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '100', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '100', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '100', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '100', 'possible_values': []}\n",
      "RandomForestClassifier n_estimators n_estimators {'value': '100', 'possible_values': []}\n",
      "DecisionTreeRegressor default\n",
      "DecisionTreeClassifier criterion, random_state, default, min_samples_leaf, max_leaf_nodes, **kwargs\n",
      "DecisionTreeClassifier criterion criterion {'value': 'entropy', 'possible_values': []}\n",
      "DecisionTreeClassifier criterion criterion {'value': 'entropy', 'possible_values': []}\n",
      "DecisionTreeClassifier criterion criterion {'value': 'entropy', 'possible_values': []}\n",
      "DecisionTreeClassifier criterion criterion {'value': 'entropy', 'possible_values': []}\n",
      "KNeighborsClassifier n_neighbors, metric\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': '5', 'possible_values': []}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': '5', 'possible_values': []}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': '5', 'possible_values': []}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': '5', 'possible_values': []}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': 'nn', 'possible_values': [['9', 'MethodArgument']]}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': 'nn', 'possible_values': [['9', 'MethodArgument']]}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': 'nn', 'possible_values': [['9', 'MethodArgument']]}\n",
      "KNeighborsClassifier n_neighbors n_neighbors {'value': 'nn', 'possible_values': [['9', 'MethodArgument']]}\n",
      "SGDRegressor **kwargs\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDRegressor **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.1, 'penalty': 'l1'}\", 'possible_values': []}\n",
      "RANSACRegressor base_estimator\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "RANSACRegressor base_estimator base_estimator {'value': 'self.inner_model', 'possible_values': []}\n",
      "DBSCAN eps, min_samples\n",
      "DBSCAN eps eps {'value': 'CFG.POSTPROCESS.DBSCAN_EPS', 'possible_values': []}\n",
      "DBSCAN eps eps {'value': 'CFG.POSTPROCESS.DBSCAN_EPS', 'possible_values': []}\n",
      "DBSCAN eps eps {'value': 'CFG.POSTPROCESS.DBSCAN_EPS', 'possible_values': []}\n",
      "DBSCAN eps eps {'value': 'CFG.POSTPROCESS.DBSCAN_EPS', 'possible_values': []}\n",
      "DBSCAN eps eps {'value': 'e', 'possible_values': [['np.arange(e_lower, e_upper, 0.1)', 'Call']]}\n",
      "KNeighborsRegressor default, **kwargs, n_neighbors\n",
      "SGDClassifier **kwargs\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': '**sklearn_params', 'possible_values': []}\n",
      "SGDClassifier **kwargs **kwargs {'value': \"**{'learning_rate': 'constant', 'eta0': 0.01, 'alpha': 0.001, 'penalty': 'l1', 'loss': 'log_loss'}\", 'possible_values': []}\n",
      "LatentDirichletAllocation n_components\n",
      "LatentDirichletAllocation n_components n_components {'value': '50', 'possible_values': []}\n",
      "LatentDirichletAllocation n_components n_components {'value': '50', 'possible_values': []}\n",
      "LatentDirichletAllocation n_components n_components {'value': 'N_COMPONENTS', 'possible_values': [['5', 'Constant']]}\n",
      "LatentDirichletAllocation n_components n_components {'value': 'N_COMPONENTS', 'possible_values': [['5', 'Constant']]}\n",
      "LatentDirichletAllocation n_components n_components {'value': 'N_COMPONENTS', 'possible_values': [['5', 'Constant']]}\n",
      "KernelDensity kernel, bandwidth\n",
      "KernelDensity kernel kernel {'value': 'tophat', 'possible_values': []}\n",
      "KernelDensity kernel kernel {'value': 'tophat', 'possible_values': []}\n",
      "KernelDensity kernel kernel {'value': 'kernel', 'possible_values': [[\"'tophat'\", 'MethodArgument']]}\n",
      "KernelDensity kernel kernel {'value': 'tophat', 'possible_values': []}\n",
      "KernelDensity kernel kernel {'value': 'tophat', 'possible_values': []}\n",
      "KernelDensity kernel kernel {'value': 'kernel', 'possible_values': [[\"'tophat'\", 'MethodArgument']]}\n",
      "KernelDensity kernel kernel {'value': 'tophat', 'possible_values': []}\n",
      "KernelDensity kernel kernel {'value': 'tophat', 'possible_values': []}\n",
      "KernelDensity kernel kernel {'value': 'kernel', 'possible_values': [[\"'tophat'\", 'MethodArgument']]}\n",
      "KernelPCA n_components, kernel, default, **kwargs\n",
      "KernelPCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "KernelPCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "KernelPCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "KernelPCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "KernelPCA n_components n_components {'value': '2', 'possible_values': []}\n",
      "AgglomerativeClustering n_clusters\n",
      "AgglomerativeClustering n_clusters n_clusters {'value': '5', 'possible_values': []}\n",
      "AgglomerativeClustering n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "AgglomerativeClustering n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "AgglomerativeClustering n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "AgglomerativeClustering n_clusters n_clusters {'value': 'k', 'possible_values': [['k - n_edge_points', 'BinOp'], ['100', 'MethodArgument']]}\n",
      "AgglomerativeClustering n_clusters n_clusters {'value': 'num_clusters', 'possible_values': [['len(set([row[1] for row in corpus]))', 'Call']]}\n",
      "GaussianNB default\n",
      "ColumnTransformer transformers\n",
      "ColumnTransformer transformers transformers {'value': \"[('continuous', SimpleImputer(missing_values=np.nan, strategy='median'), X_num.columns)]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('continuous', SimpleImputer(missing_values=np.nan, strategy='median'), X_num.columns)]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('continuous', SimpleImputer(missing_values=np.nan, strategy='median'), X_num.columns)]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('continuous', SimpleImputer(missing_values=np.nan, strategy='median'), X_num.columns)]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('continuous', SimpleImputer(missing_values=np.nan, strategy='median'), X_num.columns)]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "ColumnTransformer transformers transformers {'value': \"[('title_style', StyleFeaturizer(), 'title'), ('text_style', StyleFeaturizer(), 'text')]\", 'possible_values': []}\n",
      "Lasso alpha\n",
      "Lasso alpha alpha {'value': 'reg', 'possible_values': []}\n",
      "Lasso alpha alpha {'value': 'reg', 'possible_values': []}\n",
      "Lasso alpha alpha {'value': 'regulariser', 'possible_values': []}\n",
      "QuadraticDiscriminantAnalysis default, **kwargs\n",
      "LinearDiscriminantAnalysis default, **kwargs\n",
      "FastICA default, **kwargs\n",
      "IsolationForest default, **kwargs\n",
      "KDTree X\n",
      "KDTree X X {'value': 'self.train_x.cpu().numpy()', 'possible_values': []}\n",
      "KDTree X X {'value': 'x', 'possible_values': [['np.concatenate(sem_cond, axis=0)', 'Call'], ['x / self.sem_means', 'BinOp'], ['np.concatenate([x, x_ins / self.ins_means], axis=1)', 'Call']]}\n",
      "Ridge alpha\n",
      "Ridge alpha alpha {'value': 'alpha', 'possible_values': [[\"params.get('alpha')\", 'Call']]}\n",
      "Ridge alpha alpha {'value': 'reg', 'possible_values': []}\n",
      "Ridge alpha alpha {'value': 'reg', 'possible_values': []}\n",
      "BernoulliNB default, binarize, fit_prior\n",
      "RandomForestRegressor n_estimators\n",
      "RandomForestRegressor n_estimators n_estimators {'value': '300', 'possible_values': []}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n",
      "RandomForestRegressor n_estimators n_estimators {'value': 'N_ESTIMATORS', 'possible_values': [['500', 'Constant']]}\n"
     ]
    }
   ],
   "source": [
    "def get_value_types(df, library_name, project_dir) -> pd.DataFrame:\n",
    "    for _, row in df_sklearn_ml_algo.iterrows():\n",
    "        df_class_name = row[\"Class\"]\n",
    "        df_class_option_name = row[\"Most Used HP\"].split(\",\")[0]\n",
    "\n",
    "        print(row[\"Class\"], row[\"Most Used HP\"])\n",
    "        for project in glob.glob(project_dir):\n",
    "                with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                    project_data = json.load(project_file)\n",
    "\n",
    "                    for file in project_data.keys():\n",
    "                        file_data = project_data[file]\n",
    "                        for library in file_data.keys():\n",
    "                            module_data = file_data[library]\n",
    "                            for module_name, data in module_data.items():\n",
    "                                if library == library_name:\n",
    "                                    module_data = file_data[library]\n",
    "                                    for module_name, data in module_data.items():\n",
    "                                        if module_name[0].isupper():\n",
    "                                            name = module_name.split(\"_\")[0]\n",
    "                                            if df_class_name == name:\n",
    "                                                for key, value in data.items():\n",
    "                                                    if key == df_class_option_name:\n",
    "                                                        print(df_class_name, df_class_option_name, key, value)\n",
    "                                                        # TODO: Calculate Type of value \n",
    "\n",
    "\n",
    "get_value_types(df_sklearn_ml_algo, \"sklearn\", \"statistics/*\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baf69434822515d6eb5706280ed4fdf1abcb6899576a97bde367cb051faeb565"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
