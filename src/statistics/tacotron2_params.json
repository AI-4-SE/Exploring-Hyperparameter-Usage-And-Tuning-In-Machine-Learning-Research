{
    "hparams.py": {
        "tensorflow": {
            "info_89": {
                "msg": {
                    "value": "Parsing command line hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "hparams_string",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "info_93": {
                "msg": {
                    "value": "Final parsed hparams: %s",
                    "possible_values": []
                },
                "*args": {
                    "value": "hparams.values()",
                    "possible_values": []
                }
            }
        }
    },
    "audio_processing.py": {
        "torch": {
            "log_84": {
                "input": {
                    "value": "torch.clamp(x, min=clip_val) * C",
                    "possible_values": []
                }
            },
            "from_numpy_69": {
                "ndarray": {
                    "value": "angles",
                    "possible_values": [
                        [
                            "np.angle(np.exp(2j * np.pi * np.random.rand(*magnitudes.size())))",
                            "Call"
                        ],
                        [
                            "angles.astype(np.float32)",
                            "Call"
                        ],
                        [
                            "torch.autograd.Variable(torch.from_numpy(angles))",
                            "Call"
                        ]
                    ]
                }
            },
            "exp_93": {
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "np.zeros(n, dtype=dtype)",
                            "Call"
                        ]
                    ]
                }
            },
            "clamp_84": {
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "np.zeros(n, dtype=dtype)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "clip_val",
                    "possible_values": [
                        [
                            "1e-05",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "data_utils.py": {
        "torch": {
            "sort_80": {
                "variable": {
                    "value": "(input_lengths, ids_sorted_decreasing)",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.LongTensor([len(x[0]) for x in batch])",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "squeeze_47": {
                "variable": {
                    "value": "melspec",
                    "possible_values": []
                },
                "input": {
                    "value": "melspec",
                    "possible_values": [
                        [
                            "torch.from_numpy(np.load(filename))",
                            "Call"
                        ],
                        [
                            "self.stft.mel_spectrogram(audio_norm)",
                            "Call"
                        ],
                        [
                            "torch.squeeze(melspec, 0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "from_numpy_49": {
                "variable": {
                    "value": "melspec",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.load(filename)",
                    "possible_values": []
                }
            }
        }
    },
    "distributed.py": {
        "torch": {
            "cat_19": {
                "variable": {
                    "value": "flat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[t.contiguous().view(-1) for t in tensors]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_135": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "module.state_dict().values()",
                            "Call"
                        ],
                        [
                            "self.module.state_dict().values()",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "broadcast_66": {
                "tensor": {
                    "value": "p",
                    "possible_values": [
                        [
                            "module.state_dict().values()",
                            "Call"
                        ],
                        [
                            "self.module.state_dict().values()",
                            "Call"
                        ]
                    ]
                },
                "devices": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "is_tensor_133": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "module.state_dict().values()",
                            "Call"
                        ],
                        [
                            "self.module.state_dict().values()",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_64": {
                "obj": {
                    "value": "p",
                    "possible_values": [
                        [
                            "module.state_dict().values()",
                            "Call"
                        ],
                        [
                            "self.module.state_dict().values()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "layers.py": {
        "torch": {
            "Linear_11": {
                "variable": {
                    "value": "self.linear_layer",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "out_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Conv1d_29": {
                "variable": {
                    "value": "self.conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel_size",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "padding",
                    "possible_values": [
                        [
                            "int(dilation * (kernel_size - 1) / 2)",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dilation": {
                    "value": "dilation",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "possible_values": [
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "from_numpy_52": {
                "variable": {
                    "value": "mel_basis",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "mel_basis",
                    "possible_values": [
                        [
                            "librosa_mel_fn(sampling_rate, filter_length, n_mel_channels, mel_fmin, mel_fmax)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(mel_basis).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_78": {
                "variable": {
                    "value": "mel_output",
                    "possible_values": []
                },
                "input": {
                    "value": "self.mel_basis",
                    "possible_values": []
                },
                "other": {
                    "value": "magnitudes",
                    "possible_values": [
                        [
                            "magnitudes.data",
                            "Attribute"
                        ]
                    ]
                }
            },
            "min_73": {
                "input": {
                    "value": "y.data",
                    "possible_values": []
                }
            },
            "max_74": {
                "input": {
                    "value": "y.data",
                    "possible_values": []
                }
            }
        }
    },
    "logger.py": {
        "torch": {
            "sigmoid_47": {
                "input": {
                    "value": "gate_outputs[idx]",
                    "possible_values": []
                }
            }
        }
    },
    "loss_function.py": {
        "torch": {
            "BCEWithLogitsLoss_18": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "MSELoss_16": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "MSELoss_17": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "loss_scaler.py": {
        "torch": {
            "SGD_103": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "parameters",
                    "possible_values": [
                        [
                            "[w1, w2]",
                            "List"
                        ]
                    ]
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "1e-06",
                            "Constant"
                        ]
                    ]
                }
            },
            "randn_95": {
                "*size": {
                    "value": "N",
                    "possible_values": []
                },
                "out": {
                    "value": "D_in",
                    "possible_values": []
                }
            },
            "randn_96": {
                "*size": {
                    "value": "N",
                    "possible_values": []
                },
                "out": {
                    "value": "D_out",
                    "possible_values": []
                }
            },
            "randn_98": {
                "*size": {
                    "value": "D_in",
                    "possible_values": []
                },
                "out": {
                    "value": "H",
                    "possible_values": []
                }
            },
            "randn_99": {
                "*size": {
                    "value": "H",
                    "possible_values": []
                },
                "out": {
                    "value": "D_out",
                    "possible_values": []
                }
            }
        }
    },
    "model.py": {
        "torch": {
            "softmax_82": {
                "variable": {
                    "value": "attention_weights",
                    "possible_values": []
                },
                "input": {
                    "value": "alignment",
                    "possible_values": [
                        [
                            "self.get_alignment_energies(attention_hidden_state, processed_memory, attention_weights_cat)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_83": {
                "variable": {
                    "value": "attention_context",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_weights.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "memory",
                    "possible_values": []
                }
            },
            "ModuleList_93": {
                "variable": {
                    "value": "self.layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LinearNorm(in_size, out_size, bias=False) for (in_size, out_size) in zip(in_sizes, sizes)]",
                    "possible_values": []
                }
            },
            "ModuleList_110": {
                "variable": {
                    "value": "self.convolutions",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "dropout_144": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.convolutions[-1](x)",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "ModuleList_167": {
                "variable": {
                    "value": "self.convolutions",
                    "possible_values": []
                },
                "modules": {
                    "value": "convolutions",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "LSTM_169": {
                "variable": {
                    "value": "self.lstm",
                    "possible_values": []
                },
                "*args": {
                    "value": "hparams.encoder_embedding_dim",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "bidirectional": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_181": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "F.dropout(F.relu(linear(x)), p=0.5, training=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(torch.tanh(self.convolutions[i](x)), 0.5, self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(self.convolutions[-1](x), 0.5, self.training)",
                            "Call"
                        ],
                        [
                            "F.dropout(F.relu(conv(x)), 0.5, self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pack_padded_sequence(x, input_lengths, batch_first=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(F.relu(conv(x)), 0.5, self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "input_lengths",
                    "possible_values": [
                        [
                            "input_lengths.cpu().numpy()",
                            "Call"
                        ],
                        [
                            "to_gpu(input_lengths).long()",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_187": {
                "variable": {
                    "value": "(outputs, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "outputs",
                    "possible_values": [
                        [
                            "self.parse_output([mel_outputs, mel_outputs_postnet, gate_outputs, alignments])",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "LSTMCell_222": {
                "variable": {
                    "value": "self.attention_rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "hparams.prenet_dim + hparams.encoder_embedding_dim",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "hparams.attention_rnn_dim",
                    "possible_values": []
                }
            },
            "LSTMCell_231": {
                "variable": {
                    "value": "self.decoder_rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "hparams.attention_rnn_dim + hparams.encoder_embedding_dim",
                    "possible_values": []
                },
                "hidden_size": {
                    "value": "hparams.decoder_rnn_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_326": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "possible_values": [
                        [
                            "torch.stack(alignments).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "alignments + [alignment]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_326": {
                "variable": {
                    "value": "alignments",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_328": {
                "variable": {
                    "value": "gate_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "gate_outputs",
                    "possible_values": [
                        [
                            "torch.stack(gate_outputs).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "gate_outputs.contiguous()",
                            "Call"
                        ],
                        [
                            "gate_outputs + [gate_output]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_328": {
                "variable": {
                    "value": "gate_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "stack_331": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mel_outputs",
                    "possible_values": [
                        [
                            "torch.stack(mel_outputs).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "mel_outputs.view(mel_outputs.size(0), -1, self.n_mel_channels)",
                            "Call"
                        ],
                        [
                            "mel_outputs.transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "mel_outputs + [mel_output.squeeze(1)]",
                            "BinOp"
                        ]
                    ]
                }
            },
            "transpose_331": {
                "variable": {
                    "value": "mel_outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "possible_values": []
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_352": {
                "variable": {
                    "value": "cell_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "dropout_355": {
                "variable": {
                    "value": "self.attention_hidden",
                    "possible_values": []
                },
                "input": {
                    "value": "self.attention_hidden",
                    "possible_values": []
                },
                "p": {
                    "value": "self.p_attention_dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "cat_358": {
                "variable": {
                    "value": "attention_weights_cat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_weights.unsqueeze(1), self.attention_weights_cum.unsqueeze(1))",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_366": {
                "variable": {
                    "value": "decoder_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.attention_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "dropout_370": {
                "variable": {
                    "value": "self.decoder_hidden",
                    "possible_values": []
                },
                "input": {
                    "value": "self.decoder_hidden",
                    "possible_values": []
                },
                "p": {
                    "value": "self.p_decoder_dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "cat_373": {
                "variable": {
                    "value": "decoder_hidden_attention_context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.decoder_hidden, self.attention_context)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_398": {
                "variable": {
                    "value": "decoder_inputs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(decoder_input, decoder_inputs)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Embedding_464": {
                "variable": {
                    "value": "self.embedding",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "hparams.n_symbols",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "hparams.symbols_embedding_dim",
                    "possible_values": []
                }
            },
            "max_478": {
                "variable": {
                    "value": "max_len",
                    "possible_values": []
                },
                "input": {
                    "value": "input_lengths.data",
                    "possible_values": []
                }
            },
            "dropout_99": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(linear(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "dropout_143": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.tanh(self.convolutions[i](x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "Sequential_159": {
                "variable": {
                    "value": "conv_layer",
                    "possible_values": []
                },
                "*args": {
                    "value": "ConvNorm(hparams.encoder_embedding_dim, hparams.encoder_embedding_dim, kernel_size=hparams.encoder_kernel_size, stride=1, padding=int((hparams.encoder_kernel_size - 1) / 2), dilation=1, w_init_gain='relu')",
                    "possible_values": []
                }
            },
            "dropout_175": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_194": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "F.relu(conv(x))",
                    "possible_values": []
                },
                "p": {
                    "value": "0.5",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "tanh_59": {
                "input": {
                    "value": "processed_query + processed_attention_weights + processed_memory",
                    "possible_values": []
                }
            },
            "Sequential_113": {
                "*args": {
                    "value": "ConvNorm(hparams.n_mel_channels, hparams.postnet_embedding_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "Sequential_133": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_embedding_dim, hparams.n_mel_channels, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='linear')",
                    "possible_values": []
                }
            },
            "relu_99": {
                "input": {
                    "value": "linear(x)",
                    "possible_values": []
                }
            },
            "BatchNorm1d_118": {
                "num_features": {
                    "value": "hparams.postnet_embedding_dim",
                    "possible_values": []
                }
            },
            "Sequential_123": {
                "*args": {
                    "value": "ConvNorm(hparams.postnet_embedding_dim, hparams.postnet_embedding_dim, kernel_size=hparams.postnet_kernel_size, stride=1, padding=int((hparams.postnet_kernel_size - 1) / 2), dilation=1, w_init_gain='tanh')",
                    "possible_values": []
                }
            },
            "BatchNorm1d_138": {
                "num_features": {
                    "value": "hparams.n_mel_channels",
                    "possible_values": []
                }
            },
            "tanh_143": {
                "input": {
                    "value": "self.convolutions[i](x)",
                    "possible_values": []
                }
            },
            "BatchNorm1d_165": {
                "num_features": {
                    "value": "hparams.encoder_embedding_dim",
                    "possible_values": []
                }
            },
            "relu_175": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "relu_194": {
                "input": {
                    "value": "conv(x)",
                    "possible_values": []
                }
            },
            "sigmoid_443": {
                "input": {
                    "value": "gate_output.data",
                    "possible_values": []
                }
            },
            "BatchNorm1d_129": {
                "num_features": {
                    "value": "hparams.postnet_embedding_dim",
                    "possible_values": []
                }
            }
        }
    },
    "multiproc.py": {
        "torch": {
            "device_count_7": {
                "variable": {
                    "value": "num_gpus",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "stft.py": {
        "torch": {
            "pad_85": {
                "variable": {
                    "value": "input_data",
                    "possible_values": []
                },
                "input": {
                    "value": "input_data.unsqueeze(1)",
                    "possible_values": []
                },
                "pad": {
                    "value": "(int(self.filter_length / 2), int(self.filter_length / 2), 0, 0)",
                    "possible_values": []
                },
                "mode": {
                    "value": "reflect",
                    "possible_values": []
                }
            },
            "conv1d_91": {
                "variable": {
                    "value": "forward_transform",
                    "possible_values": []
                },
                "input": {
                    "value": "input_data",
                    "possible_values": [
                        [
                            "input_data.view(num_batches, 1, num_samples)",
                            "Call"
                        ],
                        [
                            "F.pad(input_data.unsqueeze(1), (int(self.filter_length / 2), int(self.filter_length / 2), 0, 0), mode='reflect')",
                            "Call"
                        ],
                        [
                            "input_data.squeeze(1)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "Variable(self.forward_basis, requires_grad=False)",
                    "possible_values": []
                },
                "stride": {
                    "value": "self.hop_length",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "sqrt_101": {
                "variable": {
                    "value": "magnitude",
                    "possible_values": []
                },
                "input": {
                    "value": "real_part ** 2 + imag_part ** 2",
                    "possible_values": []
                }
            },
            "cat_108": {
                "variable": {
                    "value": "recombine_magnitude_phase",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[magnitude * torch.cos(phase), magnitude * torch.sin(phase)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "conv_transpose1d_111": {
                "variable": {
                    "value": "inverse_transform",
                    "possible_values": []
                },
                "input": {
                    "value": "recombine_magnitude_phase",
                    "possible_values": [
                        [
                            "torch.cat([magnitude * torch.cos(phase), magnitude * torch.sin(phase)], dim=1)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "Variable(self.inverse_basis, requires_grad=False)",
                    "possible_values": []
                },
                "stride": {
                    "value": "self.hop_length",
                    "possible_values": []
                },
                "padding": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "from_numpy_68": {
                "variable": {
                    "value": "fft_window",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "fft_window",
                    "possible_values": [
                        [
                            "get_window(window, win_length, fftbins=True)",
                            "Call"
                        ],
                        [
                            "pad_center(fft_window, filter_length)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(fft_window).float()",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_123": {
                "variable": {
                    "value": "approx_nonzero_indices",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.where(window_sum > tiny(window_sum))[0]",
                    "possible_values": []
                }
            },
            "atan2_103": {
                "input": {
                    "value": "imag_part.data",
                    "possible_values": []
                },
                "other": {
                    "value": "real_part.data",
                    "possible_values": []
                }
            },
            "from_numpy_126": {
                "ndarray": {
                    "value": "window_sum",
                    "possible_values": [
                        [
                            "window_sumsquare(self.window, magnitude.size(-1), hop_length=self.hop_length, win_length=self.win_length, n_fft=self.filter_length, dtype=np.float32)",
                            "Call"
                        ],
                        [
                            "torch.autograd.Variable(torch.from_numpy(window_sum), requires_grad=False)",
                            "Call"
                        ],
                        [
                            "window_sum.cuda() if magnitude.is_cuda else window_sum",
                            "IfExp"
                        ]
                    ]
                }
            },
            "cos_109": {
                "input": {
                    "value": "phase",
                    "possible_values": [
                        [
                            "torch.autograd.Variable(torch.atan2(imag_part.data, real_part.data))",
                            "Call"
                        ]
                    ]
                }
            },
            "sin_109": {
                "input": {
                    "value": "phase",
                    "possible_values": [
                        [
                            "torch.autograd.Variable(torch.atan2(imag_part.data, real_part.data))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "train.py": {
        "torch": {
            "DataLoader_55": {
                "variable": {
                    "value": "train_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelLoader(hparams.training_files, hparams)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "shuffle",
                    "possible_values": [
                        [
                            "False",
                            "Constant"
                        ],
                        [
                            "True",
                            "Constant"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(trainset)",
                            "Call"
                        ],
                        [
                            "None",
                            "Constant"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "hparams.batch_size",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelCollate(hparams.n_frames_per_step)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_87": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(output_directory, 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_102": {
                "variable": {
                    "value": "checkpoint_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "possible_values": [
                        [
                            "os.path.join(output_directory, 'checkpoint_{}'.format(iteration))",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "Adam_170": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "checkpoint_dict['learning_rate']",
                            "Subscript"
                        ],
                        [
                            "hparams.learning_rate",
                            "Attribute"
                        ],
                        [
                            "_learning_rate",
                            "Name"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "hparams.weight_decay",
                    "possible_values": []
                }
            },
            "is_available_28": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "set_device_32": {
                "device": {
                    "value": "rank % torch.cuda.device_count()",
                    "possible_values": []
                }
            },
            "DistributedSampler_49": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "dataset": {
                    "value": "trainset",
                    "possible_values": [
                        [
                            "TextMelLoader(hparams.training_files, hparams)",
                            "Call"
                        ]
                    ]
                }
            },
            "save_115": {
                "obj": {
                    "value": "{'iteration': iteration, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'learning_rate': learning_rate}",
                    "possible_values": []
                },
                "f": {
                    "value": "filepath",
                    "possible_values": []
                }
            },
            "DataLoader_127": {
                "variable": {
                    "value": "val_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelLoader(hparams.validation_files, hparams)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "val_sampler",
                    "possible_values": [
                        [
                            "DistributedSampler(valset) if distributed_run else None",
                            "IfExp"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "1",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "False",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "collate_fn",
                    "possible_values": [
                        [
                            "TextMelCollate(hparams.n_frames_per_step)",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_165": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "manual_seed_166": {
                "seed": {
                    "value": "hparams.seed",
                    "possible_values": []
                }
            },
            "no_grad_125": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "device_count_32": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "DistributedSampler_126": {
                "dataset": {
                    "value": "valset",
                    "possible_values": [
                        [
                            "TextMelLoader(hparams.validation_files, hparams)",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__229": {
                "variable": {
                    "value": "grad_norm",
                    "possible_values": []
                },
                "parameters": {
                    "value": "amp.master_params(optimizer)",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            },
            "clip_grad_norm__233": {
                "variable": {
                    "value": "grad_norm",
                    "possible_values": []
                },
                "parameters": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "hparams.grad_clip_thresh",
                    "possible_values": []
                }
            }
        }
    },
    "utils.py": {
        "torch": {
            "max_7": {
                "variable": {
                    "value": "max_len",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "possible_values": []
                }
            },
            "arange_8": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "torch.max(lengths).item()",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "torch.cuda.LongTensor(max_len)",
                    "possible_values": []
                }
            },
            "is_available_27": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    }
}