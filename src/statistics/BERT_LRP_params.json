{
    "code/util/evaluation.py": {
        "sklearn": {}
    },
    "code/util/train_helper.py": {
        "sklearn": {
            "classification_report_515": {
                "variable": {
                    "value": "result_to_print",
                    "possible_values": []
                },
                "y_true": {
                    "value": "eval_f1_labels",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_labels, dim=0)",
                            "Call"
                        ],
                        [
                            "eval_f1_labels.to('cpu').numpy()",
                            "Call"
                        ]
                    ]
                },
                "y_pred": {
                    "value": "eval_f1_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_logits, dim=0)",
                            "Call"
                        ],
                        [
                            "F.softmax(eval_f1_logits, dim=-1)",
                            "Call"
                        ],
                        [
                            "eval_f1_logits.detach().cpu().numpy()",
                            "Call"
                        ],
                        [
                            "np.argmax(eval_f1_logits, axis=1)",
                            "Call"
                        ]
                    ]
                },
                "digits": {
                    "value": "5",
                    "possible_values": []
                },
                "output_dict": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "classification_report_553": {
                "y_true": {
                    "value": "eval_f1_labels",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_labels, dim=0)",
                            "Call"
                        ],
                        [
                            "eval_f1_labels.to('cpu').numpy()",
                            "Call"
                        ]
                    ]
                },
                "y_pred": {
                    "value": "eval_f1_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_logits, dim=0)",
                            "Call"
                        ],
                        [
                            "F.softmax(eval_f1_logits, dim=-1)",
                            "Call"
                        ],
                        [
                            "eval_f1_logits.detach().cpu().numpy()",
                            "Call"
                        ],
                        [
                            "np.argmax(eval_f1_logits, axis=1)",
                            "Call"
                        ]
                    ]
                },
                "digits": {
                    "value": "5",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "cat_507": {
                "variable": {
                    "value": "eval_f1_logits",
                    "possible_values": []
                },
                "tensors": {
                    "value": "eval_f1_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_logits, dim=0)",
                            "Call"
                        ],
                        [
                            "F.softmax(eval_f1_logits, dim=-1)",
                            "Call"
                        ],
                        [
                            "eval_f1_logits.detach().cpu().numpy()",
                            "Call"
                        ],
                        [
                            "np.argmax(eval_f1_logits, axis=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "softmax_508": {
                "variable": {
                    "value": "eval_f1_logits",
                    "possible_values": []
                },
                "input": {
                    "value": "eval_f1_logits",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_logits, dim=0)",
                            "Call"
                        ],
                        [
                            "F.softmax(eval_f1_logits, dim=-1)",
                            "Call"
                        ],
                        [
                            "eval_f1_logits.detach().cpu().numpy()",
                            "Call"
                        ],
                        [
                            "np.argmax(eval_f1_logits, axis=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_512": {
                "variable": {
                    "value": "eval_f1_labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "eval_f1_labels",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(eval_f1_labels, dim=0)",
                            "Call"
                        ],
                        [
                            "eval_f1_labels.to('cpu').numpy()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "tensor_582": {
                "variable": {
                    "value": "all_input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in train_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_583": {
                "variable": {
                    "value": "all_input_mask",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in train_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_586": {
                "variable": {
                    "value": "all_label_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in train_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_587": {
                "variable": {
                    "value": "all_seq_len",
                    "possible_values": []
                },
                "data": {
                    "value": "[[f.seq_len] for f in train_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "DataLoader_599": {
                "variable": {
                    "value": "train_dataloader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_seq_len)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_label_ids, all_seq_len)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "RandomSampler(train_data)",
                            "Call"
                        ],
                        [
                            "DistributedSampler(train_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "possible_values": []
                }
            },
            "Adam_261": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "0.0002",
                            "MethodArgument"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "0.0001",
                    "possible_values": []
                }
            },
            "tensor_585": {
                "variable": {
                    "value": "all_segment_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in train_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "TensorDataset_590": {
                "variable": {
                    "value": "train_data",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "possible_values": []
                }
            },
            "RandomSampler_596": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_data",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_seq_len)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_label_ids, all_seq_len)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedSampler_598": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_seq_len)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_label_ids, all_seq_len)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_609": {
                "variable": {
                    "value": "all_input_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in test_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_610": {
                "variable": {
                    "value": "all_input_mask",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in test_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_613": {
                "variable": {
                    "value": "all_label_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.label_id for f in test_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_614": {
                "variable": {
                    "value": "all_seq_len",
                    "possible_values": []
                },
                "data": {
                    "value": "[[f.seq_len] for f in test_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "DataLoader_621": {
                "variable": {
                    "value": "test_dataloader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_data",
                    "possible_values": [
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_seq_len)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_label_ids, all_seq_len)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_624": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "LSTMSequenceClassification(vocab_size=108837, n_labels=len(label_list), init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "LSTMSequenceClassification(vocab_size=108837, n_labels=len(label_list), embeddings=embeddings_layer, init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "TransformerSequenceClassification(vocab_size=108837, n_labels=len(label_list), init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "TransformerSequenceClassification(vocab_size=108837, n_labels=len(label_list), embeddings=embeddings_layer, init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "BertForSequenceClassification(bert_config, len(label_list), init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.local_rank]",
                    "possible_values": []
                },
                "output_device": {
                    "value": "args.local_rank",
                    "possible_values": []
                }
            },
            "device_635": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "possible_values": []
                }
            },
            "device_count_636": {
                "variable": {
                    "value": "n_gpu",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "device_638": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "possible_values": []
                }
            },
            "manual_seed_652": {
                "seed": {
                    "value": "args.seed",
                    "possible_values": []
                }
            },
            "load_238": {
                "variable": {
                    "value": "embeddings_layer",
                    "possible_values": []
                },
                "f": {
                    "value": "embed_file",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Adam_293": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "learning_rate",
                    "possible_values": [
                        [
                            "0.0002",
                            "MethodArgument"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "0.0001",
                    "possible_values": []
                }
            },
            "is_available_369": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "TensorDataset_593": {
                "variable": {
                    "value": "train_data",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "possible_values": []
                }
            },
            "tensor_612": {
                "variable": {
                    "value": "all_segment_ids",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in test_features]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "TensorDataset_617": {
                "variable": {
                    "value": "test_data",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "possible_values": []
                }
            },
            "DataParallel_627": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "LSTMSequenceClassification(vocab_size=108837, n_labels=len(label_list), init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "LSTMSequenceClassification(vocab_size=108837, n_labels=len(label_list), embeddings=embeddings_layer, init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "TransformerSequenceClassification(vocab_size=108837, n_labels=len(label_list), init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "TransformerSequenceClassification(vocab_size=108837, n_labels=len(label_list), embeddings=embeddings_layer, init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "BertForSequenceClassification(bert_config, len(label_list), init_lrp=init_lrp)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_all_654": {
                "seed": {
                    "value": "args.seed",
                    "possible_values": []
                }
            },
            "load_245": {
                "variable": {
                    "value": "state_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "init_checkpoint",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_270": {
                "variable": {
                    "value": "embeddings_layer",
                    "possible_values": []
                },
                "f": {
                    "value": "embed_file",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "empty_cache_370": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_451": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "softmax_492": {
                "variable": {
                    "value": "logits",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "possible_values": [
                        [
                            "F.softmax(logits, dim=-1)",
                            "Call"
                        ],
                        [
                            "logits.detach().cpu().numpy()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "save_550": {
                "obj": {
                    "value": "model.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "args.output_dir + 'best_checkpoint.bin'",
                    "possible_values": []
                }
            },
            "TensorDataset_620": {
                "variable": {
                    "value": "test_data",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "possible_values": []
                }
            },
            "load_277": {
                "variable": {
                    "value": "state_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "init_checkpoint",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "load_331": {
                "variable": {
                    "value": "state_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "init_checkpoint",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "is_available_453": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "empty_cache_454": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_635": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "load_343": {
                "f": {
                    "value": "init_checkpoint",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            }
        }
    },
    "code/convert_tf_checkpoint_to_pytorch.py": {
        "tensorflow": {
            "list_variables_49": {
                "variable": {
                    "value": "init_vars",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "path",
                    "possible_values": [
                        [
                            "args.tf_checkpoint_path",
                            "Attribute"
                        ]
                    ]
                }
            },
            "load_variable_54": {
                "variable": {
                    "value": "array",
                    "possible_values": []
                },
                "ckpt_dir_or_file": {
                    "value": "path",
                    "possible_values": [
                        [
                            "args.tf_checkpoint_path",
                            "Attribute"
                        ]
                    ]
                },
                "name": {
                    "value": "name",
                    "possible_values": [
                        [
                            "name[5:]",
                            "Subscript"
                        ],
                        [
                            "name.split('/')",
                            "Call"
                        ]
                    ]
                }
            }
        },
        "torch": {
            "from_numpy_91": {
                "variable": {
                    "value": "pointer.data",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "array",
                    "possible_values": [
                        [
                            "tf.train.load_variable(path, name)",
                            "Call"
                        ],
                        [
                            "np.transpose(array)",
                            "Call"
                        ]
                    ]
                }
            },
            "save_94": {
                "obj": {
                    "value": "model.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "args.pytorch_dump_path",
                    "possible_values": []
                }
            }
        }
    },
    "code/model/BERT.py": {
        "torch": {
            "Parameter_240": {
                "variable": {
                    "value": "self.gamma",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.ones(config.hidden_size)",
                    "possible_values": []
                }
            },
            "Parameter_241": {
                "variable": {
                    "value": "self.beta",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(config.hidden_size)",
                    "possible_values": []
                }
            },
            "Embedding_255": {
                "variable": {
                    "value": "self.word_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "Embedding_256": {
                "variable": {
                    "value": "self.position_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "Embedding_257": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "Dropout_262": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "possible_values": []
                }
            },
            "arange_266": {
                "variable": {
                    "value": "position_ids",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "possible_values": []
                }
            },
            "Linear_295": {
                "variable": {
                    "value": "self.query",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "possible_values": []
                }
            },
            "Linear_296": {
                "variable": {
                    "value": "self.key",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "possible_values": []
                }
            },
            "Linear_297": {
                "variable": {
                    "value": "self.value",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.all_head_size",
                    "possible_values": []
                }
            },
            "Dropout_299": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "config.attention_probs_dropout_prob",
                    "possible_values": []
                }
            },
            "matmul_327": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "matmul_339": {
                "variable": {
                    "value": "context_layer",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_value_layer)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_350": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "possible_values": [
                        [
                            "self.transpose_for_scores(mixed_query_layer)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "stack_381": {
                "variable": {
                    "value": "jacobian_full",
                    "possible_values": []
                },
                "tensors": {
                    "value": "jacobian_full",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(jacobian_full, dim=2)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "matmul_405": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "weights",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(logits)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "v",
                    "possible_values": []
                }
            },
            "einsum_409": {
                "variable": {
                    "value": "diag_flat_weights",
                    "possible_values": []
                },
                "equation": {
                    "value": "ij,jqk->iqjk",
                    "possible_values": []
                },
                "*operands": {
                    "value": "torch.eye(weights.shape[0])",
                    "possible_values": []
                }
            },
            "cat_417": {
                "variable": {
                    "value": "jac_out_wrt_weights",
                    "possible_values": []
                },
                "tensors": {
                    "value": "out.shape[1] * [v[:, None]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_553": {
                "variable": {
                    "value": "self.dense",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "Dropout_555": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "possible_values": []
                }
            },
            "Linear_610": {
                "variable": {
                    "value": "self.dense",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.intermediate_size",
                    "possible_values": []
                }
            },
            "Linear_631": {
                "variable": {
                    "value": "self.dense",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.intermediate_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "Dropout_633": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "possible_values": []
                }
            },
            "ModuleList_691": {
                "variable": {
                    "value": "self.layer",
                    "possible_values": []
                },
                "modules": {
                    "value": "[copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]",
                    "possible_values": []
                }
            },
            "Linear_725": {
                "variable": {
                    "value": "self.dense",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "Tanh_726": {
                "variable": {
                    "value": "self.activation",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "zeros_like_746": {
                "variable": {
                    "value": "relevance_score_all",
                    "possible_values": []
                },
                "input": {
                    "value": "pooler_in",
                    "possible_values": [
                        [
                            "func_inputs['model.bert.pooler'][0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "Dropout_834": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "possible_values": []
                }
            },
            "Linear_835": {
                "variable": {
                    "value": "self.classifier",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_labels",
                    "possible_values": []
                }
            },
            "zeros_like_897": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "stack_901": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "tensors": {
                    "value": "12 * [attention_scores]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "unsqueeze_901": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "zeros_like_269": {
                "variable": {
                    "value": "token_type_ids",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "possible_values": []
                }
            },
            "zeros_like_375": {
                "variable": {
                    "value": "jac_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "tensor_out",
                    "possible_values": []
                }
            },
            "ones_like_780": {
                "variable": {
                    "value": "attention_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "possible_values": []
                }
            },
            "zeros_like_782": {
                "variable": {
                    "value": "token_type_ids",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_862": {
                "variable": {
                    "value": "loss_fct",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "matmul_904": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_scores",
                    "possible_values": [
                        [
                            "torch.matmul(query_layer, key_layer.transpose(-1, -2))",
                            "Call"
                        ],
                        [
                            "attention_scores / math.sqrt(self.attention_head_size)",
                            "BinOp"
                        ],
                        [
                            "attention_scores + attention_mask",
                            "BinOp"
                        ],
                        [
                            "torch.matmul(query_layer, key_layer.transpose(-1, -2))",
                            "Call"
                        ],
                        [
                            "attention_scores / math.sqrt(self.attention_head_size)",
                            "BinOp"
                        ],
                        [
                            "attention_scores + attention_mask",
                            "BinOp"
                        ],
                        [
                            "torch.zeros_like(input_ids, dtype=torch.float)",
                            "Call"
                        ],
                        [
                            "torch.stack(12 * [attention_scores], dim=1).unsqueeze(dim=2)",
                            "Call"
                        ],
                        [
                            "torch.matmul(attention_scores, attention_probs[i])",
                            "Call"
                        ],
                        [
                            "attention_scores.sum(dim=1).squeeze(dim=1).unsqueeze(dim=-1).data",
                            "Attribute"
                        ]
                    ]
                },
                "other": {
                    "value": "attention_probs[i]",
                    "possible_values": []
                }
            },
            "erf_155": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "possible_values": []
                }
            },
            "ones_240": {
                "*size": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "zeros_241": {
                "*size": {
                    "value": "config.hidden_size",
                    "possible_values": []
                }
            },
            "sqrt_247": {
                "input": {
                    "value": "s + self.variance_epsilon",
                    "possible_values": []
                }
            },
            "Softmax_333": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Softmax_356": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "matmul_403": {
                "input": {
                    "value": "q",
                    "possible_values": [
                        [
                            "q / key_depth_per_head ** 0.5",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "k.permute(0, 2, 1)",
                    "possible_values": []
                }
            },
            "Softmax_404": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "eye_410": {
                "n": {
                    "value": "weights.shape[0]",
                    "possible_values": []
                }
            },
            "cat_501": {
                "variable": {
                    "value": "attention_mask_flat",
                    "possible_values": []
                },
                "tensors": {
                    "value": "n_h * [attention_mask]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "reshape_501": {
                "variable": {
                    "value": "attention_mask_flat",
                    "possible_values": []
                },
                "input": {
                    "value": "[-1, 1, seq_l]",
                    "possible_values": []
                }
            },
            "stack_527": {
                "variable": {
                    "value": "flat_relevence_qs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "flat_relevence_qs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(flat_relevence_qs, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_528": {
                "variable": {
                    "value": "flat_relevence_ks",
                    "possible_values": []
                },
                "tensors": {
                    "value": "flat_relevence_ks",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(flat_relevence_ks, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_529": {
                "variable": {
                    "value": "flat_relevence_vs",
                    "possible_values": []
                },
                "tensors": {
                    "value": "flat_relevence_vs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(flat_relevence_vs, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "grad_570": {
                "outputs": {
                    "value": "output_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ],
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "output_in_input",
                    "possible_values": [
                        [
                            "func_inputs[layer_name][1]",
                            "Subscript"
                        ],
                        [
                            "func_inputs[layer_name][1]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_578": {
                "outputs": {
                    "value": "output_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ],
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "dense_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name_dense]",
                            "Subscript"
                        ],
                        [
                            "func_activations[layer_name_dense]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_648": {
                "outputs": {
                    "value": "output_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ],
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "output_in_input",
                    "possible_values": [
                        [
                            "func_inputs[layer_name][1]",
                            "Subscript"
                        ],
                        [
                            "func_inputs[layer_name][1]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_656": {
                "outputs": {
                    "value": "output_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ],
                        [
                            "func_activations[layer_name]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "dense_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name_dense]",
                            "Subscript"
                        ],
                        [
                            "func_activations[layer_name_dense]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_871": {
                "outputs": {
                    "value": "classifier_out",
                    "possible_values": [
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ],
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ],
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "embedding_output",
                    "possible_values": [
                        [
                            "self.embeddings(input_ids, token_type_ids)",
                            "Call"
                        ],
                        [
                            "func_activations['model.bert.embeddings']",
                            "Subscript"
                        ],
                        [
                            "func_activations['model.bert.embeddings']",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "sensitivity_grads",
                    "possible_values": [
                        [
                            "torch.autograd.grad(classifier_out, embedding_output, grad_outputs=sensitivity_grads, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "torch.autograd.grad(classifier_out, embedding_output, grad_outputs=sensitivity_grads, retain_graph=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_879": {
                "outputs": {
                    "value": "classifier_out",
                    "possible_values": [
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ],
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ],
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "embedding_output",
                    "possible_values": [
                        [
                            "self.embeddings(input_ids, token_type_ids)",
                            "Call"
                        ],
                        [
                            "func_activations['model.bert.embeddings']",
                            "Subscript"
                        ],
                        [
                            "func_activations['model.bert.embeddings']",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "sensitivity_grads",
                    "possible_values": [
                        [
                            "torch.autograd.grad(classifier_out, embedding_output, grad_outputs=sensitivity_grads, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "torch.autograd.grad(classifier_out, embedding_output, grad_outputs=sensitivity_grads, retain_graph=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_377": {
                "outputs": {
                    "value": "tensor_out",
                    "possible_values": []
                },
                "inputs": {
                    "value": "tensor_in",
                    "possible_values": []
                },
                "grad_outputs": {
                    "value": "jac_mask",
                    "possible_values": [
                        [
                            "torch.zeros_like(tensor_out)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "eye_412": {
                "n": {
                    "value": "dim_per_head",
                    "possible_values": []
                }
            },
            "eye_421": {
                "n": {
                    "value": "weights.shape[-1]",
                    "possible_values": []
                }
            },
            "eye_431": {
                "n": {
                    "value": "jac_out_wrt_q.shape[1]",
                    "possible_values": []
                }
            },
            "eye_433": {
                "n": {
                    "value": "q.shape[0]",
                    "possible_values": []
                }
            },
            "eye_434": {
                "n": {
                    "value": "q.shape[0]",
                    "possible_values": []
                }
            },
            "grad_464": {
                "outputs": {
                    "value": "context_layer",
                    "possible_values": [
                        [
                            "torch.matmul(attention_probs, value_layer)",
                            "Call"
                        ],
                        [
                            "context_layer.permute(0, 2, 1, 3).contiguous()",
                            "Call"
                        ],
                        [
                            "context_layer.view(*new_context_layer_shape)",
                            "Call"
                        ],
                        [
                            "func_activations[layer_name_self][0]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "query_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name_query]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_468": {
                "outputs": {
                    "value": "context_layer",
                    "possible_values": [
                        [
                            "torch.matmul(attention_probs, value_layer)",
                            "Call"
                        ],
                        [
                            "context_layer.permute(0, 2, 1, 3).contiguous()",
                            "Call"
                        ],
                        [
                            "context_layer.view(*new_context_layer_shape)",
                            "Call"
                        ],
                        [
                            "func_activations[layer_name_self][0]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "key_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name_key]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "grad_472": {
                "outputs": {
                    "value": "context_layer",
                    "possible_values": [
                        [
                            "torch.matmul(attention_probs, value_layer)",
                            "Call"
                        ],
                        [
                            "context_layer.permute(0, 2, 1, 3).contiguous()",
                            "Call"
                        ],
                        [
                            "context_layer.view(*new_context_layer_shape)",
                            "Call"
                        ],
                        [
                            "func_activations[layer_name_self][0]",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "value_out",
                    "possible_values": [
                        [
                            "func_activations[layer_name_value]",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "relevance_score",
                    "possible_values": [
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "self.transpose_for_context(relevance_score)",
                            "Call"
                        ],
                        [
                            "relevance_query + relevance_key + relevance_value",
                            "BinOp"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.self.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "torch.autograd.grad(output_out, dense_out, grad_outputs=relevance_score, retain_graph=True)[0]",
                            "Subscript"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.intermediate.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "relevance_score + relevance_score_residual",
                            "BinOp"
                        ],
                        [
                            "self.attention.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "layer_module.backward_lrp(relevance_score, layer_module_index)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.dense.weight, self.dense.bias, dense_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.pooler.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "self.encoder.backward_lrp(relevance_score)",
                            "Call"
                        ],
                        [
                            "backprop_lrp_fc(self.classifier.weight, self.classifier.bias, classifier_in, relevance_score)",
                            "Call"
                        ],
                        [
                            "self.bert.backward_lrp(relevance_score)",
                            "Call"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "code/model/LSTM.py": {
        "torch": {
            "LSTM_50": {
                "variable": {
                    "value": "self.attendedEncoder",
                    "possible_values": []
                },
                "*args": {
                    "value": "self.encoder_in",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Dropout_54": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "attn_dropout",
                    "possible_values": [
                        [
                            "0.1",
                            "Constant"
                        ]
                    ]
                }
            },
            "Sequential_55": {
                "variable": {
                    "value": "self.encoder_gate",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.encoder_out, 128)",
                    "possible_values": []
                }
            },
            "Linear_67": {
                "variable": {
                    "value": "self.out_fc1",
                    "possible_values": []
                },
                "in_features": {
                    "value": "final_out",
                    "possible_values": [
                        [
                            "self.encoder_out",
                            "Attribute"
                        ]
                    ]
                },
                "out_features": {
                    "value": "h_out",
                    "possible_values": [
                        [
                            "64",
                            "Constant"
                        ]
                    ]
                }
            },
            "Linear_68": {
                "variable": {
                    "value": "self.classifier",
                    "possible_values": []
                },
                "in_features": {
                    "value": "h_out",
                    "possible_values": [
                        [
                            "64",
                            "Constant"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_labels",
                    "possible_values": [
                        [
                            "3",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "softmax_106": {
                "variable": {
                    "value": "attn",
                    "possible_values": []
                },
                "input": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "self.encoder_gate(attended_out)",
                            "Call"
                        ],
                        [
                            "attn.masked_fill(mask_bool == 0, -1000000000.0)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "matmul_109": {
                "variable": {
                    "value": "hs_attend",
                    "possible_values": []
                },
                "input": {
                    "value": "attn.permute(0, 2, 1)",
                    "possible_values": []
                },
                "other": {
                    "value": "attended_out",
                    "possible_values": []
                }
            },
            "squeeze_109": {
                "variable": {
                    "value": "hs_attend",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "relu_112": {
                "variable": {
                    "value": "hs_attend",
                    "possible_values": []
                },
                "input": {
                    "value": "hs_attend",
                    "possible_values": [
                        [
                            "torch.matmul(attn.permute(0, 2, 1), attended_out).squeeze(dim=1)",
                            "Call"
                        ],
                        [
                            "self.out_fc1(hs_attend)",
                            "Call"
                        ],
                        [
                            "F.relu(hs_attend)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_141": {
                "variable": {
                    "value": "tf_attns",
                    "possible_values": []
                },
                "tensors": {
                    "value": "enc_slf_attn_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "enc_slf_attn_list + [enc_slf_attn]",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "permute_141": {
                "variable": {
                    "value": "tf_attns",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "possible_values": []
                },
                "dims": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_152": {
                "variable": {
                    "value": "raw_attns",
                    "possible_values": []
                },
                "tensors": {
                    "value": "raw_attns",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(raw_attns, dim=0).sum(dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "sum_152": {
                "variable": {
                    "value": "raw_attns",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Embedding_42": {
                "variable": {
                    "value": "self.word_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.encoder_in",
                    "possible_values": []
                }
            },
            "Embedding_47": {
                "variable": {
                    "value": "self.word_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.encoder_in",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_116": {
                "variable": {
                    "value": "loss_fct",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Linear_55": {
                "in_features": {
                    "value": "self.encoder_out",
                    "possible_values": []
                },
                "out_features": {
                    "value": "128",
                    "possible_values": []
                }
            },
            "ReLU_56": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_57": {
                "p": {
                    "value": "0.3",
                    "possible_values": []
                }
            },
            "Linear_58": {
                "in_features": {
                    "value": "128",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "possible_values": []
                }
            },
            "ReLU_59": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_60": {
                "p": {
                    "value": "0.3",
                    "possible_values": []
                }
            },
            "Linear_61": {
                "in_features": {
                    "value": "64",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "grad_125": {
                "outputs": {
                    "value": "classifier_out",
                    "possible_values": [
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "embedding_output",
                    "possible_values": [
                        [
                            "func_activations['model.word_embeddings']",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "sensitivity_grads",
                    "possible_values": [
                        [
                            "torch.autograd.grad(classifier_out, embedding_output, grad_outputs=sensitivity_grads, retain_graph=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "matmul_148": {
                "variable": {
                    "value": "curr_tf_attn",
                    "possible_values": []
                },
                "input": {
                    "value": "pre_attn",
                    "possible_values": [
                        [
                            "ctx_attn.clone().permute(0, 2, 1)",
                            "Call"
                        ],
                        [
                            "curr_tf_attn",
                            "Name"
                        ]
                    ]
                },
                "other": {
                    "value": "tf_attn[i]",
                    "possible_values": []
                }
            }
        }
    },
    "code/model/transformer.py": {
        "torch": {
            "stack_84": {
                "variable": {
                    "value": "stacked",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[pad_shift(x, i) for i in range(attn.shape[2])]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "sum_86": {
                "input": {
                    "value": "attn.unsqueeze(2) * stacked",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Dropout_104": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "attn_dropout",
                    "possible_values": [
                        [
                            "0.1",
                            "Constant"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "matmul_108": {
                "variable": {
                    "value": "attention_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "query_layer",
                    "possible_values": []
                },
                "other": {
                    "value": "key_layer.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "matmul_120": {
                "variable": {
                    "value": "context_layer",
                    "possible_values": []
                },
                "input": {
                    "value": "attention_probs",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(attention_scores)",
                            "Call"
                        ],
                        [
                            "self.dropout(attention_probs)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "value_layer",
                    "possible_values": []
                }
            },
            "Linear_134": {
                "variable": {
                    "value": "self.w_qs",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "n_head * d_k",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_135": {
                "variable": {
                    "value": "self.w_ks",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "n_head * d_k",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_136": {
                "variable": {
                    "value": "self.w_vs",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "n_head * d_v",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_137": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_head * d_v",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Dropout_141": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "LayerNorm_142": {
                "variable": {
                    "value": "self.layer_norm",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "d_model",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-06",
                    "possible_values": []
                }
            },
            "Linear_186": {
                "variable": {
                    "value": "self.w_1",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_in",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_hid",
                    "possible_values": []
                }
            },
            "Linear_187": {
                "variable": {
                    "value": "self.w_2",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_hid",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_in",
                    "possible_values": []
                }
            },
            "LayerNorm_188": {
                "variable": {
                    "value": "self.layer_norm",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "d_in",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-06",
                    "possible_values": []
                }
            },
            "Dropout_189": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "relu_196": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.w_1(x)",
                    "possible_values": []
                }
            },
            "Dropout_230": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ModuleList_231": {
                "variable": {
                    "value": "self.layer_stack",
                    "possible_values": []
                },
                "modules": {
                    "value": "[EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout) for _ in range(n_layers)]",
                    "possible_values": []
                }
            },
            "LayerNorm_234": {
                "variable": {
                    "value": "self.layer_norm",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "d_model",
                    "possible_values": []
                },
                "eps": {
                    "value": "1e-06",
                    "possible_values": []
                }
            },
            "Dropout_282": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "attn_dropout",
                    "possible_values": [
                        [
                            "0.1",
                            "Constant"
                        ],
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Sequential_283": {
                "variable": {
                    "value": "self.encoder_gate",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.encoder_out, 128)",
                    "possible_values": []
                }
            },
            "Linear_295": {
                "variable": {
                    "value": "self.out_fc1",
                    "possible_values": []
                },
                "in_features": {
                    "value": "final_out",
                    "possible_values": [
                        [
                            "self.encoder_out",
                            "Attribute"
                        ]
                    ]
                },
                "out_features": {
                    "value": "h_out",
                    "possible_values": [
                        [
                            "64",
                            "Constant"
                        ]
                    ]
                }
            },
            "Linear_296": {
                "variable": {
                    "value": "self.classifier",
                    "possible_values": []
                },
                "in_features": {
                    "value": "h_out",
                    "possible_values": [
                        [
                            "64",
                            "Constant"
                        ]
                    ]
                },
                "out_features": {
                    "value": "n_labels",
                    "possible_values": [
                        [
                            "3",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "softmax_336": {
                "variable": {
                    "value": "attn",
                    "possible_values": []
                },
                "input": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "self.encoder_gate(attended_out)",
                            "Call"
                        ],
                        [
                            "attn.masked_fill(mask_bool == 0, -1000000000.0)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "matmul_339": {
                "variable": {
                    "value": "hs_attend",
                    "possible_values": []
                },
                "input": {
                    "value": "attn.permute(0, 2, 1)",
                    "possible_values": []
                },
                "other": {
                    "value": "attended_out",
                    "possible_values": [
                        [
                            "self.attendedEncoder(inputs, extended_attention_mask)",
                            "Call"
                        ]
                    ]
                }
            },
            "squeeze_339": {
                "variable": {
                    "value": "hs_attend",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "relu_342": {
                "variable": {
                    "value": "hs_attend",
                    "possible_values": []
                },
                "input": {
                    "value": "hs_attend",
                    "possible_values": [
                        [
                            "torch.matmul(attn.permute(0, 2, 1), attended_out).squeeze(dim=1)",
                            "Call"
                        ],
                        [
                            "self.out_fc1(hs_attend)",
                            "Call"
                        ],
                        [
                            "F.relu(hs_attend)",
                            "Call"
                        ]
                    ]
                }
            },
            "stack_371": {
                "variable": {
                    "value": "tf_attns",
                    "possible_values": []
                },
                "tensors": {
                    "value": "enc_slf_attn_list",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "enc_slf_attn_list + [enc_slf_attn]",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "permute_371": {
                "variable": {
                    "value": "tf_attns",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "possible_values": []
                },
                "dims": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_382": {
                "variable": {
                    "value": "raw_attns",
                    "possible_values": []
                },
                "tensors": {
                    "value": "raw_attns",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(raw_attns, dim=0).sum(dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "sum_382": {
                "variable": {
                    "value": "raw_attns",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_75": {
                "tensors": {
                    "value": "(padding, x[:, :-shift, :])",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Embedding_265": {
                "variable": {
                    "value": "self.word_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.encoder_in",
                    "possible_values": []
                }
            },
            "Embedding_270": {
                "variable": {
                    "value": "self.word_embeddings",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.encoder_in",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_346": {
                "variable": {
                    "value": "loss_fct",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ones_74": {
                "*size": {
                    "value": "x.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "shift",
                    "possible_values": []
                },
                "dtype": {
                    "value": "x.size(2)",
                    "possible_values": []
                }
            },
            "cat_78": {
                "tensors": {
                    "value": "(x[:, -shift:, :], padding)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Softmax_114": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_283": {
                "in_features": {
                    "value": "self.encoder_out",
                    "possible_values": []
                },
                "out_features": {
                    "value": "128",
                    "possible_values": []
                }
            },
            "ReLU_284": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_285": {
                "p": {
                    "value": "0.3",
                    "possible_values": []
                }
            },
            "Linear_286": {
                "in_features": {
                    "value": "128",
                    "possible_values": []
                },
                "out_features": {
                    "value": "64",
                    "possible_values": []
                }
            },
            "ReLU_287": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_288": {
                "p": {
                    "value": "0.3",
                    "possible_values": []
                }
            },
            "Linear_289": {
                "in_features": {
                    "value": "64",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "grad_355": {
                "outputs": {
                    "value": "classifier_out",
                    "possible_values": [
                        [
                            "func_activations['model.classifier']",
                            "Subscript"
                        ]
                    ]
                },
                "inputs": {
                    "value": "embedding_output",
                    "possible_values": [
                        [
                            "func_activations['model.word_embeddings']",
                            "Subscript"
                        ]
                    ]
                },
                "grad_outputs": {
                    "value": "sensitivity_grads",
                    "possible_values": [
                        [
                            "torch.autograd.grad(classifier_out, embedding_output, grad_outputs=sensitivity_grads, retain_graph=True)[0]",
                            "Subscript"
                        ]
                    ]
                },
                "retain_graph": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "matmul_378": {
                "variable": {
                    "value": "curr_tf_attn",
                    "possible_values": []
                },
                "input": {
                    "value": "pre_attn",
                    "possible_values": [
                        [
                            "ctx_attn.clone().permute(0, 2, 1)",
                            "Call"
                        ],
                        [
                            "curr_tf_attn",
                            "Name"
                        ]
                    ]
                },
                "other": {
                    "value": "tf_attn[i]",
                    "possible_values": []
                }
            },
            "ones_77": {
                "*size": {
                    "value": "x.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "-shift",
                    "possible_values": []
                },
                "dtype": {
                    "value": "x.size(2)",
                    "possible_values": []
                }
            },
            "triu_94": {
                "input": {
                    "value": "torch.ones((1, len_s, len_s), device=seq.device)",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ones_95": {
                "*size": {
                    "value": "(1, len_s, len_s)",
                    "possible_values": []
                },
                "device": {
                    "value": "seq.device",
                    "possible_values": []
                }
            }
        }
    },
    "code/run_classifier.py": {
        "torch": {}
    },
    "code/util/lrp.py": {
        "torch": {
            "abs_13": {
                "variable": {
                    "value": "inp_relevances",
                    "possible_values": []
                },
                "input": {
                    "value": "inp_relevances",
                    "possible_values": [
                        [
                            "torch.abs(inp_relevances)",
                            "Call"
                        ],
                        [
                            "inp_relevances * scaler",
                            "BinOp"
                        ]
                    ]
                }
            },
            "clamp_28": {
                "variable": {
                    "value": "weight_p",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "possible_values": []
                },
                "min": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "clamp_29": {
                "variable": {
                    "value": "bias_p",
                    "possible_values": []
                },
                "input": {
                    "value": "bias",
                    "possible_values": []
                },
                "min": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "matmul_32": {
                "variable": {
                    "value": "c_p",
                    "possible_values": []
                },
                "input": {
                    "value": "s_p",
                    "possible_values": [
                        [
                            "R / z_p",
                            "BinOp"
                        ],
                        [
                            "R / z_p",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_p",
                    "possible_values": [
                        [
                            "torch.clamp(weight, min=0.0)",
                            "Call"
                        ],
                        [
                            "torch.clamp(weight, min=0.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "clamp_34": {
                "variable": {
                    "value": "weight_n",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "possible_values": []
                },
                "max": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "clamp_35": {
                "variable": {
                    "value": "bias_n",
                    "possible_values": []
                },
                "input": {
                    "value": "bias",
                    "possible_values": []
                },
                "max": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "matmul_38": {
                "variable": {
                    "value": "c_n",
                    "possible_values": []
                },
                "input": {
                    "value": "s_n",
                    "possible_values": [
                        [
                            "R / z_n",
                            "BinOp"
                        ],
                        [
                            "R / z_n",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_n",
                    "possible_values": [
                        [
                            "torch.clamp(weight, max=0.0)",
                            "Call"
                        ],
                        [
                            "torch.clamp(weight, max=0.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "clamp_59": {
                "variable": {
                    "value": "weight_p",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "possible_values": []
                },
                "min": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "matmul_62": {
                "variable": {
                    "value": "c_p",
                    "possible_values": []
                },
                "input": {
                    "value": "s_p",
                    "possible_values": [
                        [
                            "R / z_p",
                            "BinOp"
                        ],
                        [
                            "R / z_p",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_p",
                    "possible_values": [
                        [
                            "torch.clamp(weight, min=0.0)",
                            "Call"
                        ],
                        [
                            "torch.clamp(weight, min=0.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "clamp_64": {
                "variable": {
                    "value": "weight_n",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "possible_values": []
                },
                "max": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "matmul_67": {
                "variable": {
                    "value": "c_n",
                    "possible_values": []
                },
                "input": {
                    "value": "s_n",
                    "possible_values": [
                        [
                            "R / z_n",
                            "BinOp"
                        ],
                        [
                            "R / z_n",
                            "BinOp"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_n",
                    "possible_values": [
                        [
                            "torch.clamp(weight, max=0.0)",
                            "Call"
                        ],
                        [
                            "torch.clamp(weight, max=0.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_106": {
                "variable": {
                    "value": "flat_jacobian",
                    "possible_values": []
                },
                "tensors": {
                    "value": "jac_flat_components",
                    "possible_values": [
                        [
                            "[jac.reshape([output_size, -1]) for jac in jacobians]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_109": {
                "variable": {
                    "value": "flat_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[inp.reshape([-1]) for inp in inps]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_110": {
                "variable": {
                    "value": "flat_reference_input",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[ref.reshape([-1]) for ref in reference_inputs]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "clamp_119": {
                "variable": {
                    "value": "flat_positive_impact",
                    "possible_values": []
                },
                "input": {
                    "value": "flat_impact",
                    "possible_values": [
                        [
                            "flat_jacobian * flat_input[None, :]",
                            "BinOp"
                        ]
                    ]
                },
                "min": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "clamp_123": {
                "variable": {
                    "value": "flat_negative_impact",
                    "possible_values": []
                },
                "input": {
                    "value": "flat_impact",
                    "possible_values": [
                        [
                            "flat_jacobian * flat_input[None, :]",
                            "BinOp"
                        ]
                    ]
                },
                "max": {
                    "value": "0.0",
                    "possible_values": []
                }
            },
            "einsum_128": {
                "variable": {
                    "value": "flat_input_relevance",
                    "possible_values": []
                },
                "equation": {
                    "value": "o,oi->i",
                    "possible_values": []
                },
                "*operands": {
                    "value": "flat_output_relevance",
                    "possible_values": [
                        [
                            "R.reshape([-1])",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_60": {
                "input": {
                    "value": "activations",
                    "possible_values": [
                        [
                            "activations.unsqueeze(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_p.transpose(2, 3)",
                    "possible_values": []
                }
            },
            "matmul_65": {
                "input": {
                    "value": "activations",
                    "possible_values": [
                        [
                            "activations.unsqueeze(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_n.transpose(2, 3)",
                    "possible_values": []
                }
            },
            "sum_15": {
                "input": {
                    "value": "post_A",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_16": {
                "input": {
                    "value": "inp_relevances",
                    "possible_values": [
                        [
                            "torch.abs(inp_relevances)",
                            "Call"
                        ],
                        [
                            "inp_relevances * scaler",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "matmul_30": {
                "input": {
                    "value": "activations",
                    "possible_values": [
                        [
                            "activations.unsqueeze(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_p.T",
                    "possible_values": []
                }
            },
            "matmul_36": {
                "input": {
                    "value": "activations",
                    "possible_values": [
                        [
                            "activations.unsqueeze(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "weight_n.T",
                    "possible_values": []
                }
            }
        }
    },
    "code/util/optimization.py": {
        "torch": {
            "cos_17": {
                "input": {
                    "value": "math.pi * x",
                    "possible_values": []
                }
            },
            "zeros_like_104": {
                "variable": {
                    "value": "state[exp_avg]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "zeros_like_106": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "zeros_like_133": {
                "variable": {
                    "value": "state[next_m]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "zeros_like_135": {
                "variable": {
                    "value": "state[next_v]",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "possible_values": []
                }
            },
            "clip_grad_norm__142": {
                "parameters": {
                    "value": "p",
                    "possible_values": [
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ],
                        [
                            "group['params']",
                            "Subscript"
                        ]
                    ]
                },
                "max_norm": {
                    "value": "group['max_grad_norm']",
                    "possible_values": []
                }
            }
        }
    }
}