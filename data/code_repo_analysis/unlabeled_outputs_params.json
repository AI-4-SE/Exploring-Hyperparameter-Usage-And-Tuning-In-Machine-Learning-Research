{
    "code/fairseq/fairseq/benchmark/dummy_lm.py": {
        "torch": {
            "arange_35": {
                "start": {
                    "value": "args.tokens_per_sample + 1",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "stack_62": {
                "tensors": {
                    "value": "[self.dummy_tgt for _ in range(bsz)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "stack_59": {
                "tensors": {
                    "value": "[self.dummy_src for _ in range(bsz)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "full_60": {
                "size": {
                    "value": "(bsz,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "self.args.tokens_per_sample",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/benchmark/dummy_masked_lm.py": {
        "torch": {
            "arange_42": {
                "variable": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "args.tokens_per_sample",
                    "type": "Attribute",
                    "possible_values": []
                },
                "step": {
                    "value": "7",
                    "type": "int",
                    "possible_values": []
                }
            },
            "full_like_45": {
                "variable": {
                    "value": "tgt",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "seq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.arange(args.tokens_per_sample) + pad_idx + 1",
                            "BinOp"
                        ]
                    ]
                },
                "fill_value": {
                    "value": "pad_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1",
                            "int"
                        ]
                    ]
                }
            },
            "arange_41": {
                "start": {
                    "value": "args.tokens_per_sample",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_73": {
                "tensors": {
                    "value": "[self.dummy_tgt for _ in range(bsz)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "stack_70": {
                "tensors": {
                    "value": "[self.dummy_src for _ in range(bsz)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "full_71": {
                "size": {
                    "value": "(bsz,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "self.args.tokens_per_sample",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/benchmark/dummy_model.py": {
        "torch": {
            "Embedding_47": {
                "variable": {
                    "value": "self.embed",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "50000",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_50": {
                "variable": {
                    "value": "self.layers_a",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 3 * embed_dim), nn.Linear(3 * embed_dim, embed_dim), nn.Linear(embed_dim, embed_dim), nn.Dropout()) for i in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_60": {
                "variable": {
                    "value": "self.layers_b",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 4 * embed_dim), nn.ReLU(), nn.Linear(4 * embed_dim, embed_dim), nn.Dropout(0.1)) for i in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Linear_70": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "50000",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_88": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output[0].float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_90": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output[0].float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Sequential_51": {
                "*args": {
                    "value": "nn.LayerNorm(embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_61": {
                "*args": {
                    "value": "nn.LayerNorm(embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "LayerNorm_52": {
                "normalized_shape": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_53": {
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "3 * embed_dim",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_54": {
                "in_features": {
                    "value": "3 * embed_dim",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_55": {
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_56": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "LayerNorm_62": {
                "normalized_shape": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_63": {
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "4 * embed_dim",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ReLU_64": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_65": {
                "in_features": {
                    "value": "4 * embed_dim",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1024",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_66": {
                "p": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/binarizer.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/bleu.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/checkpoint_utils.py": {
        "torch": {
            "load_165": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "f in enumerate(files)",
                            "Call"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, l: default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "save_234": {
                "obj": {
                    "value": "*args",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "is_tensor_248": {
                "obj": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'args': args, 'model': model_state_dict if model_state_dict else {}, 'optimizer_history': optim_history + [{'criterion_name': criterion.__class__.__name__, 'optimizer_name': optimizer.__class__.__name__, 'lr_scheduler_state': lr_scheduler.state_dict(), 'num_updates': num_updates}], 'extra_state': extra_state}",
                            "Dict"
                        ],
                        [
                            "state_dict",
                            "Method Argument"
                        ],
                        [
                            "state_dict",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/adaptive_loss.py": {
        "torch": {
            "cross_entropy_62": {
                "input": {
                    "value": "logits[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "target": {
                    "value": "target[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum if reduce else none",
                    "type": "IfExp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/binary_cross_entropy.py": {
        "torch": {
            "cross_entropy_56": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_logits(net_output).float()",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, net_output)",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum if reduce else none",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_58": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_logits(net_output).float()",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "model.get_target_weights(target, net_output)",
                            "Call"
                        ],
                        [
                            "weights.float()",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum if reduce else none",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "is_tensor_50": {
                "obj": {
                    "value": "weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "model.get_target_weights(target, net_output)",
                            "Call"
                        ],
                        [
                            "weights.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_65": {
                "obj": {
                    "value": "extra_losses",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_extra_losses(net_output)",
                            "Call"
                        ],
                        [
                            "[extra_losses]",
                            "List"
                        ]
                    ]
                }
            },
            "no_grad_92": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/composite_loss.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/criterions/cross_entropy.py": {
        "torch": {
            "nll_loss_44": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_normalized_probs(net_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "lprobs.view(-1, lprobs.size(-1))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, net_output).view(-1)",
                            "Call"
                        ]
                    ]
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum if reduce else none",
                    "type": "IfExp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/fairseq_criterion.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/criterions/legacy_masked_lm.py": {
        "torch": {
            "nll_loss_24": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.log_softmax(logits, -1, dtype=torch.float32)",
                    "type": "Call",
                    "possible_values": []
                },
                "target": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "targets",
                            "Method Argument"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "ignore_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-100",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_25": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "logits",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/masked_lm.py": {
        "torch": {
            "nll_loss_50": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.log_softmax(logits.view(-1, logits.size(-1)), dim=-1, dtype=torch.float32)",
                    "type": "Call",
                    "possible_values": []
                },
                "target": {
                    "value": "targets.view(-1)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "where_40": {
                "variable": {
                    "value": "masked_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "masked_tokens.any()",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "masked_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sample['target'].ne(self.padding_idx)",
                            "Call"
                        ],
                        [
                            "torch.where(masked_tokens.any(), masked_tokens, masked_tokens.new([True]))",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "masked_tokens.new([True])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "device_36": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "log_softmax_51": {
                "input": {
                    "value": "logits.view(-1, logits.size(-1))",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/nat_loss.py": {
        "torch": {
            "tensor_56": {
                "variable": {
                    "value": "nll_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_59": {
                "variable": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "outputs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "outputs[masks]",
                            "Subscript"
                        ],
                        [
                            "model(src_tokens, src_lengths, prev_output_tokens, tgt_tokens)",
                            "Call"
                        ],
                        [
                            "outputs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "nll_loss_61": {
                "variable": {
                    "value": "losses",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(outputs, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets.to(logits.device)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            },
            "kl_div_64": {
                "variable": {
                    "value": "losses",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(outputs, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets.to(logits.device)",
                    "type": "Call",
                    "possible_values": []
                },
                "reduction": {
                    "value": "none",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/sentence_prediction.py": {
        "torch": {
            "log_softmax_53": {
                "variable": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(**sample['net_input'], features_only=True, classification_head_name=self.classification_head_name)",
                            "Call"
                        ],
                        [
                            "logits.view(-1).float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "nll_loss_54": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(logits, dim=-1, dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits]).view(-1)",
                            "Call"
                        ],
                        [
                            "targets.float()",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "mse_loss_58": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model(**sample['net_input'], features_only=True, classification_head_name=self.classification_head_name)",
                            "Call"
                        ],
                        [
                            "logits.view(-1).float()",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits]).view(-1)",
                            "Call"
                        ],
                        [
                            "targets.float()",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/criterions/sentence_ranking.py": {
        "torch": {
            "cat_62": {
                "variable": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_67": {
                "variable": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat(scores, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "nll_loss_68": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.log_softmax(logits, dim=-1, dtype=torch.float32)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.get_targets(sample, [logits]).view(-1)",
                            "Call"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "tensor_71": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/append_token_dataset.py": {
        "torch": {
            "cat_25": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item, item.new([self.token])]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/audio/raw_audio_dataset.py": {
        "torch": {
            "from_numpy_154": {
                "variable": {
                    "value": "feats",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "wav",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sf.read(fname)",
                            "Call"
                        ],
                        [
                            "wav",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "interpolate_47": {
                "input": {
                    "value": "x.view(1, 1, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "scale_factor": {
                    "value": "factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.sample_rate / curr_sample_rate",
                            "BinOp"
                        ],
                        [
                            "factor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "squeeze_47": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/backtranslation_dataset.py": {
        "torch": {
            "is_available_92": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/base_wrapper_dataset.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/colorize_dataset.py": {
        "torch": {
            "tensor_20": {
                "variable": {
                    "value": "base_collate[net_input][colors]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "list((self.color_getter(self.dataset, s['id']) for s in samples))",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/concat_dataset.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/concat_sentences_dataset.py": {
        "torch": {
            "cat_20": {
                "tensors": {
                    "value": "[ds[index] for ds in self.datasets]",
                    "type": "ListComp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/denoising_dataset.py": {
        "torch": {
            "arange_201": {
                "variable": {
                    "value": "ordering",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "num_sentences",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sentence_ends.size(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_262": {
                "variable": {
                    "value": "to_keep",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "source_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "source.size(0)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_321": {
                "variable": {
                    "value": "tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(tokens[0:1], tokens[offset:-1], tokens[1:offset], tokens[-1:])",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_335": {
                "variable": {
                    "value": "noise_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "(num_tokens + n,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "randint_341": {
                "variable": {
                    "value": "result[noise_indices[:num_random]]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "low": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "len(self.vocab)",
                    "type": "Call",
                    "possible_values": []
                },
                "size": {
                    "value": "(num_random,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Categorical_150": {
                "variable": {
                    "value": "self.mask_span_distribution",
                    "type": "Attribute",
                    "possible_values": []
                },
                "probs": {
                    "value": "ps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.FloatTensor(ps)",
                            "Call"
                        ]
                    ]
                }
            },
            "ones_216": {
                "variable": {
                    "value": "is_word_start",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "source.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cumsum_232": {
                "variable": {
                    "value": "cum_length",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.mask_span_distribution.sample(sample_shape=(num_to_mask,))",
                            "Call"
                        ],
                        [
                            "torch.ones((num_to_mask,)).long()",
                            "Call"
                        ],
                        [
                            "torch.cat([lengths, self.mask_span_distribution.sample(sample_shape=(num_to_mask,))], dim=0)",
                            "Call"
                        ],
                        [
                            "lengths[:num_to_mask]",
                            "Subscript"
                        ],
                        [
                            "lengths[lengths > 0]",
                            "Subscript"
                        ],
                        [
                            "lengths - is_word_start[indices + 1].long()",
                            "BinOp"
                        ],
                        [
                            "lengths[uncompleted]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_254": {
                "variable": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(num_to_mask,)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randint_269": {
                "variable": {
                    "value": "source[indices[mask_random]]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "low": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "len(self.vocab)",
                    "type": "Call",
                    "possible_values": []
                },
                "size": {
                    "value": "(mask_random.sum(),)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randperm_200": {
                "n": {
                    "value": "num_sentences",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sentence_ends.size(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "randperm_202": {
                "n": {
                    "value": "num_to_permute",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.ceil(num_sentences * 2 * p / 2.0)",
                            "Call"
                        ],
                        [
                            "math.ceil(num_words * 2 * p / 2.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_234": {
                "variable": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[lengths, self.mask_span_distribution.sample(sample_shape=(num_to_mask,))]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cumsum_235": {
                "variable": {
                    "value": "cum_length",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lengths",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.mask_span_distribution.sample(sample_shape=(num_to_mask,))",
                            "Call"
                        ],
                        [
                            "torch.ones((num_to_mask,)).long()",
                            "Call"
                        ],
                        [
                            "torch.cat([lengths, self.mask_span_distribution.sample(sample_shape=(num_to_mask,))], dim=0)",
                            "Call"
                        ],
                        [
                            "lengths[:num_to_mask]",
                            "Subscript"
                        ],
                        [
                            "lengths[lengths > 0]",
                            "Subscript"
                        ],
                        [
                            "lengths - is_word_start[indices + 1].long()",
                            "BinOp"
                        ],
                        [
                            "lengths[uncompleted]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randint_288": {
                "variable": {
                    "value": "source[indices[mask_random]]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "low": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "len(self.vocab)",
                    "type": "Call",
                    "possible_values": []
                },
                "size": {
                    "value": "(mask_random.sum(),)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randint_301": {
                "variable": {
                    "value": "source[indices[mask_random]]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "low": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "len(self.vocab)",
                    "type": "Call",
                    "possible_values": []
                },
                "size": {
                    "value": "(mask_random.sum(),)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randperm_315": {
                "n": {
                    "value": "num_words - 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "randperm_316": {
                "n": {
                    "value": "num_to_permute",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.ceil(num_sentences * 2 * p / 2.0)",
                            "Call"
                        ],
                        [
                            "math.ceil(num_words * 2 * p / 2.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "randperm_334": {
                "n": {
                    "value": "num_tokens + n - 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "randperm_257": {
                "n": {
                    "value": "word_starts.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/dictionary.py": {
        "torch": {
            "Tensor_270": {
                "variable": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "is_tensor_68": {
                "obj": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/encoders/utils.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/fairseq_dataset.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/id_dataset.py": {
        "torch": {
            "tensor_20": {
                "data": {
                    "value": "samples",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samples",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/indexed_dataset.py": {
        "torch": {
            "from_numpy_157": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "a",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "from_numpy_224": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty(n, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "self.cache[ptx:ptx + size]",
                            "Subscript"
                        ],
                        [
                            "np.empty(tensor_size, dtype=self.dtype)",
                            "Call"
                        ],
                        [
                            "a",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "from_numpy_479": {
                "ndarray": {
                    "value": "np_array",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.frombuffer(self._bin_buffer, dtype=self._index.dtype, count=size, offset=ptr)",
                            "Call"
                        ],
                        [
                            "np_array.astype(np.int64)",
                            "Call"
                        ],
                        [
                            "np.array(tensor.numpy(), dtype=self._dtype)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/iterators.py": {
        "torch": {
            "DataLoader_309": {
                "dataset": {
                    "value": "self.dataset",
                    "type": "Attribute",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "self.collate_fn",
                    "type": "Attribute",
                    "possible_values": []
                },
                "batch_sampler": {
                    "value": "batches[offset:]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(list(batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "list(ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[]))",
                            "Call"
                        ],
                        [
                            "shuffle_batches(list(self.frozen_batches), self.seed + epoch)",
                            "Call"
                        ],
                        [
                            "self.frozen_batches",
                            "Attribute"
                        ],
                        [
                            "shuffle_batches(batches, self.seed + epoch + self.shard_id)",
                            "Call"
                        ],
                        [
                            "list(ShardedIterator(batches, self.num_shards, self.shard_id, fill_value=[]))",
                            "Call"
                        ],
                        [
                            "batches",
                            "Method Argument"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "self.num_workers",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/language_pair_dataset.py": {
        "torch": {
            "unique_48": {
                "variable": {
                    "value": "(_, align_tgt_i, align_tgt_c)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "align_tgt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "alignments[:, 1]",
                            "Subscript"
                        ]
                    ]
                },
                "return_inverse": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "return_counts": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "index_select_65": {
                "variable": {
                    "value": "tgt_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "sort_order",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_lengths.sort(descending=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_97": {
                "variable": {
                    "value": "offsets",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(len(sort_order), 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_112": {
                "variable": {
                    "value": "alignments",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "alignments",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[alignment + offset for (align_idx, offset, src_len, tgt_len) in zip(sort_order, offsets, src_lengths, tgt_lengths) for alignment in [samples[align_idx]['alignment'].view(-1, 2)] if check_alignment(alignment, src_len, tgt_len)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(alignments, dim=0)",
                            "Call"
                        ],
                        [
                            "alignments",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_98": {
                "start": {
                    "value": "len(sort_order)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_198": {
                "variable": {
                    "value": "tgt_item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.tgt[index], torch.LongTensor([eos])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_203": {
                "variable": {
                    "value": "tgt_item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.LongTensor([bos]), self.tgt[index]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_207": {
                "variable": {
                    "value": "src_item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.LongTensor([bos]), self.src[index]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/legacy/block_pair_dataset.py": {
        "torch": {
            "cat_285": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.dataset[idx] for idx in range(start_ds_idx, end_ds_idx + 1)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/legacy/masked_lm_dataset.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/lm_context_window_dataset.py": {
        "torch": {
            "from_numpy_57": {
                "variable": {
                    "value": "sample[net_input][src_tokens]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_toks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.empty([bsz, tsz + self.context_window], dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_58": {
                "variable": {
                    "value": "sample[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "new_tgt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.full([bsz, tsz + self.context_window], pad, dtype=np.int64)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/mask_tokens_dataset.py": {
        "torch": {
            "from_numpy_172": {
                "ndarray": {
                    "value": "new_item",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.full(len(mask), self.pad_idx)",
                            "Call"
                        ],
                        [
                            "np.copy(item)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_131": {
                "ndarray": {
                    "value": "new_item",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.full(len(mask), self.pad_idx)",
                            "Call"
                        ],
                        [
                            "np.copy(item)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_130": {
                "ndarray": {
                    "value": "mask.astype(np.uint8)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/monolingual_dataset.py": {
        "torch": {
            "cat_134": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[source.new([self.vocab.bos()]), source]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_106": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[source, source.new([self.vocab.eos()])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_136": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[target.new([self.tgt_vocab.bos()]), target]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_109": {
                "variable": {
                    "value": "future_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[future_target, future_target.new([self.vocab.pad()])]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_113": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[past_target.new([self.vocab.pad()]), past_target[1:], source[-2, None]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/nested_dictionary_dataset.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/noising.py": {
        "torch": {
            "t_63": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.t(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "t_293": {
                "variable": {
                    "value": "src_tokens_t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.src_dataset[index]",
                            "Subscript"
                        ],
                        [
                            "src_tokens.unsqueeze(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "t_300": {
                "variable": {
                    "value": "noisy_src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "noisy_src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.word_shuffle.noising(x=x, lengths=lengths, max_shuffle_distance=self.max_word_shuffle_distance)",
                            "Call"
                        ],
                        [
                            "self.word_dropout.noising(x=noisy_src_tokens, lengths=noisy_src_lengths, dropout_prob=self.word_dropout_prob)",
                            "Call"
                        ],
                        [
                            "self.word_dropout.noising(x=noisy_src_tokens, lengths=noisy_src_lengths, dropout_prob=self.word_blanking_prob, blank_idx=self.dictionary.unk())",
                            "Call"
                        ],
                        [
                            "self.noiser.noising(src_tokens_t, src_lengths)",
                            "Call"
                        ],
                        [
                            "torch.t(noisy_src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "from_numpy_182": {
                "ndarray": {
                    "value": "permutation",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.argsort()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/numel_dataset.py": {
        "torch": {
            "is_tensor_20": {
                "obj": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dataset[index]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "numel_21": {
                "input": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dataset[index]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "tensor_32": {
                "data": {
                    "value": "samples",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samples",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/prepend_dataset.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/data/prepend_token_dataset.py": {
        "torch": {
            "cat_25": {
                "variable": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.token]), item]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/raw_label_dataset.py": {
        "torch": {
            "tensor_24": {
                "data": {
                    "value": "samples",
                    "type": "variable",
                    "possible_values": [
                        [
                            "samples",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/data/roll_dataset.py": {
        "torch": {
            "roll_19": {
                "input": {
                    "value": "item",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dataset[index]",
                            "Subscript"
                        ]
                    ]
                },
                "shifts": {
                    "value": "self.shifts",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/token_block_dataset.py": {
        "torch": {
            "cat_122": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.dataset[idx] for idx in range(start_ds_idx, end_ds_idx + 1)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "is_tensor_68": {
                "obj": {
                    "value": "sizes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sizes",
                            "Call"
                        ],
                        [
                            "np.array(sizes, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "sizes.numpy()",
                            "Call"
                        ],
                        [
                            "sizes.astype(np.int64)",
                            "Call"
                        ],
                        [
                            "sizes",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_136": {
                "variable": {
                    "value": "source",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.eos]), buffer[0:e - 1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_137": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.pad, self.eos]), buffer[0:e - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_143": {
                "variable": {
                    "value": "past_target",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item.new([self.eos]), buffer[0:e - 2]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/transform_eos_dataset.py": {
        "torch": {
            "cat_83": {
                "variable": {
                    "value": "item[source]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item['source'], self.eos]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_91": {
                "variable": {
                    "value": "item[target]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[item['target'], self.eos]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/data/transform_eos_lang_pair_dataset.py": {
        "torch": {
            "arange_58": {
                "start": {
                    "value": "eos_idx.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/distributed_utils.py": {
        "torch": {
            "is_initialized_82": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "stack_240": {
                "variable": {
                    "value": "buf",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "list(data.values())",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_available_99": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_231": {
                "variable": {
                    "value": "cpu_data[k]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data[k]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.double",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_tensor_230": {
                "obj": {
                    "value": "t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data[k]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_100": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_102": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/file_utils.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/hub_utils.py": {
        "torch": {
            "ModuleList_93": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "models",
                    "type": "variable",
                    "possible_values": [
                        [
                            "checkpoint_utils.load_model_ensemble_and_task([os.path.join(model_path, cpt) for cpt in checkpoint_file.split(os.pathsep)], arg_overrides=kwargs)",
                            "Call"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "tensor_119": {
                "data": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_tensor_150": {
                "obj": {
                    "value": "tokenized_sentences",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[self.encode(sentence) for sentence in sentences]",
                            "ListComp"
                        ],
                        [
                            "[self.encode(sentence) for sentence in sentences]",
                            "ListComp"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/incremental_decoding_utils.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/iterative_refinement_generator.py": {
        "torch": {
            "arange_146": {
                "variable": {
                    "value": "sent_idxs",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size()",
                            "Call"
                        ],
                        [
                            "bsz * self.beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "no_grad_107": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_157": {
                "variable": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[y, x.new_zeros(b, l_x - l_y).fill_(self.pad)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_158": {
                "variable": {
                    "value": "s",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[s, s.new_zeros(b, l_x - l_y)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "no_grad_90": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_160": {
                "variable": {
                    "value": "a",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[a, a.new_zeros(b, l_x - l_y, a.size(2))]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_162": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x, y.new_zeros(b, l_y - l_x).fill_(self.pad)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/legacy_distributed_data_parallel.py": {
        "torch": {
            "zeros_like_152": {
                "variable": {
                    "value": "param.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "param",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_119": {
                "variable": {
                    "value": "buffer",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.module.parameters()",
                            "Call"
                        ],
                        [
                            "params[0]",
                            "Subscript"
                        ],
                        [
                            "params",
                            "variable"
                        ],
                        [
                            "params",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/logging/meters.py": {
        "torch": {
            "is_tensor_46": {
                "obj": {
                    "value": "number",
                    "type": "variable",
                    "possible_values": [
                        [
                            "number",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/logging/progress_bar.py": {
        "torch": {
            "is_tensor_100": {
                "obj": {
                    "value": "stat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "'{:g}'.format(stat)",
                            "Call"
                        ],
                        [
                            "'{:.3f}'.format(stat.avg)",
                            "Call"
                        ],
                        [
                            "'{:g}'.format(round(stat.avg))",
                            "Call"
                        ],
                        [
                            "'{:g}'.format(round(stat.sum))",
                            "Call"
                        ],
                        [
                            "stat.tolist()",
                            "Call"
                        ],
                        [
                            "stat",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/model_parallel/models/transformer.py": {
        "torch": {
            "linear_104": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "copy_to_model_parallel_region(features)",
                            "Call"
                        ],
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_106": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "copy_to_model_parallel_region(features)",
                            "Call"
                        ],
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/model_parallel/models/transformer_lm.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/model_parallel/modules/multihead_attention.py": {
        "torch": {
            "bmm_209": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.q_proj(query)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads_partition, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.q_proj(query)",
                            "Call"
                        ],
                        [
                            "self.q_proj(query)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_238": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.dropout(attn_weights_float.type_as(attn_weights), p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.v_proj(query)",
                            "Call"
                        ],
                        [
                            "self.v_proj(key)",
                            "Call"
                        ],
                        [
                            "self.v_proj(value)",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(-1, bsz * self.num_heads_partition, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "prev_value",
                            "variable"
                        ],
                        [
                            "torch.cat([prev_value, v], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "dropout_231": {
                "variable": {
                    "value": "attn_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights_float.type_as(attn_weights)",
                    "type": "Call",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_261": {
                "variable": {
                    "value": "new_key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_key_padding_mask.float(), key_padding_mask.float()]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_169": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_key, k]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_178": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_value, v]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_269": {
                "variable": {
                    "value": "filler",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "src_len - prev_key_padding_mask.size(1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_272": {
                "variable": {
                    "value": "new_key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_key_padding_mask.float(), filler.float()]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_276": {
                "variable": {
                    "value": "filler",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "src_len - key_padding_mask.size(1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_279": {
                "variable": {
                    "value": "new_key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[filler.float(), key_padding_mask.float()]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/bart/hub_interface.py": {
        "torch": {
            "log_softmax_186": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model.classification_heads[head](sentence_representation)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_43": {
                "data": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/bart/model.py": {
        "torch": {
            "ModuleDict_46": {
                "variable": {
                    "value": "self.classification_heads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_203": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "inner_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state_dict[prefix + 'classification_heads.' + head_name + '.dense.weight'].size(0)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "inner_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_205": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "pooler_dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pooler_dropout",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_206": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "inner_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state_dict[prefix + 'classification_heads.' + head_name + '.dense.weight'].size(0)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "inner_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state_dict[prefix + 'classification_heads.' + head_name + '.out_proj.weight'].size(0)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "num_classes",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/models/distributed_fairseq_model.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/models/fairseq_decoder.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/models/fairseq_encoder.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/models/fairseq_model.py": {
        "torch": {
            "ModuleDict_325": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "{key: FairseqEncoderDecoderModel(encoders[key], decoders[key]) for key in self.keys}",
                    "type": "DictComp",
                    "possible_values": []
                }
            },
            "is_tensor_499": {
                "obj": {
                    "value": "encoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)",
                            "Call"
                        ],
                        [
                            "self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)",
                            "Call"
                        ],
                        [
                            "self.models[key].encoder(src_tokens, src_lengths, **kwargs)",
                            "Call"
                        ],
                        [
                            "net_output['encoder_out']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "is_tensor_68": {
                "obj": {
                    "value": "net_output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output",
                            "Method Argument"
                        ],
                        [
                            "net_output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "remove_weight_norm_140": {
                "module": {
                    "value": "module",
                    "type": "variable",
                    "possible_values": [
                        [
                            "module",
                            "Method Argument"
                        ],
                        [
                            "module",
                            "Method Argument"
                        ],
                        [
                            "module",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_softmax_502": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_504": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_71": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_73": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "net_output.float()",
                            "Call"
                        ],
                        [
                            "encoder_out.float()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/fconv.py": {
        "torch": {
            "Embedding_571": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_586": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_172": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_173": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_217": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_321": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x.view(sz[0] * sz[1], sz[2])",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_383": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_384": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_385": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_443": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "weight_norm_589": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_598": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "weight_norm_608": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)",
                            "Call"
                        ],
                        [
                            "LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx)",
                            "Call"
                        ],
                        [
                            "nn.Linear(in_features, out_features)",
                            "Call"
                        ],
                        [
                            "LinearizedConvolution(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "ConvTBC(in_channels, out_channels, kernel_size, **kwargs)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_243": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_252": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_464": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_466": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_494": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_250": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "(self.in_projection(x) + target_embedding) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.bmm(x, encoder_out[0])",
                            "Call"
                        ],
                        [
                            "x.float().masked_fill(encoder_padding_mask.unsqueeze(1), float('-inf')).type_as(x)",
                            "Call"
                        ],
                        [
                            "F.softmax(x.view(sz[0] * sz[1], sz[2]), dim=1)",
                            "Call"
                        ],
                        [
                            "x.view(sz)",
                            "Call"
                        ],
                        [
                            "self.bmm(x, encoder_out[1])",
                            "Call"
                        ],
                        [
                            "x * (s * math.sqrt(1.0 / s))",
                            "BinOp"
                        ],
                        [
                            "x * (s * s.rsqrt())",
                            "BinOp"
                        ],
                        [
                            "(self.out_projection(x) + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self._embed_tokens(prev_output_tokens, incremental_state)",
                            "Call"
                        ],
                        [
                            "x + pos_embed",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self._transpose_if_training(x, incremental_state)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, padding_r)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Linear_419": {
                "variable": {
                    "value": "self.fc3",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "out_embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "256",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "weight_norm_516": {
                "variable": {
                    "value": "self.convolutions[i]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "module": {
                    "value": "conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "zip(self.projections, self.convolutions, self.residuals)",
                            "Call"
                        ],
                        [
                            "zip(self.projections, self.convolutions, self.attention, self.residuals)",
                            "Call"
                        ],
                        [
                            "conv in enumerate(self.convolutions)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "remove_weight_norm_515": {
                "module": {
                    "value": "conv",
                    "type": "variable",
                    "possible_values": [
                        [
                            "zip(self.projections, self.convolutions, self.residuals)",
                            "Call"
                        ],
                        [
                            "zip(self.projections, self.convolutions, self.attention, self.residuals)",
                            "Call"
                        ],
                        [
                            "conv in enumerate(self.convolutions)",
                            "Call"
                        ]
                    ]
                }
            },
            "Tensor_511": {}
        }
    },
    "code/fairseq/fairseq/models/fconv_self_att.py": {
        "torch": {
            "Embedding_513": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ],
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_526": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_199": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_200": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_201": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_202": {
                "variable": {
                    "value": "self.attproj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_221": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_336": {
                "variable": {
                    "value": "self.projections",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_337": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_338": {
                "variable": {
                    "value": "self.attention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_339": {
                "variable": {
                    "value": "self.selfattention",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_340": {
                "variable": {
                    "value": "self.attproj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_413": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_454": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_241": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_244": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, padding_r)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "glu_246": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_377": {
                "variable": {
                    "value": "self.gate1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_378": {
                "variable": {
                    "value": "self.gate2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_380": {
                "variable": {
                    "value": "self.joining",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "Linear(out_embed_dim * 2, out_embed_dim * 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_429": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "glu_431": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, padding_r))",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.unsqueeze(-1), 0)",
                            "Call"
                        ],
                        [
                            "GradMultiply.apply(x, 1.0 / (2.0 * self.num_attention_layers))",
                            "Call"
                        ],
                        [
                            "attention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens) + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc1(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "F.glu(x, dim=2)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attention(attproj(x) + target_embedding, encoder_a, encoder_b)",
                            "Call"
                        ],
                        [
                            "x + r",
                            "BinOp"
                        ],
                        [
                            "self.fc3(x)",
                            "Call"
                        ],
                        [
                            "selfattention(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * math.sqrt(0.5)",
                            "BinOp"
                        ],
                        [
                            "self.attention(query, key, value, mask_future_timesteps=True, use_scalar_bias=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_461": {
                "variable": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x, self.pretrained_outputs['out']]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_466": {
                "variable": {
                    "value": "fusion",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[gated_x1, gated_x2]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Sigmoid_377": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sigmoid_378": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_383": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_386": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/huggingface/hf_gpt2.py": {
        "torch": {
            "arange_122": {
                "start": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "1 + prev_output_tokens.size(1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/lightconv.py": {
        "torch": {
            "Embedding_678": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "embed_tokens.padding_idx",
                            "Attribute"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_685": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_230": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_257": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_340": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_405": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_496": {
                "variable": {
                    "value": "self.layer_norms",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LayerNorm(self.embed_dim) for _ in range(2)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_510": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_518": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_524": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_525": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_527": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_619": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.input_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_625": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "relu_654": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc1(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_655": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.relu_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_657": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "triu_450": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_452": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "GLU_472": {
                "variable": {
                    "value": "self.act",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_560": {
                "variable": {
                    "value": "self.act",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_648": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_362": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_435": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_437": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out['encoder_out'] if encoder_out is not None else None, encoder_out['encoder_padding_mask'] if encoder_out is not None else None, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_out)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "x.masked_fill(encoder_padding_mask.transpose(0, 1).unsqueeze(2), 0)",
                            "Call"
                        ],
                        [
                            "self.conv(x)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(0, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(1, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.input_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.linear1(x)",
                            "Call"
                        ],
                        [
                            "self.act(x)",
                            "Call"
                        ],
                        [
                            "self.conv(x, incremental_state=incremental_state)",
                            "Call"
                        ],
                        [
                            "self.linear2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.conv_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, before=True)",
                            "Call"
                        ],
                        [
                            "F.relu(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.relu_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.final_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=not self.training and self.need_attn)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.maybe_layer_norm(self.encoder_attn_layer_norm, x, after=True)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/lstm.py": {
        "torch": {
            "Embedding_524": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(task.source_dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "LSTM_531": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "LSTMCell_539": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "input_size": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size",
                            "Method Argument"
                        ],
                        [
                            "input_size",
                            "Method Argument"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "hidden_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "hidden_size",
                            "Method Argument"
                        ],
                        [
                            "hidden_size",
                            "Method Argument"
                        ],
                        [
                            "512",
                            "Method Argument"
                        ],
                        [
                            "512",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_548": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_230": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_in",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_236": {
                "variable": {
                    "value": "packed_x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "lengths": {
                    "value": "src_lengths.data.tolist()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_248": {
                "variable": {
                    "value": "(x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "sequence": {
                    "value": "packed_outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.lstm(packed_x, (h0, c0))",
                            "Call"
                        ]
                    ]
                },
                "padding_value": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_249": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_307": {
                "variable": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(source_hids * x.unsqueeze(0)).sum(dim=2)",
                            "Call"
                        ],
                        [
                            "attn_scores.float().masked_fill_(encoder_padding_mask, float('-inf')).type_as(attn_scores)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_scores, dim=0)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "x.new_zeros(srclen, seqlen, bsz) if self.attention is not None else None",
                            "IfExp"
                        ],
                        [
                            "attn_scores.transpose(0, 2)",
                            "Call"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tanh_312": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.output_proj(torch.cat((x, input), dim=1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_351": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[LSTMCell(input_size=input_feed_size + embed_dim if layer == 0 else hidden_size, hidden_size=hidden_size) for layer in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_404": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_in",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_473": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "outs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_457": {
                "variable": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()",
                            "Call"
                        ],
                        [
                            "self.attention(hidden, encoder_outs, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "hidden",
                            "variable"
                        ],
                        [
                            "F.dropout(out, p=self.dropout_out, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_480": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_437": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x[j, :, :], input_feed)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_446": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hidden",
                    "type": "variable",
                    "possible_values": [
                        [
                            "rnn(input, (prev_hiddens[i], prev_cells[i]))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_493": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(src_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.input_proj(input)",
                            "Call"
                        ],
                        [
                            "(attn_scores.unsqueeze(2) * source_hids).sum(dim=0)",
                            "Call"
                        ],
                        [
                            "torch.tanh(self.output_proj(torch.cat((x, input), dim=1)))",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out, incremental_state)",
                            "Call"
                        ],
                        [
                            "self.embed_tokens(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_in, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "torch.cat(outs, dim=0).view(seqlen, bsz, self.hidden_size)",
                            "Call"
                        ],
                        [
                            "x.transpose(1, 0)",
                            "Call"
                        ],
                        [
                            "self.additional_fc(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout_out, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.fc_out(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_312": {
                "tensors": {
                    "value": "(x, input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/masked_lm.py": {
        "torch": {
            "Linear_164": {
                "variable": {
                    "value": "self.masked_lm_pooler",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_169": {
                "variable": {
                    "value": "self.lm_head_transform_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_175": {
                "variable": {
                    "value": "self.lm_output_learned_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(self.vocab_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_228": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "inner_states[-1].transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(self.activation_fn(self.lm_head_transform_weight(x)))",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.sentence_encoder.embed_tokens.weight)",
                            "Call"
                        ],
                        [
                            "self.embed_out(x)",
                            "Call"
                        ],
                        [
                            "x + self.lm_output_learned_bias",
                            "BinOp"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.sentence_encoder.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_178": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_185": {
                "variable": {
                    "value": "self.sentence_projection_layer",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.sentence_out_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "zeros_175": {
                "*size": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/model_utils.py": {
        "torch": {
            "cat_52": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x, torch.zeros(dims).to(x).fill_(padding_idx)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_83": {
                "variable": {
                    "value": "x[mask]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "data": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_52": {
                "*size": {
                    "value": "dims",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[x.size(0), trg_dim - x.size(1)]",
                            "List"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/fairseq_nat_model.py": {
        "torch": {
            "stack_22": {
                "tensors": {
                    "value": "outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[getattr(e, key) for e in encoder_outs]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "logsumexp_53": {
                "input": {
                    "value": "torch.stack([a[i] for a in action_outs], -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "stack_59": {
                "tensors": {
                    "value": "[a[i] for a in action_outs]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "stack_54": {
                "tensors": {
                    "value": "[a[i] for a in action_outs]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/insertion_transformer.py": {
        "torch": {
            "cat_115": {
                "variable": {
                    "value": "out_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[in_tokens, word_ins_pred]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "gather_115": {
                "variable": {
                    "value": "out_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "out_coords",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(in_coords[:, 1:] - 0.5).masked_fill(word_ins_pred.eq(padding_idx), float('inf'))",
                            "Call"
                        ],
                        [
                            "torch.cat([in_coords, out_coords], 1).sort(-1)[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "cat_116": {
                "variable": {
                    "value": "out_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[in_scores, word_ins_scores]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "gather_116": {
                "variable": {
                    "value": "out_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dim": {
                    "value": "out_coords",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(in_coords[:, 1:] - 0.5).masked_fill(word_ins_pred.eq(padding_idx), float('inf'))",
                            "Call"
                        ],
                        [
                            "torch.cat([in_coords, out_coords], 1).sort(-1)[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "device_of_68": {
                "obj": {
                    "value": "in_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "tensor_93": {
                "data": {
                    "value": "list(a)",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "in_tokens.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_114": {
                "tensors": {
                    "value": "[in_coords, out_coords]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sort_114": {
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_228": {
                "tensors": {
                    "value": "[features[:, :-1, :], features[:, 1:, :]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_231": {
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.output_layer(features)",
                            "Call"
                        ],
                        [
                            "decoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/iterative_nonautoregressive_transformer.py": {
        "torch": {
            "randint_15": {
                "variable": {
                    "value": "rand_words",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "V",
                    "type": "variable",
                    "possible_values": [
                        [
                            "V",
                            "Method Argument"
                        ]
                    ]
                },
                "size": {
                    "value": "s.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "s.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "rand_16": {
                "variable": {
                    "value": "choices",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "s.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "device": {
                    "value": "s.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_130": {
                "variable": {
                    "value": "word_ins_out",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "word_ins_outs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_131": {
                "variable": {
                    "value": "word_ins_tgt",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "word_ins_tgts",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_132": {
                "variable": {
                    "value": "word_ins_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "word_ins_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "rand_116": {
                "size": {
                    "value": "(B,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "prev_output_tokens.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/levenshtein_transformer.py": {
        "torch": {
            "dropout_336": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out.encoder_out if encoder_out is not None else None, encoder_out.encoder_padding_mask if encoder_out is not None else None, self_attn_mask=None, self_attn_padding_mask=decoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_373": {
                "variable": {
                    "value": "features_cat",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[features[:, :-1, :], features[:, 1:, :]]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "linear_374": {
                "variable": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features_cat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([features[:, :-1, :], features[:, 1:, :]], 2)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_mask_ins.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_394": {
                "variable": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.extract_features(prev_output_tokens, encoder_out=encoder_out, early_exit=self.early_exit[1], layers=self.layers_msk, **unused)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out=encoder_out, early_exit=self.early_exit[2], layers=self.layers, **unused)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out=encoder_out, early_exit=self.early_exit[0], layers=self.layers_del, **unused)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_word_del.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "multinomial_106": {
                "variable": {
                    "value": "word_predictions",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.softmax(word_ins_out, -1).view(-1, word_ins_out.size(-1))",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_like_151": {
                "variable": {
                    "value": "max_lens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "output_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out.output_tokens",
                            "Attribute"
                        ],
                        [
                            "_fill(output_tokens, can_del_word, _tokens, self.pad)",
                            "Call"
                        ],
                        [
                            "_fill(output_tokens, can_ins_mask, _tokens, self.pad)",
                            "Call"
                        ],
                        [
                            "_fill(output_tokens, can_ins_word, _tokens, self.pad)",
                            "Call"
                        ],
                        [
                            "output_tokens[:, :cut_off]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "min_198": {
                "variable": {
                    "value": "mask_ins_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_ins_pred",
                    "type": "variable",
                    "possible_values": [
                        [
                            "mask_ins_score.max(-1)[1]",
                            "Subscript"
                        ],
                        [
                            "torch.min(mask_ins_pred, max_lens[can_ins_mask, None].expand_as(mask_ins_pred))",
                            "Call"
                        ]
                    ]
                }
            },
            "ModuleList_292": {
                "variable": {
                    "value": "self.layers_msk",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[TransformerDecoderLayer(args, no_encoder_attn) for _ in range(self.early_exit[1])]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ModuleList_298": {
                "variable": {
                    "value": "self.layers_del",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[TransformerDecoderLayer(args, no_encoder_attn) for _ in range(self.early_exit[0])]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "log_softmax_110": {
                "input": {
                    "value": "word_ins_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.forward_word_ins(normalize=False, prev_output_tokens=masked_tgt_tokens, encoder_out=encoder_out)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "max_110": {
                "input": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_376": {
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.linear(features_cat, self.embed_mask_ins.weight)",
                            "Call"
                        ],
                        [
                            "self.output_layer(features)",
                            "Call"
                        ],
                        [
                            "F.linear(features, self.embed_word_del.weight)",
                            "Call"
                        ],
                        [
                            "decoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_386": {
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.linear(features_cat, self.embed_mask_ins.weight)",
                            "Call"
                        ],
                        [
                            "self.output_layer(features)",
                            "Call"
                        ],
                        [
                            "F.linear(features, self.embed_word_del.weight)",
                            "Call"
                        ],
                        [
                            "decoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_396": {
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.linear(features_cat, self.embed_mask_ins.weight)",
                            "Call"
                        ],
                        [
                            "self.output_layer(features)",
                            "Call"
                        ],
                        [
                            "F.linear(features, self.embed_word_del.weight)",
                            "Call"
                        ],
                        [
                            "decoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "softmax_107": {
                "input": {
                    "value": "word_ins_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.forward_word_ins(normalize=False, prev_output_tokens=masked_tgt_tokens, encoder_out=encoder_out)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/levenshtein_utils.py": {
        "torch": {
            "tensor_81": {
                "variable": {
                    "value": "masked_tgt_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "masked_tgt_masks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "libnat.generate_insertion_labels(out_tokens.int(), libnat.levenshtein_distance(in_tokens.int(), out_tokens.int(), in_masks.sum(1).int(), out_masks.sum(1).int()))",
                            "Call"
                        ],
                        [
                            "masked_tgt_masks.bool() & out_masks",
                            "BinOp"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.tensor(masked_tgt_masks, device=out_tokens.device).bool()",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "out_tokens.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_84": {
                "variable": {
                    "value": "mask_ins_targets",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mask_ins_targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "libnat.generate_insertion_labels(out_tokens.int(), libnat.levenshtein_distance(in_tokens.int(), out_tokens.int(), in_masks.sum(1).int(), out_masks.sum(1).int()))",
                            "Call"
                        ],
                        [
                            "mask_ins_targets.type_as(in_tokens)[:, 1:in_masks.size(1)].masked_fill_(~in_masks[:, 1:], 0)",
                            "Call"
                        ],
                        [
                            "[mask_input[1:-1] + [0 for _ in range(in_seq_len - 1 - len(mask_input[1:-1]))] for mask_input in mask_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(mask_ins_targets, device=in_tokens.device)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "in_tokens.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_131": {
                "variable": {
                    "value": "word_del_targets",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "word_del_targets",
                    "type": "variable",
                    "possible_values": [
                        [
                            "libnat.generate_deletion_labels(in_tokens.int(), libnat.levenshtein_distance(in_tokens.int(), out_tokens.int(), in_masks.sum(1).int(), out_masks.sum(1).int()))",
                            "Call"
                        ],
                        [
                            "word_del_targets.type_as(in_tokens).masked_fill_(~in_masks, 0)",
                            "Call"
                        ],
                        [
                            "[b[-1] for b in full_labels]",
                            "ListComp"
                        ],
                        [
                            "[labels + [0 for _ in range(out_seq_len - len(labels))] for labels in word_del_targets]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(word_del_targets, device=out_tokens.device)",
                            "Call"
                        ]
                    ]
                },
                "device": {
                    "value": "out_tokens.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_274": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[x, x.new_zeros(*dims).fill_(padding_idx)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_of_112": {
                "obj": {
                    "value": "in_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ],
                        [
                            "in_tokens",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/nonautoregressive_ensembles.py": {
        "torch": {
            "ModuleList_38": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "models",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_51": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_57": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_71": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "min_183": {
                "variable": {
                    "value": "mask_ins_pred",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_ins_pred",
                    "type": "variable",
                    "possible_values": [
                        [
                            "mask_ins_score_avg.max(-1)[1]",
                            "Subscript"
                        ],
                        [
                            "torch.min(mask_ins_pred, max_lens[can_ins_mask, None].expand_as(mask_ins_pred))",
                            "Call"
                        ]
                    ]
                }
            },
            "log_softmax_146": {
                "variable": {
                    "value": "word_del_score",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "word_del_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.decoder.forward_word_del(_skip(output_tokens, can_del_word), _skip_encoder_out(model.encoder, encoder_out, can_del_word))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_177": {
                "variable": {
                    "value": "mask_ins_score",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_ins_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.decoder.forward_mask_ins(_skip(output_tokens, can_ins_mask), _skip_encoder_out(model.encoder, encoder_out, can_ins_mask))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "log_softmax_206": {
                "variable": {
                    "value": "word_ins_score",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "word_ins_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "model.decoder.forward_word_ins(_skip(output_tokens, can_ins_word), _skip_encoder_out(model.encoder, encoder_out, can_ins_word))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "logsumexp_149": {
                "input": {
                    "value": "torch.stack(word_del_score_avg, dim=0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "logsumexp_181": {
                "input": {
                    "value": "torch.stack(mask_ins_score_avg, dim=0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "logsumexp_209": {
                "input": {
                    "value": "torch.stack(word_ins_score_avg, dim=0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_149": {
                "tensors": {
                    "value": "word_del_score_avg",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.logsumexp(torch.stack(word_del_score_avg, dim=0), dim=0) - math.log(len(self.models))",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_152": {
                "tensors": {
                    "value": "word_del_attn_avg",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(word_del_attn_avg, dim=0) / len(self.models)",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_181": {
                "tensors": {
                    "value": "mask_ins_score_avg",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.logsumexp(torch.stack(mask_ins_score_avg, dim=0), dim=0) - math.log(len(self.models))",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_209": {
                "tensors": {
                    "value": "word_ins_score_avg",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.logsumexp(torch.stack(word_ins_score_avg, dim=0), dim=0) - math.log(len(self.models))",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_211": {
                "tensors": {
                    "value": "word_ins_attn_avg",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(word_ins_attn_avg, dim=0) / len(self.models)",
                            "BinOp"
                        ],
                        [
                            "None",
                            "NoneType"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/nat/nonautoregressive_transformer.py": {
        "torch": {
            "round_45": {
                "variable": {
                    "value": "index_t",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "index_t",
                    "type": "variable",
                    "possible_values": [
                        [
                            "utils.new_arange(trg_lens, max_trg_len).float()",
                            "Call"
                        ],
                        [
                            "steps[:, None] * index_t[None, :]",
                            "BinOp"
                        ],
                        [
                            "torch.round(index_t).long().detach()",
                            "Call"
                        ]
                    ]
                }
            },
            "linear_225": {
                "variable": {
                    "value": "length_out",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "enc_feats",
                    "type": "variable",
                    "possible_values": [
                        [
                            "enc_feats.mean(0)",
                            "Call"
                        ],
                        [
                            "(enc_feats / src_masks.sum(0)[None, :, None] * src_masks[:, :, None]).sum(0)",
                            "Call"
                        ],
                        [
                            "encoder_out.encoder_out",
                            "Attribute"
                        ],
                        [
                            "_mean_pooling(enc_feats, src_masks)",
                            "Call"
                        ],
                        [
                            "enc_feats.detach()",
                            "Call"
                        ],
                        [
                            "encoder_out.encoder_out",
                            "Attribute"
                        ],
                        [
                            "enc_feats",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_length.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_320": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.forward_embedding(prev_output_tokens, self.forward_copying_source(src_embd, src_mask, prev_output_tokens.ne(self.padding_idx)))",
                            "Call"
                        ],
                        [
                            "self.forward_embedding(prev_output_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_out.encoder_out if encoder_out is not None else None, encoder_out.encoder_padding_mask if encoder_out is not None else None, self_attn_mask=None, self_attn_padding_mask=decoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "states",
                            "variable"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "gather_330": {
                "variable": {
                    "value": "copied_embedding",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_embeds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_embeds",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "mapped_inputs.unsqueeze(-1).expand(*mapped_inputs.size(), src_embeds.size(-1))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_softmax_216": {
                "input": {
                    "value": "decoder_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.output_layer(features)",
                            "Call"
                        ],
                        [
                            "decoder_out",
                            "Method Argument"
                        ],
                        [
                            "decoder_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_softmax_226": {
                "input": {
                    "value": "length_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder.forward_length(normalize=False, encoder_out=encoder_out)",
                            "Call"
                        ],
                        [
                            "F.linear(enc_feats, self.embed_length.weight)",
                            "Call"
                        ],
                        [
                            "length_out",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/roberta/alignment_utils.py": {
        "torch": {
            "stack_93": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[weighted_features[0]]",
                            "List"
                        ],
                        [
                            "torch.stack(output)",
                            "Call"
                        ]
                    ]
                }
            },
            "all_94": {
                "input": {
                    "value": "torch.abs(output.sum(dim=0) - features.sum(dim=0)) < 0.0001",
                    "type": "Compare",
                    "possible_values": []
                }
            },
            "abs_94": {
                "input": {
                    "value": "output.sum(dim=0) - features.sum(dim=0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/roberta/hub_interface.py": {
        "torch": {
            "log_softmax_108": {
                "input": {
                    "value": "logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model.classification_heads[head](features)",
                            "Call"
                        ],
                        [
                            "features[0, masked_index, :].squeeze()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_30": {
                "data": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/roberta/model.py": {
        "torch": {
            "ModuleDict_53": {
                "variable": {
                    "value": "self.classification_heads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_207": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_214": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(output_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_235": {
                "variable": {
                    "value": "self.dense",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "inner_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state_dict[prefix + 'classification_heads.' + head_name + '.dense.weight'].size(0)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "inner_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_237": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "pooler_dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "pooler_dropout",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_238": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "inner_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state_dict[prefix + 'classification_heads.' + head_name + '.dense.weight'].size(0)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "inner_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state_dict[prefix + 'classification_heads.' + head_name + '.out_proj.weight'].size(0)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "num_classes",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_214": {
                "*size": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "linear_226": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.decoder(src_tokens, features_only, return_all_hiddens, **kwargs)",
                            "Call"
                        ],
                        [
                            "self.classification_heads[classification_head_name](x)",
                            "Call"
                        ],
                        [
                            "hub_utils.from_pretrained(model_name_or_path, checkpoint_file, data_name_or_path, archive_map=cls.hub_models(), bpe=bpe, load_checkpoint_heads=True, **kwargs)",
                            "Call"
                        ],
                        [
                            "self.dense(features)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(x)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.linear(x, self.weight) + self.bias",
                            "BinOp"
                        ],
                        [
                            "features[:, 0, :]",
                            "Subscript"
                        ],
                        [
                            "self.dropout(x)",
                            "Call"
                        ],
                        [
                            "self.dense(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(x)",
                            "Call"
                        ],
                        [
                            "self.dropout(x)",
                            "Call"
                        ],
                        [
                            "self.out_proj(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(src_tokens, return_all_hiddens=return_all_hiddens)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x, masked_tokens=masked_tokens)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_212": {
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/models/transformer.py": {
        "torch": {
            "Embedding_919": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(dictionary)",
                            "Call"
                        ],
                        [
                            "num_embeddings",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "embedding_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "padding_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dictionary.pad()",
                            "Call"
                        ],
                        [
                            "padding_idx",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_926": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_399": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_424": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.layernorm_embedding(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.forward_embedding(src_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out=encoder_out, incremental_state=incremental_state, alignment_layer=alignment_layer, alignment_heads=alignment_heads)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "self.layernorm_embedding(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_state, encoder_out.encoder_padding_mask if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, self_attn_padding_mask=self_attn_padding_mask, need_attn=bool(idx == alignment_layer), need_head_weights=bool(idx == alignment_layer))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "empty_596": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_634": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "dropout_776": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.layernorm_embedding(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.forward_embedding(src_tokens)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.extract_features(prev_output_tokens, encoder_out=encoder_out, incremental_state=incremental_state, alignment_layer=alignment_layer, alignment_heads=alignment_heads)",
                            "Call"
                        ],
                        [
                            "self.output_layer(x)",
                            "Call"
                        ],
                        [
                            "self.embed_scale * self.embed_tokens(prev_output_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.project_in_dim(x)",
                            "Call"
                        ],
                        [
                            "x + positions",
                            "BinOp"
                        ],
                        [
                            "self.layernorm_embedding(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.project_out_dim(x)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_state, encoder_out.encoder_padding_mask if encoder_out is not None else None, incremental_state, self_attn_mask=self_attn_mask, self_attn_padding_mask=self_attn_padding_mask, need_attn=bool(idx == alignment_layer), need_head_weights=bool(idx == alignment_layer))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "empty_471": {
                "variable": {
                    "value": "dropout_probability",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_545": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(tensor.new(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_804": {
                "variable": {
                    "value": "dropout_probability",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_865": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(torch.zeros([dim, dim]))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "triu_549": {
                "variable": {
                    "value": "self._future_mask",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "utils.fill_with_neg_inf(self._future_mask.resize_(dim, dim))",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_662": {
                "variable": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(len(dictionary), self.output_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "linear_845": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_tokens.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_847": {
                "input": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "features",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.embed_out",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_866": {
                "*size": {
                    "value": "[dim, dim]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "Tensor_571": {},
            "Tensor_909": {}
        }
    },
    "code/fairseq/fairseq/models/wav2vec.py": {
        "torch": {
            "Dropout_339": {
                "variable": {
                    "value": "self.dropout_feats",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "args.dropout_features",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_340": {
                "variable": {
                    "value": "self.dropout_agg",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "args.dropout_agg",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Sequential_417": {
                "variable": {
                    "value": "mod",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "TransposeLast()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_452": {
                "variable": {
                    "value": "self.conv_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_525": {
                "variable": {
                    "value": "self.conv_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_526": {
                "variable": {
                    "value": "self.residual_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_535": {
                "variable": {
                    "value": "self.conv_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*self.conv_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "ConvTranspose2d_569": {
                "variable": {
                    "value": "self.project_to_steps",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "in_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "out_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "(1, prediction_steps)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Dropout_572": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dropout",
                            "Method Argument"
                        ],
                        [
                            "dropout",
                            "Method Argument"
                        ],
                        [
                            "dropout",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "randint_587": {
                "variable": {
                    "value": "neg_idxs",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "high",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tsz if self.sample_distance is None else min(tsz, self.sample_distance)",
                            "IfExp"
                        ]
                    ]
                },
                "size": {
                    "value": "(bsz, self.n_negatives * tsz)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_644": {
                "variable": {
                    "value": "targets",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[y, negatives]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_226": {
                "variable": {
                    "value": "activation",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "pad_489": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.dropout_feats(features)",
                            "Call"
                        ],
                        [
                            "self.feature_aggregator(x)",
                            "Call"
                        ],
                        [
                            "self.dropout_agg(x)",
                            "Call"
                        ],
                        [
                            "self.wav2vec_predictions(x, features)",
                            "Call"
                        ],
                        [
                            "x[self.deconstruct_idx]",
                            "Subscript"
                        ],
                        [
                            "x.unsqueeze(1)",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * self.residual_scale",
                            "BinOp"
                        ],
                        [
                            "x.abs()",
                            "Call"
                        ],
                        [
                            "x + 1",
                            "BinOp"
                        ],
                        [
                            "x.log()",
                            "Call"
                        ],
                        [
                            "conv(x)",
                            "Call"
                        ],
                        [
                            "(x + residual) * self.residual_scale",
                            "BinOp"
                        ],
                        [
                            "x.unsqueeze(-1)",
                            "Call"
                        ],
                        [
                            "self.project_to_steps(x)",
                            "Call"
                        ],
                        [
                            "self.dropout(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(self.pad_left, self.pad_right)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_625": {
                "variable": {
                    "value": "neg_idxs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[neg_idxs, cross_neg_idxs]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_like_659": {
                "variable": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "predictions",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.new(bsz * copies * (tsz - self.offset + 1) * steps - (steps + 1) * steps // 2 * copies * bsz)",
                            "Call"
                        ],
                        [
                            "predictions.view(-1, copies)",
                            "Call"
                        ]
                    ]
                }
            },
            "GELU_228": {
                "variable": {
                    "value": "activation",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_442": {
                "*args": {
                    "value": "nn.Conv1d(n_in, n_out, k, stride=stride, bias=False)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_516": {
                "*args": {
                    "value": "pad",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_589": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "randint_598": {
                "variable": {
                    "value": "neg_idxs",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "high - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "size": {
                    "value": "(bsz, self.n_negatives * tsz)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "randint_611": {
                "variable": {
                    "value": "cross_neg_idxs",
                    "type": "variable",
                    "possible_values": []
                },
                "low": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "high": {
                    "value": "cross_high - 1",
                    "type": "BinOp",
                    "possible_values": []
                },
                "size": {
                    "value": "(bsz, self.cross_sample_negatives * tsz)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "full_like_661": {
                "input": {
                    "value": "labels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "predictions.new_full((predictions.shape[0] // copies,), 0, dtype=torch.long)",
                            "Call"
                        ],
                        [
                            "torch.zeros_like(predictions)",
                            "Call"
                        ],
                        [
                            "(labels, weights)",
                            "Tuple"
                        ]
                    ]
                },
                "fill_value": {
                    "value": "1 / self.n_negatives",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "einsum_671": {
                "variable": {
                    "value": "predictions[start:end]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "equation": {
                    "value": "bct,nbct->tbn",
                    "type": "str",
                    "possible_values": []
                },
                "*operands": {
                    "value": "x[..., :-offset, i]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "flatten_671": {
                "variable": {
                    "value": "predictions[start:end]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "einsum_676": {
                "variable": {
                    "value": "predictions[start:end]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "equation": {
                    "value": "bct,nbct->nbt",
                    "type": "str",
                    "possible_values": []
                },
                "*operands": {
                    "value": "x[..., :-offset, i]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "flatten_676": {
                "variable": {
                    "value": "predictions[start:end]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_309": {
                "variable": {
                    "value": "feature_aggregator",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "TransposeLast()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Conv1d_443": {
                "in_channels": {
                    "value": "n_in",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_in",
                            "Method Argument"
                        ],
                        [
                            "n_in",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "n_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_out",
                            "Method Argument"
                        ],
                        [
                            "n_out",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": [
                        [
                            "feature_enc_layers",
                            "variable"
                        ],
                        [
                            "q_res.keys()",
                            "Call"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "k",
                            "Method Argument"
                        ],
                        [
                            "k",
                            "Method Argument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "type": "variable",
                    "possible_values": [
                        [
                            "feature_enc_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "stride",
                            "Method Argument"
                        ],
                        [
                            "stride",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_444": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dropout",
                            "Method Argument"
                        ],
                        [
                            "dropout",
                            "Method Argument"
                        ],
                        [
                            "dropout",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ReplicationPad1d_513": {
                "padding": {
                    "value": "(ka + kb, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Conv1d_518": {
                "in_channels": {
                    "value": "n_in",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_in",
                            "Method Argument"
                        ],
                        [
                            "n_in",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "n_out",
                    "type": "variable",
                    "possible_values": [
                        [
                            "n_out",
                            "Method Argument"
                        ],
                        [
                            "n_out",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": [
                        [
                            "feature_enc_layers",
                            "variable"
                        ],
                        [
                            "q_res.keys()",
                            "Call"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "k",
                            "Method Argument"
                        ],
                        [
                            "k",
                            "Method Argument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "type": "variable",
                    "possible_values": [
                        [
                            "feature_enc_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "stride",
                            "Method Argument"
                        ],
                        [
                            "stride",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "conv_bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv_bias",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_519": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dropout",
                            "Method Argument"
                        ],
                        [
                            "dropout",
                            "Method Argument"
                        ],
                        [
                            "dropout",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Conv1d_529": {
                "in_channels": {
                    "value": "in_d",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1",
                            "int"
                        ],
                        [
                            "dim",
                            "variable"
                        ],
                        [
                            "embed",
                            "variable"
                        ],
                        [
                            "dim",
                            "variable"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "conv_layers",
                            "variable"
                        ],
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "GRU_311": {
                "input_size": {
                    "value": "embed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "feature_enc_layers[-1][0]",
                            "Subscript"
                        ],
                        [
                            "embed",
                            "Method Argument"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "agg_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "make_aggregator()",
                            "Call"
                        ],
                        [
                            "agg_layers[-1][0]",
                            "Subscript"
                        ],
                        [
                            "args.gru_dim",
                            "Attribute"
                        ]
                    ]
                },
                "num_layers": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "dropout": {
                    "value": "args.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/adaptive_input.py": {
        "torch": {
            "ModuleList_36": {
                "variable": {
                    "value": "self.embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_41": {
                "variable": {
                    "value": "seq",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Embedding(size, dim, self.padding_idx)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Embedding_42": {
                "num_embeddings": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.cutoff[i] - prev",
                            "BinOp"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_43": {
                "in_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(initial_dim // factor ** i)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/adaptive_softmax.py": {
        "torch": {
            "Linear_37": {
                "variable": {
                    "value": "self.class_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_classes",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "LogSoftmax_74": {
                "variable": {
                    "value": "self.lsm",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ModuleList_92": {
                "variable": {
                    "value": "self.tail",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_157": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "linear_21": {
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.contiguous().view(-1, input.size(-1))",
                            "Call"
                        ],
                        [
                            "F.dropout(input, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "input.contiguous().view(-1, dim)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight.t() if self.transpose else self.weight",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "Sequential_32": {
                "variable": {
                    "value": "self.word_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(input_dim, emb_dim, bias=False)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_79": {
                "variable": {
                    "value": "self.head",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cutoff[0] + len(cutoff) - 1",
                            "BinOp"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Sequential_107": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "*args": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_105": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + 1))",
                            "Call"
                        ],
                        [
                            "input.size()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_33": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "emb_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tied_emb.size()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_103": {
                "variable": {
                    "value": "proj",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "tied_proj.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out_features": {
                    "value": "tied_proj.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Dropout_109": {
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_110": {
                "in_features": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "int(self.input_dim // self.factor ** (i + 1))",
                            "Call"
                        ],
                        [
                            "input.size()",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.cutoff[i + 1] - self.cutoff[i]",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/beamable_mm.py": {
        "torch": {
            "mm_39": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input1[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mat2": {
                    "value": "input2[0, :, :]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/character_token_embedder.py": {
        "torch": {
            "Embedding_38": {
                "variable": {
                    "value": "self.char_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "257",
                    "type": "int",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "char_embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_39": {
                "variable": {
                    "value": "self.symbol_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(2, word_embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ModuleList_43": {
                "variable": {
                    "value": "self.convolutions",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_53": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "last_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sum((f[1] for f in filters))",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "word_embed_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_154": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "conv_result",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "ModuleList_176": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "ReLU_178": {
                "variable": {
                    "value": "self.activation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "max_150": {
                "variable": {
                    "value": "(x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv(char_embs)",
                            "Call"
                        ],
                        [
                            "torch.max(x, -1)",
                            "Call"
                        ],
                        [
                            "F.relu(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(conv_result, dim=-1)",
                            "Call"
                        ],
                        [
                            "self.highway(x)",
                            "Call"
                        ],
                        [
                            "self.projection(x)",
                            "Call"
                        ],
                        [
                            "gate * x + (gate.new_tensor([1]) - gate) * proj_x",
                            "BinOp"
                        ]
                    ]
                }
            },
            "relu_151": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "conv(char_embs)",
                            "Call"
                        ],
                        [
                            "torch.max(x, -1)",
                            "Call"
                        ],
                        [
                            "F.relu(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(conv_result, dim=-1)",
                            "Call"
                        ],
                        [
                            "self.highway(x)",
                            "Call"
                        ],
                        [
                            "self.projection(x)",
                            "Call"
                        ],
                        [
                            "gate * x + (gate.new_tensor([1]) - gate) * proj_x",
                            "BinOp"
                        ]
                    ]
                }
            },
            "sigmoid_202": {
                "variable": {
                    "value": "gate",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "gate",
                    "type": "variable",
                    "possible_values": [
                        [
                            "projection.chunk(2, dim=-1)",
                            "Call"
                        ],
                        [
                            "torch.sigmoid(gate)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_124": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "pads.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "word_embs.new_zeros(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_126": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "eos.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "self.symbol_embeddings[self.eos_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "where_128": {
                "variable": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "unk.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "self.symbol_embeddings[self.unk_idx]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "y": {
                    "value": "word_embs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._convolve(chars)",
                            "Call"
                        ],
                        [
                            "torch.where(pads.unsqueeze(1), word_embs.new_zeros(1), word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), self.symbol_embeddings[self.eos_idx], word_embs)",
                            "Call"
                        ],
                        [
                            "torch.where(unk.unsqueeze(1), self.symbol_embeddings[self.unk_idx], word_embs)",
                            "Call"
                        ]
                    ]
                }
            },
            "Conv1d_46": {
                "in_channels": {
                    "value": "char_embed_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_c",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filters",
                            "variable"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "width",
                    "type": "variable",
                    "possible_values": [
                        [
                            "filters",
                            "variable"
                        ]
                    ]
                }
            },
            "where_109": {
                "variable": {
                    "value": "chars",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "eos.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "x": {
                    "value": "chars.new_zeros(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "chars",
                    "type": "variable",
                    "possible_values": [
                        [
                            "vocab[i].encode()",
                            "Call"
                        ],
                        [
                            "input.view(-1, self.max_char_len)",
                            "Call"
                        ],
                        [
                            "self.word_to_char[flat_words.type_as(self.word_to_char)].type_as(input)",
                            "Call"
                        ],
                        [
                            "torch.where(eos.unsqueeze(1), chars.new_zeros(1), chars)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_176": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/conv_tbc.py": {
        "torch": {
            "Parameter_23": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.kernel_size[0], in_channels, out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_25": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/downsampled_multihead_attention.py": {
        "torch": {
            "Linear_242": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ],
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ],
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Sequential_52": {
                "variable": {
                    "value": "self.in_proj_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*k_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Sequential_53": {
                "variable": {
                    "value": "self.in_proj_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*v_layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "bmm_106": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query",
                            "variable"
                        ],
                        [
                            "self.in_proj_q(q)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "q.view(tgt_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "q.transpose(0, 1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_136": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_137": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_139": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "value",
                            "variable"
                        ],
                        [
                            "self.in_proj_v(v)",
                            "Call"
                        ],
                        [
                            "v.view(src_len, size, self.head_dim)",
                            "Call"
                        ],
                        [
                            "v.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "scalar_bias(v, 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "weight_norm_245": {
                "module": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nn.Linear(in_features, out_features, bias=bias)",
                            "Call"
                        ]
                    ]
                }
            },
            "Sequential_250": {
                "*args": {
                    "value": "Linear(in_features, out_features * 4, dropout, bias)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_212": {
                "variable": {
                    "value": "full_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_221": {
                "variable": {
                    "value": "full_attn",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(attn_weights, v)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.head_dim)",
                            "Call"
                        ],
                        [
                            "attn.transpose(0, 1).contiguous().view(tgt_len, bsz, self.embed_dim)",
                            "Call"
                        ],
                        [
                            "self.out_proj(attn)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_222": {
                "variable": {
                    "value": "full_attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(q, k.transpose(1, 2))",
                            "Call"
                        ],
                        [
                            "attn_weights + torch.triu(attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone(), diagonal=0)[:, ::self.head_index + 1 if self.downsample else 1].unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "scalar_bias(attn_weights, 2)",
                            "Call"
                        ],
                        [
                            "F.softmax(attn_weights, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(attn_weights, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(bsz, 1, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, self.num_heads, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "attn_weights.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), -math.inf)",
                            "Call"
                        ],
                        [
                            "attn_weights.view(size, tgt_len, src_len)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "GLU_252": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GLU_254": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "unsqueeze_110": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "unsqueeze_114": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tril_110": {
                "input": {
                    "value": "attn_weights.data.new([1]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "triu_114": {
                "input": {
                    "value": "attn_weights.data.new([-math.inf]).expand(tgt_len, tgt_len).clone()",
                    "type": "Call",
                    "possible_values": []
                },
                "diagonal": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/dynamic_convolution.py": {
        "torch": {
            "Linear_35": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "False",
                            "Method Argument"
                        ],
                        [
                            "True",
                            "Method Argument"
                        ],
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "is_available_19": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "dropout_169": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "bmm_171": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "unfold1d(x, K, padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight.unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_217": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, 0, self.input_size).contiguous()",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, 0, self.input_size).contiguous()",
                            "Call"
                        ],
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_86": {
                "variable": {
                    "value": "self.conv_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_145": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_159": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_167": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_194": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_205": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_206": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_193": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "proj.narrow(2, self.input_size, H * K).contiguous().view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/dynamic_crf_layer.py": {
        "torch": {
            "logsumexp_25": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Embedding_45": {
                "variable": {
                    "value": "self.E1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embedding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_embedding",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "low_rank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Embedding_46": {
                "variable": {
                    "value": "self.E2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "num_embedding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_embedding",
                            "Method Argument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "low_rank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "32",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_114": {
                "variable": {
                    "value": "beam_transition_matrix",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "beam_transition_score1.view(-1, beam, self.rank)",
                    "type": "Call",
                    "possible_values": []
                },
                "mat2": {
                    "value": "beam_transition_score2.view(-1, beam, self.rank).transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_141": {
                "variable": {
                    "value": "beam_transition_matrix",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "beam_transition_score1.view(-1, beam, self.rank)",
                    "type": "Call",
                    "possible_values": []
                },
                "mat2": {
                    "value": "beam_transition_score2.view(-1, beam, self.rank).transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_151": {
                "variable": {
                    "value": "dummy",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "beam",
                    "type": "variable",
                    "possible_values": [
                        [
                            "beam if beam is not None else self.beam",
                            "IfExp"
                        ],
                        [
                            "beam if beam is not None else self.beam",
                            "IfExp"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "device": {
                    "value": "score.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_177": {
                "variable": {
                    "value": "finalized_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "finalized_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(finalized_tokens, 1)",
                            "Call"
                        ],
                        [
                            "beam_targets.gather(2, finalized_tokens[:, :, None])[:, :, 0]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_181": {
                "variable": {
                    "value": "finalized_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "finalized_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(finalized_scores, 1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "where_126": {
                "variable": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "masks[:, i:i + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "x": {
                    "value": "next_score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "score[:, :, None] + beam_transition_matrix[:, i - 1]",
                            "BinOp"
                        ],
                        [
                            "logsumexp(next_score, dim=1) + beam_emission_scores[:, i]",
                            "BinOp"
                        ]
                    ]
                },
                "y": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "beam_emission_scores[:, 0]",
                            "Subscript"
                        ],
                        [
                            "torch.where(masks[:, i:i + 1], next_score, score)",
                            "Call"
                        ],
                        [
                            "next_score",
                            "variable"
                        ],
                        [
                            "beam_emission_scores[:, 0]",
                            "Subscript"
                        ],
                        [
                            "torch.where(masks[:, i:i + 1], _score, score)",
                            "Call"
                        ],
                        [
                            "_score",
                            "variable"
                        ]
                    ]
                }
            },
            "where_160": {
                "variable": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "masks[:, i:i + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "x": {
                    "value": "_score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "score[:, :, None] + beam_transition_matrix[:, i - 1]",
                            "BinOp"
                        ],
                        [
                            "_score.max(dim=1)",
                            "Call"
                        ],
                        [
                            "_score + beam_emission_scores[:, i]",
                            "BinOp"
                        ]
                    ]
                },
                "y": {
                    "value": "score",
                    "type": "variable",
                    "possible_values": [
                        [
                            "beam_emission_scores[:, 0]",
                            "Subscript"
                        ],
                        [
                            "torch.where(masks[:, i:i + 1], next_score, score)",
                            "Call"
                        ],
                        [
                            "next_score",
                            "variable"
                        ],
                        [
                            "beam_emission_scores[:, 0]",
                            "Subscript"
                        ],
                        [
                            "torch.where(masks[:, i:i + 1], _score, score)",
                            "Call"
                        ],
                        [
                            "_score",
                            "variable"
                        ]
                    ]
                }
            },
            "where_161": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "masks[:, i:i + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "x": {
                    "value": "_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "_score.max(dim=1)",
                            "Call"
                        ]
                    ]
                },
                "y": {
                    "value": "dummy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.arange(beam, device=score.device).expand(*score.size()).contiguous()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/dynamicconv_layer/dynamicconv_layer.py": {
        "torch": {
            "Linear_63": {
                "variable": {
                    "value": "self.weight_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_heads * kernel_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "False",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_169": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "bmm_171": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "unfold1d(x, K, padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight.unsqueeze(2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "bmm_212": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.permute(1, 2, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_65": {
                "variable": {
                    "value": "self.conv_bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_145": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_159": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_167": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_189": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_200": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_201": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new(B * H, T, T + K - 1).fill_(float('-inf'))",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, self.padding_l, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight_expanded, dim=2)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                },
                "inplace": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "softmax_104": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_106": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "softmax_188": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight_linear(x).view(T, B, H, K)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "weight.permute(1, 2, 3, 0).contiguous()",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, K - T, T)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "self.weight_linear(query).view(T * B * H, -1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(1, 0, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight, dim=1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training, inplace=False)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/dynamicconv_layer/setup.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/modules/fp32_group_norm.py": {
        "torch": {
            "group_norm_18": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "num_groups": {
                    "value": "self.num_groups",
                    "type": "Attribute",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.weight.float() if self.weight is not None else None",
                    "type": "IfExp",
                    "possible_values": []
                },
                "bias": {
                    "value": "self.bias.float() if self.bias is not None else None",
                    "type": "IfExp",
                    "possible_values": []
                },
                "eps": {
                    "value": "self.eps",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/gelu.py": {
        "torch": {
            "gelu_26": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tanh_20": {
                "input": {
                    "value": "gelu_accurate._a * (x + 0.044715 * torch.pow(x, 3))",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "erf_28": {
                "input": {
                    "value": "x / math.sqrt(2.0)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "pow_20": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "exponent": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/grad_multiply.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/modules/gumbel_vector_quantizer.py": {
        "torch": {
            "Parameter_55": {
                "variable": {
                    "value": "self.vars",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(1, num_groups * num_vars, var_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_131": {
                "variable": {
                    "value": "hard_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hard_x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_132": {
                "variable": {
                    "value": "result[code_perplexity]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "-torch.sum(hard_probs * torch.log(hard_probs + 1e-07), dim=-1)",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "sum_132": {
                "variable": {
                    "value": "result[code_perplexity]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "softmax_136": {
                "variable": {
                    "value": "avg_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x.view(bsz * tsz, self.groups, -1).float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "mean_136": {
                "variable": {
                    "value": "avg_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_139": {
                "variable": {
                    "value": "result[prob_perplexity]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "-torch.sum(avg_probs * torch.log(avg_probs + 1e-07), dim=-1)",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "sum_139": {
                "variable": {
                    "value": "result[prob_perplexity]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "GELU_21": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_64": {
                "variable": {
                    "value": "self.weight_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*[block(self.input_dim if i == 0 else inner_dim, inner_dim) for i in range(weight_proj_depth - 1)]",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Linear_72": {
                "variable": {
                    "value": "self.weight_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.input_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "groups * num_vars",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "tensor_91": {
                "variable": {
                    "value": "self.codebook_indices",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "inds",
                    "type": "variable",
                    "possible_values": [
                        [
                            "list(product(*p))",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "self.vars.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "flatten_91": {
                "variable": {
                    "value": "self.codebook_indices",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "gumbel_softmax_146": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "tau": {
                    "value": "self.curr_temp",
                    "type": "Attribute",
                    "possible_values": []
                },
                "hard": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Sequential_61": {
                "*args": {
                    "value": "nn.Linear(input_dim, output_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_69": {
                "in_features": {
                    "value": "inner_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.input_dim * weight_proj_factor",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "groups * num_vars",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_61": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "sum_133": {
                "input": {
                    "value": "hard_probs * torch.log(hard_probs + 1e-07)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "sum_140": {
                "input": {
                    "value": "avg_probs * torch.log(avg_probs + 1e-07)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_133": {
                "input": {
                    "value": "hard_probs + 1e-07",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "log_140": {
                "input": {
                    "value": "avg_probs + 1e-07",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/kmeans_vector_quantizer.py": {
        "torch": {
            "Parameter_43": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "0.01 * torch.randn(num_vars, num_groups, self.var_dim)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Sequential_46": {
                "variable": {
                    "value": "self.projection",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv1d(dim, dim, kernel_size=1, groups=groups, bias=False)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "MSELoss_51": {
                "variable": {
                    "value": "self.mse_mean",
                    "type": "Attribute",
                    "possible_values": []
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "stack_91": {
                "variable": {
                    "value": "zq",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.expand_embedding[idx[..., group], group] for group in range(self.groups)]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-2",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "permute_91": {
                "variable": {
                    "value": "zq",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "dims": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "mean_109": {
                "variable": {
                    "value": "hard_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "hard_x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_110": {
                "variable": {
                    "value": "result[code_perplexity]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "-torch.sum(hard_probs * torch.log(hard_probs + 1e-07), dim=-1)",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "sum_110": {
                "variable": {
                    "value": "result[code_perplexity]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv1d_47": {
                "in_channels": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dim",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "groups": {
                    "value": "groups",
                    "type": "variable",
                    "possible_values": [
                        [
                            "groups",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "randn_44": {
                "*size": {
                    "value": "num_vars",
                    "type": "variable",
                    "possible_values": [
                        [
                            "num_vars",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "num_groups",
                    "type": "variable",
                    "possible_values": [
                        [
                            "groups if not combine_groups else 1",
                            "IfExp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "self.var_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sum_111": {
                "input": {
                    "value": "hard_probs * torch.log(hard_probs + 1e-07)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "log_111": {
                "input": {
                    "value": "hard_probs + 1e-07",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/layer_norm.py": {
        "torch": {
            "LayerNorm_32": {
                "normalized_shape": {
                    "value": "normalized_shape",
                    "type": "variable",
                    "possible_values": [
                        [
                            "normalized_shape",
                            "Method Argument"
                        ]
                    ]
                },
                "eps": {
                    "value": "eps",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1e-05",
                            "Method Argument"
                        ]
                    ]
                },
                "elementwise_affine": {
                    "value": "elementwise_affine",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "layer_norm_40": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "normalized_shape": {
                    "value": "self.normalized_shape",
                    "type": "Attribute",
                    "possible_values": []
                },
                "weight": {
                    "value": "self.weight.float() if self.weight is not None else None",
                    "type": "IfExp",
                    "possible_values": []
                },
                "bias": {
                    "value": "self.bias.float() if self.bias is not None else None",
                    "type": "IfExp",
                    "possible_values": []
                },
                "eps": {
                    "value": "self.eps",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_30": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_22": {
                "type": {
                    "value": "x.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/learned_positional_embedding.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/modules/lightconv_layer/lightconv_layer.py": {
        "torch": {
            "Parameter_55": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_57": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_84": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_99": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(self.weight, -1)",
                            "Call"
                        ],
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight.float(), dim=1).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_100": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(self.weight, -1)",
                            "Call"
                        ],
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight.float(), dim=1).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_91": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "softmax_109": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "dropout_111": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(self.weight, -1)",
                            "Call"
                        ],
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "F.softmax(weight.float(), dim=1).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/lightconv_layer/setup.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/modules/lightweight_convolution.py": {
        "torch": {
            "is_available_17": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Parameter_63": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, 1, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_89": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "conv1d_95": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input.view(-1, H, T)",
                            "Call"
                        ],
                        [
                            "input",
                            "Method Argument"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "groups": {
                    "value": "self.num_heads",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_134": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(num_heads, 1, kernel_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_200": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_201": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": [
                        [
                            "unfold1d(x, self.kernel_size, self.padding_l, 0)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, K)",
                            "Call"
                        ],
                        [
                            "torch.cat([input_buffer, x.unsqueeze(3)], dim=3)",
                            "Call"
                        ],
                        [
                            "x_unfold.view(T * B * H, R, -1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                }
            },
            "dropout_230": {
                "variable": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.weight_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_232": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight_expanded",
                    "type": "variable",
                    "possible_values": [
                        [
                            "weight.new_zeros(B * H, T, T + K - 1, requires_grad=False)",
                            "Call"
                        ],
                        [
                            "weight_expanded.narrow(2, P, T)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight_expanded, self.weight_dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.view(T, B * H, R).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_66": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "softmax_87": {
                "variable": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.weight",
                            "Attribute"
                        ],
                        [
                            "F.softmax(weight, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight[:, -x_unfold.size(2):]",
                            "Subscript"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous().view(T * B * H, K, 1)",
                            "Call"
                        ],
                        [
                            "F.dropout(weight, self.weight_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.weight.view(H, K)",
                            "Call"
                        ],
                        [
                            "utils.softmax(weight, dim=1, onnx_trace=self.onnx_trace).type_as(weight)",
                            "Call"
                        ],
                        [
                            "weight.view(1, H, K).expand(T * B, H, K).contiguous()",
                            "Call"
                        ],
                        [
                            "weight.view(T, B * H, K).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "weight.narrow(2, K - T, T)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Parameter_136": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(input_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_182": {
                "variable": {
                    "value": "x_unfold",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[input_buffer, x.unsqueeze(3)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/linearized_convolution.py": {
        "torch": {
            "linear_64": {
                "variable": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "weight": {
                    "value": "weight",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self._get_linearized_weight()",
                            "Call"
                        ],
                        [
                            "self.weight.transpose(2, 1).transpose(1, 0).contiguous()",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_84": {
                "variable": {
                    "value": "self._linearized_weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "weight.view(self.out_channels, -1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_63": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/multihead_attention.py": {
        "torch": {
            "Linear_58": {
                "variable": {
                    "value": "self.k_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.kdim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_59": {
                "variable": {
                    "value": "self.v_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.vdim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_60": {
                "variable": {
                    "value": "self.q_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_62": {
                "variable": {
                    "value": "self.out_proj",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "embed_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "query.size()",
                            "Call"
                        ],
                        [
                            "embed_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "bmm_310": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "q",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.q_proj(query)",
                            "Call"
                        ],
                        [
                            "q * self.scaling",
                            "BinOp"
                        ],
                        [
                            "self.q_proj(query)",
                            "Call"
                        ],
                        [
                            "q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "self.q_proj(query)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "k.transpose(1, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "dropout_336": {
                "variable": {
                    "value": "attn_probs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_weights_float.type_as(attn_weights)",
                    "type": "Call",
                    "possible_values": []
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "bmm_342": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "attn_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.dropout(attn_weights_float.type_as(attn_weights), p=self.dropout, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.v_proj(query)",
                            "Call"
                        ],
                        [
                            "self.v_proj(key)",
                            "Call"
                        ],
                        [
                            "self.v_proj(value)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, self.bias_v.repeat(1, bsz, 1)])",
                            "Call"
                        ],
                        [
                            "v.contiguous().view(-1, bsz * self.num_heads, self.head_dim).transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "prev_value",
                            "variable"
                        ],
                        [
                            "torch.cat([prev_value, v], dim=1)",
                            "Call"
                        ],
                        [
                            "torch.cat([v, v.new_zeros((v.size(0), 1) + v.size()[2:])], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_65": {
                "variable": {
                    "value": "self.bias_k",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Parameter_66": {
                "variable": {
                    "value": "self.bias_v",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(1, 1, embed_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cat_207": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, self.bias_k.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_208": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, self.bias_v.repeat(1, bsz, 1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_293": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[k, k.new_zeros((k.size(0), 1) + k.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_294": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[v, v.new_zeros((v.size(0), 1) + v.size()[2:])]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_210": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_214": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, key_padding_mask.new_zeros(key_padding_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_296": {
                "variable": {
                    "value": "attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[attn_mask, attn_mask.new_zeros(attn_mask.size(0), 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_300": {
                "variable": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[key_padding_mask, torch.zeros(key_padding_mask.size(0), 1).type_as(key_padding_mask)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_374": {
                "variable": {
                    "value": "new_key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_key_padding_mask.float(), key_padding_mask.float()]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_155": {
                "*size": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_156": {
                "tensors": {
                    "value": "(self.q_proj.bias, self.k_proj.bias, self.v_proj.bias)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "cat_250": {
                "variable": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_key, k]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_259": {
                "variable": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_value, v]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_381": {
                "variable": {
                    "value": "filler",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, src_len - prev_key_padding_mask.size(1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "prev_key_padding_mask.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_385": {
                "variable": {
                    "value": "new_key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[prev_key_padding_mask.float(), filler.float()]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_389": {
                "variable": {
                    "value": "filler",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, src_len - key_padding_mask.size(1))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "device": {
                    "value": "key_padding_mask.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_393": {
                "variable": {
                    "value": "new_key_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[filler.float(), key_padding_mask.float()]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_303": {
                "*size": {
                    "value": "key_padding_mask.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/positional_embedding.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/modules/scalar_bias.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/modules/sinusoidal_positional_embedding.py": {
        "torch": {
            "exp_46": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(half_dim, dtype=torch.float) * -emb",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "cat_50": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.sin(emb), torch.cos(emb)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_55": {
                "variable": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[emb, torch.zeros(num_embeddings, 1)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_94": {
                "variable": {
                    "value": "embedding_shape",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(bsz.view(1), seq_len.view(1), torch.tensor([-1], dtype=torch.long))",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "arange_47": {
                "start": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_47": {
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_46": {
                "start": {
                    "value": "half_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embedding_dim // 2",
                            "BinOp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_55": {
                "*size": {
                    "value": "num_embeddings",
                    "type": "variable",
                    "possible_values": []
                },
                "out": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_95": {
                "data": {
                    "value": "[-1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sin_50": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "cos_50": {
                "input": {
                    "value": "emb",
                    "type": "variable",
                    "possible_values": [
                        [
                            "math.log(10000) / (half_dim - 1)",
                            "BinOp"
                        ],
                        [
                            "torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)",
                            "Call"
                        ],
                        [
                            "torch.arange(num_embeddings, dtype=torch.float).unsqueeze(1) * emb.unsqueeze(0)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(num_embeddings, -1)",
                            "Call"
                        ],
                        [
                            "torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/sparse_multihead_attention.py": {
        "torch": {
            "empty_87": {
                "variable": {
                    "value": "sparse_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(tgt_len, src_len)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/sparse_transformer_sentence_encoder.py": {
        "torch": {
            "ModuleList_54": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[SparseTransformerSentenceEncoderLayer(embedding_dim=self.embedding_dim, ffn_embedding_dim=ffn_embedding_dim, num_attention_heads=num_attention_heads, dropout=self.dropout, attention_dropout=attention_dropout, activation_dropout=activation_dropout, activation_fn=activation_fn, export=export, is_bidirectional=is_bidirectional, stride=stride, expressivity=expressivity) for _ in range(num_encoder_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/transformer_layer.py": {
        "torch": {
            "Linear_372": {
                "variable": {
                    "value": "m",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_features",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_features",
                            "Method Argument"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "variable",
                    "possible_values": [
                        [
                            "True",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "dropout_112": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_121": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "float(self.activation_dropout)",
                    "type": "Call",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_123": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_296": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_335": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "float(self.activation_dropout)",
                    "type": "Call",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_337": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_50": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_53": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_192": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Linear_195": {
                "in_features": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ],
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_283": {
                "variable": {
                    "value": "y",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(encoder_out, x)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_326": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=encoder_padding_mask, attn_mask=attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.self_attn(query=x, key=y, value=y, key_padding_mask=self_attn_padding_mask, incremental_state=incremental_state, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=float(self.activation_dropout), training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.encoder_attn(query=x, key=encoder_out, value=encoder_out, key_padding_mask=encoder_padding_mask, incremental_state=incremental_state, static_kv=True, need_weights=need_attn or (not self.training and self.need_attn), need_head_weights=need_head_weights)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.encoder_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_270": {
                "variable": {
                    "value": "self_attn_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x.new_zeros(x.size(0), encoder_out.size(0)), self_attn_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_279": {
                "variable": {
                    "value": "self_attn_padding_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(encoder_padding_mask, self_attn_padding_mask)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/transformer_sentence_encoder.py": {
        "torch": {
            "Embedding_112": {
                "variable": {
                    "value": "self.embed_tokens",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ModuleList_134": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "[TransformerSentenceEncoderLayer(embedding_dim=self.embedding_dim, ffn_embedding_dim=ffn_embedding_dim, num_attention_heads=num_attention_heads, dropout=self.dropout, attention_dropout=attention_dropout, activation_dropout=activation_dropout, activation_fn=activation_fn, export=export) for _ in range(num_encoder_layers)]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "dropout_200": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.embed_tokens(tokens)",
                            "Call"
                        ],
                        [
                            "x * (1 - padding_mask.unsqueeze(-1).type_as(x))",
                            "BinOp"
                        ],
                        [
                            "self.emb_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, self_attn_padding_mask=padding_mask)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_118": {
                "num_embeddings": {
                    "value": "self.num_segments",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "None",
                    "type": "NoneType",
                    "possible_values": []
                }
            },
            "stack_227": {
                "tensors": {
                    "value": "inner_states",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[x]",
                            "List"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/transformer_sentence_encoder_layer.py": {
        "torch": {
            "Linear_54": {
                "variable": {
                    "value": "self.fc1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "Linear_55": {
                "variable": {
                    "value": "self.fc2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ffn_embedding_dim",
                    "type": "variable",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.embedding_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_79": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_85": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.activation_dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "dropout_87": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.self_attn(query=x, key=x, value=x, key_padding_mask=self_attn_padding_mask, need_weights=False, attn_mask=self_attn_mask)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.self_attn_layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.activation_fn(self.fc1(x))",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.activation_dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.fc2(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "residual + x",
                            "BinOp"
                        ],
                        [
                            "self.final_layer_norm(x)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/unfold.py": {
        "torch": {
            "pad_13": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "F.pad(x, (0, 0, 0, 0, padding_l, kernel_size - 1 - padding_l), value=pad_value)",
                            "Call"
                        ],
                        [
                            "x.as_strided((T, B, C, kernel_size), (B * C, C, 1, B * C))",
                            "Call"
                        ],
                        [
                            "x.unsqueeze(3)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, 0, 0, 0, padding_l, kernel_size - 1 - padding_l)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "pad_value",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/modules/vggblock.py": {
        "torch": {
            "randn_25": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "sample_bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "10",
                            "int"
                        ]
                    ]
                },
                "out": {
                    "value": "sample_inchannel",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sample_inchannel",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "sample_seq_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "200",
                            "int"
                        ]
                    ]
                },
                "layout": {
                    "value": "input_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "per_channel_dim",
                            "variable"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ],
                        [
                            "input_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleList_88": {
                "variable": {
                    "value": "self.layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_90": {
                "variable": {
                    "value": "conv_op",
                    "type": "variable",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "in_channels if layer == 0 else out_channels",
                    "type": "IfExp",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_channels",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "self.conv_kernel_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "stride": {
                    "value": "self.conv_stride",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "MaxPool2d_107": {
                "variable": {
                    "value": "pool_op",
                    "type": "variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "self.pooling_kernel_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "ceil_mode": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "ReLU_104": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "LayerNorm_102": {
                "normalized_shape": {
                    "value": "per_channel_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x.size()[3]",
                            "Subscript"
                        ],
                        [
                            "infer_conv_output_dim(conv_op, input_dim, in_channels if layer == 0 else out_channels)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/nan_detector.py": {
        "torch": {
            "is_tensor_59": {
                "obj": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_49": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "isnan_50": {
                "input": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "any_50": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "isinf_52": {
                "input": {
                    "value": "tensor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "any_52": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_tensor_64": {
                "obj": {
                    "value": "inp",
                    "type": "variable",
                    "possible_values": [
                        [
                            "inp[0]",
                            "Subscript"
                        ],
                        [
                            "inp",
                            "Method Argument"
                        ],
                        [
                            "inp",
                            "Method Argument"
                        ],
                        [
                            "inp",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/adadelta.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/optim/adafactor.py": {
        "torch": {
            "mul_141": {
                "input": {
                    "value": "r_factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(exp_avg_sq_row / exp_avg_sq_row.mean(dim=-1).unsqueeze(-1)).rsqrt_().unsqueeze(-1)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "c_factor",
                    "type": "variable",
                    "possible_values": [
                        [
                            "exp_avg_sq_col.unsqueeze(-2).rsqrt()",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "output",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_like_172": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "grad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_174": {
                "variable": {
                    "value": "state[exp_avg_sq_row]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "*size": {
                    "value": "grad_shape[:-1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "zeros_175": {
                "variable": {
                    "value": "state[exp_avg_sq_col]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "*size": {
                    "value": "grad_shape[:-2] + grad_shape[-1:]",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_177": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "grad",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "rsqrt_211": {
                "input": {
                    "value": "exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "update",
                    "type": "variable",
                    "possible_values": [
                        [
                            "grad ** 2 + group['eps'][0]",
                            "BinOp"
                        ],
                        [
                            "exp_avg",
                            "variable"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/adagrad.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/optim/adam.py": {
        "torch": {
            "is_available_35": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "zeros_like_159": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_161": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_164": {
                "variable": {
                    "value": "state[max_exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "max_183": {
                "input": {
                    "value": "max_exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "max_exp_avg_sq",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['max_exp_avg_sq']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/adamax.py": {
        "torch": {
            "zeros_like_121": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_122": {
                "variable": {
                    "value": "state[exp_inf]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "max_137": {
                "input": {
                    "value": "exp_inf.mul_(beta2)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "exp_inf",
                    "type": "variable",
                    "possible_values": [
                        [
                            "state['exp_inf']",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/bmuf.py": {
        "torch": {
            "no_grad_171": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_182": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_199": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "broadcast_140": {
                "tensor": {
                    "value": "param.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "src": {
                    "value": "root_rank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_like_174": {
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/fairseq_optimizer.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/optim/fp16_optimizer.py": {
        "torch": {
            "is_tensor_65": {
                "obj": {
                    "value": "self.fp32_params",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_72": {
                "variable": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "total_param_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sum((p.data.numel() for p in params))",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "params[0].device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_78": {
                "variable": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "fp32_params",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros(total_param_size, dtype=torch.float, device=params[0].device)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.nn.Parameter(fp32_params)",
                            "Call"
                        ],
                        [
                            "cls.build_fp32_params(params, flatten=flatten)",
                            "Call"
                        ],
                        [
                            "fp32_params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Parameter_84": {
                "variable": {
                    "value": "p32",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "p.data.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_like_85": {
                "variable": {
                    "value": "p32.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "p32.data",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_142": {
                "variable": {
                    "value": "p32.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/fused_adam.py": {
        "torch": {
            "zeros_like_165": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_167": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p_data_fp32",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.data.float()",
                            "Call"
                        ]
                    ]
                }
            },
            "device_179": {
                "type": {
                    "value": "p.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_255": {
                "variable": {
                    "value": "state[exp_avg]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_257": {
                "variable": {
                    "value": "state[exp_avg_sq]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "p.data",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_273": {
                "type": {
                    "value": "p.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/optim/nag.py": {
        "torch": {
            "zeros_like_83": {
                "variable": {
                    "value": "param_state[momentum_buffer]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "input": {
                    "value": "d_p",
                    "type": "variable",
                    "possible_values": [
                        [
                            "p.grad.data.float()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/optim/sgd.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/options.py": {
        "torch": {
            "device_count_355": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/search.py": {
        "torch": {
            "tensor_21": {
                "variable": {
                    "value": "self.src_lengths",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "topk_67": {
                "variable": {
                    "value": "top_prediction",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "k": {
                    "value": "min(beam_size * 2, lprobs.view(bsz, -1).size(1) - 1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "div_78": {
                "variable": {
                    "value": "beams_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "indices_buf",
                    "type": "variable",
                    "possible_values": [
                        [
                            "top_prediction[1]",
                            "Subscript"
                        ],
                        [
                            "torch.stack(indices_G, dim=2).view(bsz, -1)",
                            "Call"
                        ],
                        [
                            "self.beam.step(step, lprobs_g, scores_g)",
                            "Call"
                        ],
                        [
                            "torch.multinomial(probs.view(bsz, -1), beam_size, replacement=True).view(bsz, beam_size)",
                            "Call"
                        ],
                        [
                            "torch.multinomial(probs.view(bsz * beam_size, -1), 1, replacement=True).view(bsz, beam_size)",
                            "Call"
                        ],
                        [
                            "torch.gather(top_indices.expand(bsz, beam_size, -1), dim=2, index=indices_buf.unsqueeze(-1)).squeeze(2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "vocab_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_126": {
                "variable": {
                    "value": "diversity_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "lprobs[:, 0, :].size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "stack_156": {
                "variable": {
                    "value": "scores_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "scores_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_157": {
                "variable": {
                    "value": "indices_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "indices_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "stack_158": {
                "variable": {
                    "value": "beams_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "beams_G",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "gather_254": {
                "variable": {
                    "value": "scores_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.exp_()",
                            "Call"
                        ],
                        [
                            "self._sample_topp(lprobs)",
                            "Call"
                        ],
                        [
                            "lprobs.exp_()",
                            "Call"
                        ],
                        [
                            "lprobs.exp_()",
                            "Call"
                        ],
                        [
                            "probs.expand(bsz, beam_size, -1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "indices_buf.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "stack_326": {
                "variable": {
                    "value": "indices",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "i_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[torch.LongTensor().to(device=lprobs.device) for i in range(beam_size)]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_328": {
                "variable": {
                    "value": "final_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "topk_331": {
                "variable": {
                    "value": "(final_scores, final_indices)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.stack(s_list, dim=1).view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "k": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": [
                        [
                            "min(beam_size * 2, lprobs.view(bsz, -1).size(1) - 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "div_336": {
                "variable": {
                    "value": "final_beams",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "final_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.LongTensor().to(device=lprobs.device)",
                            "Call"
                        ],
                        [
                            "torch.topk(torch.stack(s_list, dim=1).view(bsz, -1), k)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": [
                        [
                            "min(beam_size * 2, lprobs.view(bsz, -1).size(1) - 1)",
                            "Call"
                        ]
                    ]
                }
            },
            "multinomial_239": {
                "variable": {
                    "value": "indices_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs.view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ]
                    ]
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "multinomial_243": {
                "variable": {
                    "value": "indices_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "probs.view(bsz * beam_size, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "num_samples": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "replacement": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "gather_261": {
                "variable": {
                    "value": "indices_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "top_indices.expand(bsz, beam_size, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "indices_buf.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "squeeze_261": {
                "variable": {
                    "value": "indices_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_270": {
                "variable": {
                    "value": "beams_buf",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ],
                        [
                            "lprobs.size()",
                            "Call"
                        ]
                    ]
                }
            },
            "add_135": {
                "variable": {
                    "value": "lprobs_g",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "lprobs_g",
                    "type": "variable",
                    "possible_values": [
                        [
                            "lprobs[:, g::self.num_groups, :]",
                            "Subscript"
                        ],
                        [
                            "torch.add(lprobs_g, self.diversity_strength, diversity_buf.unsqueeze(1))",
                            "Call"
                        ],
                        [
                            "lprobs_g.contiguous()",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.diversity_strength",
                    "type": "Attribute",
                    "possible_values": []
                },
                "alpha": {
                    "value": "diversity_buf.unsqueeze(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "empty_236": {
                "variable": {
                    "value": "top_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_309": {
                "*size": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_311": {
                "start": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "k + 1",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "topk_319": {
                "input": {
                    "value": "lprobs[:, i, :].view(bsz, -1)",
                    "type": "Call",
                    "possible_values": []
                },
                "k": {
                    "value": "k",
                    "type": "variable",
                    "possible_values": [
                        [
                            "min(beam_size * 2, lprobs.view(bsz, -1).size(1) - 1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "(s_list[i], i_list[i])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "stack_332": {
                "tensors": {
                    "value": "s_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[torch.empty(0).to(lprobs) for i in range(beam_size)]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_152": {
                "*size": {
                    "value": "indices_buf.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "gather_273": {
                "input": {
                    "value": "scores[:, :, step - 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "beams_buf",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.div(indices_buf, vocab_size)",
                            "Call"
                        ],
                        [
                            "torch.stack(beams_G, dim=2).view(bsz, -1)",
                            "Call"
                        ],
                        [
                            "self.beam.step(step, lprobs_g, scores_g)",
                            "Call"
                        ],
                        [
                            "indices_buf.new_zeros(bsz, beam_size)",
                            "Call"
                        ],
                        [
                            "torch.arange(0, beam_size).to(indices_buf).repeat(bsz, 1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/sequence_generator.py": {
        "torch": {
            "no_grad_80": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "arange_134": {
                "variable": {
                    "value": "new_order",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size[0]",
                            "Subscript"
                        ],
                        [
                            "new_bsz",
                            "variable"
                        ],
                        [
                            "src_tokens.shape[0]",
                            "Subscript"
                        ],
                        [
                            "src_tokens.shape[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "arange_162": {
                "variable": {
                    "value": "cand_offsets",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "cand_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "2 * beam_size",
                            "BinOp"
                        ]
                    ]
                }
            },
            "no_grad_95": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ModuleList_517": {
                "variable": {
                    "value": "self.models",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "models",
                    "type": "variable",
                    "possible_values": [
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ],
                        [
                            "models",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_528": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_534": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_623": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "gather_463": {
                "variable": {
                    "value": "active_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores[:, step].view(bsz, beam_size)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "masked_select_383": {
                "input": {
                    "value": "cand_bbsz_idx[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "prefix_toks.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "cand_indices.eq(self.eos) & cand_scores.ne(-math.inf)",
                            "BinOp"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_bbsz_idx')",
                            "Call"
                        ]
                    ]
                }
            },
            "add_440": {
                "input": {
                    "value": "eos_mask.type_as(cand_offsets) * cand_size",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "cand_offsets[:eos_mask.size(1)]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                }
            },
            "topk_449": {
                "input": {
                    "value": "active_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_mask')",
                            "Call"
                        ]
                    ]
                },
                "k": {
                    "value": "beam_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.beam_size",
                            "Attribute"
                        ],
                        [
                            "self.beam_size",
                            "Attribute"
                        ],
                        [
                            "1",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "largest": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "out": {
                    "value": "(new_blacklist, active_hypos)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "gather_459": {
                "input": {
                    "value": "cand_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ],
                        [
                            "cand_beams.add(bbsz_offsets)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_472": {
                "input": {
                    "value": "tokens[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf[:, :step + 1]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "tokens.clone()",
                            "Call"
                        ],
                        [
                            "tokens",
                            "variable"
                        ]
                    ]
                }
            },
            "gather_476": {
                "input": {
                    "value": "cand_indices",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_indices[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tokens_buf.view(bsz, beam_size, -1)[:, :, step + 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "gather_485": {
                "input": {
                    "value": "cand_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.search.step(step, lprobs.view(bsz, -1, self.vocab_size), scores.view(bsz, beam_size, -1)[:, :, :step])",
                            "Call"
                        ],
                        [
                            "cand_scores[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_hypos",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_hypos')",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf.view(bsz, beam_size, -1)[:, :, step]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "logsumexp_563": {
                "input": {
                    "value": "torch.stack(log_probs, dim=0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "masked_select_391": {
                "input": {
                    "value": "cand_scores[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "mask": {
                    "value": "eos_mask[:, :beam_size]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "prefix_toks.eq(self.eos)",
                            "Call"
                        ],
                        [
                            "cand_indices.eq(self.eos) & cand_scores.ne(-math.inf)",
                            "BinOp"
                        ],
                        [
                            "eos_mask[batch_idxs]",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "eos_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('eos_scores', type_of=scores)",
                            "Call"
                        ],
                        [
                            "eos_scores / (step + 1) ** self.len_penalty",
                            "BinOp"
                        ],
                        [
                            "eos_scores",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "index_select_481": {
                "input": {
                    "value": "scores[:, :step]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "scores_buf[:, :step]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "scores.clone()",
                            "Call"
                        ],
                        [
                            "scores_buf.type_as(lprobs)",
                            "Call"
                        ],
                        [
                            "scores",
                            "variable"
                        ]
                    ]
                }
            },
            "index_select_492": {
                "input": {
                    "value": "attn[:, :, :step + 2]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "index": {
                    "value": "active_bbsz_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "buffer('active_bbsz_idx')",
                            "Call"
                        ],
                        [
                            "active_bbsz_idx.view(-1)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "attn_buf[:, :, :step + 2]",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "attn.clone()",
                            "Call"
                        ],
                        [
                            "attn",
                            "variable"
                        ]
                    ]
                }
            },
            "stack_563": {
                "tensors": {
                    "value": "log_probs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "log_probs",
                            "Method Argument"
                        ],
                        [
                            "log_probs",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "arange_270": {
                "start": {
                    "value": "batch_idxs.numel()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_161": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "bsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size[0]",
                            "Subscript"
                        ],
                        [
                            "new_bsz",
                            "variable"
                        ],
                        [
                            "src_tokens.shape[0]",
                            "Subscript"
                        ],
                        [
                            "src_tokens.shape[0]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/sequence_scorer.py": {
        "torch": {
            "no_grad_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_tensor_84": {
                "obj": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": [
                        [
                            "decoder_out[1] if len(decoder_out) > 1 else None",
                            "IfExp"
                        ],
                        [
                            "attn.get('attn', None)",
                            "Call"
                        ],
                        [
                            "attn.data",
                            "Attribute"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/fairseq/tasks/fairseq_task.py": {
        "torch": {
            "no_grad_345": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_350": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/tasks/language_modeling.py": {
        "torch": {
            "no_grad_239": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/tasks/multilingual_masked_lm.py": {
        "torch": {}
    },
    "code/fairseq/fairseq/tasks/multilingual_translation.py": {
        "torch": {
            "no_grad_285": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_301": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/tasks/translation_from_pretrained_bart.py": {
        "torch": {
            "cat_110": {
                "variable": {
                    "value": "s_t",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[s_t, s_t.new(1).fill_(src_lang_id)]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/tasks/translation_lev.py": {
        "torch": {
            "no_grad_158": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/trainer.py": {
        "torch": {
            "device_44": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                }
            },
            "device_46": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "is_tensor_395": {
                "obj": {
                    "value": "sample_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "int"
                        ],
                        [
                            "sample_size.float()",
                            "Call"
                        ],
                        [
                            "float(sample_size)",
                            "Call"
                        ],
                        [
                            "sample_size * 0",
                            "BinOp"
                        ],
                        [
                            "self.task.valid_step(sample, self.model, self.criterion)",
                            "Call"
                        ],
                        [
                            "sample_size",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "manual_seed_636": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "is_available_42": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_480": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_638": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.args.seed + self.get_num_updates()",
                            "BinOp"
                        ]
                    ]
                }
            },
            "is_available_655": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_445": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "empty_cache_448": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_656": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "empty_cache_381": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "memory_summary_657": {
                "device": {
                    "value": "device_idx",
                    "type": "variable",
                    "possible_values": [
                        [
                            "device_idx in range(torch.cuda.device_count())",
                            "Call"
                        ]
                    ]
                }
            },
            "where_760": {
                "condition": {
                    "value": "grad_norm > self.args.clip_norm",
                    "type": "Compare",
                    "possible_values": []
                },
                "x": {
                    "value": "grad_norm.new_tensor(100)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "grad_norm.new_tensor(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "get_device_capability_151": {
                "device": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "get_device_capability_163": {
                "device": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_tensor_721": {
                "obj": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sum((log[k] for log in logging_outputs if k in log))",
                            "Call"
                        ],
                        [
                            "logging_outputs[0][k]",
                            "Subscript"
                        ],
                        [
                            "torch.zeros_like(v) if torch.is_tensor(v) else 0",
                            "IfExp"
                        ]
                    ]
                }
            },
            "zeros_like_721": {
                "input": {
                    "value": "v",
                    "type": "variable",
                    "possible_values": [
                        [
                            "sum((log[k] for log in logging_outputs if k in log))",
                            "Call"
                        ],
                        [
                            "logging_outputs[0][k]",
                            "Subscript"
                        ],
                        [
                            "torch.zeros_like(v) if torch.is_tensor(v) else 0",
                            "IfExp"
                        ]
                    ]
                }
            },
            "empty_cache_506": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq/utils.py": {
        "torch": {
            "norm_252": {
                "input": {
                    "value": "g",
                    "type": "variable",
                    "possible_values": [
                        [
                            "grads",
                            "variable"
                        ]
                    ]
                }
            },
            "get_rng_state_434": {
                "variable": {
                    "value": "rng_state",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "get_rng_state_435": {
                "variable": {
                    "value": "cuda_rng_state",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "remainder_228": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range - num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "remainder_230": {
                "variable": {
                    "value": "index",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "range + num_pads",
                    "type": "BinOp",
                    "possible_values": []
                },
                "other": {
                    "value": "max_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_427": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "seed",
                            "Method Argument"
                        ],
                        [
                            "seed",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "manual_seed_428": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "seed",
                            "Method Argument"
                        ],
                        [
                            "seed",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "set_rng_state_438": {
                "new_state": {
                    "value": "rng_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.get_rng_state()",
                            "Call"
                        ]
                    ]
                }
            },
            "set_rng_state_439": {
                "new_state": {
                    "value": "cuda_rng_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.cuda.get_rng_state()",
                            "Call"
                        ]
                    ]
                }
            },
            "arange_498": {
                "start": {
                    "value": "size[-1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "device": {
                    "value": "x.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_tensor_51": {
                "obj": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Tensor_140": {
                "variable": {
                    "value": "embed_dict[pieces[0]]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_206": {
                "start": {
                    "value": "max",
                    "type": "variable",
                    "possible_values": [
                        [
                            "max",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "buffered_arange.buf",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_252": {
                "tensors": {
                    "value": "[torch.norm(g) for g in grads]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "softmax_349": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "softmax_351": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "log_softmax_356": {
                "input": {
                    "value": "x.float()",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "log_softmax_358": {
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "dim",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_251": {
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "cumsum_194": {
                "input": {
                    "value": "mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tensor.ne(padding_idx).int()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq_cli/eval_lm.py": {
        "torch": {
            "is_available_65": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq_cli/generate.py": {
        "torch": {
            "is_available_54": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq_cli/interactive.py": {
        "torch": {
            "is_available_86": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq_cli/train.py": {
        "torch": {
            "manual_seed_46": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "is_available_43": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "set_device_44": {
                "device": {
                    "value": "args.device_id",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_count_341": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_353": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_count_347": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/fairseq_cli/validate.py": {
        "torch": {
            "is_available_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/scripts/average_checkpoints.py": {
        "torch": {
            "load_31": {
                "variable": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "f",
                    "type": "variable",
                    "possible_values": [
                        [
                            "inputs",
                            "variable"
                        ],
                        [
                            "files",
                            "variable"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda s, _: torch.serialization.default_restore_location(s, 'cpu')",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "save_138": {
                "obj": {
                    "value": "new_state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "state",
                            "variable"
                        ],
                        [
                            "average_checkpoints(args.inputs)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "args.output",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/setup.py": {
        "torch": {}
    },
    "code/fairseq/tests/speech_recognition/asr_test_base.py": {
        "torch": {
            "randn_76": {
                "variable": {
                    "value": "feature",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "B",
                    "type": "variable",
                    "possible_values": [
                        [
                            "5",
                            "Method Argument"
                        ]
                    ]
                },
                "out": {
                    "value": "T",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "D",
                    "type": "variable",
                    "possible_values": [
                        [
                            "80",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "from_numpy_79": {
                "variable": {
                    "value": "src_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.random.randint(low=1, high=T, size=B, dtype=np.int64)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_111": {
                "variable": {
                    "value": "encoder_out[encoder_out]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.random.randn(*encoder_out_shape).astype(np.float32)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_114": {
                "variable": {
                    "value": "seq_lengths",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.random.randint(low=1, high=T, size=B)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_116": {
                "start": {
                    "value": "T",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "log_484": {
                "input": {
                    "value": "torch.div(net_output['encoder_out'], 1 - net_output['encoder_out'])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_530": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(2, 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_534": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(2, 10, 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_542": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(2, 2)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_546": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(2, 10)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "from_numpy_87": {
                "ndarray": {
                    "value": "tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "np.random.randint(low=0, high=K, size=token_length, dtype=np.int64)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "div_485": {
                "input": {
                    "value": "net_output['encoder_out']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "1 - net_output['encoder_out']",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "is_tensor_313": {
                "obj": {
                    "value": "logprob",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_314": {
                "obj": {
                    "value": "prob",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=False)",
                            "Call"
                        ],
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_381": {
                "obj": {
                    "value": "logprob",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_tensor_382": {
                "obj": {
                    "value": "prob",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=False)",
                            "Call"
                        ],
                        [
                            "self.model.get_normalized_probs(forward_output, log_probs=False)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_554": {
                "data": {
                    "value": "[L]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/speech_recognition/test_collaters.py": {
        "torch": {
            "tensor_33": {
                "data": {
                    "value": "[1, 0]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_37": {
                "data": {
                    "value": "[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [pad_idx, pad_idx]]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_43": {
                "data": {
                    "value": "[[eos_idx, 3, 2, pad_idx], [eos_idx, 4, 2, 3]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_45": {
                "data": {
                    "value": "[3, 2]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_48": {
                "data": {
                    "value": "[[3, 2, eos_idx, pad_idx], [4, 2, 3, eos_idx]]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_average_checkpoints.py": {
        "torch": {
            "Embedding_23": {
                "variable": {
                    "value": "self.embedding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "1000",
                    "type": "int",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_24": {
                "variable": {
                    "value": "self.FC1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_25": {
                "variable": {
                    "value": "self.FC2",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "200",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_27": {
                "variable": {
                    "value": "self.FC2.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.FC1.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Parameter_28": {
                "variable": {
                    "value": "self.FC2.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "self.FC1.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ReLU_30": {
                "variable": {
                    "value": "self.relu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_63": {
                "obj": {
                    "value": "collections.OrderedDict([('model', params_0)])",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "path_0",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tempfile.mkstemp()",
                            "Call"
                        ]
                    ]
                }
            },
            "save_64": {
                "obj": {
                    "value": "collections.OrderedDict([('model', params_1)])",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "path_1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "tempfile.mkstemp()",
                            "Call"
                        ]
                    ]
                }
            },
            "save_92": {
                "obj": {
                    "value": "{'model': m.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(tmpdir, 'm1.pt')",
                            "Call"
                        ],
                        [
                            "os.path.join(tmpdir, 'm2.pt')",
                            "Call"
                        ],
                        [
                            "os.path.join(tmpdir, 'm3.pt')",
                            "Call"
                        ],
                        [
                            "path",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "equal_114": {
                "input": {
                    "value": "new_model['model']['embedding.weight']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "(m1.embedding.weight + m2.embedding.weight + m3.embedding.weight) / 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "equal_123": {
                "input": {
                    "value": "new_model['model']['FC1.weight']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "(m1.FC1.weight + m2.FC1.weight + m3.FC1.weight) / 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "equal_132": {
                "input": {
                    "value": "new_model['model']['FC2.weight']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "other": {
                    "value": "(m1.FC2.weight + m2.FC2.weight + m3.FC2.weight) / 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_backtranslation_dataset.py": {
        "torch": {
            "is_available_30": {
                "variable": {
                    "value": "self.cuda",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataLoader_73": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "backtranslation_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "BacktranslationDataset(tgt_dataset=TransformEosDataset(dataset=tgt_dataset, eos=self.tgt_dict.eos(), remove_eos_from_src=remove_eos_from_input_src), src_dict=self.tgt_dict, backtranslation_fn=lambda sample: generator.generate([self.model], sample), output_collater=TransformEosDataset(dataset=tgt_dataset, eos=self.tgt_dict.eos(), append_eos_to_tgt=remove_eos_from_input_src, remove_eos_from_src=remove_eos_from_output_src).collater, cuda=self.cuda)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "backtranslation_dataset.collater",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_binaries.py": {
        "torch": {
            "rand_758": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_examples * maxlen",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "rand_798": {
                "variable": {
                    "value": "random_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "num_examples * maxlen",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "rand_801": {
                "variable": {
                    "value": "output_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(num_examples, num_classes)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "is_available_50": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_59": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_285": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_726": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "floor_759": {
                "input": {
                    "value": "26 * data",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "floor_777": {
                "variable": {
                    "value": "src_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.rand(num_alignments) * src_len",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "floor_778": {
                "variable": {
                    "value": "tgt_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.rand(num_alignments) * tgt_len",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "floor_799": {
                "input": {
                    "value": "26 * random_data",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "floor_803": {
                "input": {
                    "value": "num_classes * torch.rand(num_examples)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "rand_777": {
                "*size": {
                    "value": "num_alignments",
                    "type": "variable",
                    "possible_values": [
                        [
                            "random.randint(avg_len // 2, 2 * avg_len)",
                            "Call"
                        ]
                    ]
                }
            },
            "rand_778": {
                "*size": {
                    "value": "num_alignments",
                    "type": "variable",
                    "possible_values": [
                        [
                            "random.randint(avg_len // 2, 2 * avg_len)",
                            "Call"
                        ]
                    ]
                }
            },
            "rand_803": {
                "*size": {
                    "value": "num_examples",
                    "type": "variable",
                    "possible_values": [
                        [
                            "100",
                            "Method Argument"
                        ],
                        [
                            "100",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/tests/test_bmuf.py": {
        "torch": {
            "CrossEntropyLoss_35": {
                "variable": {
                    "value": "loss_fn",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_57": {
                "variable": {
                    "value": "is_cuda",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_20": {
                "variable": {
                    "value": "self.fc",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_size",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_size",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "manual_seed_33": {
                "seed": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_64": {
                "variable": {
                    "value": "input",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "args.input_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "empty_65": {
                "variable": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "args.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "set_device_59": {
                "device": {
                    "value": "rank",
                    "type": "variable",
                    "possible_values": [
                        [
                            "rank in range(args.distributed_world_size)",
                            "Call"
                        ],
                        [
                            "rank",
                            "Method Argument"
                        ],
                        [
                            "rank",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_77": {
                "variable": {
                    "value": "results",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(results, param.flatten().cpu().data)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_count_108": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_character_token_embedder.py": {
        "torch": {}
    },
    "code/fairseq/tests/test_concat_dataset.py": {
        "torch": {}
    },
    "code/fairseq/tests/test_convtbc.py": {
        "torch": {
            "Conv1d_18": {
                "variable": {
                    "value": "conv1d",
                    "type": "variable",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "randn_23": {
                "variable": {
                    "value": "input_tbc",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "7",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "randn_32": {
                "variable": {
                    "value": "grad_tbc",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "output_tbc.size()",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_dictionary.py": {
        "torch": {}
    },
    "code/fairseq/tests/test_export.py": {
        "torch": {
            "script_69": {
                "variable": {
                    "value": "scripted",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "module",
                    "type": "variable",
                    "possible_values": [
                        [
                            "multihead_attention.MultiheadAttention(embed_dim=8, num_heads=2)",
                            "Call"
                        ],
                        [
                            "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding(embedding_dim=8, padding_idx=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "script_74": {
                "variable": {
                    "value": "module1",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "module1",
                    "type": "variable",
                    "possible_values": [
                        [
                            "multihead_attention.MultiheadAttention(embed_dim=8, num_heads=2)",
                            "Call"
                        ],
                        [
                            "torch.jit.script(module1)",
                            "Call"
                        ]
                    ]
                }
            },
            "script_76": {
                "variable": {
                    "value": "module2",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "module2",
                    "type": "variable",
                    "possible_values": [
                        [
                            "multihead_attention.MultiheadAttention(embed_dim=8, num_heads=2)",
                            "Call"
                        ],
                        [
                            "torch.jit.script(module2)",
                            "Call"
                        ]
                    ]
                }
            },
            "script_91": {
                "variable": {
                    "value": "scripted",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "module",
                    "type": "variable",
                    "possible_values": [
                        [
                            "multihead_attention.MultiheadAttention(embed_dim=8, num_heads=2)",
                            "Call"
                        ],
                        [
                            "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding(embedding_dim=8, padding_idx=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "script_102": {
                "variable": {
                    "value": "scripted",
                    "type": "variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TransformerModel.build_model(args, task)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_65": {
                "f": {
                    "value": "f.name",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_79": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_80": {
                "data": {
                    "value": "[2]",
                    "type": "List",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_label_smoothing.py": {
        "torch": {
            "unsqueeze_41": {
                "variable": {
                    "value": "self.args.probs",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_memory_efficient_fp16.py": {
        "torch": {
            "Linear_27": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_16": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_tensor_63": {
                "obj": {
                    "value": "v_i",
                    "type": "variable",
                    "possible_values": [
                        [
                            "v.values()",
                            "Call"
                        ]
                    ]
                }
            },
            "rand_53": {
                "*size": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_multi_corpus_sampled_dataset.py": {
        "torch": {}
    },
    "code/fairseq/tests/test_multihead_attention.py": {
        "torch": {
            "tensor_21": {
                "data": {
                    "value": "[[1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_23": {
                "data": {
                    "value": "[[0, 0, 0, 1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_28": {
                "data": {
                    "value": "[[0, 1, 0]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_29": {
                "data": {
                    "value": "[[0, 1, 0, 0]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_33": {
                "data": {
                    "value": "[[1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_34": {
                "data": {
                    "value": "[[0, 1, 0]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_35": {
                "data": {
                    "value": "[[0, 1, 0, 1]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "all_49": {
                "input": {
                    "value": "torch.eq(key_padding_mask, c[2])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "eq_49": {
                "input": {
                    "value": "key_padding_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "MultiheadAttention._append_prev_key_padding_mask(c[0], c[1], batch_size=bsz, src_len=src_len, static_kv=False)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "c[2]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_noising.py": {
        "torch": {
            "DataLoader_440": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "language_pair_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "LanguagePairDataset(src=noising_dataset, tgt=tgt, src_sizes=None, src_dict=src_dict)",
                            "Call"
                        ],
                        [
                            "TransformEosDataset(language_pair_dataset, src_dict.eos(), append_eos_to_tgt=append_eos_to_tgt)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "language_pair_dataset.collater",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "t_454": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[['he@@', 'llo', 'n@@', 'ew', 'y@@', 'or@@', 'k'], ['how', 'are', 'y@@', 'ou']]",
                            "List"
                        ],
                        [
                            "[['he', 'llo_EOW', 'n', 'ew_EOW', 'y', 'or', 'k_EOW'], ['how_EOW', 'are_EOW', 'y', 'ou_EOW']]",
                            "List"
                        ],
                        [
                            "[['hello', 'new', 'york', 'you'], ['how', 'are', 'you', 'new', 'york']]",
                            "List"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=True)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=False)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            },
            "t_491": {
                "variable": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "src_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[['he@@', 'llo', 'n@@', 'ew', 'y@@', 'or@@', 'k'], ['how', 'are', 'y@@', 'ou']]",
                            "List"
                        ],
                        [
                            "[['he', 'llo_EOW', 'n', 'ew_EOW', 'y', 'or', 'k_EOW'], ['how_EOW', 'are_EOW', 'y', 'ou_EOW']]",
                            "List"
                        ],
                        [
                            "[['hello', 'new', 'york', 'you'], ['how', 'are', 'you', 'new', 'york']]",
                            "List"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=True)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ],
                        [
                            "self._get_test_data_with_bpe_cont_marker(append_eos=False)",
                            "Call"
                        ],
                        [
                            "torch.t(src_tokens)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/tests/test_reproducibility.py": {
        "torch": {
            "is_available_72": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_79": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_sequence_generator.py": {
        "torch": {
            "log_23": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_236": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_406": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_sequence_scorer.py": {
        "torch": {
            "log_97": {
                "variable": {
                    "value": "pos_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_sparse_multihead_attention.py": {
        "torch": {
            "randn_13": {
                "variable": {
                    "value": "attn_weights",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "out": {
                    "value": "8",
                    "type": "int",
                    "possible_values": []
                },
                "dtype": {
                    "value": "8",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_14": {
                "variable": {
                    "value": "bidirectional_sparse_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[[0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_29": {
                "variable": {
                    "value": "sparse_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[[0, float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, 0, float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, 0, 0, float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), float('-inf')], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, float('-inf'), float('-inf')], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, float('-inf')], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "all_27": {
                "input": {
                    "value": "torch.eq(bidirectional_attention_sparse_mask, bidirectional_sparse_mask)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "all_44": {
                "input": {
                    "value": "torch.eq(attention_sparse_mask, sparse_mask)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "eq_27": {
                "input": {
                    "value": "bidirectional_attention_sparse_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bidirectional_attention.buffered_sparse_mask(attn_weights, 8, 8)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "bidirectional_sparse_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([[0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0]])",
                            "Call"
                        ]
                    ]
                }
            },
            "eq_44": {
                "input": {
                    "value": "attention_sparse_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "attention.buffered_sparse_mask(attn_weights, 8, 8)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "sparse_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor([[0, float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, 0, float('-inf'), float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, 0, 0, float('-inf'), float('-inf'), float('-inf'), float('-inf')], [0, 0, 0, 0, 0, float('-inf'), float('-inf'), float('-inf')], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, float('-inf'), float('-inf')], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, float('-inf')], [float('-inf'), float('-inf'), float('-inf'), 0, 0, 0, 0, 0]])",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "code/fairseq/tests/test_token_block_dataset.py": {
        "torch": {
            "tensor_24": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_25": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_26": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_34": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_35": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_36": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_45": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_46": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_47": {
                "data": {
                    "value": "[9, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_57": {
                "data": {
                    "value": "[5, 4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_58": {
                "data": {
                    "value": "[8, 7, 6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_59": {
                "data": {
                    "value": "[9, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_66": {
                "data": {
                    "value": "[4, 3, 2, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_67": {
                "data": {
                    "value": "[5, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_68": {
                "data": {
                    "value": "[1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_69": {
                "data": {
                    "value": "[6, 1]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/test_train.py": {
        "torch": {}
    },
    "code/fairseq/tests/test_utils.py": {
        "torch": {
            "Parameter_78": {
                "variable": {
                    "value": "params",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.zeros(5)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "full_87": {
                "variable": {
                    "value": "exp_grad_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "size": {
                    "value": "(15,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "norm_87": {
                "variable": {
                    "value": "exp_grad_norm",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "full_85": {
                "variable": {
                    "value": "p.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "size": {
                    "value": "(5,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_tensor_80": {
                "obj": {
                    "value": "grad_norm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "utils.clip_grad_norm_(params, 1.0)",
                            "Call"
                        ],
                        [
                            "utils.clip_grad_norm_(params, 1.0)",
                            "Call"
                        ],
                        [
                            "utils.clip_grad_norm_(params, 1.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "Parameter_83": {
                "data": {
                    "value": "torch.zeros(5)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_tensor_88": {
                "obj": {
                    "value": "grad_norm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "utils.clip_grad_norm_(params, 1.0)",
                            "Call"
                        ],
                        [
                            "utils.clip_grad_norm_(params, 1.0)",
                            "Call"
                        ],
                        [
                            "utils.clip_grad_norm_(params, 1.0)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_92": {
                "data": {
                    "value": "1.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "zeros_83": {
                "*size": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_78": {
                "*size": {
                    "value": "5",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq/tests/utils.py": {
        "torch": {
            "DataLoader_47": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TestDataset(samples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "len(samples)",
                            "Call"
                        ],
                        [
                            "None",
                            "Method Argument"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "lambda samples: collate(samples, padding_idx, eos_idx)",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "rand_232": {
                "variable": {
                    "value": "attn",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "bbsz",
                    "type": "variable",
                    "possible_values": [
                        [
                            "prev_output_tokens.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "tgt_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "prev_output_tokens.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "src_len",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encoder_out.encoder_out.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "pad_260": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "src_tokens",
                            "variable"
                        ],
                        [
                            "F.pad(x, (0, padding_needed))",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "(0, padding_needed)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq_modules/criterion.py": {
        "torch": {
            "sum_17": {
                "input": {
                    "value": "tokens != pad_idx",
                    "type": "Compare",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "nonzero_23": {
                "variable": {
                    "value": "eos",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "tokens[i] == eos_idx",
                    "type": "Compare",
                    "possible_values": []
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "stack_80": {
                "tensors": {
                    "value": "new_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_87": {
                "tensors": {
                    "value": "[tokens, pad]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "mean_159": {
                "variable": {
                    "value": "reinforce_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.stack([r[0] for r in reinforce_loss_outs])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_160": {
                "variable": {
                    "value": "stacked_acc",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.stack([r[1] for r in reinforce_loss_outs])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_161": {
                "variable": {
                    "value": "loss_2",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.stack([r[2] for r in reinforce_loss_outs])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "mean_162": {
                "variable": {
                    "value": "nll_loss_2",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.stack([r[3] for r in reinforce_loss_outs])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_29": {
                "data": {
                    "value": "lens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[len(tok_list) for tok_list in tokens]",
                            "ListComp"
                        ],
                        [
                            "[len(tok_list) for tok_list in tokens]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "stack_70": {
                "tensors": {
                    "value": "new_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "stack_68": {
                "tensors": {
                    "value": "new_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_79": {
                "tensors": {
                    "value": "[tok_list, torch.tensor([eos_idx]).long().cuda(), (pad_idx * torch.ones(max_len - len(tok_list))).long().cuda()]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "stack_159": {
                "tensors": {
                    "value": "[r[0] for r in reinforce_loss_outs]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "stack_160": {
                "tensors": {
                    "value": "[r[1] for r in reinforce_loss_outs]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "stack_161": {
                "tensors": {
                    "value": "[r[2] for r in reinforce_loss_outs]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "stack_162": {
                "tensors": {
                    "value": "[r[3] for r in reinforce_loss_outs]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_265": {
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "cat_41": {
                "tensors": {
                    "value": "[(pad_idx * torch.ones(max_len - len(tok_list))).long().cuda(), tok_list, torch.tensor([eos_idx]).long().cuda()]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_43": {
                "tensors": {
                    "value": "[(pad_idx * torch.ones(max_len - len(tok_list))).long().cuda(), tok_list]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_48": {
                "tensors": {
                    "value": "[torch.zeros(max_len - len(tok_list)).bool().cuda(), torch.ones(len(tok_list)).bool().cuda(), torch.tensor([0]).bool().cuda()]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_54": {
                "tensors": {
                    "value": "[torch.ones(len(tok_list)).bool().cuda(), torch.tensor([0]).bool().cuda(), torch.zeros(max_len - len(tok_list)).bool().cuda()]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_60": {
                "tensors": {
                    "value": "[torch.zeros(max_len - len(tok_list)).bool().cuda(), torch.ones(len(tok_list)).bool().cuda()]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_64": {
                "tensors": {
                    "value": "[torch.ones(len(tok_list)).bool().cuda(), torch.zeros(max_len - len(tok_list)).bool().cuda()]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_79": {
                "data": {
                    "value": "[eos_idx]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "tensor_41": {
                "data": {
                    "value": "[eos_idx]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "ones_86": {
                "*size": {
                    "value": "(tokens.shape[0], desired_length - tokens.shape[1])",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "zeros_49": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_50": {
                "*size": {
                    "value": "len(tok_list)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_51": {
                "data": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "ones_55": {
                "*size": {
                    "value": "len(tok_list)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_56": {
                "data": {
                    "value": "[0]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "zeros_57": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_61": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_62": {
                "*size": {
                    "value": "len(tok_list)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ones_65": {
                "*size": {
                    "value": "len(tok_list)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_66": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_79": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_41": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_43": {
                "*size": {
                    "value": "max_len - len(tok_list)",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "code/fairseq_modules/model.py": {
        "torch": {
            "nonzero_26": {
                "variable": {
                    "value": "eos",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "tokens[i] == eos_idx",
                    "type": "Compare",
                    "possible_values": []
                },
                "as_tuple": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Linear_207": {
                "variable": {
                    "value": "classifier",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "args.encoder_embed_dim",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "dropout_312": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": [
                        [
                            "embed + self.embed_positions(src_tokens)",
                            "BinOp"
                        ],
                        [
                            "self.layernorm_embedding(x)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.dropout, training=self.training)",
                            "Call"
                        ],
                        [
                            "self.forward_embedding(src_tokens, token_embedding)",
                            "Call"
                        ],
                        [
                            "x.transpose(0, 1)",
                            "Call"
                        ],
                        [
                            "layer(x, encoder_padding_mask)",
                            "Call"
                        ],
                        [
                            "self.layer_norm(x)",
                            "Call"
                        ],
                        [
                            "self.bpe.decode(x)",
                            "Call"
                        ],
                        [
                            "self.tokenizer.decode(x)",
                            "Call"
                        ],
                        [
                            "x",
                            "Method Argument"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "pad_sequence_543": {
                "variable": {
                    "value": "sample_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sample_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[s[0]['tokens'] for s in sample]",
                            "ListComp"
                        ],
                        [
                            "pad_sequence(sample_tokens, batch_first=True, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "[s[0]['tokens'] for s in sample]",
                            "ListComp"
                        ],
                        [
                            "pad_sequence(sample_tokens, batch_first=True, padding_value=self.padding_idx)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_546": {
                "variable": {
                    "value": "sample_tokens_prev",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.generator.eos * torch.ones((sample_tokens_prev.shape[0], 1)).long().cuda(), sample_tokens_prev]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Categorical_551": {
                "variable": {
                    "value": "p_yhat",
                    "type": "variable",
                    "possible_values": []
                },
                "logits": {
                    "value": "sample_lprobs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.get_normalized_probs(sample_output, log_probs=True)",
                            "Call"
                        ],
                        [
                            "sample_lprobs.view(-1, sample_lprobs.size(-1))",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_32": {
                "data": {
                    "value": "lens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "load_211": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.pi_restore_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "empty_358": {
                "variable": {
                    "value": "dropout_probability",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "pad_sequence_570": {
                "variable": {
                    "value": "sample_tokens",
                    "type": "variable",
                    "possible_values": []
                },
                "sequences": {
                    "value": "sample_tokens",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[s[0]['tokens'] for s in sample]",
                            "ListComp"
                        ],
                        [
                            "pad_sequence(sample_tokens, batch_first=True, padding_value=self.padding_idx)",
                            "Call"
                        ],
                        [
                            "[s[0]['tokens'] for s in sample]",
                            "ListComp"
                        ],
                        [
                            "pad_sequence(sample_tokens, batch_first=True, padding_value=self.padding_idx)",
                            "Call"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "padding_value": {
                    "value": "self.padding_idx",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cat_573": {
                "variable": {
                    "value": "sample_tokens_prev",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[self.generator.eos * torch.ones((sample_tokens_prev.shape[0], 1)).long().cuda(), sample_tokens_prev]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_580": {
                "variable": {
                    "value": "pad_onehot",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "logits.shape[2]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "load_505": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.pi_restore_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_518": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.f_restore_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_558": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_765": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "args.f_restore_path",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ones_546": {
                "*size": {
                    "value": "(sample_tokens_prev.shape[0], 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "ones_573": {
                "*size": {
                    "value": "(sample_tokens_prev.shape[0], 1)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "code/run_spoc.py": {
        "torch": {}
    },
    "imggen/run_composed.py": {
        "torch": {
            "MSELoss_134": {
                "variable": {
                    "value": "mse_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "MSELoss_135": {
                "variable": {
                    "value": "eval_mse_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Adam_140": {
                "variable": {
                    "value": "optimizer_pi",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "pi_model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "opt.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "betas": {
                    "value": "(opt.b1, opt.b2)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "DataLoader_182": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "Fonts(DATA_DIR, split='train', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), denoise=True, denoise_transform=denoise_transform, num_fonts_pi=opt.num_fonts_pi)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "load_232": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.pi_restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_252": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "Fonts(DATA_DIR, split='train', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), num_examples=opt.num_examples)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_273": {
                "variable": {
                    "value": "val_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Fonts(DATA_DIR, split='val', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), num_examples=opt.num_examples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_287": {
                "variable": {
                    "value": "test_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Fonts(DATA_DIR, split='test', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), num_examples=opt.num_examples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Adam_294": {
                "variable": {
                    "value": "optimizer_G",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "generator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "opt.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "betas": {
                    "value": "(opt.b1, opt.b2)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "stack_320": {
                "variable": {
                    "value": "all_imgs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "all_imgs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[test_dataset.get_item_from_all(i)[0] for i in range(len(test_dataset.all_data))]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(all_imgs)",
                            "Call"
                        ]
                    ]
                }
            },
            "load_391": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.pi_restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "load_247": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.pi_restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "Embedding_100": {
                "variable": {
                    "value": "self.label_emb",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "opt.n_classes",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "opt.n_classes",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_101": {
                "variable": {
                    "value": "self.domain_emb",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "opt.n_domains",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "opt.latent_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Sequential_113": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*block(opt.latent_dim + opt.n_classes, 128, normalize=False)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "cat_126": {
                "variable": {
                    "value": "gen_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.label_emb(labels), self.domain_emb(domain))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "save_226": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'state_dict': pi_model.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'state_dict': generator.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.pi_restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_345": {
                "variable": {
                    "value": "l2_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_120": {
                "in_features": {
                    "value": "1024",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "int(np.prod(img_shape))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Tanh_121": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_386": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'state_dict': pi_model.state_dict()}",
                            "Dict"
                        ],
                        [
                            "{'state_dict': generator.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.pi_restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'pi_checkpoint{pi_path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "opt.restore_path",
                            "Attribute"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ],
                        [
                            "str(save_dir / f'checkpoint{path_suffix}.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_104": {
                "in_features": {
                    "value": "in_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_feat",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "LeakyReLU_107": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm1d_106": {
                "num_features": {
                    "value": "out_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "eps": {
                    "value": "0.8",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Dropout_109": {
                "p": {
                    "value": "opt.dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "sum_349": {
                "input": {
                    "value": "torch.pow(param, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "pow_349": {
                "input": {
                    "value": "param",
                    "type": "variable",
                    "possible_values": [
                        [
                            "generator.named_parameters()",
                            "Call"
                        ]
                    ]
                },
                "exponent": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "imggen/run_direct.py": {
        "torch": {
            "MSELoss_104": {
                "variable": {
                    "value": "mse_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "MSELoss_105": {
                "variable": {
                    "value": "eval_mse_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "type": "str",
                    "possible_values": []
                }
            },
            "DataLoader_115": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "Fonts(DATA_DIR, split='train', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), num_examples=opt.num_examples)",
                    "type": "Call",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_136": {
                "variable": {
                    "value": "val_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "val_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Fonts(DATA_DIR, split='val', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), num_examples=opt.num_examples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataLoader_150": {
                "variable": {
                    "value": "test_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_dataset",
                    "type": "variable",
                    "possible_values": [
                        [
                            "Fonts(DATA_DIR, split='test', transform=transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]), num_examples=opt.num_examples)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "opt.batch_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Adam_157": {
                "variable": {
                    "value": "optimizer_G",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "generator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "opt.lr",
                    "type": "Attribute",
                    "possible_values": []
                },
                "betas": {
                    "value": "(opt.b1, opt.b2)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "load_248": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / 'checkpoint.pt')",
                            "Call"
                        ],
                        [
                            "'models/composed_diff_dropout0.1/pi_checkpoint.pt'",
                            "str"
                        ],
                        [
                            "str(save_dir / 'checkpoint.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "load_257": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / 'checkpoint.pt')",
                            "Call"
                        ],
                        [
                            "'models/composed_diff_dropout0.1/pi_checkpoint.pt'",
                            "str"
                        ],
                        [
                            "str(save_dir / 'checkpoint.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_67": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Embedding_74": {
                "variable": {
                    "value": "self.label_emb",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "opt.n_classes",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "opt.n_classes",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_75": {
                "variable": {
                    "value": "self.domain_emb",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "opt.n_domains",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "opt.latent_dim",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Sequential_84": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*block(opt.latent_dim + opt.n_classes, 128, normalize=False)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "cat_97": {
                "variable": {
                    "value": "gen_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(self.label_emb(labels), self.domain_emb(domain))",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_205": {
                "variable": {
                    "value": "l2_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "0.0",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_91": {
                "in_features": {
                    "value": "1024",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "int(np.prod(img_shape))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Tanh_92": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_244": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'state_dict': generator.state_dict()}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "checkpoint_fpath",
                    "type": "variable",
                    "possible_values": [
                        [
                            "str(save_dir / 'checkpoint.pt')",
                            "Call"
                        ],
                        [
                            "'models/composed_diff_dropout0.1/pi_checkpoint.pt'",
                            "str"
                        ],
                        [
                            "str(save_dir / 'checkpoint.pt')",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_78": {
                "in_features": {
                    "value": "in_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "out_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_feat",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "LeakyReLU_81": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "BatchNorm1d_80": {
                "num_features": {
                    "value": "out_feat",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_feat",
                            "Method Argument"
                        ]
                    ]
                },
                "eps": {
                    "value": "0.8",
                    "type": "float",
                    "possible_values": []
                }
            },
            "sum_209": {
                "input": {
                    "value": "torch.pow(param, 2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "pow_209": {
                "input": {
                    "value": "param",
                    "type": "variable",
                    "possible_values": [
                        [
                            "generator.named_parameters()",
                            "Call"
                        ]
                    ]
                },
                "exponent": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "imggen/unet.py": {
        "torch": {
            "Sequential_29": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Sequential_46": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "cat_50": {
                "variable": {
                    "value": "x",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(x, skip_input)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sequential_79": {
                "variable": {
                    "value": "self.final",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Upsample(scale_factor=2)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_113": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*discriminator_block(in_channels * 2, 64, normalization=False)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "cat_124": {
                "variable": {
                    "value": "img_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(img_A, img_B)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Conv2d_23": {
                "in_channels": {
                    "value": "in_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_size",
                            "Method Argument"
                        ],
                        [
                            "in_size",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "out_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_size",
                            "Method Argument"
                        ],
                        [
                            "out_size",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "LeakyReLU_26": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                }
            },
            "ConvTranspose2d_39": {
                "in_channels": {
                    "value": "in_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_size",
                            "Method Argument"
                        ],
                        [
                            "in_size",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "out_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_size",
                            "Method Argument"
                        ],
                        [
                            "out_size",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "InstanceNorm2d_40": {
                "num_features": {
                    "value": "out_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_size",
                            "Method Argument"
                        ],
                        [
                            "out_size",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ReLU_41": {
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "Upsample_80": {
                "scale_factor": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ZeroPad2d_81": {
                "padding": {
                    "value": "(1, 0, 1, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Conv2d_82": {
                "in_channels": {
                    "value": "128",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_channels",
                    "type": "variable",
                    "possible_values": [
                        [
                            "3",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Tanh_83": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ZeroPad2d_118": {
                "padding": {
                    "value": "(1, 0, 1, 0)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "Conv2d_119": {
                "in_channels": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "InstanceNorm2d_25": {
                "num_features": {
                    "value": "out_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_size",
                            "Method Argument"
                        ],
                        [
                            "out_size",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_28": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.0",
                            "Method Argument"
                        ],
                        [
                            "0.0",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_44": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.0",
                            "Method Argument"
                        ],
                        [
                            "0.0",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Conv2d_107": {
                "in_channels": {
                    "value": "in_filters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "in_filters",
                            "Method Argument"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "out_filters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_filters",
                            "Method Argument"
                        ]
                    ]
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "LeakyReLU_110": {
                "negative_slope": {
                    "value": "0.2",
                    "type": "float",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "InstanceNorm2d_109": {
                "num_features": {
                    "value": "out_filters",
                    "type": "variable",
                    "possible_values": [
                        [
                            "out_filters",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    }
}