{
    "data/tf_preprocessing.py": {
        "tensorflow": {
            "equal_88": {
                "variable": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "a",
                    "type": "Variable",
                    "possible_values": []
                },
                "y": {
                    "value": "b",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cast_89": {
                "variable": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.equal(a, b)",
                            "Call"
                        ],
                        [
                            "tf.cast(match, tf.int32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "constant_95": {
                "variable": {
                    "value": "bbox",
                    "type": "Variable",
                    "possible_values": []
                },
                "value": {
                    "value": "[0.0, 0.0, 1.0, 1.0]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shape": {
                    "value": "[1, 1, 4]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "extract_jpeg_shape_104": {
                "variable": {
                    "value": "original_shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cond_107": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "pred": {
                    "value": "bad",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "_at_least_x_are_equal(original_shape, tf.shape(image), 3)",
                            "Call"
                        ]
                    ]
                },
                "true_fn": {
                    "value": "lambda : _decode_and_center_crop(image_bytes, image_size)",
                    "type": "Lambda",
                    "possible_values": []
                },
                "false_fn": {
                    "value": "lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "extract_jpeg_shape_117": {
                "variable": {
                    "value": "shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "cast_121": {
                "variable": {
                    "value": "padded_center_crop_size",
                    "type": "Variable",
                    "possible_values": []
                },
                "x": {
                    "value": "image_size / (image_size + CROP_PADDING) * tf.cast(tf.minimum(image_height, image_width), tf.float32)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.int32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_128": {
                "variable": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": []
                },
                "values": {
                    "value": "[offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "decode_and_crop_jpeg_130": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                },
                "crop_window": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.stack([offset_y, offset_x, target_height, target_width])",
                            "Call"
                        ],
                        [
                            "tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])",
                            "Call"
                        ]
                    ]
                },
                "channels": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "random_flip_left_right_138": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "reshape_157": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[image_size, image_size, 3]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "convert_image_dtype_158": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.bfloat16 if use_bfloat16 else tf.float32",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "reshape_177": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "shape": {
                    "value": "[image_size, image_size, 3]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "convert_image_dtype_178": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "image": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "tf.bfloat16 if use_bfloat16 else tf.float32",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "extract_jpeg_shape_66": {
                "variable": {
                    "value": "shape",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "sample_distorted_bounding_box_67": {
                "variable": {
                    "value": "sample_distorted_bounding_box",
                    "type": "Variable",
                    "possible_values": []
                },
                "image_size": {
                    "value": "shape",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.extract_jpeg_shape(image_bytes)",
                            "Call"
                        ],
                        [
                            "tf.image.extract_jpeg_shape(image_bytes)",
                            "Call"
                        ]
                    ]
                },
                "bounding_boxes": {
                    "value": "bbox",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])",
                            "Call"
                        ]
                    ]
                },
                "min_object_covered": {
                    "value": "min_object_covered",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "0.1",
                            "MethodArgument"
                        ]
                    ]
                },
                "aspect_ratio_range": {
                    "value": "aspect_ratio_range",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(0.75",
                            "MethodArgument"
                        ]
                    ]
                },
                "area_range": {
                    "value": "area_range",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(0.05",
                            "MethodArgument"
                        ]
                    ]
                },
                "max_attempts": {
                    "value": "max_attempts",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "100",
                            "MethodArgument"
                        ]
                    ]
                },
                "use_image_if_no_bounding_boxes": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "unstack_78": {
                "variable": {
                    "value": "(offset_y, offset_x, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "bbox_begin",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "unstack_79": {
                "variable": {
                    "value": "(target_height, target_width, _)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "value": {
                    "value": "bbox_size",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "stack_80": {
                "variable": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": []
                },
                "values": {
                    "value": "[offset_y, offset_x, target_height, target_width]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "decode_and_crop_jpeg_81": {
                "variable": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": []
                },
                "contents": {
                    "value": "image_bytes",
                    "type": "Variable",
                    "possible_values": []
                },
                "crop_window": {
                    "value": "crop_window",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.stack([offset_y, offset_x, target_height, target_width])",
                            "Call"
                        ],
                        [
                            "tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])",
                            "Call"
                        ]
                    ]
                },
                "channels": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "greater_equal_90": {
                "x": {
                    "value": "tf.reduce_sum(match)",
                    "type": "Call",
                    "possible_values": []
                },
                "y": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "name_scope_65": {
                "name": {
                    "value": "scope",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "reduce_sum_90": {
                "input_tensor": {
                    "value": "match",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.equal(a, b)",
                            "Call"
                        ],
                        [
                            "tf.cast(match, tf.int32)",
                            "Call"
                        ]
                    ]
                }
            },
            "shape_105": {
                "input": {
                    "value": "image",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "distorted_bounding_box_crop(image_bytes, bbox, min_object_covered=0.1, aspect_ratio_range=(3.0 / 4, 4.0 / 3.0), area_range=(0.08, 1.0), max_attempts=10, scope=None)",
                            "Call"
                        ],
                        [
                            "tf.cond(bad, lambda : _decode_and_center_crop(image_bytes, image_size), lambda : tf.image.resize([image], [image_size, image_size], resize_method)[0])",
                            "Call"
                        ],
                        [
                            "tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)",
                            "Call"
                        ],
                        [
                            "tf.image.resize([image], [image_size, image_size], resize_method)[0]",
                            "Subscript"
                        ],
                        [
                            "tf.image.random_flip_left_right(image)",
                            "Call"
                        ],
                        [
                            "_decode_and_random_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "_flip(image)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ],
                        [
                            "_decode_and_center_crop(image_bytes, image_size, resize_method)",
                            "Call"
                        ],
                        [
                            "tf.reshape(image, [image_size, image_size, 3])",
                            "Call"
                        ],
                        [
                            "tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)",
                            "Call"
                        ]
                    ]
                }
            },
            "resize_131": {
                "images": {
                    "value": "[image]",
                    "type": "List",
                    "possible_values": []
                },
                "size": {
                    "value": "[image_size, image_size]",
                    "type": "List",
                    "possible_values": []
                },
                "method": {
                    "value": "resize_method",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ],
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ]
                    ]
                }
            },
            "placeholder_218": {
                "variable": {
                    "value": "self._image_bytes",
                    "type": "Attribute",
                    "possible_values": []
                },
                "shape": {
                    "value": "[]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.string",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Session_228": {
                "variable": {
                    "value": "self.sess",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cast_123": {
                "x": {
                    "value": "tf.minimum(image_height, image_width)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "tf.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_217": {
                "device_name": {
                    "value": "/cpu:0",
                    "type": "str",
                    "possible_values": []
                }
            },
            "resize_110": {
                "images": {
                    "value": "[image]",
                    "type": "List",
                    "possible_values": []
                },
                "size": {
                    "value": "[image_size, image_size]",
                    "type": "List",
                    "possible_values": []
                },
                "method": {
                    "value": "resize_method",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ],
                        [
                            "tf.image.ResizeMethod.BICUBIC if interpolation == 'bicubic' else tf.image.ResizeMethod.BILINEAR",
                            "IfExp"
                        ]
                    ]
                }
            },
            "minimum_123": {
                "x": {
                    "value": "image_height",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "shape[0]",
                            "Subscript"
                        ]
                    ]
                },
                "y": {
                    "value": "image_width",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "shape[1]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "data/dataset.py": {
        "torch": {
            "zeros_75": {
                "variable": {
                    "value": "target",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "data/loader.py": {
        "torch": {
            "tensor_14": {
                "variable": {
                    "value": "targets",
                    "type": "Variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[b[1] for b in batch]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.int64",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_16": {
                "variable": {
                    "value": "tensor",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(batch_size, *batch[0][0].shape)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_95": {
                "variable": {
                    "value": "loader",
                    "type": "Variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "type": "Variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "len(targets)",
                            "Call"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "False",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "num_workers",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "collate_fn": {
                    "value": "fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "tensor_30": {
                "variable": {
                    "value": "self.mean",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[x * 255 for x in mean]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "tensor_31": {
                "variable": {
                    "value": "self.std",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "[x * 255 for x in std]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "Stream_34": {
                "variable": {
                    "value": "stream",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "from_numpy_18": {
                "ndarray": {
                    "value": "batch[i][0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "current_stream_48": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "data/transforms.py": {
        "torch": {
            "from_numpy_101": {
                "ndarray": {
                    "value": "np_img",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "np.array(pil_img, dtype=np.uint8)",
                            "Call"
                        ],
                        [
                            "np.expand_dims(np_img, axis=-1)",
                            "Call"
                        ],
                        [
                            "np.rollaxis(np_img, 2)",
                            "Call"
                        ],
                        [
                            "np.array(pil_img, dtype=np.uint8)",
                            "Call"
                        ],
                        [
                            "np.expand_dims(np_img, axis=-1)",
                            "Call"
                        ],
                        [
                            "np.rollaxis(np_img, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_146": {
                "data": {
                    "value": "mean",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tuple(args.mean)",
                            "Call"
                        ],
                        [
                            "tuple(list(mean) * in_chans)",
                            "Call"
                        ],
                        [
                            "IMAGENET_DEFAULT_MEAN",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_147": {
                "data": {
                    "value": "std",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "tuple(args.std)",
                            "Call"
                        ],
                        [
                            "tuple(list(std) * in_chans)",
                            "Call"
                        ],
                        [
                            "IMAGENET_DEFAULT_STD",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "geffnet/activations/__init__.py": {
        "torch": {}
    },
    "geffnet/activations/activations.py": {
        "torch": {
            "relu6_74": {
                "variable": {
                    "value": "inner",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x + 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "softplus_33": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "tanh_33": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "relu6_91": {
                "input": {
                    "value": "x + 3.0",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "geffnet/activations/activations_jit.py": {
        "torch": {
            "softplus_35": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                }
            },
            "tanh_35": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "geffnet/activations/activations_me.py": {
        "torch": {
            "sigmoid_28": {
                "variable": {
                    "value": "x_sigmoid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "sigmoid_73": {
                "variable": {
                    "value": "x_sigmoid",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "softplus_74": {
                "variable": {
                    "value": "x_tanh_sp",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "tanh_74": {
                "variable": {
                    "value": "x_tanh_sp",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "where_148": {
                "variable": {
                    "value": "m",
                    "type": "Variable",
                    "possible_values": []
                },
                "condition": {
                    "value": "(x >= -3.0) & (x <= 3.0)",
                    "type": "BinOp",
                    "possible_values": []
                },
                "x": {
                    "value": "x / 3.0 + 0.5",
                    "type": "BinOp",
                    "possible_values": []
                },
                "y": {
                    "value": "m",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.ones_like(x) * ((x >= -3.0) & (x <= 3.0)) / 6.0",
                            "BinOp"
                        ],
                        [
                            "torch.ones_like(x) * (x >= 3.0)",
                            "BinOp"
                        ],
                        [
                            "torch.where((x >= -3.0) & (x <= 3.0), x / 3.0 + 0.5, m)",
                            "Call"
                        ]
                    ]
                }
            },
            "sigmoid_23": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "tanh_68": {
                "input": {
                    "value": "F.softplus(x)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ones_like_147": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "softplus_68": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "ones_like_112": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ],
                        [
                            "ctx.saved_tensors[0]",
                            "Subscript"
                        ]
                    ]
                }
            }
        }
    },
    "geffnet/conv2d_layers.py": {
        "torch": {
            "pad_71": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])",
                            "Call"
                        ],
                        [
                            "self.pad(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(x_out, 1)",
                            "Call"
                        ],
                        [
                            "x.view(1, B * C, H, W)",
                            "Call"
                        ]
                    ]
                },
                "pad": {
                    "value": "[pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "conv2d_72": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])",
                            "Call"
                        ],
                        [
                            "self.pad(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(x_out, 1)",
                            "Call"
                        ],
                        [
                            "x.view(1, B * C, H, W)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.matmul(routing_weights, self.weight)",
                            "Call"
                        ],
                        [
                            "weight.view(new_weight_shape)",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.matmul(routing_weights, self.bias)",
                            "Call"
                        ],
                        [
                            "bias.view(B * self.out_channels)",
                            "Call"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "False",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "stride",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "(0, 0)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "dilation": {
                    "value": "dilation",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                },
                "groups": {
                    "value": "groups",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "out_chs if depthwise else 1",
                            "IfExp"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ],
                        [
                            "1",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "split_180": {
                "variable": {
                    "value": "x_split",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensor": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])",
                            "Call"
                        ],
                        [
                            "self.pad(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(x_out, 1)",
                            "Call"
                        ],
                        [
                            "x.view(1, B * C, H, W)",
                            "Call"
                        ]
                    ]
                },
                "split_size_or_sections": {
                    "value": "self.splits",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_182": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "x_out",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "[conv(x_split[i]) for (i, conv) in enumerate(self.values())]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Parameter_228": {
                "variable": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.num_experts, weight_num_param)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_251": {
                "variable": {
                    "value": "weight",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "routing_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "other": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "ZeroPad2d_107": {
                "variable": {
                    "value": "self.pad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "pad_arg",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "_same_pad_arg(input_size, self.weight.size()[-2:], self.stride, self.dilation)",
                            "Call"
                        ]
                    ]
                }
            },
            "conv2d_112": {
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])",
                            "Call"
                        ],
                        [
                            "self.pad(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(x_out, 1)",
                            "Call"
                        ],
                        [
                            "x.view(1, B * C, H, W)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "self.weight",
                    "type": "Attribute",
                    "possible_values": []
                },
                "bias": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "stride": {
                    "value": "self.stride",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dilation": {
                    "value": "self.dilation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "groups": {
                    "value": "self.groups",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Conv2d_150": {
                "in_channels": {
                    "value": "in_chs",
                    "type": "Variable",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_chs",
                    "type": "Variable",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "kernel_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "kernel_size if isinstance(kernel_size, list) else [kernel_size]",
                            "IfExp"
                        ],
                        [
                            "3",
                            "MethodArgument"
                        ],
                        [
                            "3",
                            "MethodArgument"
                        ]
                    ]
                },
                "padding": {
                    "value": "padding",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "(stride - 1 + dilation * (kernel_size - 1)) // 2",
                            "BinOp"
                        ],
                        [
                            "padding.lower()",
                            "Call"
                        ],
                        [
                            "_get_padding(kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "_get_padding(kernel_size, **kwargs)",
                            "Call"
                        ],
                        [
                            "kwargs.pop('padding', '')",
                            "Call"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ],
                        [
                            "0",
                            "MethodArgument"
                        ],
                        [
                            "''",
                            "MethodArgument"
                        ],
                        [
                            "''",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Parameter_232": {
                "variable": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(self.num_experts, self.out_channels)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "matmul_256": {
                "variable": {
                    "value": "bias",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "routing_weights",
                    "type": "Variable",
                    "possible_values": []
                },
                "other": {
                    "value": "self.bias",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "conv2d_265": {
                "variable": {
                    "value": "out",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])",
                            "Call"
                        ],
                        [
                            "self.pad(x)",
                            "Call"
                        ],
                        [
                            "torch.cat(x_out, 1)",
                            "Call"
                        ],
                        [
                            "x.view(1, B * C, H, W)",
                            "Call"
                        ]
                    ]
                },
                "weight": {
                    "value": "weight",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "torch.matmul(routing_weights, self.weight)",
                            "Call"
                        ],
                        [
                            "weight.view(new_weight_shape)",
                            "Call"
                        ]
                    ]
                },
                "bias": {
                    "value": "bias",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "torch.matmul(routing_weights, self.bias)",
                            "Call"
                        ],
                        [
                            "bias.view(B * self.out_channels)",
                            "Call"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "True",
                            "MethodArgument"
                        ],
                        [
                            "False",
                            "MethodArgument"
                        ]
                    ]
                },
                "stride": {
                    "value": "self.stride",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding": {
                    "value": "self.padding",
                    "type": "Attribute",
                    "possible_values": []
                },
                "dilation": {
                    "value": "self.dilation",
                    "type": "Attribute",
                    "possible_values": []
                },
                "groups": {
                    "value": "self.groups * B",
                    "type": "BinOp",
                    "possible_values": []
                }
            }
        }
    },
    "geffnet/gen_efficientnet.py": {
        "torch": {
            "Sequential_244": {
                "variable": {
                    "value": "self.blocks",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*builder(in_chs, block_args)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_250": {
                "variable": {
                    "value": "self.global_pool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "output_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_251": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "num_features",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1280",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1000",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Sequential_275": {
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "dropout_282": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "self.conv_stem(x)",
                            "Call"
                        ],
                        [
                            "self.bn1(x)",
                            "Call"
                        ],
                        [
                            "self.act1(x)",
                            "Call"
                        ],
                        [
                            "self.blocks(x)",
                            "Call"
                        ],
                        [
                            "self.conv_head(x)",
                            "Call"
                        ],
                        [
                            "self.bn2(x)",
                            "Call"
                        ],
                        [
                            "self.act2(x)",
                            "Call"
                        ],
                        [
                            "self.features(x)",
                            "Call"
                        ],
                        [
                            "self.global_pool(x)",
                            "Call"
                        ],
                        [
                            "x.flatten(1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.drop_rate, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.drop_rate",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Flatten_274": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_274": {
                "p": {
                    "value": "self.drop_rate",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "geffnet/helpers.py": {
        "torch": {
            "load_16": {
                "variable": {
                    "value": "checkpoint",
                    "type": "Variable",
                    "possible_values": []
                },
                "f": {
                    "value": "checkpoint_path",
                    "type": "Variable",
                    "possible_values": []
                }
            }
        }
    },
    "geffnet/mobilenetv3.py": {
        "torch": {
            "BatchNorm2d_65": {
                "variable": {
                    "value": "self.bn1",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_features": {
                    "value": "stem_size",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "round_channels(stem_size, channel_multiplier)",
                            "Call"
                        ],
                        [
                            "16",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Sequential_72": {
                "variable": {
                    "value": "self.blocks",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "*builder(in_chs, block_args)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "AdaptiveAvgPool2d_75": {
                "variable": {
                    "value": "self.global_pool",
                    "type": "Attribute",
                    "possible_values": []
                },
                "output_size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_78": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "num_features",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1280",
                            "Constant"
                        ],
                        [
                            "1280",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "num_classes",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "1000",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Sequential_92": {
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "dropout_108": {
                "variable": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "self.conv_stem(x)",
                            "Call"
                        ],
                        [
                            "self.bn1(x)",
                            "Call"
                        ],
                        [
                            "self.act1(x)",
                            "Call"
                        ],
                        [
                            "self.blocks(x)",
                            "Call"
                        ],
                        [
                            "self.global_pool(x)",
                            "Call"
                        ],
                        [
                            "self.conv_head(x)",
                            "Call"
                        ],
                        [
                            "self.act2(x)",
                            "Call"
                        ],
                        [
                            "self.features(x)",
                            "Call"
                        ],
                        [
                            "x.flatten(1)",
                            "Call"
                        ],
                        [
                            "F.dropout(x, p=self.drop_rate, training=self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.drop_rate",
                    "type": "Attribute",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Flatten_91": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_91": {
                "p": {
                    "value": "self.drop_rate",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "onnx_export.py": {
        "torch": {
            "randn_75": {
                "variable": {
                    "value": "example_input",
                    "type": "Variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "(args.batch_size, 3, args.img_size or 224, args.img_size or 224)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            }
        }
    },
    "validate.py": {
        "torch": {
            "CrossEntropyLoss_100": {
                "variable": {
                    "value": "criterion",
                    "type": "Variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "script_93": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "obj": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "geffnet.create_model(args.model, num_classes=args.num_classes, in_chans=3, pretrained=args.pretrained, checkpoint_path=args.checkpoint, scriptable=args.torchscript)",
                            "Call"
                        ],
                        [
                            "model.to(memory_format=torch.channels_last)",
                            "Call"
                        ],
                        [
                            "torch.jit.script(model)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model, device_ids=list(range(args.num_gpu))).cuda()",
                            "Call"
                        ],
                        [
                            "model.cuda()",
                            "Call"
                        ]
                    ]
                }
            },
            "DataParallel_104": {
                "variable": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "Variable",
                    "possible_values": [
                        [
                            "geffnet.create_model(args.model, num_classes=args.num_classes, in_chans=3, pretrained=args.pretrained, checkpoint_path=args.checkpoint, scriptable=args.torchscript)",
                            "Call"
                        ],
                        [
                            "model.to(memory_format=torch.channels_last)",
                            "Call"
                        ],
                        [
                            "torch.jit.script(model)",
                            "Call"
                        ],
                        [
                            "torch.nn.DataParallel(model, device_ids=list(range(args.num_gpu))).cuda()",
                            "Call"
                        ],
                        [
                            "model.cuda()",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "list(range(args.num_gpu))",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_128": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}