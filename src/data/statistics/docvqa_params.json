{
    "tokenization.py": {
        "tensorflow": {
            "GFile_125": {
                "name": {
                    "value": "vocab_file",
                    "type": "variable",
                    "possible_values": []
                },
                "mode": {
                    "value": "r",
                    "type": "str",
                    "possible_values": []
                }
            }
        }
    },
    "utils_docvqa.py": {
        "tensorflow": {
            "info_334": {
                "msg": {
                    "value": "*** Example ***",
                    "type": "str",
                    "possible_values": []
                }
            },
            "info_335": {
                "msg": {
                    "value": "'unique_id: %s' % unique_id",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_336": {
                "msg": {
                    "value": "'example_index: %s' % example_index",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_337": {
                "msg": {
                    "value": "'doc_span_index: %s' % doc_span_index",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_338": {
                "msg": {
                    "value": "'tokens: %s' % ' '.join([tokenization.printable_text(x) for x in tokens])",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_340": {
                "msg": {
                    "value": "'token_to_orig_map: %s' % ' '.join(['%d:%d' % (x, y) for (x, y) in six.iteritems(token_to_orig_map)])",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_342": {
                "msg": {
                    "value": "'token_is_max_context: %s' % ' '.join(['%d:%s' % (x, y) for (x, y) in six.iteritems(token_is_max_context)])",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_345": {
                "msg": {
                    "value": "'input_ids: %s' % ' '.join([str(x) for x in input_ids])",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_346": {
                "msg": {
                    "value": "'input_mask: %s' % ' '.join([str(x) for x in input_mask])",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_348": {
                "msg": {
                    "value": "'segment_ids: %s' % ' '.join([str(x) for x in segment_ids])",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_351": {
                "msg": {
                    "value": "impossible example",
                    "type": "str",
                    "possible_values": []
                }
            },
            "info_354": {
                "msg": {
                    "value": "'start_position: %d' % start_position",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_355": {
                "msg": {
                    "value": "'end_position: %d' % end_position",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "info_356": {
                "msg": {
                    "value": "'answer: %s' % tokenization.printable_text(answer_text)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "warning_138": {
                "msg": {
                    "value": "\"Could not find answer: '%s' vs. '%s'\"",
                    "type": "str",
                    "possible_values": []
                },
                "*args": {
                    "value": "actual_text",
                    "type": "variable",
                    "possible_values": [
                        [
                            "' '.join(doc_tokens[start_position:end_position + 1])",
                            "Call"
                        ]
                    ]
                },
                "**kwargs": {
                    "value": "cleaned_answer_text",
                    "type": "variable",
                    "possible_values": [
                        [
                            "' '.join(tokenization.whitespace_tokenize(orig_answer_text))",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "modeling_layoutlm.py": {
        "torch": {
            "Embedding_19": {
                "variable": {
                    "value": "self.word_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "padding_idx": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Embedding_22": {
                "variable": {
                    "value": "self.position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_25": {
                "variable": {
                    "value": "self.x_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_2d_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_28": {
                "variable": {
                    "value": "self.y_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_2d_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_31": {
                "variable": {
                    "value": "self.h_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_2d_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_34": {
                "variable": {
                    "value": "self.w_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.max_2d_position_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Embedding_37": {
                "variable": {
                    "value": "self.token_type_embeddings",
                    "type": "Attribute",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "config.type_vocab_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_44": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_242": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_243": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "config.num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Dropout_348": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_349": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.config.num_labels",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_51": {
                "variable": {
                    "value": "position_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "seq_length",
                    "type": "variable",
                    "possible_values": [
                        [
                            "input_ids.size(1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                },
                "device": {
                    "value": "input_ids.device",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_like_56": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "ones_like_152": {
                "variable": {
                    "value": "attention_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_like_154": {
                "variable": {
                    "value": "token_type_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_291": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "ignored_index",
                    "type": "variable",
                    "possible_values": [
                        [
                            "start_logits.size(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "MSELoss_386": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_389": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "run_docvqa.py": {
        "torch": {
            "DataLoader_90": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)",
                            "IfExp"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.train_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataLoader_309": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_dataset",
                    "type": "variable",
                    "possible_values": []
                },
                "sampler": {
                    "value": "eval_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)",
                            "IfExp"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.eval_batch_size",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_418": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_ids for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_419": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.input_mask for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_420": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.segment_ids for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_421": {
                "variable": {
                    "value": "all_bboxes",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.boxes for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_422": {
                "variable": {
                    "value": "all_start_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.start_positions for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_423": {
                "variable": {
                    "value": "all_end_positions",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.end_positions for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_424": {
                "variable": {
                    "value": "all_p_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[f.p_mask for f in features]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_425": {
                "variable": {
                    "value": "all_example_index",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "all_input_ids.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_426": {
                "variable": {
                    "value": "dataset",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "manual_seed_74": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "DataParallel_147": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True)",
                            "Call"
                        ],
                        [
                            "model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path), config=config, cache_dir=args.cache_dir if args.cache_dir else None)",
                            "Call"
                        ],
                        [
                            "model_class.from_pretrained(args.output_dir)",
                            "Call"
                        ],
                        [
                            "model_class.from_pretrained(checkpoint)",
                            "Call"
                        ]
                    ]
                }
            },
            "DistributedDataParallel_151": {
                "variable": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.nn.DataParallel(model)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True)",
                            "Call"
                        ],
                        [
                            "model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path), config=config, cache_dir=args.cache_dir if args.cache_dir else None)",
                            "Call"
                        ],
                        [
                            "model_class.from_pretrained(args.output_dir)",
                            "Call"
                        ],
                        [
                            "model_class.from_pretrained(checkpoint)",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.local_rank]",
                    "type": "List",
                    "possible_values": []
                },
                "output_device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                },
                "find_unused_parameters": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "load_390": {
                "variable": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "cached_features_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(args.data_dir, 'cached_{}_{}_{}'.format(mode, list(filter(None, args.model_name_or_path.split('/'))).pop(), str(args.max_seq_length)))",
                            "Call"
                        ]
                    ]
                }
            },
            "device_661": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() and (not args.no_cuda) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_665": {
                "variable": {
                    "value": "args.n_gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_668": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda",
                    "type": "str",
                    "possible_values": []
                },
                "index": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "manual_seed_all_76": {
                "seed": {
                    "value": "args.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "RandomSampler_86": {
                "data_source": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DistributedSampler_88": {
                "dataset": {
                    "value": "train_dataset",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "SequentialSampler_305": {
                "data_source": {
                    "value": "eval_dataset",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "DistributedSampler_307": {
                "dataset": {
                    "value": "eval_dataset",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "set_device_664": {
                "device": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.device('cuda:0' if torch.cuda.is_available() and (not args.no_cuda) else 'cpu')",
                            "Call"
                        ],
                        [
                            "torch.device('cuda', args.local_rank)",
                            "Call"
                        ]
                    ]
                }
            },
            "set_device_667": {
                "device": {
                    "value": "args.local_rank",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_700": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_763": {
                "obj": {
                    "value": "args",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(args.output_dir, 'training_args.bin')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_326": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_412": {
                "obj": {
                    "value": "features",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.load(cached_features_file)",
                            "Call"
                        ],
                        [
                            "convert_examples_to_features(examples=train_examples, label_list=labels, tokenizer=tokenizer, max_seq_length=args.max_seq_length, doc_stride=doc_stride, max_query_length=max_query_length, is_training=True, pad_token_label_id=pad_token_label_id)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "cached_features_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(args.data_dir, 'cached_{}_{}_{}'.format(mode, list(filter(None, args.model_name_or_path.split('/'))).pop(), str(args.max_seq_length)))",
                            "Call"
                        ]
                    ]
                }
            },
            "clip_grad_norm__223": {
                "parameters": {
                    "value": "amp.master_params(optimizer)",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "args.max_grad_norm",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "clip_grad_norm__227": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "args.max_grad_norm",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_280": {
                "obj": {
                    "value": "args",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(output_dir, 'training_args.bin')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_available_662": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    }
}