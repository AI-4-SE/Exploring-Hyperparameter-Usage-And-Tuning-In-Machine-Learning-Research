\documentclass[sigconf,review,anonymous]{acmart}

\acmConference[ESEC/FSE 2022]{The 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering}{14 - 18 November, 2022}{Singapore}

\overfullrule=2cm

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[ruled, linesnumbered]{algorithm2e}

\usepackage{hyperref}

\usepackage{graphicx}
\usepackage{microtype}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{multirow}
\renewcommand{\arraystretch}{1.2}
\usepackage{fancyvrb}
\usepackage{caption}
\DeclareCaptionType[placement={!ht}]{listing}[Listing][Code Listings]
\usepackage{wrapfig}
\usepackage[inline]{enumitem}
\usepackage{listings}

\newlist{questions}{enumerate}{2}
\setlist[questions,1]{label=RQ\textsubscript{\arabic*}:,ref=RQ\textsubscript{\arabic*}}

\graphicspath{{figures/}}


\title{Parameter Space in Machine Learning Projects}

\author{Sebastian Simon}
%\authornote{Both authors contributed equally to this research.}
%\authornotemark[1]
\affiliation{%
    \institution{Leipzig University}
    \country{Germany}
}

\renewcommand{\shortauthors}{Simon, et al.}

\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

\begin{document}

\maketitle

\section{Introduction}\label{sec:intro}
% Motivation
Machine learning (ML) is pervasive in the current research and industrial landscape. 
In recent year, ML has become one of the most important research fields in academia and industrial research.

Similarly to traditional software systems, ML projects exhibit a wide range of configuration options, influencing, for instance, the performance of ML models. 
Especially ML algorithm-specific options are crucial for a ML model. 
Typically, ML libraries, such as Tensorflow, Pytorch, and Sci-Kit Learn provide ML algorithms with their corresponding options for initialization. 
Those libraries often provide default values, which, however, can also be customized. 
Default options of learning algorithms may not be optimal for a given data set or problem. 
While default options may be adequate for some time, these default options may change in new versions of libraries, complicating the replication of ML projects. (Paper: Code Smells for Machine Learning Applications)

% Current Approaches/State of the Art
Previous work already showed that configuration may be a severe threat. 
However, only a few dealt with configuration options for ML algorithms, showing that options have a huge impact on the resulting model, may lead to code smells in ML code, and complicate the replication of ML projects. 
To the best of our knowledge, none of them investigated the parameter space of ML algorithms to understand how researcher/developer/data scientists configure ML algorithms.

% Own approach
With this work, we make a step in investigating the parameter space of ML algorithms of three common ML libraries. 
Specifically, we study the parameter space of Tensorflow, Pytorch, and Sci-Kit Learn.
To this end, we analyze ML algorithm and their configuration parameters in ML projects selected from paperswithcode.com for each ML library.
The goal is to shed light on the parameter space of ML algorithms provided by the ML libraries.

% Research Questions
To guide our paper, we answer the following questions:
\begin{questions}
    \item How is ML code configured? (project- or algorithm-specific) 
    \item What the parameter space of machine learning libraries?
    \item Which and what kind of values are used?
    \item What is the value range/parameter distribution of options?
    \item By which rule do people decide to use specific/default values?
\end{questions}

% Results

% Contribution
In summary, we make the following contributions:
\begin{itemize}
    \item A comprehensive study on the paperswithcode dataset.
    \item A comprehensive analysis of the parameter space in machine learning projects in terms of the most common machine learning libraries.
\end{itemize}


\section{State-of-the-Art}\label{sec:background}
- Introduction of ML's importance
- Which areas are affected?
- How are configuration options find?


\section{Methodology}\label{sec:methodology}
For this paper, we performed an empirical study on the parameter space of ML algorithms of three popular ML libraries. 
We initially selected a sample set of 1000 subjects systems from paperswithcode.com and check whether these subject systems incorporate on of the libraries, resulting into three data sets of subject systems, one for each ML library.
We then analyzed each data set using static analysis and data obtained from API crawling.

Our study encompasses three steps: (1) Subject System Selection, (2) API Crawling, and (3) Static Analysis. 

\subsection{Subject System Selection}
Paperswithcode pursues the mission to create an open source resource with machine learning papers, code, datasets and tools for analysis. 
Today it is one of the biggest platforms to collect papers and the corresponding paper, forming an excellent source to extract a sample set of ML projects.

% TODO: Revise this part!
It is an extensive representation of the field with 63,517~papers indexed by October~2021. 
For each paper, the portal provides a list of repositories that link to the paper.
These can be the official repository, or third-party repositories implementing a certain aspect of a publication.
We processed the list of repositories and downloaded 86,053~HEAD revisions of repositories hosted on GitHub as well as additional GitHub metadata on them, resulting in a collection of over 1,4~TB of code repositories.

\begin{itemize}
    \item crawled this papers and their code to create a sample set of X repositories
    \item to ensure considering machine learning projects that incorporate the target library, we employed regular expression to check whether these libraries where used within the projects
    \item specifically, we focused here on import statements in the source code
    \item each python file was inspected and checked
    \item projects that fulfilled the condition has been added to the final set of subjects Systems
    \item this procedure was conducted for each library
    \item resulting into three data sets of subject systems, one for each library
\end{itemize}

\subsection{ML API Crawling}
\begin{itemize}
    \item for each machine learning library, we crawled the API
    \item thereby we extract all machine learning algorithms (classes) and their corresponding options used for initialization
    \item we dropped all methods, e.g., methods used for calculating metrics
    \item on top of that, we employ a data flow analysis to ensure receiving the correct option values
\end{itemize}

\subsection{Extracting Configuration Options}
\begin{itemize}
    \item static code analysis to locate occurrences of machine learning algorithm and to extract the options
    \item on top of that, we employ a data flow analysis to ensure that we get correct option values
    \item extracted data is compared to API data
\end{itemize}

\subsection{Analysis}

\section{Results}\label{sec:results}

\section{Discussion}\label{sec:discusssion}
\section{Threats-to-Validity}\label{sec:threats}
% External Validity
% Internal Validity
% Construct to Validity
\section{Conclusion}\label{sec:conclusion}

\begin{acks}
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}
\end{document}