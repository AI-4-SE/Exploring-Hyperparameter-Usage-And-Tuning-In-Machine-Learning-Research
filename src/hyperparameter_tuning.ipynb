{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number repos:  514\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "statistic_dir = \"../data/statistics/\"\n",
    "\n",
    "with open(\"../data/repos_hyperparameter_tuning.json\", \"r\", encoding=\"utf-8\") as src:\n",
    "    repos = json.load(src)\n",
    "    print(\"Number repos: \", len(repos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_latex(df: pd.DataFrame) -> None:\n",
    "    print(df.to_latex(index=False))\n",
    "\n",
    "def get_module(name, data):\n",
    "    try:\n",
    "        return next(filter(lambda x: name == x[\"name\"], data))\n",
    "    except StopIteration:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(library_name: str, library_dir: str, files: List) -> Dict:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [x[\"name\"] for x in library_data]\n",
    "\n",
    "    # Get Most used Class\n",
    "    classes = []\n",
    "\n",
    "    for project in files:\n",
    "        with open(statistic_dir + project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, _ in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "\n",
    "                                if class_name in class_names:\n",
    "                                    classes.append(class_name)\n",
    "\n",
    "    return Counter(classes).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(library_name, files, classes) -> List:\n",
    "    param_data = []\n",
    "    value_data = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        params_set = []\n",
    "\n",
    "        for project in list(files):\n",
    "            with open(statistic_dir + project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                project_data = json.load(project_file)\n",
    "\n",
    "                for file in project_data.keys():\n",
    "                    file_data = project_data[file]\n",
    "                    for library in file_data.keys():\n",
    "                        if library == library_name:\n",
    "                            module_data = file_data[library]\n",
    "                            for key, data in module_data.items():\n",
    "                                if key[0].isupper():\n",
    "                                    module_name_parts = key.split(\"_\")\n",
    "                                    if len(module_name_parts) > 2:\n",
    "                                        module_name = \"_\".join(module_name_parts[:-1])\n",
    "                                    else:\n",
    "                                        module_name = module_name_parts[0]\n",
    "\n",
    "                                    if class_name == module_name:\n",
    "                                        for name, _ in data.items():\n",
    "                                            if name in (\"variable\", \"params\"):\n",
    "                                                continue\n",
    "                                            else:\n",
    "                                                if name == \"lr\" and library_name == \"tensorflow\":\n",
    "                                                    params_set.append(\"learning_rate\")\n",
    "                                                else:\n",
    "                                                    params_set.append(name)\n",
    "                                                        \n",
    "                                            \n",
    "        param_counter = Counter(params_set).most_common(3)\n",
    "        param_data.append(param_counter)\n",
    "        \n",
    "    return param_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(top_classes, top_classes_count, top_params, top_params_count):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"Algorithm\"] = top_classes\n",
    "    df[\"Algorithm Count\"] = top_classes_count\n",
    "    df[\"Top Hyperparameters\"] = top_params\n",
    "    df[\"Top Hyperparameter Count\"] = top_params_count\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(library_name: str, library_data: str, files: List[str]) -> pd.DataFrame:\n",
    "    # get all estimator classes\n",
    "    classes = get_classes(library_name, library_data, repos)\n",
    "    # get top ten estimator classes\n",
    "    top_classes = [x[0] for x in classes][:5]\n",
    "    # get count for the top ten estimator classes\n",
    "    top_classes_count = [x[1] for x in classes][:5]\n",
    "\n",
    "    # get top three hyperparameter for each class\n",
    "    params = get_params(library_name, repos, top_classes)\n",
    "\n",
    "    top_params = []  \n",
    "    top_params_count = []  \n",
    "    for item in params:\n",
    "        _params = [x[0] for x in item]\n",
    "        _count = [x[1] for x in item]\n",
    "        top_params.append(_params)\n",
    "        top_params_count.append(_count)\n",
    "\n",
    "    return create_dataframe(top_classes, top_classes_count, top_params, top_params_count)\n",
    "\n",
    "df_sklearn = get_all_data(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", repos)\n",
    "df_tensorflow = get_all_data(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", repos)\n",
    "df_pytorch = get_all_data(\"torch\", \"../data/library_data/torch_optimizer.json\", repos)\n",
    "df_all = pd.concat([df_sklearn, df_tensorflow, df_pytorch])\n",
    "\n",
    "#print(df_all.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_method_data(df: pd.DataFrame):\n",
    "\n",
    "    method_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        params = []\n",
    "        name = row[0]\n",
    "        count = row[1]\n",
    "        for (x, y) in zip(row[2], row[3]):\n",
    "            params.append({\"name\": x, \"count\": y})\n",
    "\n",
    "        \n",
    "        method_data.append({\"name\": name, \"count\": count, \"params\": params})\n",
    "    \n",
    "    return method_data\n",
    "\n",
    "\n",
    "sklearn_method_data = get_method_data(df_sklearn)\n",
    "tensorflow_method_data = get_method_data(df_tensorflow)\n",
    "torch_method_data = get_method_data(df_pytorch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_library_data(library_name, library_dir, data, files):\n",
    "\n",
    "    tmp_data = []\n",
    "\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [x[\"name\"] for x in library_data]\n",
    "\n",
    "    for item in data:\n",
    "        class_name = item[\"name\"]\n",
    "        param_data = []\n",
    "        for param in item[\"params\"]:\n",
    "            param_name = param[\"name\"]\n",
    "            param_values = []\n",
    "            \n",
    "            \n",
    "            for project in list(files):\n",
    "                with open(statistic_dir + project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "                    project_data = json.load(project_file)\n",
    "\n",
    "                    for file in project_data.keys():\n",
    "                        file_data = project_data[file]\n",
    "                        for library in file_data.keys():\n",
    "                            if library == library_name:\n",
    "                                module_data = file_data[library]\n",
    "                                for key, data in module_data.items():\n",
    "                                    if key[0].isupper():\n",
    "                                        module_name_parts = key.split(\"_\")\n",
    "                                        if len(module_name_parts) > 2:\n",
    "                                            module_name = \"_\".join(module_name_parts[:-1])\n",
    "                                        else:\n",
    "                                            module_name = module_name_parts[0]\n",
    "\n",
    "                                        if class_name == module_name:\n",
    "                                            for name, data in data.items():\n",
    "                                                if name in (\"variable\", \"params\"):\n",
    "                                                    continue\n",
    "                                                else:\n",
    "                                                    if name == \"lr\" and library_name == \"tensorflow\":\n",
    "                                                        #print(\"Class, Param, Data: \", class_name, name, data)\n",
    "                                                        param_values.append(data)\n",
    "                                                    else:\n",
    "                                                        if name == param_name:\n",
    "                                                            param_values.append(data)\n",
    "                                                            #print(\"Class, Param, Data: \", class_name, name, data)\n",
    "            param_data.append({\"name\": param_name, \"data\": param_values})\n",
    "        tmp_data.append({\"name\": class_name, \"param_data\": param_data})\n",
    "\n",
    "    return tmp_data\n",
    "\n",
    "sklearn_data = prepare_library_data(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", sklearn_method_data, repos)\n",
    "tensorflow_data = prepare_library_data(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", tensorflow_method_data, repos)\n",
    "torch_data = prepare_library_data(\"torch\", \"../data/library_data/torch_optimizer.json\", torch_method_data, repos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 13, 12], [9, 6, 4], [22, 13, 7], [19, 17, 15], [12, 8, 7], [405, 223, 19], [81, 12, 8], [42, 2], [30, 7, 1], [29, 29, 12], [601, 188, 181], [219, 151, 101], [44, 25, 24], [18, 13, 11], [11, 7, 3]]\n",
      "Total:  2676\n",
      "Const:  951\n",
      "Var:  1753\n",
      "\\begin{tabular}{lrlllll}\n",
      "\\toprule\n",
      "                 Algorithm &  Algorithm Count &                                Top Hyperparameters & Top Hyperparameter Count &                           Type &       Constant &      Variabel \\\\\n",
      "\\midrule\n",
      "        LogisticRegression &               33 &                          [C, solver, random\\_state] &             [15, 13, 12] &    [Variable, String, Numeric] &     [3, 13, 8] &    [12, 0, 4] \\\\\n",
      "                       SVC &               28 &                                 [gamma, kernel, C] &                [9, 6, 4] &        [Numeric, String, Call] &      [6, 4, 1] &     [3, 2, 3] \\\\\n",
      "                    KMeans &               22 &                   [n\\_clusters, random\\_state, init] &              [22, 13, 7] &    [Variable, Numeric, String] &      [5, 7, 5] &    [17, 6, 2] \\\\\n",
      "GradientBoostingClassifier &               20 &        [n\\_estimators, learning\\_rate, random\\_state] &             [19, 17, 15] &    [Numeric, Numeric, Numeric] &   [14, 16, 14] &     [5, 1, 1] \\\\\n",
      "                 LinearSVC &               17 &                            [C, dual, class\\_weight] &               [12, 8, 7] &         [Variable, Bool, Call] &      [3, 8, 6] &     [9, 0, 1] \\\\\n",
      "             AdamOptimizer &              414 &                      [learning\\_rate, beta1, beta2] &           [405, 223, 19] &   [Variable, Numeric, Numeric] &   [20, 209, 8] & [385, 14, 11] \\\\\n",
      "                      Adam &               91 &                [learning\\_rate, epsilon, clipvalue] &              [81, 12, 8] &    [Numeric, Numeric, Numeric] &    [29, 17, 9] &   [52, 9, 13] \\\\\n",
      "  GradientDescentOptimizer &               42 &                       [learning\\_rate, use\\_locking] &                  [42, 2] &           [Variable, Variable] &        [13, 1] &       [29, 1] \\\\\n",
      "          AdagradOptimizer &               30 & [learning\\_rate, initial\\_accumulator\\_value, use\\_... &               [30, 7, 1] &  [Variable, Numeric, Variable] &      [1, 5, 0] &    [29, 2, 1] \\\\\n",
      "         MomentumOptimizer &               29 &            [learning\\_rate, momentum, use\\_nesterov] &             [29, 29, 12] &      [Variable, Numeric, Bool] &    [4, 18, 10] &   [25, 11, 2] \\\\\n",
      "                      Adam &              646 &                          [lr, betas, weight\\_decay] &          [601, 188, 181] & [Variable, Sequence, Variable] & [135, 180, 42] & [466, 8, 139] \\\\\n",
      "                       SGD &              233 &                       [lr, momentum, weight\\_decay] &          [219, 151, 101] & [Variable, Variable, Variable] &   [30, 56, 20] & [189, 95, 81] \\\\\n",
      "                   RMSprop &               47 &                              [lr, momentum, alpha] &             [44, 25, 24] & [Variable, Variable, Variable] &      [0, 4, 6] &  [44, 21, 18] \\\\\n",
      "                     AdamW &               18 &                            [lr, weight\\_decay, eps] &             [18, 13, 11] &       [Call, Numeric, Numeric] &     [1, 10, 8] &    [17, 3, 3] \\\\\n",
      "                   Adagrad &               13 &                       [lr, weight\\_decay, lr\\_decay] &               [11, 7, 3] &       [Numeric, Numeric, Call] &      [1, 0, 1] &    [10, 7, 2] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def assign_category(type_name: str) -> str:\n",
    "\n",
    "    if type_name.lower() in (\"str\", \"joinedstr\"):\n",
    "        return \"String\"\n",
    "\n",
    "    if type_name.lower() in (\"int\", \"float\", \"complex\", \"number\",\"binop\"):\n",
    "        return \"Numeric\"\n",
    "\n",
    "    if type_name.lower() in (\"list\", \"tuple\", \"listcomp\", \"generatorexp\"):\n",
    "        return \"Sequence\"\n",
    "\n",
    "    if type_name.lower() in (\"dict\", \"dictcomp\", \"kwargs\"):\n",
    "        return \"Mapping\"\n",
    "    \n",
    "    if type_name.lower() in (\"set\", \"setcomp\"):\n",
    "        return \"Set\"\n",
    "\n",
    "    if type_name.lower() in (\"lambda\", \"subscript\"):\n",
    "        return \"Call\"\n",
    "\n",
    "    if type_name.lower() in (\"compare\", \"ifexp\"):\n",
    "        return \"Operation\"\n",
    "\n",
    "    if type_name.lower() == \"none\":\n",
    "        return \"None Type\"\n",
    "\n",
    "    if type_name.lower() in (\"method argument\", \"starred\", \"variable\", \"attribute\", \"yield\"):\n",
    "        return \"Variable\"\n",
    "    \n",
    "    if type_name.lower() in (\"bool\", \"boolop\", \"unaryop\"):\n",
    "        return \"Bool\"\n",
    "\n",
    "    return type_name\n",
    "\n",
    "\n",
    "\n",
    "def assign_top_category(type_name: str) -> str:\n",
    "    if type_name.lower() in (\"str\", \"joinedstr\", \"int\", \"float\", \"complex\", \"number\",\"binop\", \"bool\", \"boolop\", \"unaryop\", \"dict\", \"dictcomp\", \"kwargs\", \"list\", \"tuple\", \"listcomp\", \"generatorexp\", \"set\", \"setcomp\", \"none\"):\n",
    "        return \"Constant\"\n",
    "    else:\n",
    "        return \"Variabel\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_param_type(library_name, library_dir, data) -> List[List]:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "\n",
    "    type_data = []\n",
    "    default_data = []\n",
    "\n",
    "    constant_data = []\n",
    "    variabel_data = []\n",
    "\n",
    "    for item in data:\n",
    "        class_name = item[\"name\"]\n",
    "        class_type_data = []\n",
    "        class_default_data = []\n",
    "        class_constant_data = []\n",
    "        class_variabel_data = []\n",
    "        for param in item[\"param_data\"]:\n",
    "            constant = 0\n",
    "            variabel = 0\n",
    "            types = []\n",
    "            default = []\n",
    "            param_name = param[\"name\"]\n",
    "            modulue_data = get_module(class_name, library_data)\n",
    "            options = modulue_data[\"params\"]\n",
    "\n",
    "\n",
    "            for x in param[\"data\"]:               \n",
    "                \n",
    "                # Check types of parameters\n",
    "                if x[\"type\"].lower() in (\"method argument\", \"starred\", \"variable\", \"attribute\", \"yield\"):\n",
    "                    possible_values = x[\"possible_values\"]\n",
    "                    if possible_values:\n",
    "                        for possible_value in possible_values:\n",
    "                            val = possible_value[0]\n",
    "                            val_type = possible_value[1]\n",
    "                            if val.isnumeric():\n",
    "                                types.append(\"number\")\n",
    "                            elif val.lower() in (\"true\", \"false\"):\n",
    "                                types.append(\"bool\")\n",
    "                            else:\n",
    "                                types.append(val_type)\n",
    "                    else:\n",
    "                        types.append(x[\"type\"])\n",
    "                else:\n",
    "                    types.append(x[\"type\"])\n",
    "                    \n",
    "                if x[\"type\"].lower() in (\"str\", \"joinedstr\", \"int\", \"float\", \"complex\", \"number\",\"binop\", \"bool\", \"boolop\", \"unaryop\", \"dict\", \"dictcomp\", \"kwargs\", \"list\", \"tuple\", \"listcomp\", \"generatorexp\", \"set\", \"setcomp\", \"none\"):\n",
    "                    constant += 1\n",
    "                else:\n",
    "                    variabel += 1\n",
    "            \n",
    "\n",
    "\n",
    "            counter_types = Counter(types)\n",
    "            #print(\"Class Name: \", class_name)\n",
    "            #print(\"Param: \", param_name)\n",
    "            #print(\"Types:\", counter_types.most_common())\n",
    "            most_common_type = counter_types.most_common(1)[0][0]\n",
    "            #print(\"Most Common Type:\", assign_category(most_common_type))\n",
    "            class_type_data.append(assign_category(most_common_type))\n",
    "            class_constant_data.append(constant)\n",
    "            class_variabel_data.append(variabel)\n",
    "\n",
    "        constant_data.append(class_constant_data)\n",
    "        variabel_data.append(class_variabel_data)\n",
    "        type_data.append(class_type_data)\n",
    "\n",
    "    return type_data, constant_data, variabel_data\n",
    "\n",
    "\n",
    "sklearn_type_data, sklearn_constant_data, sklearn_variabel_data = get_param_type(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", sklearn_data)\n",
    "tensorflow_type_data, tf_constant_data, tf_variabel_data= get_param_type(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", tensorflow_data)\n",
    "torch_type_data, torch_constant_data, torch_variabel_data = get_param_type(\"torch\", \"../data/library_data/torch_optimizer.json\", torch_data)\n",
    "\n",
    "df_sklearn[\"Type\"] = sklearn_type_data\n",
    "df_sklearn[\"Constant\"] = sklearn_constant_data\n",
    "df_sklearn[\"Variabel\"] = sklearn_variabel_data\n",
    "df_tensorflow[\"Type\"] = tensorflow_type_data\n",
    "df_tensorflow[\"Constant\"] = tf_constant_data\n",
    "df_tensorflow[\"Variabel\"] = tf_variabel_data\n",
    "df_pytorch[\"Type\"] = torch_type_data\n",
    "df_pytorch[\"Constant\"] = torch_constant_data\n",
    "df_pytorch[\"Variabel\"] = torch_variabel_data\n",
    "\n",
    "\n",
    "#df_to_latex(df_pytorch)\n",
    "\n",
    "df_all_mew = pd.concat([df_sklearn, df_tensorflow, df_pytorch])\n",
    "\n",
    "total_count = df_all_mew[\"Top Hyperparameter Count\"].tolist()\n",
    "total_const = df_all_mew[\"Constant\"].tolist()\n",
    "total_var = df_all_mew[\"Variabel\"].tolist()\n",
    "print(total_count)\n",
    "\n",
    "tmp_total = []\n",
    "tmp_const = []\n",
    "tmp_var = []\n",
    "for item in total_var:\n",
    "    for x in item:\n",
    "        tmp_var.append(x)\n",
    "\n",
    "for item in total_const:\n",
    "    for x in item:\n",
    "        tmp_const.append(x)\n",
    "\n",
    "for item in total_count:\n",
    "    for x in item:\n",
    "        tmp_total.append(x)\n",
    "\n",
    "print(\"Total: \", sum(tmp_total))\n",
    "print(\"Const: \", sum(tmp_const))\n",
    "print(\"Var: \", sum(tmp_var))\n",
    "\n",
    "print(df_all_mew.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
