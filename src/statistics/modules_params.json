{
    "models/vqvae/model.py": {
        "torch": {
            "device_264": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "Adam_266": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "vqvae.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "LEARNING_RATE",
                    "possible_values": [
                        [
                            "0.001",
                            "Constant"
                        ]
                    ]
                },
                "amsgrad": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "DataLoader_267": {
                "variable": {
                    "value": "training_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "training_data",
                    "possible_values": [
                        [
                            "VAEDataset()",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "BATCH_SIZE",
                    "possible_values": [
                        [
                            "256",
                            "Constant"
                        ]
                    ]
                },
                "shuffle": {
                    "value": "True",
                    "possible_values": []
                },
                "pin_memory": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "manual_seed_21": {
                "seed": {
                    "value": "seed",
                    "possible_values": []
                }
            },
            "manual_seed_all_22": {
                "seed": {
                    "value": "seed",
                    "possible_values": []
                }
            },
            "Embedding_35": {
                "variable": {
                    "value": "self.codebook",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "hidden_dim",
                    "possible_values": []
                }
            },
            "argmin_51": {
                "variable": {
                    "value": "encoding_indices",
                    "possible_values": []
                },
                "input": {
                    "value": "distances",
                    "possible_values": [
                        [
                            "torch.sum(flat_input ** 2, dim=1, keepdim=True) + torch.sum(self.codebook.weight ** 2, dim=1) - 2 * torch.matmul(flat_input, self.codebook.weight.t())",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "unsqueeze_51": {
                "variable": {
                    "value": "encoding_indices",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_55": {
                "variable": {
                    "value": "codebook_embeds",
                    "possible_values": []
                },
                "*size": {
                    "value": "encoded_ids.shape[0]",
                    "possible_values": []
                },
                "out": {
                    "value": "self.vocab_size",
                    "possible_values": []
                },
                "device": {
                    "value": "encoded_ids.device",
                    "possible_values": []
                }
            },
            "zeros_64": {
                "variable": {
                    "value": "codebook_embeds",
                    "possible_values": []
                },
                "*size": {
                    "value": "encoded_ids.shape[0]",
                    "possible_values": []
                },
                "out": {
                    "value": "self.vocab_size",
                    "possible_values": []
                },
                "device": {
                    "value": "encoded_ids.device",
                    "possible_values": []
                }
            },
            "matmul_67": {
                "variable": {
                    "value": "quantized",
                    "possible_values": []
                },
                "input": {
                    "value": "codebook_embeds",
                    "possible_values": [
                        [
                            "torch.zeros(encoded_ids.shape[0], self.vocab_size, device=encoded_ids.device)",
                            "Call"
                        ],
                        [
                            "torch.zeros(encoded_ids.shape[0], self.vocab_size, device=encoded_ids.device)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.codebook.weight",
                    "possible_values": []
                }
            },
            "mse_loss_70": {
                "variable": {
                    "value": "e_latent_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "quantized.detach()",
                    "possible_values": []
                },
                "target": {
                    "value": "inputs",
                    "possible_values": [
                        [
                            "inputs.permute(0, 2, 3, 1).contiguous()",
                            "Call"
                        ]
                    ]
                }
            },
            "mse_loss_71": {
                "variable": {
                    "value": "q_latent_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "quantized",
                    "possible_values": [
                        [
                            "torch.matmul(codebook_embeds, self.codebook.weight).view(input_shape)",
                            "Call"
                        ],
                        [
                            "inputs + (quantized - inputs).detach()",
                            "BinOp"
                        ]
                    ]
                },
                "target": {
                    "value": "inputs.detach()",
                    "possible_values": []
                }
            },
            "mean_75": {
                "variable": {
                    "value": "avg_probs",
                    "possible_values": []
                },
                "input": {
                    "value": "codebook_embeds",
                    "possible_values": [
                        [
                            "torch.zeros(encoded_ids.shape[0], self.vocab_size, device=encoded_ids.device)",
                            "Call"
                        ],
                        [
                            "torch.zeros(encoded_ids.shape[0], self.vocab_size, device=encoded_ids.device)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "exp_76": {
                "variable": {
                    "value": "perplexity",
                    "possible_values": []
                },
                "input": {
                    "value": "-torch.sum(avg_probs * torch.log(avg_probs + 1e-10))",
                    "possible_values": []
                }
            },
            "Sequential_84": {
                "variable": {
                    "value": "self._block",
                    "possible_values": []
                },
                "*args": {
                    "value": "OrderedDict([('relu_1', nn.ReLU(True)), ('conv_1', nn.Conv2d(in_dim, hidden_dim, 3, padding=1, bias=False)), ('relu_2', nn.ReLU(True)), ('conv_2', nn.Conv2d(hidden_dim, out_dim, 1, bias=False))])",
                    "possible_values": []
                }
            },
            "Sequential_98": {
                "variable": {
                    "value": "self.residual_blocks",
                    "possible_values": []
                },
                "*args": {
                    "value": "OrderedDict([*[(f'residual_{i}', Residual(in_dim, out_dim, hidden_dim)) for i in range(n_residual_layers)], ('relu', nn.ReLU())])",
                    "possible_values": []
                }
            },
            "Sequential_109": {
                "variable": {
                    "value": "self._blocks",
                    "possible_values": []
                },
                "*args": {
                    "value": "OrderedDict([('conv_1', nn.Conv2d(in_dim, hidden_dim // 2, 4, 2, padding=1)), ('relu_1', nn.ReLU()), ('conv_2', nn.Conv2d(hidden_dim // 2, hidden_dim, 4, 2, padding=1)), ('relu_2', nn.ReLU()), ('conv_3', nn.Conv2d(hidden_dim, hidden_dim, 3, 1, padding=1)), ('residual', ResidualStack(hidden_dim, hidden_dim, n_residual_layers, hidden_dim_residual))])",
                    "possible_values": []
                }
            },
            "Sequential_124": {
                "variable": {
                    "value": "self._blocks",
                    "possible_values": []
                },
                "*args": {
                    "value": "OrderedDict([('conv_1', nn.Conv2d(in_dim, hidden_dim, 3, 1, padding=1)), ('residual', ResidualStack(hidden_dim, hidden_dim, n_residual_layers, hidden_dim_residual)), ('conv_t_1', nn.ConvTranspose2d(hidden_dim, hidden_dim // 2, 4, 2, padding=1)), ('relu_1', nn.ReLU()), ('conv_t_2', nn.ConvTranspose2d(hidden_dim // 2, 3, 4, 2, padding=1))])",
                    "possible_values": []
                }
            },
            "Conv2d_148": {
                "variable": {
                    "value": "self.pre_vq_conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "save_292": {
                "obj": {
                    "value": "vqvae.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "./vqvae.pt",
                    "possible_values": []
                }
            },
            "matmul_57": {
                "input": {
                    "value": "codebook_embeds",
                    "possible_values": [
                        [
                            "torch.zeros(encoded_ids.shape[0], self.vocab_size, device=encoded_ids.device)",
                            "Call"
                        ],
                        [
                            "torch.zeros(encoded_ids.shape[0], self.vocab_size, device=encoded_ids.device)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.codebook.weight",
                    "possible_values": []
                }
            },
            "load_255": {
                "f": {
                    "value": "path",
                    "possible_values": []
                }
            },
            "is_available_264": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "mse_loss_283": {
                "input": {
                    "value": "data_recon",
                    "possible_values": []
                },
                "target": {
                    "value": "data",
                    "possible_values": [
                        [
                            "next(iter(training_loader))",
                            "Call"
                        ],
                        [
                            "data.to(device)",
                            "Call"
                        ]
                    ]
                }
            },
            "sum_45": {
                "input": {
                    "value": "flat_input ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_46": {
                "input": {
                    "value": "self.codebook.weight ** 2",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "matmul_47": {
                "input": {
                    "value": "flat_input",
                    "possible_values": [
                        [
                            "inputs.view(-1, self.hidden_dim)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "self.codebook.weight.t()",
                    "possible_values": []
                }
            },
            "sum_76": {
                "input": {
                    "value": "avg_probs * torch.log(avg_probs + 1e-10)",
                    "possible_values": []
                }
            },
            "log_76": {
                "input": {
                    "value": "avg_probs + 1e-10",
                    "possible_values": []
                }
            },
            "ReLU_85": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Conv2d_86": {
                "in_channels": {
                    "value": "in_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_87": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Conv2d_88": {
                "in_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "out_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_100": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Conv2d_110": {
                "in_channels": {
                    "value": "in_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim // 2",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ReLU_111": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Conv2d_112": {
                "in_channels": {
                    "value": "hidden_dim // 2",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ReLU_113": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Conv2d_114": {
                "in_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Conv2d_125": {
                "in_channels": {
                    "value": "in_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ConvTranspose2d_127": {
                "in_channels": {
                    "value": "hidden_dim",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "hidden_dim // 2",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "ReLU_128": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "ConvTranspose2d_129": {
                "in_channels": {
                    "value": "hidden_dim // 2",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "3",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    }
}