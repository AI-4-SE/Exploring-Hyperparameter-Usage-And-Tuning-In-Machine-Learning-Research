{
    "Model/MyDataset.py": {
        "torch": {}
    },
    "Model/_main_.py": {
        "torch": {
            "device_19": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() else cpu",
                    "possible_values": []
                }
            },
            "DataLoader_78": {
                "variable": {
                    "value": "evl_data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "evl_data",
                    "possible_values": [
                        [
                            "MySet(A_2, X_2, A2_2, A3_2, A4_2, A5_2, enc_2, dec_in_2, dec_out_2)",
                            "Call"
                        ]
                    ]
                },
                "batch_sampler": {
                    "value": "my_sampler2",
                    "possible_values": [
                        [
                            "MySampler(evl_data, args.batch_size)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_79": {
                "variable": {
                    "value": "train_data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_data",
                    "possible_values": [
                        [
                            "MySet(A_1, X_1, A2_1, A3_1, A4_1, A5_1, enc_1, dec_in_1, dec_out_1)",
                            "Call"
                        ]
                    ]
                },
                "batch_sampler": {
                    "value": "my_sampler1",
                    "possible_values": [
                        [
                            "MySampler(train_data, args.batch_size)",
                            "Call"
                        ]
                    ]
                }
            },
            "CrossEntropyLoss_85": {
                "variable": {
                    "value": "criterion",
                    "possible_values": []
                },
                "ignore_index": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "SGD_88": {
                "variable": {
                    "value": "tran_optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "trans_model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "LEARNING_RATE",
                    "possible_values": [
                        [
                            "args.lr",
                            "Attribute"
                        ]
                    ]
                },
                "momentum": {
                    "value": "0.99",
                    "possible_values": []
                }
            },
            "zeros_124": {
                "variable": {
                    "value": "dec_input",
                    "possible_values": []
                },
                "*size": {
                    "value": "1",
                    "possible_values": []
                },
                "out": {
                    "value": "nl_max_len",
                    "possible_values": []
                }
            },
            "is_available_19": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "save_118": {
                "obj": {
                    "value": "trans_model.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "save_model/trans.pt",
                    "possible_values": []
                }
            },
            "load_138": {
                "f": {
                    "value": "save_model/trans.pt",
                    "possible_values": []
                }
            }
        }
    },
    "Model/fusion_module.py": {
        "torch": {
            "matmul_22": {
                "variable": {
                    "value": "context",
                    "possible_values": []
                },
                "input": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(scores)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "V",
                    "possible_values": []
                }
            },
            "Conv1d_29": {
                "variable": {
                    "value": "self.conv1",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "max_ast_node",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "max_ast_node",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Conv1d_30": {
                "variable": {
                    "value": "self.conv2",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "src_max_length",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "max_ast_node",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "1",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "matmul_18": {
                "input": {
                    "value": "Q",
                    "possible_values": []
                },
                "other": {
                    "value": "K.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "Softmax_21": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "Model/gcn_encoder.py": {
        "torch": {
            "Parameter_16": {
                "variable": {
                    "value": "self.weight",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(batch_size, in_features, out_features)",
                    "possible_values": []
                }
            },
            "zeros_like_30": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "input",
                    "possible_values": []
                }
            },
            "relu_53": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.gc1(x, adj)",
                    "possible_values": []
                }
            },
            "dropout_54": {
                "variable": {
                    "value": "x1",
                    "possible_values": []
                },
                "input": {
                    "value": "x",
                    "possible_values": [
                        [
                            "F.relu(self.gc1(x, adj))",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "relu_66": {
                "variable": {
                    "value": "outputs",
                    "possible_values": []
                },
                "input": {
                    "value": "self.gcn1(x, adj)",
                    "possible_values": []
                }
            },
            "Linear_79": {
                "variable": {
                    "value": "self.ffn",
                    "possible_values": []
                },
                "in_features": {
                    "value": "nout",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                }
            },
            "matmul_109": {
                "variable": {
                    "value": "context",
                    "possible_values": []
                },
                "input": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(scores)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "V",
                    "possible_values": [
                        [
                            "self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_120": {
                "variable": {
                    "value": "self.W_Q",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_k * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_121": {
                "variable": {
                    "value": "self.W_K",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_k * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_122": {
                "variable": {
                    "value": "self.W_V",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_v * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_123": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_heads * d_v",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Sequential_147": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(d_model, d_ff, bias=False)",
                    "possible_values": []
                }
            },
            "ModuleList_186": {
                "variable": {
                    "value": "self.layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[EncoderLayer(d_model, d_k, d_v, d_ff, n_heads, device) for _ in range(n_layers)]",
                    "possible_values": []
                }
            },
            "Parameter_18": {
                "variable": {
                    "value": "self.bias",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.FloatTensor(out_features)",
                    "possible_values": []
                }
            },
            "mm_32": {
                "variable": {
                    "value": "support",
                    "possible_values": []
                },
                "input": {
                    "value": "input[i]",
                    "possible_values": []
                },
                "mat2": {
                    "value": "self.weight[i]",
                    "possible_values": []
                }
            },
            "mm_33": {
                "variable": {
                    "value": "output",
                    "possible_values": []
                },
                "input": {
                    "value": "adj[i]",
                    "possible_values": []
                },
                "mat2": {
                    "value": "support",
                    "possible_values": [
                        [
                            "torch.mm(input[i], self.weight[i])",
                            "Call"
                        ]
                    ]
                }
            },
            "relu_55": {
                "input": {
                    "value": "self.gc2(x1, adj)",
                    "possible_values": []
                }
            },
            "matmul_105": {
                "input": {
                    "value": "Q",
                    "possible_values": [
                        [
                            "self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "K.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "Softmax_108": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_148": {
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_ff",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_149": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Linear_150": {
                "in_features": {
                    "value": "d_ff",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "LayerNorm_162": {
                "normalized_shape": {
                    "value": "self.d_model",
                    "possible_values": []
                }
            }
        }
    },
    "Model/get_A.py": {
        "torch": {
            "from_numpy_103": {
                "variable": {
                    "value": "indices",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)",
                    "possible_values": []
                }
            },
            "from_numpy_105": {
                "variable": {
                    "value": "values",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "sparse_mx.data",
                    "possible_values": []
                }
            }
        }
    },
    "Model/get_node_embedding.py": {
        "torch": {
            "zeros_44": {
                "variable": {
                    "value": "features",
                    "possible_values": []
                },
                "*size": {
                    "value": "max_node",
                    "possible_values": []
                },
                "out": {
                    "value": "768",
                    "possible_values": []
                }
            }
        }
    },
    "Model/model.py": {
        "torch": {
            "from_numpy_51": {
                "variable": {
                    "value": "subsequence_mask",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "subsequence_mask",
                    "possible_values": [
                        [
                            "np.triu(np.ones(attn_shape), k=1)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(subsequence_mask).byte()",
                            "Call"
                        ]
                    ]
                }
            },
            "Dropout_13": {
                "variable": {
                    "value": "self.dropout",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": []
                }
            },
            "zeros_15": {
                "variable": {
                    "value": "pe",
                    "possible_values": []
                },
                "*size": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "5000",
                            "MethodArgument"
                        ]
                    ]
                },
                "out": {
                    "value": "d_model",
                    "possible_values": []
                }
            },
            "arange_16": {
                "variable": {
                    "value": "position",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "5000",
                            "MethodArgument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "unsqueeze_16": {
                "variable": {
                    "value": "position",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "exp_17": {
                "variable": {
                    "value": "div_term",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)",
                    "possible_values": []
                }
            },
            "sin_18": {
                "variable": {
                    "value": "pe[:, 0::2]",
                    "possible_values": []
                },
                "input": {
                    "value": "position * div_term",
                    "possible_values": []
                }
            },
            "cos_19": {
                "variable": {
                    "value": "pe[:, 1::2]",
                    "possible_values": []
                },
                "input": {
                    "value": "position * div_term",
                    "possible_values": []
                }
            },
            "matmul_71": {
                "variable": {
                    "value": "context",
                    "possible_values": []
                },
                "input": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(scores)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(scores)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "V",
                    "possible_values": [
                        [
                            "self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "matmul_91": {
                "variable": {
                    "value": "context",
                    "possible_values": []
                },
                "input": {
                    "value": "attn",
                    "possible_values": [
                        [
                            "nn.Softmax(dim=-1)(scores)",
                            "Call"
                        ],
                        [
                            "nn.Softmax(dim=-1)(scores)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "V",
                    "possible_values": [
                        [
                            "self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_98": {
                "variable": {
                    "value": "self.W_Q",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_k * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_99": {
                "variable": {
                    "value": "self.W_K",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_k * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_100": {
                "variable": {
                    "value": "self.W_V",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_v * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_101": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_heads * d_v",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_137": {
                "variable": {
                    "value": "self.W_Q",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_k * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_138": {
                "variable": {
                    "value": "self.W_K",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_k * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_139": {
                "variable": {
                    "value": "self.W_V",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_v * n_heads",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_140": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "in_features": {
                    "value": "n_heads * d_v",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Sequential_176": {
                "variable": {
                    "value": "self.fc",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(d_model, d_ff, bias=False)",
                    "possible_values": []
                }
            },
            "Embedding_240": {
                "variable": {
                    "value": "self.src_emb",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.src_vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "d_model",
                    "possible_values": []
                }
            },
            "ModuleList_243": {
                "variable": {
                    "value": "self.layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[EncoderLayer(d_model, d_k, n_heads, d_v, d_ff, device) for _ in range(n_layers)]",
                    "possible_values": []
                }
            },
            "Embedding_264": {
                "variable": {
                    "value": "self.tgt_emb",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.tgt_vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "d_model",
                    "possible_values": []
                }
            },
            "ModuleList_266": {
                "variable": {
                    "value": "self.layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[MultiDecoderLayer(d_model, d_k, n_heads, d_v, d_ff, device) for _ in range(n_layers)]",
                    "possible_values": []
                }
            },
            "gt_285": {
                "variable": {
                    "value": "dec_self_attn_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "dec_self_attn_pad_mask + dec_self_attn_subsequence_mask",
                    "possible_values": []
                },
                "other": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Embedding_327": {
                "variable": {
                    "value": "self.tgt_emb",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "tgt_vocab_size",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "d_model",
                    "possible_values": []
                }
            },
            "ModuleList_329": {
                "variable": {
                    "value": "self.layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[DecoderLayer(d_model, d_k, n_heads, d_v, d_ff, device) for _ in range(n_layers)]",
                    "possible_values": []
                }
            },
            "gt_341": {
                "variable": {
                    "value": "dec_self_attn_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "dec_self_attn_pad_mask + dec_self_attn_subsequence_mask",
                    "possible_values": []
                },
                "other": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "Linear_363": {
                "variable": {
                    "value": "self.projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "tgt_vocab_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "matmul_67": {
                "input": {
                    "value": "Q",
                    "possible_values": [
                        [
                            "self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "K.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "Softmax_70": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "matmul_87": {
                "input": {
                    "value": "Q",
                    "possible_values": [
                        [
                            "self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)",
                            "Call"
                        ],
                        [
                            "self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "K.transpose(-1, -2)",
                    "possible_values": []
                }
            },
            "Softmax_90": {
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Linear_177": {
                "in_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_ff",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "ReLU_178": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Linear_179": {
                "in_features": {
                    "value": "d_ff",
                    "possible_values": []
                },
                "out_features": {
                    "value": "d_model",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "LayerNorm_190": {
                "normalized_shape": {
                    "value": "self.d_model",
                    "possible_values": []
                }
            },
            "arange_17": {
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "d_model",
                    "possible_values": []
                },
                "step": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "LayerNorm_131": {
                "normalized_shape": {
                    "value": "self.d_model",
                    "possible_values": []
                }
            },
            "LayerNorm_170": {
                "normalized_shape": {
                    "value": "self.d_model",
                    "possible_values": []
                }
            }
        }
    },
    "Model/trains.py": {
        "torch": {
            "tensor_38": {
                "variable": {
                    "value": "perplexity",
                    "possible_values": []
                },
                "data": {
                    "value": "perplexity",
                    "possible_values": [
                        [
                            "math.exp(losses)",
                            "Call"
                        ],
                        [
                            "torch.tensor(perplexity).item()",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_29": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    }
}