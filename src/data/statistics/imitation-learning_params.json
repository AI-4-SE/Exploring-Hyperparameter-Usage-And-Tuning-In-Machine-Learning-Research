{
    "environments.py": {
        "torch": {
            "tensor_23": {
                "data": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.env.reset()",
                            "Call"
                        ],
                        [
                            "self.env.reset()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_23": {
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_61": {
                "data": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.env.reset()",
                            "Call"
                        ],
                        [
                            "self.env.reset()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_61": {
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "as_tensor_19": {
                "data": {
                    "value": "self.env.action_space.low",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_28": {
                "data": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.env.reset()",
                            "Call"
                        ],
                        [
                            "self.env.reset()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_28": {
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "as_tensor_57": {
                "data": {
                    "value": "self.env.action_space.low",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_66": {
                "data": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.env.reset()",
                            "Call"
                        ],
                        [
                            "self.env.reset()",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_66": {
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "as_tensor_88": {
                "data": {
                    "value": "dataset['observations'][:-1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "as_tensor_89": {
                "data": {
                    "value": "dataset['actions'][:-1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "as_tensor_90": {
                "data": {
                    "value": "dataset['rewards'][:-1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "as_tensor_91": {
                "data": {
                    "value": "dataset['observations'][1:]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "as_tensor_92": {
                "data": {
                    "value": "dataset['terminals'][:-1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "evaluation.py": {
        "torch": {
            "inference_mode_14": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_31": {
                "variable": {
                    "value": "terminals",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.zeros(len(rewards) - 1), torch.ones(1)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "zeros_31": {
                "*size": {
                    "value": "len(rewards) - 1",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ones_31": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "cat_32": {
                "tensors": {
                    "value": "actions",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_32": {
                "data": {
                    "value": "rewards",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "main.py": {
        "torch": {
            "RMSprop_35": {
                "variable": {
                    "value": "agent_optimiser",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "agent.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "cfg.reinforcement.learning_rate",
                    "type": "Attribute",
                    "possible_values": []
                },
                "alpha": {
                    "value": "0.9",
                    "type": "float",
                    "possible_values": []
                }
            },
            "manual_seed_25": {
                "seed": {
                    "value": "cfg.seed",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_158": {
                "obj": {
                    "value": "agent.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "agent.pth",
                    "type": "str",
                    "possible_values": []
                }
            },
            "save_160": {
                "obj": {
                    "value": "metrics",
                    "type": "variable",
                    "possible_values": [
                        [
                            "dict(train_steps=[], train_returns=[], test_steps=[], test_returns=[])",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "metrics.pth",
                    "type": "str",
                    "possible_values": []
                }
            },
            "RMSprop_49": {
                "variable": {
                    "value": "discriminator_optimiser",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "discriminator.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "cfg.imitation.learning_rate",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "save_156": {
                "obj": {
                    "value": "trajectories",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "trajectories.pth",
                    "type": "str",
                    "possible_values": []
                }
            },
            "save_159": {
                "obj": {
                    "value": "discriminator.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "discriminator.pth",
                    "type": "str",
                    "possible_values": []
                }
            },
            "inference_mode_85": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_115": {
                "tensors": {
                    "value": "[policy_trajectories['states'][1:], next_state]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "inference_mode_116": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_91": {
                "data": {
                    "value": "[terminal]",
                    "type": "List",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "no_grad_71": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "inference_mode_76": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "models.py": {
        "torch": {
            "Linear_41": {
                "variable": {
                    "value": "final_layer",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "network_dims[-1]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "output_size",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "cat_12": {
                "tensors": {
                    "value": "[state, action]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_24": {
                "input": {
                    "value": "-gamma * _squared_distance(x, y)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Linear_34": {
                "variable": {
                    "value": "layer",
                    "type": "variable",
                    "possible_values": []
                },
                "in_features": {
                    "value": "network_dims[l]",
                    "type": "Subscript",
                    "possible_values": []
                },
                "out_features": {
                    "value": "network_dims[l + 1]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "Sequential_46": {
                "*args": {
                    "value": "*layers",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "Parameter_53": {
                "variable": {
                    "value": "self.log_std_dev",
                    "type": "Attribute",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.full((action_size,), log_std_dev_init, dtype=torch.float32)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Independent_57": {
                "variable": {
                    "value": "policy",
                    "type": "variable",
                    "possible_values": []
                },
                "base_distribution": {
                    "value": "Normal(mean, self.log_std_dev.exp())",
                    "type": "Call",
                    "possible_values": []
                },
                "reinterpreted_batch_ndims": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "quantile_72": {
                "variable": {
                    "value": "self.q",
                    "type": "Attribute",
                    "possible_values": []
                },
                "input": {
                    "value": "self._get_action_uncertainty(expert_state, expert_action)",
                    "type": "Call",
                    "possible_values": []
                },
                "q": {
                    "value": "0.98",
                    "type": "float",
                    "possible_values": []
                }
            },
            "sigmoid_123": {
                "variable": {
                    "value": "D",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.forward(state, action)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_153": {
                "variable": {
                    "value": "self.g",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "state_size if state_only else state_size + action_size",
                    "type": "IfExp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sigmoid_170": {
                "variable": {
                    "value": "D",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "self.forward(state, action, next_state, log_policy, terminal)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "stack_68": {
                "tensors": {
                    "value": "ensemble_policies",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "var_68": {
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "exp_205": {
                "input": {
                    "value": "-self.sigma_1 * (prediction - target).pow(2).mean(dim=1)",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "full_53": {
                "size": {
                    "value": "(action_size,)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "log_std_dev_init",
                    "type": "variable",
                    "possible_values": [
                        [
                            "-0.5",
                            "Method Argument"
                        ],
                        [
                            "-0.5",
                            "Method Argument"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Normal_57": {
                "loc": {
                    "value": "mean",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.actor(state)",
                            "Call"
                        ]
                    ]
                },
                "scale": {
                    "value": "self.log_std_dev.exp()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_124": {
                "input": {
                    "value": "D + 1e-06",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "log1p_124": {
                "input": {
                    "value": "-D + 1e-06",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "log_171": {
                "input": {
                    "value": "D + 1e-06",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "log1p_171": {
                "input": {
                    "value": "-D + 1e-06",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "Dropout_38": {
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0",
                            "Method Argument"
                        ],
                        [
                            "0",
                            "Method Argument"
                        ],
                        [
                            "0",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "exp_125": {
                "input": {
                    "value": "h",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.log(D + 1e-06) - torch.log1p(-D + 1e-06)",
                            "BinOp"
                        ]
                    ]
                }
            }
        }
    },
    "scripts/analyze_performance_test.py": {
        "torch": {
            "load_40": {
                "variable": {
                    "value": "metric_data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(data_folder, 'metrics.pth')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "scripts/plot_result.py": {
        "torch": {
            "load_37": {
                "f": {
                    "value": "os.path.join(s, 'metrics.pth')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "training.py": {
        "torch": {
            "mse_loss_55": {
                "variable": {
                    "value": "value_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "trajectories['values']",
                    "type": "Subscript",
                    "possible_values": []
                },
                "target": {
                    "value": "trajectories['rewards_to_go']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "DataLoader_66": {
                "variable": {
                    "value": "expert_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "expert_trajectories",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                }
            },
            "DataLoader_79": {
                "variable": {
                    "value": "expert_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "expert_trajectories",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                }
            },
            "DataLoader_93": {
                "variable": {
                    "value": "expert_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "expert_trajectories",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                }
            },
            "DataLoader_94": {
                "variable": {
                    "value": "policy_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "policy_trajectories",
                    "type": "variable",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "batch_size",
                    "type": "variable",
                    "possible_values": []
                },
                "shuffle": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                },
                "num_workers": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                }
            },
            "clip_grad_norm__60": {
                "parameters": {
                    "value": "agent.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "max_grad_norm",
                    "type": "variable",
                    "possible_values": [
                        [
                            "1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "mse_loss_86": {
                "variable": {
                    "value": "regression_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "prediction",
                    "type": "variable",
                    "possible_values": []
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_32": {
                "*size": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "empty_like_33": {
                "input": {
                    "value": "trajectories['rewards']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "no_grad_49": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "min_54": {
                "input": {
                    "value": "policy_ratio * trajectories['advantages']",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "mean_54": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "backward_114": {
                "tensors": {
                    "value": "expert_loss",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(pos_class_prior if algorithm == 'PUGAIL' else 1) * F.binary_cross_entropy_with_logits(D_expert, torch.ones_like(D_expert))",
                            "BinOp"
                        ]
                    ]
                },
                "create_graph": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "clamp_119": {
                "variable": {
                    "value": "policy_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "F.binary_cross_entropy_with_logits(D_expert, torch.zeros_like(D_expert)) - pos_class_prior * F.binary_cross_entropy_with_logits(D_policy, torch.zeros_like(D_policy))",
                    "type": "BinOp",
                    "possible_values": []
                },
                "min": {
                    "value": "-nonnegative_margin",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_121": {
                "variable": {
                    "value": "policy_loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "D_policy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discriminator(policy_state, policy_action)",
                            "Call"
                        ],
                        [
                            "discriminator(policy_state, policy_action, policy_next_state, policy_data_log_policy, policy_terminal)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "torch.zeros_like(D_policy)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_113": {
                "input": {
                    "value": "D_expert",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discriminator(expert_state, expert_action)",
                            "Call"
                        ],
                        [
                            "discriminator(expert_state, expert_action, expert_next_state, expert_data_log_policy, expert_terminal)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "torch.ones_like(D_expert)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "ones_like_113": {
                "input": {
                    "value": "D_expert",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discriminator(expert_state, expert_action)",
                            "Call"
                        ],
                        [
                            "discriminator(expert_state, expert_action, expert_next_state, expert_data_log_policy, expert_terminal)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_121": {
                "input": {
                    "value": "D_policy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discriminator(policy_state, policy_action)",
                            "Call"
                        ],
                        [
                            "discriminator(policy_state, policy_action, policy_next_state, policy_data_log_policy, policy_terminal)",
                            "Call"
                        ]
                    ]
                }
            },
            "no_grad_105": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_119": {
                "input": {
                    "value": "D_policy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discriminator(policy_state, policy_action)",
                            "Call"
                        ],
                        [
                            "discriminator(policy_state, policy_action, policy_next_state, policy_data_log_policy, policy_terminal)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "torch.zeros_like(D_policy)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "clamp_54": {
                "input": {
                    "value": "policy_ratio",
                    "type": "variable",
                    "possible_values": [
                        [
                            "(trajectories['log_prob_actions'] - trajectories['old_log_prob_actions']).exp()",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "1 - ppo_clip",
                    "type": "BinOp",
                    "possible_values": []
                },
                "max": {
                    "value": "1 + ppo_clip",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "zeros_like_119": {
                "input": {
                    "value": "D_policy",
                    "type": "variable",
                    "possible_values": [
                        [
                            "discriminator(policy_state, policy_action)",
                            "Call"
                        ],
                        [
                            "discriminator(policy_state, policy_action, policy_next_state, policy_data_log_policy, policy_terminal)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "utils.py": {
        "torch": {
            "cat_11": {
                "tensors": {
                    "value": "[d[k] for d in list_dicts]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    }
}