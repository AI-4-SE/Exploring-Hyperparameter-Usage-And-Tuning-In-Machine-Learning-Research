{
    "blink/biencoder/biencoder.py": {
        "torch": {
            "device_77": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not params[no_cuda]) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_80": {
                "variable": {
                    "value": "self.n_gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_97": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_101": {
                "variable": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "fname",
                            "Method Argument"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda storage, location: 'cpu'",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "load_103": {
                "variable": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "fname",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "save_115": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            },
            "bmm_182": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embedding_ctxt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "self.context_encoder(token_idx_ctxt, segment_idx_ctxt, mask_ctxt)",
                            "Call"
                        ],
                        [
                            "self.model(token_idx_ctxt, segment_idx_ctxt, mask_ctxt, None, None, None)",
                            "Call"
                        ],
                        [
                            "embedding_ctxt.unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "embedding_cands",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "self.cand_encoder(token_idx_cands, segment_idx_cands, mask_cands)",
                            "Call"
                        ],
                        [
                            "self.model(None, None, None, token_idx_cands, segment_idx_cands, mask_cands)",
                            "Call"
                        ],
                        [
                            "self.model(None, None, None, token_idx_cands, segment_idx_cands, mask_cands)",
                            "Call"
                        ],
                        [
                            "embedding_cands.unsqueeze(2)",
                            "Call"
                        ]
                    ]
                }
            },
            "squeeze_183": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(embedding_ctxt, embedding_cands)",
                            "Call"
                        ],
                        [
                            "torch.squeeze(scores)",
                            "Call"
                        ],
                        [
                            "self.score_candidate(context_input, cand_input, flag)",
                            "Call"
                        ]
                    ]
                }
            },
            "cross_entropy_195": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(embedding_ctxt, embedding_cands)",
                            "Call"
                        ],
                        [
                            "torch.squeeze(scores)",
                            "Call"
                        ],
                        [
                            "self.score_candidate(context_input, cand_input, flag)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.LongTensor(torch.arange(bs))",
                            "Call"
                        ],
                        [
                            "target.to(self.device)",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_197": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "arange_193": {
                "start": {
                    "value": "bs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "scores.size(0)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_78": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "blink/biencoder/data_process.py": {
        "torch": {
            "tensor_176": {
                "variable": {
                    "value": "context_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'context', 'ids')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_179": {
                "variable": {
                    "value": "cand_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'label', 'ids')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_186": {
                "variable": {
                    "value": "label_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'label_idx')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_183": {
                "variable": {
                    "value": "src_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'src')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_197": {
                "variable": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_vecs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "TensorDataset_199": {
                "variable": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_vecs",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "blink/biencoder/eval_biencoder.py": {
        "torch": {
            "SequentialSampler_147": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ],
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "torch.load(cand_pool_path)",
                            "Call"
                        ],
                        [
                            "get_candidate_pool_tensor_helper(entity_desc_list, tokenizer, params['max_cand_length'], logger, is_zeshel)",
                            "Call"
                        ],
                        [
                            "load_or_generate_candidate_pool(tokenizer, params, logger, cand_pool_path)",
                            "Call"
                        ],
                        [
                            "candidate_pool",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "DataLoader_148": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ],
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "torch.load(cand_pool_path)",
                            "Call"
                        ],
                        [
                            "get_candidate_pool_tensor_helper(entity_desc_list, tokenizer, params['max_cand_length'], logger, is_zeshel)",
                            "Call"
                        ],
                        [
                            "load_or_generate_candidate_pool(tokenizer, params, logger, cand_pool_path)",
                            "Call"
                        ],
                        [
                            "candidate_pool",
                            "Method Argument"
                        ]
                    ]
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(candidate_pool)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "encode_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encode_batch_size",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "SequentialSampler_269": {
                "variable": {
                    "value": "test_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "test_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(test_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_270": {
                "variable": {
                    "value": "test_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "test_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(test_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "test_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(test_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "params['eval_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "args.__dict__",
                            "Attribute"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_164": {
                "variable": {
                    "value": "cand_encode_list",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(cand_encode_list, cand_encode)",
                    "type": "Tuple",
                    "possible_values": []
                }
            },
            "load_182": {
                "variable": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "cand_pool_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.get('cand_pool_path', None)",
                            "Call"
                        ],
                        [
                            "cand_pool_path",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "load_235": {
                "variable": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "cand_encode_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.get('cand_encode_path', None)",
                            "Call"
                        ]
                    ]
                }
            },
            "save_297": {
                "obj": {
                    "value": "new_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "nnquery.get_topk_predictions(reranker, test_dataloader, candidate_pool, candidate_encoding, params['silent'], logger, params['top_k'], params.get('zeshel', None), save_results)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "save_data_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(save_data_dir, '%s.t7' % params['mode'])",
                            "Call"
                        ]
                    ]
                }
            },
            "save_199": {
                "obj": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{}",
                            "Dict"
                        ],
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "torch.load(cand_pool_path)",
                            "Call"
                        ],
                        [
                            "get_candidate_pool_tensor_helper(entity_desc_list, tokenizer, params['max_cand_length'], logger, is_zeshel)",
                            "Call"
                        ],
                        [
                            "load_or_generate_candidate_pool(tokenizer, params, logger, cand_pool_path)",
                            "Call"
                        ],
                        [
                            "candidate_pool",
                            "Method Argument"
                        ]
                    ]
                },
                "f": {
                    "value": "cand_pool_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.get('cand_pool_path', None)",
                            "Call"
                        ],
                        [
                            "cand_pool_path",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "save_253": {
                "obj": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "torch.load(cand_encode_path)",
                            "Call"
                        ],
                        [
                            "encode_candidate(reranker, candidate_pool, params['encode_batch_size'], silent=params['silent'], logger=logger, is_zeshel=params.get('zeshel', None))",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "cand_encode_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.get('cand_encode_path', None)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "blink/biencoder/nn_prediction.py": {
        "torch": {}
    },
    "blink/biencoder/train_biencoder.py": {
        "torch": {
            "DataLoader_166": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(train_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "RandomSampler(train_tensor_data)",
                            "Call"
                        ],
                        [
                            "SequentialSampler(train_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "train_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['train_batch_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "SequentialSampler_185": {
                "variable": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(valid_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_186": {
                "variable": {
                    "value": "valid_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(valid_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(valid_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "eval_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['eval_batch_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "manual_seed_143": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "RandomSampler_162": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(train_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_164": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "data.process_mention_data(train_samples, tokenizer, params['max_context_length'], params['max_cand_length'], context_key=params['context_key'], silent=params['silent'], logger=logger, debug=params['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "manual_seed_all_145": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "no_grad_63": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clip_grad_norm__252": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "params['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_69": {
                "start": {
                    "value": "params['eval_batch_size']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "blink/biencoder/zeshel_utils.py": {
        "torch": {}
    },
    "blink/build_faiss_index.py": {
        "torch": {
            "load_27": {
                "variable": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params['candidate_encoding']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "blink/candidate_ranking/bert_reranking.py": {
        "torch": {
            "Dropout_99": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "config.hidden_dropout_prob",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_100": {
                "variable": {
                    "value": "self.classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "config.hidden_size",
                    "type": "Attribute",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "device_167": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not parameters[no_cuda]) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_170": {
                "variable": {
                    "value": "self.n_gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "SequentialSampler_195": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "BertReranker._process_mentions_for_model(p['context_key'], mentions, tokenizer, p['max_seq_length'], p['top_k'], p['silent'], sentences=sentences)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_mention_indices, all_entity_masks)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label, all_entity_masks)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_196": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "BertReranker._process_mentions_for_model(p['context_key'], mentions, tokenizer, p['max_seq_length'], p['top_k'], p['silent'], sentences=sentences)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_mention_indices, all_entity_masks)",
                            "Call"
                        ],
                        [
                            "TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label, all_entity_masks)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "p['evaluation_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "self.parameters",
                            "Attribute"
                        ]
                    ]
                }
            },
            "Softmax_200": {
                "variable": {
                    "value": "softmax",
                    "type": "variable",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_489": {
                "variable": {
                    "value": "all_input_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "BertReranker._select_field(processed_mentions, 'input_ids')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_493": {
                "variable": {
                    "value": "all_input_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "BertReranker._select_field(processed_mentions, 'input_mask')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_497": {
                "variable": {
                    "value": "all_segment_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "BertReranker._select_field(processed_mentions, 'segment_ids')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_501": {
                "variable": {
                    "value": "all_entity_masks",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[s['entity_mask'] for s in processed_mentions]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_153": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "DataParallel_290": {
                "variable": {
                    "value": "model.bert",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "model.bert",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_513": {
                "variable": {
                    "value": "all_mention_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[s['mention_idx'] for s in processed_mentions]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_517": {
                "variable": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "tensor_525": {
                "variable": {
                    "value": "all_label",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "[s['label'] for s in processed_mentions]",
                    "type": "ListComp",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "TensorDataset_529": {
                "variable": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "all_input_ids",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "no_grad_211": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_168": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "blink/candidate_ranking/evaluate.py": {
        "torch": {
            "SequentialSampler_167": {
                "variable": {
                    "value": "eval_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "eval_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "reranker._process_mentions_for_model(parameters['context_key'], eval_samples_filtered, reranker.tokenizer, parameters['max_seq_length'], parameters['top_k'], parameters['silent'], candidates_key=candidates_key, gold_key=gold_key, debug=parameters['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_168": {
                "variable": {
                    "value": "eval_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "eval_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "reranker._process_mentions_for_model(parameters['context_key'], eval_samples_filtered, reranker.tokenizer, parameters['max_seq_length'], parameters['top_k'], parameters['silent'], candidates_key=candidates_key, gold_key=gold_key, debug=parameters['debug'])",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "eval_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(eval_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "parameters['evaluation_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "args.__dict__",
                            "Attribute"
                        ],
                        [
                            "parameters",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_44": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "blink/candidate_ranking/train.py": {
        "torch": {
            "RandomSampler_135": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "reranker._process_mentions_for_model(parameters['context_key'], train_samples_filtered, tokenizer, parameters['max_seq_length'], silent=parameters['silent'], logger=logger, top_k=parameters['top_k'], debug=parameters['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_136": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "reranker._process_mentions_for_model(parameters['context_key'], train_samples_filtered, tokenizer, parameters['max_seq_length'], silent=parameters['silent'], logger=logger, top_k=parameters['top_k'], debug=parameters['debug'])",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "RandomSampler(train_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "train_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parameters['train_batch_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "SequentialSampler_164": {
                "variable": {
                    "value": "dev_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dev_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "reranker._process_mentions_for_model(parameters['context_key'], train_samples_filtered, tokenizer, parameters['max_seq_length'], silent=parameters['silent'], logger=logger, top_k=parameters['top_k'], debug=parameters['debug'])",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_165": {
                "variable": {
                    "value": "dev_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dev_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "reranker._process_mentions_for_model(parameters['context_key'], train_samples_filtered, tokenizer, parameters['max_seq_length'], silent=parameters['silent'], logger=logger, top_k=parameters['top_k'], debug=parameters['debug'])",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "dev_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(dev_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "evaluation_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parameters['evaluation_batch_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "manual_seed_70": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parameters['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "manual_seed_all_76": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "parameters['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "clip_grad_norm__225": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "parameters['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "blink/candidate_ranking/utils.py": {
        "torch": {
            "cat_64": {
                "variable": {
                    "value": "label_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[label_ids for (_, _, _, label_ids, _) in dataloader]",
                    "type": "ListComp",
                    "possible_values": []
                }
            },
            "save_107": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "blink/common/optimizer.py": {
        "torch": {}
    },
    "blink/common/ranker_base.py": {
        "torch": {
            "Linear_23": {
                "variable": {
                    "value": "self.additional_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_model.embeddings.word_embeddings.weight.size(1)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "Dropout_24": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            }
        }
    },
    "blink/crossencoder/crossencoder.py": {
        "torch": {
            "device_70": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not params[no_cuda]) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_73": {
                "variable": {
                    "value": "self.n_gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cross_entropy_148": {
                "variable": {
                    "value": "loss",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.score_candidate(input_idx, context_len)",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "label_input",
                    "type": "variable",
                    "possible_values": [
                        [
                            "label_input",
                            "Method Argument"
                        ]
                    ]
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "DataParallel_102": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_106": {
                "variable": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "fname",
                            "Method Argument"
                        ]
                    ]
                },
                "map_location": {
                    "value": "lambda storage, location: 'cpu'",
                    "type": "Lambda",
                    "possible_values": []
                }
            },
            "load_108": {
                "variable": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "fname",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "save_124": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_71": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "blink/crossencoder/data_process.py": {
        "torch": {}
    },
    "blink/crossencoder/train_cross.py": {
        "torch": {
            "load_203": {
                "variable": {
                    "value": "train_data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(params['data_path'], 'train.t7')",
                            "Call"
                        ],
                        [
                            "os.path.join(params['data_path'], 'valid.t7')",
                            "Call"
                        ]
                    ]
                }
            },
            "RandomSampler_219": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(context_input, label_input, src_input)",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_221": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(context_input, label_input, src_input)",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "RandomSampler(train_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "params['train_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "args.__dict__",
                            "Attribute"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "load_228": {
                "variable": {
                    "value": "valid_data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(params['data_path'], 'train.t7')",
                            "Call"
                        ],
                        [
                            "os.path.join(params['data_path'], 'valid.t7')",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_244": {
                "variable": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(context_input, label_input, src_input)",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_246": {
                "variable": {
                    "value": "valid_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(context_input, label_input, src_input)",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(valid_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "params['eval_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "args.__dict__",
                            "Attribute"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ],
                        [
                            "params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "manual_seed_195": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "TensorDataset_216": {
                "variable": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "TensorDataset_218": {
                "variable": {
                    "value": "train_tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "TensorDataset_241": {
                "variable": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "TensorDataset_243": {
                "variable": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "manual_seed_all_197": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "no_grad_92": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clip_grad_norm__323": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "params['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "blink/main_dense.py": {
        "torch": {
            "SequentialSampler_230": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "process_mention_data(samples, tokenizer, biencoder_params['max_context_length'], biencoder_params['max_cand_length'], silent=True, logger=None, debug=biencoder_params['debug'])",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_231": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "process_mention_data(samples, tokenizer, biencoder_params['max_context_length'], biencoder_params['max_cand_length'], silent=True, logger=None, debug=biencoder_params['debug'])",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(tensor_data)",
                            "Call"
                        ],
                        [
                            "SequentialSampler(tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "biencoder_params['eval_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "json.load(json_file)",
                            "Call"
                        ],
                        [
                            "biencoder_params",
                            "Method Argument"
                        ],
                        [
                            "biencoder_params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "TensorDataset_264": {
                "variable": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "context_input",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "SequentialSampler_265": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "process_mention_data(samples, tokenizer, biencoder_params['max_context_length'], biencoder_params['max_cand_length'], silent=True, logger=None, debug=biencoder_params['debug'])",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_266": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "process_mention_data(samples, tokenizer, biencoder_params['max_context_length'], biencoder_params['max_cand_length'], silent=True, logger=None, debug=biencoder_params['debug'])",
                            "Call"
                        ],
                        [
                            "TensorDataset(context_input, label_input)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(tensor_data)",
                            "Call"
                        ],
                        [
                            "SequentialSampler(tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "crossencoder_params['eval_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "json.load(json_file)",
                            "Call"
                        ],
                        [
                            "crossencoder_params",
                            "Method Argument"
                        ],
                        [
                            "crossencoder_params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "load_104": {
                "variable": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "entity_encoding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "entity_encoding",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "no_grad_244": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "elq/biencoder/allennlp_span_utils.py": {
        "torch": {
            "relu_186": {
                "variable": {
                    "value": "span_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "raw_span_indices.float()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_32": {
                "start": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                },
                "end": {
                    "value": "size",
                    "type": "variable",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "cumsum_30": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "max_61": {
                "input": {
                    "value": "indices",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "min_61": {
                "input": {
                    "value": "indices",
                    "type": "variable",
                    "possible_values": []
                }
            }
        }
    },
    "elq/biencoder/biencoder.py": {
        "torch": {
            "Dropout_159": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "type": "variable",
                    "possible_values": [
                        [
                            "0.1",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleDict_255": {
                "variable": {
                    "value": "self.classification_heads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "{}",
                    "type": "Dict",
                    "possible_values": []
                }
            },
            "stack_345": {
                "variable": {
                    "value": "mention_pos",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.arange(mention_pos.size(0)).to(mention_pos.device).unsqueeze(-1).expand_as(mention_pos), mention_pos]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "zeros_357": {
                "variable": {
                    "value": "mention_pos_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "mention_logits.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "device_553": {
                "variable": {
                    "value": "self.device",
                    "type": "Attribute",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda if torch.cuda.is_available() and (not params[no_cuda]) else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "device_count_556": {
                "variable": {
                    "value": "self.n_gpu",
                    "type": "Attribute",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "BCEWithLogitsLoss_887": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "zeros_900": {
                "variable": {
                    "value": "gold_mention_binary",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "mention_logits.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "mention_logits.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Linear_53": {
                "variable": {
                    "value": "self.bound_classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "zeros_87": {
                "variable": {
                    "value": "mention_cum_scores",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "mention_scores.size()",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "mention_scores.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_89": {
                "variable": {
                    "value": "mention_logprobs_end_cumsum",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "mask_ctxt.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "mention_scores.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_94": {
                "variable": {
                    "value": "mention_logprobs_start_cumsum",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "mask_ctxt.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "mention_scores.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "stack_103": {
                "variable": {
                    "value": "mention_bounds",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.arange(mention_scores.size(1)).unsqueeze(-1).expand(mention_scores.size(1), mention_scores.size(2)), torch.arange(mention_scores.size(1)).unsqueeze(0).expand(mention_scores.size(1), mention_scores.size(2))]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Linear_164": {
                "variable": {
                    "value": "self.mention_agg_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ctxt_output_dim * 2",
                    "type": "BinOp",
                    "possible_values": []
                },
                "out_features": {
                    "value": "cand_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ModuleDict_268": {
                "variable": {
                    "value": "self.classification_heads",
                    "type": "Attribute",
                    "possible_values": []
                },
                "modules": {
                    "value": "classification_heads_dict",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'get_context_embeds': GetContextEmbedsHead(self.mention_aggregation_type, ctxt_bert_output_dim, cand_bert.embeddings.word_embeddings.weight.size(1))}",
                            "Dict"
                        ]
                    ]
                }
            },
            "DataParallel_575": {
                "variable": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "self.model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_579": {
                "variable": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "fname",
                            "Method Argument"
                        ]
                    ]
                },
                "map_location": {
                    "value": "torch.device('cpu')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_581": {
                "variable": {
                    "value": "state_dict",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "fname",
                    "type": "variable",
                    "possible_values": [
                        [
                            "fname",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "save_598": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            },
            "bmm_776": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "embedding_ctxt",
                    "type": "variable",
                    "possible_values": [
                        [
                            "batched_span_select(bert_output, mention_bounds)",
                            "Call"
                        ],
                        [
                            "embedding_ctxt.sum(2) / mask.sum(2).float().unsqueeze(-1)",
                            "BinOp"
                        ],
                        [
                            "torch.cat([start_embeddings.unsqueeze(2), end_embeddings.unsqueeze(2)], dim=2)",
                            "Call"
                        ],
                        [
                            "self.mention_agg_linear(embedding_ctxt)",
                            "Call"
                        ],
                        [
                            "embedding_ctxt.mean(2)",
                            "Call"
                        ],
                        [
                            "embedding_ctxt.view(embedding_ctxt.size(0), embedding_ctxt.size(1), -1)",
                            "Call"
                        ],
                        [
                            "self.mention_agg_linear(embedding_ctxt)",
                            "Call"
                        ],
                        [
                            "self.classification_heads['get_context_embeds'](raw_ctxt_encoding, mention_bounds)",
                            "Call"
                        ],
                        [
                            "self.linear_compression(embedding_ctxt)",
                            "Call"
                        ],
                        [
                            "self.context_encoder(token_idx_ctxt, segment_idx_ctxt, mask_ctxt)",
                            "Call"
                        ],
                        [
                            "self.linear_compression(embedding_ctxt)",
                            "Call"
                        ],
                        [
                            "self.get_ctxt_embeds(raw_ctxt_encoding, top_mention_bounds)",
                            "Call"
                        ],
                        [
                            "text_encs",
                            "variable"
                        ],
                        [
                            "context_outs['mention_reps'][context_outs['mention_masks']]",
                            "Subscript"
                        ],
                        [
                            "context_outs['mention_reps'][gold_mention_bounds_mask]",
                            "Subscript"
                        ],
                        [
                            "embedding_ctxt[hard_negs_mask]",
                            "Subscript"
                        ],
                        [
                            "embedding_ctxt.unsqueeze(1)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "embedding_cands",
                    "type": "variable",
                    "possible_values": [
                        [
                            "self.model(None, None, None, token_idx_cands, segment_idx_cands, mask_cands)",
                            "Call"
                        ],
                        [
                            "self.encode_candidate(cand_vecs)",
                            "Call"
                        ],
                        [
                            "cand_encs",
                            "variable"
                        ],
                        [
                            "embedding_cands[hard_negs_mask]",
                            "Subscript"
                        ],
                        [
                            "embedding_cands.unsqueeze(2)",
                            "Call"
                        ]
                    ]
                }
            },
            "squeeze_777": {
                "variable": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(embedding_ctxt, embedding_cands)",
                            "Call"
                        ],
                        [
                            "torch.squeeze(scores)",
                            "Call"
                        ],
                        [
                            "self.score_candidate(context_input, cand_input, hard_negs=hard_negs, cand_encs=cand_encs, text_encs=text_encs, gold_mention_bounds=gold_mention_bounds, gold_mention_bounds_mask=gold_mention_bounds_mask, hard_negs_mask=hard_negs_mask, get_mention_scores=return_loss and (mention_logits is None or mention_bounds is None))",
                            "Call"
                        ]
                    ]
                }
            },
            "BCEWithLogitsLoss_862": {
                "variable": {
                    "value": "loss_fct",
                    "type": "variable",
                    "possible_values": []
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Sequential_55": {
                "variable": {
                    "value": "self.bound_classifier",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(bert_output_dim, bert_output_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_166": {
                "variable": {
                    "value": "self.mention_agg_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ctxt_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ctxt_output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "cand_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "cat_206": {
                "variable": {
                    "value": "embedding_ctxt",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[start_embeddings.unsqueeze(2), end_embeddings.unsqueeze(2)]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Linear_271": {
                "variable": {
                    "value": "self.linear_compression",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "ctxt_bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "ctxt_bert.embeddings.word_embeddings.weight.size(1)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "cand_bert.embeddings.word_embeddings.weight.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "sigmoid_347": {
                "input": {
                    "value": "top_mention_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "mention_logits.topk(num_cand_mentions, sorted=True)",
                            "Call"
                        ],
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "self.prune_ctxt_mentions(mention_logits, mention_bounds, num_cand_mentions, topK_threshold)",
                            "Call"
                        ]
                    ]
                }
            },
            "log_347": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Sequential_168": {
                "variable": {
                    "value": "self.mention_agg_mlp",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(bert_output_dim, bert_output_dim)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "arange_345": {
                "start": {
                    "value": "mention_pos.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "unsqueeze_345": {
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_460": {
                "data": {
                    "value": "top_mention_mask.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "unsqueeze_460": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "rand_478": {
                "*size": {
                    "value": "token_idx_cands.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_available_578": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ones_652": {
                "*size": {
                    "value": "shape",
                    "type": "variable",
                    "possible_values": [
                        [
                            "shape",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "arange_871": {
                "start": {
                    "value": "scores.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "cross_entropy_874": {
                "input": {
                    "value": "scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.bmm(embedding_ctxt, embedding_cands)",
                            "Call"
                        ],
                        [
                            "torch.squeeze(scores)",
                            "Call"
                        ],
                        [
                            "self.score_candidate(context_input, cand_input, hard_negs=hard_negs, cand_encs=cand_encs, text_encs=text_encs, gold_mention_bounds=gold_mention_bounds, gold_mention_bounds_mask=gold_mention_bounds_mask, hard_negs_mask=hard_negs_mask, get_mention_scores=return_loss and (mention_logits is None or mention_bounds is None))",
                            "Call"
                        ]
                    ]
                },
                "target": {
                    "value": "target",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.LongTensor(torch.arange(scores.size(1)))",
                            "Call"
                        ],
                        [
                            "target.to(self.device)",
                            "Call"
                        ]
                    ]
                },
                "reduction": {
                    "value": "mean",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Linear_56": {
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ReLU_57": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_58": {
                "p": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_59": {
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                }
            },
            "is_available_554": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "device_579": {
                "type": {
                    "value": "cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "Linear_169": {
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "ReLU_170": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_171": {
                "p": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_172": {
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_output_dim",
                            "Method Argument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "arange_104": {
                "start": {
                    "value": "mention_scores.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "unsqueeze_104": {
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "arange_105": {
                "start": {
                    "value": "mention_scores.size(1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "unsqueeze_105": {
                "input": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "elq/biencoder/data_process.py": {
        "torch": {
            "tensor_483": {
                "variable": {
                    "value": "context_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'context', 'ids')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "load_373": {
                "variable": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(saved_context_dir, 'data.pt')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_374": {
                "variable": {
                    "value": "tensor_data_tuple",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(saved_context_dir, 'tensor_tuple.pt')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_378": {
                "variable": {
                    "value": "candidate_token_ids",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params['cand_token_ids_path']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "tensor_489": {
                "variable": {
                    "value": "mention_idx_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'context', 'mention_idxs')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_489": {
                "variable": {
                    "value": "mention_idx_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ones_492": {
                "variable": {
                    "value": "mention_idx_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "mention_idx_vecs.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_492": {
                "variable": {
                    "value": "mention_idx_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_502": {
                "variable": {
                    "value": "label_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'label_idx')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "unsqueeze_502": {
                "variable": {
                    "value": "label_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_512": {
                "variable": {
                    "value": "mention_idx_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mention_idx_vecs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.tensor(select_field(processed_samples, 'context', 'mention_idxs'), dtype=torch.long).unsqueeze(1)",
                            "Call"
                        ],
                        [
                            "select_field_with_padding(processed_samples, 'context', 'mention_idxs', pad_idx=[0, 1])",
                            "Call"
                        ],
                        [
                            "torch.tensor(mention_idx_vecs, dtype=torch.long)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_514": {
                "variable": {
                    "value": "mention_idx_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "mention_idx_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.ones(mention_idx_vecs.size(0), dtype=torch.bool).unsqueeze(-1)",
                            "Call"
                        ],
                        [
                            "select_field_with_padding(processed_samples, 'context', 'mention_idxs', pad_idx=[0, 1])",
                            "Call"
                        ],
                        [
                            "torch.tensor(mention_idx_mask, dtype=torch.bool)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_531": {
                "variable": {
                    "value": "label_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "label_idx_vecs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "select_field_with_padding(processed_samples, 'label_idx', pad_idx=-1)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_532": {
                "variable": {
                    "value": "label_idx_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "label_idx_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "select_field_with_padding(processed_samples, 'label_idx', pad_idx=-1)",
                            "Call"
                        ],
                        [
                            "torch.tensor(label_idx_mask, dtype=torch.bool)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_542": {
                "variable": {
                    "value": "src_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'src')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_497": {
                "variable": {
                    "value": "cand_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "select_field(processed_samples, 'label', 'ids')",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_521": {
                "variable": {
                    "value": "cand_vecs",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "cand_vecs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "select_field_with_padding(processed_samples, 'label', 'ids', pad_idx=[[0 for _ in range(max_cand_length)]])",
                            "Call"
                        ],
                        [
                            "torch.tensor(cand_vecs, dtype=torch.long)",
                            "Call"
                        ],
                        [
                            "torch.Tensor(context_vecs.size())",
                            "Call"
                        ],
                        [
                            "torch.tensor(select_field(processed_samples, 'label', 'ids'), dtype=torch.long)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_522": {
                "variable": {
                    "value": "cand_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "cand_mask",
                    "type": "variable",
                    "possible_values": [
                        [
                            "select_field_with_padding(processed_samples, 'label', 'ids', pad_idx=[[0 for _ in range(max_cand_length)]])",
                            "Call"
                        ],
                        [
                            "torch.tensor(cand_mask, dtype=torch.bool)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.bool",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "Tensor_527": {
                "variable": {
                    "value": "cand_vecs",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "save_563": {
                "obj": {
                    "value": "data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.load(os.path.join(saved_context_dir, 'data.pt'))",
                            "Call"
                        ],
                        [
                            "{'context_vecs': context_vecs, 'mention_idx_vecs': mention_idx_vecs, 'cand_vecs': cand_vecs, 'label_idx': label_idx}",
                            "Dict"
                        ],
                        [
                            "data",
                            "Method Argument"
                        ],
                        [
                            "data",
                            "Method Argument"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(saved_context_dir, 'data.pt')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "save_564": {
                "obj": {
                    "value": "tensor_data_tuple",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.load(os.path.join(saved_context_dir, 'tensor_tuple.pt'))",
                            "Call"
                        ],
                        [
                            "(context_vecs, cand_vecs, src_vecs, label_idx, mention_idx_vecs, mention_idx_mask)",
                            "Tuple"
                        ],
                        [
                            "(context_vecs, cand_vecs, label_idx, mention_idx_vecs, mention_idx_mask)",
                            "Tuple"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(saved_context_dir, 'tensor_tuple.pt')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "elq/biencoder/train_biencoder.py": {
        "torch": {
            "TensorDataset_264": {
                "variable": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "*valid_tensor_data",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "SequentialSampler_265": {
                "variable": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "process_mention_data(samples=valid_samples[:valid_subset], tokenizer=tokenizer, max_context_length=params['max_context_length'], max_cand_length=params['max_cand_length'], context_key=params['context_key'], title_key=params['title_key'], silent=params['silent'], logger=logger, debug=params['debug'], add_mention_bounds=not args.no_mention_bounds, candidate_token_ids=None, params=params)",
                            "Call"
                        ],
                        [
                            "TensorDataset(*valid_tensor_data)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_266": {
                "variable": {
                    "value": "valid_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "valid_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "process_mention_data(samples=valid_samples[:valid_subset], tokenizer=tokenizer, max_context_length=params['max_context_length'], max_cand_length=params['max_cand_length'], context_key=params['context_key'], title_key=params['title_key'], silent=params['silent'], logger=logger, debug=params['debug'], add_mention_bounds=not args.no_mention_bounds, candidate_token_ids=None, params=params)",
                            "Call"
                        ],
                        [
                            "TensorDataset(*valid_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "valid_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(valid_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "eval_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['eval_batch_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "manual_seed_228": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "load_274": {
                "variable": {
                    "value": "cand_encs",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params['cand_enc_path']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "load_335": {
                "variable": {
                    "value": "training_state",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "trainer_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params.get('path_to_trainer_state', None)",
                            "Call"
                        ]
                    ]
                }
            },
            "TensorDataset_369": {
                "variable": {
                    "value": "batch_train_tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "*list(train_tensor_data_tuple)",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "DataLoader_377": {
                "variable": {
                    "value": "train_dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "batch_train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(*list(train_tensor_data_tuple))",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "RandomSampler(batch_train_tensor_data)",
                            "Call"
                        ],
                        [
                            "SequentialSampler(batch_train_tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "train_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['train_batch_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "empty_cache_70": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "empty_cache_146": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "manual_seed_all_230": {
                "seed": {
                    "value": "seed",
                    "type": "variable",
                    "possible_values": [
                        [
                            "params['seed']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "RandomSampler_373": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "batch_train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(*list(train_tensor_data_tuple))",
                            "Call"
                        ]
                    ]
                }
            },
            "SequentialSampler_375": {
                "variable": {
                    "value": "train_sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "batch_train_tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(*list(train_tensor_data_tuple))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_536": {
                "obj": {
                    "value": "{'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}",
                    "type": "Dict",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(epoch_output_folder_path, 'training_state.th')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_84": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "from_numpy_424": {
                "variable": {
                    "value": "neg_cand_encs_input_idxs",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "neg_cand_encs_input_idxs",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_encs_index.search_knn(masked_mention_reps.detach().cpu().numpy(), num_neighbors)",
                            "Call"
                        ],
                        [
                            "torch.from_numpy(neg_cand_encs_input_idxs)",
                            "Call"
                        ],
                        [
                            "neg_cand_encs_input_idxs_reconstruct",
                            "variable"
                        ],
                        [
                            "neg_cand_encs_input_idxs.permute(0, 2, 1)",
                            "Call"
                        ],
                        [
                            "neg_cand_encs_input_idxs.reshape(-1, neg_cand_encs_input_idxs.size(-1))",
                            "Call"
                        ],
                        [
                            "neg_cand_encs_input_idxs[mask]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "zeros_433": {
                "variable": {
                    "value": "neg_cand_encs_input_idxs_reconstruct",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "label_ids.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "label_ids.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "neg_cand_encs_input_idxs.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "arange_439": {
                "variable": {
                    "value": "neg_example_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "start": {
                    "value": "neg_cand_encs_input_idxs.size(0)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "unsqueeze_439": {
                "variable": {
                    "value": "neg_example_idx",
                    "type": "variable",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "cat_463": {
                "variable": {
                    "value": "mention_reps_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mention_reps, mention_reps[neg_example_idx.to(device)]]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_469": {
                "variable": {
                    "value": "label_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[torch.ones(pos_cand_encs_input.size(0), pos_cand_encs_input.size(1), dtype=label_ids.dtype), torch.zeros(neg_cand_encs_input.size(0), neg_cand_encs_input.size(1), dtype=label_ids.dtype)]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_474": {
                "variable": {
                    "value": "cand_encs_input",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[pos_cand_encs_input, neg_cand_encs_input]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "cat_477": {
                "variable": {
                    "value": "hard_negs_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[mention_idx_mask, neg_mention_idx_mask]",
                    "type": "List",
                    "possible_values": []
                }
            },
            "device_count_246": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "clip_grad_norm__507": {
                "parameters": {
                    "value": "model.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "params['max_grad_norm']",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "arange_130": {
                "start": {
                    "value": "logits.shape[0]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "sigmoid_103": {
                "input": {
                    "value": "context_outs['mention_logits'].unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_103": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ones_470": {
                "*size": {
                    "value": "pos_cand_encs_input.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "pos_cand_encs_input.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "label_ids.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "zeros_471": {
                "*size": {
                    "value": "neg_cand_encs_input.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "neg_cand_encs_input.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "label_ids.dtype",
                    "type": "Attribute",
                    "possible_values": []
                }
            }
        }
    },
    "elq/biencoder/utils.py": {
        "torch": {
            "stack_31": {
                "variable": {
                    "value": "repeat_freqs",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[batch_num_selected, max_num_selected - batch_num_selected]",
                    "type": "List",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "Tensor_47": {
                "variable": {
                    "value": "input_reshape",
                    "type": "variable",
                    "possible_values": []
                }
            },
            "zeros_37": {
                "variable": {
                    "value": "left_align_mask",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "input_t.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                }
            }
        }
    },
    "elq/build_faiss_index.py": {
        "torch": {
            "load_23": {
                "variable": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "params['candidate_encoding']",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    },
    "elq/candidate_ranking/utils.py": {
        "torch": {
            "save_59": {
                "obj": {
                    "value": "model_to_save.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "output_model_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(output_dir, WEIGHTS_NAME)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "elq/common/ranker_base.py": {
        "torch": {
            "Dropout_24": {
                "variable": {
                    "value": "self.dropout",
                    "type": "Attribute",
                    "possible_values": []
                },
                "p": {
                    "value": "0.1",
                    "type": "float",
                    "possible_values": []
                }
            },
            "Linear_26": {
                "variable": {
                    "value": "self.additional_linear",
                    "type": "Attribute",
                    "possible_values": []
                },
                "in_features": {
                    "value": "bert_output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "bert_model.embeddings.word_embeddings.weight.size(1)",
                            "Call"
                        ]
                    ]
                },
                "out_features": {
                    "value": "output_dim",
                    "type": "variable",
                    "possible_values": [
                        [
                            "output_dim",
                            "Method Argument"
                        ]
                    ]
                }
            }
        }
    },
    "elq/main_dense.py": {
        "torch": {
            "load_114": {
                "variable": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "entity_encoding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "entity_encoding",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "TensorDataset_240": {
                "variable": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": []
                },
                "*tensors": {
                    "value": "*tensor_data_tuple",
                    "type": "Starred",
                    "possible_values": []
                }
            },
            "SequentialSampler_241": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(*tensor_data_tuple)",
                            "Call"
                        ]
                    ]
                }
            },
            "DataLoader_242": {
                "variable": {
                    "value": "dataloader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "tensor_data",
                    "type": "variable",
                    "possible_values": [
                        [
                            "TensorDataset(*tensor_data_tuple)",
                            "Call"
                        ]
                    ]
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(tensor_data)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "biencoder_params['eval_batch_size']",
                    "type": "Subscript",
                    "possible_values": [
                        [
                            "json.load(json_file)",
                            "Call"
                        ],
                        [
                            "json.loads(line)",
                            "Call"
                        ],
                        [
                            "biencoder_params",
                            "Method Argument"
                        ],
                        [
                            "biencoder_params",
                            "Method Argument"
                        ],
                        [
                            "biencoder_params",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "load_99": {
                "variable": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "entity_encoding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "entity_encoding",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "zeros_342": {
                "variable": {
                    "value": "top_cand_logits",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "chosen_mention_logits.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "chosen_mention_logits.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "top_cand_logits_shape.size(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_345": {
                "variable": {
                    "value": "top_cand_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "*size": {
                    "value": "chosen_mention_logits.size(0)",
                    "type": "Call",
                    "possible_values": []
                },
                "out": {
                    "value": "chosen_mention_logits.size(1)",
                    "type": "Call",
                    "possible_values": []
                },
                "dtype": {
                    "value": "top_cand_indices_shape.size(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "tensor_441": {
                "variable": {
                    "value": "(_, sort_idxs)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "data": {
                    "value": "distances[:, 0][top_mentions_mask]",
                    "type": "Subscript",
                    "possible_values": []
                }
            },
            "sort_441": {
                "variable": {
                    "value": "(_, sort_idxs)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "DataParallel_633": {
                "variable": {
                    "value": "biencoder.model",
                    "type": "Attribute",
                    "possible_values": []
                },
                "module": {
                    "value": "biencoder.model",
                    "type": "Attribute",
                    "possible_values": []
                }
            },
            "tensor_239": {
                "data": {
                    "value": "samples_text_tuple",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "no_grad_281": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "tensor_338": {
                "variable": {
                    "value": "top_cand_logits_shape",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "top_cand_logits_shape",
                    "type": "variable",
                    "possible_values": [
                        [
                            "indexer.search_knn(embedding_ctxt.cpu().numpy(), num_cand_entities)",
                            "Call"
                        ],
                        [
                            "torch.tensor(top_cand_logits_shape).to(embedding_ctxt.device)",
                            "Call"
                        ],
                        [
                            "cand_logits.topk(num_cand_entities, dim=-1, sorted=True)",
                            "Call"
                        ],
                        [
                            "torch.cat(top_cand_logits_list, dim=-1).topk(num_cand_entities, dim=-1, sorted=True)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_339": {
                "variable": {
                    "value": "top_cand_indices_shape",
                    "type": "variable",
                    "possible_values": []
                },
                "data": {
                    "value": "top_cand_indices_shape",
                    "type": "variable",
                    "possible_values": [
                        [
                            "indexer.search_knn(embedding_ctxt.cpu().numpy(), num_cand_entities)",
                            "Call"
                        ],
                        [
                            "torch.tensor(top_cand_indices_shape).to(embedding_ctxt.device)",
                            "Call"
                        ],
                        [
                            "cand_logits.topk(num_cand_entities, dim=-1, sorted=True)",
                            "Call"
                        ],
                        [
                            "all_top_cand_indices.gather(-1, top_top_cand_indices_shape)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_623": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "log_softmax_355": {
                "input": {
                    "value": "top_cand_logits",
                    "type": "variable",
                    "possible_values": [
                        [
                            "torch.zeros(chosen_mention_logits.size(0), chosen_mention_logits.size(1), top_cand_logits_shape.size(-1)).to(top_cand_logits_shape.device, top_cand_logits_shape.dtype)",
                            "Call"
                        ],
                        [
                            "embedding_ctxt.mm(candidate_encoding[chunk_idx * SPLIT_SIZE:(chunk_idx + 1) * SPLIT_SIZE].to(device).t().contiguous()).topk(10, dim=-1, sorted=True)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "sigmoid_355": {
                "input": {
                    "value": "chosen_mention_logits.unsqueeze(-1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_355": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "cat_327": {
                "variable": {
                    "value": "(top_cand_logits_shape, top_top_cand_indices_shape)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "tensors": {
                    "value": "top_cand_logits_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "topk_327": {
                "variable": {
                    "value": "(top_cand_logits_shape, top_top_cand_indices_shape)",
                    "type": "Tuple",
                    "possible_values": []
                },
                "input": {
                    "value": "num_cand_entities",
                    "type": "variable",
                    "possible_values": [
                        [
                            "10",
                            "Method Argument"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                },
                "sorted": {
                    "value": "True",
                    "type": "bool",
                    "possible_values": []
                }
            },
            "cat_331": {
                "variable": {
                    "value": "all_top_cand_indices",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "top_cand_indices_list",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            }
        }
    },
    "examples/zeshel/create_BLINK_zeshel_data.py": {
        "torch": {}
    },
    "scripts/generate_candidates.py": {
        "torch": {
            "SequentialSampler_30": {
                "variable": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": []
                },
                "data_source": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": [
                        [
                            "load_candidate_pool(biencoder.tokenizer, biencoder_params, logger, getattr(args, 'saved_cand_ids', None))",
                            "Call"
                        ],
                        [
                            "candidate_pool[:10]",
                            "Subscript"
                        ],
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "torch.load(cand_pool_path)",
                            "Call"
                        ],
                        [
                            "candidate_pool",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "DataLoader_31": {
                "variable": {
                    "value": "data_loader",
                    "type": "variable",
                    "possible_values": []
                },
                "dataset": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": [
                        [
                            "load_candidate_pool(biencoder.tokenizer, biencoder_params, logger, getattr(args, 'saved_cand_ids', None))",
                            "Call"
                        ],
                        [
                            "candidate_pool[:10]",
                            "Subscript"
                        ],
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "torch.load(cand_pool_path)",
                            "Call"
                        ],
                        [
                            "candidate_pool",
                            "Method Argument"
                        ]
                    ]
                },
                "sampler": {
                    "value": "sampler",
                    "type": "variable",
                    "possible_values": [
                        [
                            "SequentialSampler(candidate_pool)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "encode_batch_size",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encode_batch_size",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "load_120": {
                "variable": {
                    "value": "baseline_candidate_encoding",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "getattr(args, 'compare_saved_embeds')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_63": {
                "variable": {
                    "value": "candidate_pool",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "cand_pool_path",
                    "type": "variable",
                    "possible_values": [
                        [
                            "cand_pool_path",
                            "Method Argument"
                        ]
                    ]
                }
            },
            "save_152": {
                "obj": {
                    "value": "candidate_encoding",
                    "type": "variable",
                    "possible_values": [
                        [
                            "encode_candidate(biencoder, candidate_pool[args.chunk_start:args.chunk_end], biencoder_params['encode_batch_size'], biencoder_params['silent'], logger)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "save_file",
                    "type": "variable",
                    "possible_values": [
                        [
                            "None",
                            "NoneType"
                        ],
                        [
                            "os.path.join(args.encoding_save_file_dir, '{}_{}.t7'.format(args.chunk_start, args.chunk_end))",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_47": {
                "variable": {
                    "value": "cand_encode_list",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(cand_encode_list, cand_encode)",
                    "type": "Tuple",
                    "possible_values": []
                }
            }
        }
    },
    "scripts/merge_candidates.py": {
        "torch": {
            "cat_33": {
                "variable": {
                    "value": "all_chunks",
                    "type": "variable",
                    "possible_values": []
                },
                "tensors": {
                    "value": "all_chunks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(all_chunks, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "type": "int",
                    "possible_values": []
                }
            },
            "load_30": {
                "variable": {
                    "value": "loaded_chunk",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "f_chunk",
                    "type": "variable",
                    "possible_values": [
                        [
                            "os.path.join(args.path_to_saved_chunks, '{}_{}.t7'.format(fn, fn + CHUNK_SIZES))",
                            "Call"
                        ]
                    ]
                }
            },
            "save_34": {
                "obj": {
                    "value": "all_chunks",
                    "type": "variable",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(all_chunks, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "f": {
                    "value": "os.path.join(args.path_to_saved_chunks, 'all.t7'.format(fn, fn + CHUNK_SIZES))",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "scripts/tune_hyperparams_new.py": {
        "torch": {
            "log_softmax_102": {
                "input": {
                    "value": "torch.tensor(cand_dists[valid_cands_mask])",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "sigmoid_102": {
                "input": {
                    "value": "torch.tensor(mention_scores)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "log_102": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "unsqueeze_102": {
                "input": {
                    "value": "-1",
                    "type": "UnaryOp",
                    "possible_values": []
                }
            },
            "tensor_102": {
                "data": {
                    "value": "mention_scores",
                    "type": "variable",
                    "possible_values": [
                        [
                            "mention_dists[valid_cands_mask]",
                            "Subscript"
                        ],
                        [
                            "mention_scores[:, 0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "log_softmax_37": {
                "input": {
                    "value": "torch.tensor(cand_dists[i])",
                    "type": "Call",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "tensor_37": {
                "data": {
                    "value": "cand_dists[i]",
                    "type": "Subscript",
                    "possible_values": []
                }
            }
        }
    }
}