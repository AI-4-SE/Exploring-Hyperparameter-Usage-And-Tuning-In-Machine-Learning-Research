{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_category(type_name: str) -> str:\n",
    "\n",
    "    if type_name.lower() in (\"str\", \"joinedstr\"):\n",
    "        return \"Text\"\n",
    "\n",
    "    if type_name.lower() in (\"int\", \"float\", \"complex\"):\n",
    "        return \"Numeric\"\n",
    "\n",
    "    if type_name.lower() in (\"list\", \"tuple\", \"listcomp\", \"generatorexp\"):\n",
    "        return \"Sequence\"\n",
    "\n",
    "    if type_name.lower() in (\"dict\", \"dictcomp\", \"kwargs\"):\n",
    "        return \"Mapping\"\n",
    "    \n",
    "    if type_name.lower() in (\"set\", \"setcomp\"):\n",
    "        return \"Set\"\n",
    "\n",
    "    if type_name.lower() in (\"lambda\", \"subscript\"):\n",
    "        return \"Call\"\n",
    "\n",
    "    if type_name.lower() in (\"binop\", \"boolop\", \"unaryop\", \"compare\", \"ifexp\"):\n",
    "        return \"Operation\"\n",
    "\n",
    "    if type_name.lower() == \"none\":\n",
    "        return \"None Type\"\n",
    "\n",
    "    if type_name.lower() in (\"method argument\", \"starred\", \"variable\", \"attribute\", \"yield\"):\n",
    "        return \"Variable\"\n",
    "    \n",
    "    if type_name.lower() in (\"bool\"):\n",
    "        return \"Bool\"\n",
    "\n",
    "    return type_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &   1510 &   33.5\\% \\\\\n",
      "1 &    Numeric &   1414 &   31.4\\% \\\\\n",
      "2 &       Text &    574 &   12.7\\% \\\\\n",
      "5 &       Bool &    398 &    8.8\\% \\\\\n",
      "3 &       Call &    237 &    5.3\\% \\\\\n",
      "4 &  Operation &    134 &    3.0\\% \\\\\n",
      "6 &   Sequence &    121 &    2.7\\% \\\\\n",
      "7 &   NoneType &     67 &    1.5\\% \\\\\n",
      "8 &    Mapping &     53 &    1.2\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &  13237 &   35.1\\% \\\\\n",
      "2 &       Text &   9113 &   24.2\\% \\\\\n",
      "1 &    Numeric &   4531 &   12.0\\% \\\\\n",
      "4 &       Call &   4003 &   10.6\\% \\\\\n",
      "5 &   Sequence &   3133 &    8.3\\% \\\\\n",
      "3 &       Bool &   2212 &    5.9\\% \\\\\n",
      "7 &  Operation &    771 &    2.0\\% \\\\\n",
      "8 &   NoneType &    539 &    1.4\\% \\\\\n",
      "6 &    Mapping &    190 &    0.5\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "1 &   Variable &  81679 &   38.5\\% \\\\\n",
      "2 &    Numeric &  70441 &   33.2\\% \\\\\n",
      "3 &       Bool &  24134 &   11.4\\% \\\\\n",
      "5 &       Call &  17720 &    8.3\\% \\\\\n",
      "4 &  Operation &  10413 &    4.9\\% \\\\\n",
      "0 &   Sequence &   6790 &    3.2\\% \\\\\n",
      "6 &       Text &   1014 &    0.5\\% \\\\\n",
      "8 &   NoneType &    124 &    0.1\\% \\\\\n",
      "7 &    Mapping &     67 &    0.0\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_value_types_all_methods(library_name: str, project_dir: str) -> pd.DataFrame:\n",
    "    value_types = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                for param, param_data in data.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        #if str(param_data[\"type\"]) == \"Subscript\":\n",
    "                                        #    for item in param_data[\"possible_values\"]:\n",
    "                                        #        if \"parse_args\" in item[0] or \"sys.argv\" in item[0]:\n",
    "                                        #            print(project, file)\n",
    "                                        #           print(param_data[\"value\"], param_data[\"possible_values\"])\n",
    "\n",
    "                                        value_type = assign_category(str(param_data[\"type\"]))\n",
    "                                        value_types.append(value_type)\n",
    "\n",
    "\n",
    "    type_data = Counter(value_types)\n",
    "    type_data_portion = OrderedDict([(i, str(round(count / sum(type_data.values()) * 100.0, 1)) + '%') for i, count in type_data.most_common()])\n",
    "    portion = [y for _, y in type_data_portion.items()]\n",
    "    df = pd.DataFrame.from_dict(type_data, orient=\"index\").reset_index()\n",
    "    df = df.rename(columns={'index':'Type', 0:'Count'})\n",
    "    df = df.sort_values(by=['Count'], ascending=False)\n",
    "    df[\"portion\"] = portion\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sklearn = get_value_types_all_methods(\"sklearn\", \"../data/statistics/*\")\n",
    "df_tf = get_value_types_all_methods(\"tensorflow\", \"../data/statistics/*\")\n",
    "df_torch = get_value_types_all_methods(\"torch\", \"../data/statistics/*\")\n",
    "        \n",
    "print(df_sklearn.to_latex())\n",
    "print(df_tf.to_latex())\n",
    "print(df_torch.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "2 &    Numeric &    678 &  34.04\\% \\\\\n",
      "0 &   Variable &    601 &  30.17\\% \\\\\n",
      "1 &       Text &    335 &  16.82\\% \\\\\n",
      "4 &       Bool &    135 &   6.78\\% \\\\\n",
      "3 &       Call &     79 &   3.97\\% \\\\\n",
      "5 &  Operation &     64 &   3.21\\% \\\\\n",
      "6 &   NoneType &     51 &   2.56\\% \\\\\n",
      "8 &    Mapping &     34 &   1.71\\% \\\\\n",
      "7 &   Sequence &     15 &   0.75\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "1 &    Numeric &    196 &  47.23\\% \\\\\n",
      "0 &   Variable &    160 &  38.55\\% \\\\\n",
      "3 &       Call &     33 &   7.95\\% \\\\\n",
      "2 &       Bool &     20 &   4.82\\% \\\\\n",
      "4 &  Operation &      4 &   0.96\\% \\\\\n",
      "5 &   NoneType &      2 &   0.48\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &       Type &  Count & portion \\\\\n",
      "\\midrule\n",
      "0 &   Variable &   3879 &  57.42\\% \\\\\n",
      "2 &    Numeric &   1474 &  21.82\\% \\\\\n",
      "4 &   Sequence &    641 &   9.49\\% \\\\\n",
      "3 &       Call &    467 &   6.91\\% \\\\\n",
      "1 &       Bool &    221 &   3.27\\% \\\\\n",
      "5 &  Operation &     65 &   0.96\\% \\\\\n",
      "6 &   NoneType &      7 &    0.1\\% \\\\\n",
      "7 &       Text &      1 &   0.01\\% \\\\\n",
      "8 &    Mapping &      1 &   0.01\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_value_types_ml_methods(library_name: str, library_dir: str ,project_dir: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [x[\"name\"] for x in library_data]\n",
    "    \n",
    "    value_types = []\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "\n",
    "                                if class_name not in class_names:\n",
    "                                    continue    \n",
    "\n",
    "                                for param, param_data in data.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        #if str(param_data[\"type\"]) == \"Subscript\":\n",
    "                                        #    for item in param_data[\"possible_values\"]:\n",
    "                                        #        if \"parse_args\" in item[0] or \"sys.argv\" in item[0]:\n",
    "                                        #            print(project, file)\n",
    "                                        #           print(param_data[\"value\"], param_data[\"possible_values\"])\n",
    "\n",
    "                                        value_type = assign_category(str(param_data[\"type\"]))\n",
    "                                        value_types.append(value_type)\n",
    "\n",
    "\n",
    "    type_data = Counter(value_types)\n",
    "    type_data_portion = OrderedDict([(i, str(round(count / sum(type_data.values()) * 100.0, 2)) + '%') for i, count in type_data.most_common()])\n",
    "    portion = [y for _, y in type_data_portion.items()]\n",
    "    df = pd.DataFrame.from_dict(type_data, orient=\"index\").reset_index()\n",
    "    df = df.rename(columns={'index':'Type', 0:'Count'})\n",
    "    df = df.sort_values(by=['Count'], ascending=False)\n",
    "    df[\"portion\"] = portion\n",
    "    return df\n",
    "\n",
    "\n",
    "df_sklearn = get_value_types_ml_methods(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", \"../data/statistics/*\")\n",
    "df_tf = get_value_types_ml_methods(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", \"../data/statistics/*\")\n",
    "df_torch = get_value_types_ml_methods(\"torch\", \"../data/library_data/torch_optimizer.json\", \"../data/statistics/*\")\n",
    "        \n",
    "print(df_sklearn.to_latex())\n",
    "print(df_tf.to_latex())\n",
    "print(df_torch.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_type(values: List) -> str:\n",
    "    value_types = []\n",
    "\n",
    "    for item in values:\n",
    "        value_types.append(item[-1])\n",
    "\n",
    "    count_data = Counter(value_types)\n",
    "    most_common = count_data.most_common(1)\n",
    "    counter = 0\n",
    "    for value in count_data:\n",
    "        if count_data[value] == most_common[0][1]:\n",
    "            counter +=1\n",
    "\n",
    "    if counter > 1:\n",
    "        return \"Multiple Types\"\n",
    "    else:\n",
    "        return count_data.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &            Type &  Count &  portion \\\\\n",
      "\\midrule\n",
      "0 &        Variable &    157 &  37.381\\% \\\\\n",
      "4 &            Call &     86 &  20.476\\% \\\\\n",
      "1 &         Numeric &     62 &  14.762\\% \\\\\n",
      "3 &  Multiple Types &     39 &   9.286\\% \\\\\n",
      "2 &       Operation &     35 &   8.333\\% \\\\\n",
      "5 &         Unknown &     29 &   6.905\\% \\\\\n",
      "6 &        Sequence &     10 &   2.381\\% \\\\\n",
      "7 &            Text &      2 &   0.476\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &            Type &  Count &  portion \\\\\n",
      "\\midrule\n",
      "0 &         Numeric &     43 &  35.537\\% \\\\\n",
      "2 &        Variable &     26 &  21.488\\% \\\\\n",
      "3 &  Multiple Types &     26 &  21.488\\% \\\\\n",
      "1 &            Call &     13 &  10.744\\% \\\\\n",
      "4 &         Unknown &     10 &   8.264\\% \\\\\n",
      "5 &       Operation &      2 &   1.653\\% \\\\\n",
      "6 &        Sequence &      1 &   0.826\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llrl}\n",
      "\\toprule\n",
      "{} &            Type &  Count &  portion \\\\\n",
      "\\midrule\n",
      "2 &        Variable &    542 &  42.812\\% \\\\\n",
      "3 &         Numeric &    246 &  19.431\\% \\\\\n",
      "4 &            Call &    156 &  12.322\\% \\\\\n",
      "5 &       Operation &    131 &  10.348\\% \\\\\n",
      "0 &  Multiple Types &    127 &  10.032\\% \\\\\n",
      "1 &         Unknown &     51 &   4.028\\% \\\\\n",
      "6 &        Sequence &     13 &   1.027\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict \n",
    "\n",
    "def get_types_of_variables_ml_methods(library_name: str, library_dir: str ,project_dir: str):\n",
    "    variable_types = []\n",
    "\n",
    "    with open(library_dir, \"r\", encoding=\"utf-8\") as library_file:\n",
    "        library_data = json.load(library_file)\n",
    "        class_names = [x[\"name\"] for x in library_data]\n",
    "\n",
    "    for project in glob.glob(project_dir):\n",
    "        with open(project, \"r\", encoding=\"utf-8\") as project_file:\n",
    "            project_data = json.load(project_file)\n",
    "\n",
    "            for file in project_data.keys():\n",
    "                file_data = project_data[file]\n",
    "                for library in file_data.keys():\n",
    "                    if library == library_name:\n",
    "                        module_data = file_data[library]\n",
    "                        for key, data in module_data.items():\n",
    "                            if key[0].isupper():\n",
    "                                class_name_parts = key.split(\"_\")\n",
    "                                if len(class_name_parts) > 2:\n",
    "                                    class_name = \"_\".join(class_name_parts[:-1])\n",
    "                                else:\n",
    "                                    class_name = class_name_parts[0]\n",
    "\n",
    "                                if class_name not in class_names:\n",
    "                                    continue    \n",
    "                                \n",
    "                                for param, param_data in data.items():\n",
    "                                    if param in (\"variable\", \"params\"):\n",
    "                                        continue\n",
    "                                    \n",
    "                                    value_type = param_data[\"type\"]\n",
    "                                    if value_type == \"variable\":\n",
    "                                        if param_data[\"possible_values\"]:\n",
    "                                            most_common_type = get_most_common_type(param_data[\"possible_values\"])\n",
    "                                            variable_types.append(assign_category(most_common_type))\n",
    "                                        else:\n",
    "                                            variable_types.append(\"Unknown\")\n",
    "\n",
    "\n",
    "    type_data = Counter(variable_types)\n",
    "    type_data_portion = OrderedDict([(i, str(round(count / sum(type_data.values()) * 100.0, 3)) + '%') for i, count in type_data.most_common()])\n",
    "    portion = [y for _, y in type_data_portion.items()]\n",
    "    df = pd.DataFrame.from_dict(type_data, orient=\"index\").reset_index()\n",
    "    df = df.rename(columns={'index':'Type', 0:'Count'})\n",
    "    df = df.sort_values(by=['Count'], ascending=False)\n",
    "    df[\"portion\"] = portion\n",
    "\n",
    "    return df\n",
    "\n",
    "df_sklearn_variables = get_types_of_variables_ml_methods(\"sklearn\", \"../data/library_data/sklearn_estimators.json\", \"../data/statistics/*\")\n",
    "df_tf_variables = get_types_of_variables_ml_methods(\"tensorflow\", \"../data/library_data/tensorflow_optimizer.json\", \"../data/statistics/*\")\n",
    "df_torch_variables = get_types_of_variables_ml_methods(\"torch\", \"../data/library_data/torch_optimizer.json\", \"../data/statistics/*\")\n",
    "\n",
    "print(df_sklearn_variables.to_latex())\n",
    "print(df_tf_variables.to_latex())\n",
    "print(df_torch_variables.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
