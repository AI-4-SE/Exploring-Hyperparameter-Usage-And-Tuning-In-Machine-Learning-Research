{
    "Benchmark_Perceptual_Offline/Conv_decoder_model/conv_decoder.py": {
        "torch": {
            "Sequential_13": {
                "variable": {
                    "value": "self.ff_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(4, 512)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_21": {
                "variable": {
                    "value": "self.conv_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.ConvTranspose2d(16, 64, 4, stride=2, padding=1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_44": {
                "f": {
                    "value": "os.path.join('Trained_Model', 'trained_decoder_net')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_14": {
                "in_features": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_15": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_16": {
                "in_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "7 * 10 * 16",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ReLU_17": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ConvTranspose2d_22": {
                "in_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_23": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_24": {
                "in_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_25": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ConvTranspose2d_26": {
                "in_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_27": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_28": {
                "in_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_29": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_30": {
                "p": {
                    "value": "0.15",
                    "type": "float",
                    "possible_values": []
                }
            },
            "ConvTranspose2d_31": {
                "in_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sigmoid_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "Benchmark_Perceptual_Offline/int_traj_recorder.py": {
        "torch": {}
    },
    "Benchmark_Perceptual_Offline/pixelAI.py": {
        "torch": {
            "device_24": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "zeros_120": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_128": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_available_24": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_100": {
                "f": {
                    "value": "os.path.join(self.model_path, 'trained_model')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "Benchmark_Perceptual_Offline/run_benchmark.py": {
        "torch": {}
    },
    "nao_simulation/catkin_ws/src/my_executables/scripts/Conv_decoder_model/conv_decoder.py": {
        "torch": {
            "Sequential_13": {
                "variable": {
                    "value": "self.ff_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(4, 512)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Sequential_21": {
                "variable": {
                    "value": "self.conv_layers",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.ConvTranspose2d(16, 64, 4, stride=2, padding=1)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_44": {
                "f": {
                    "value": "os.path.join('Trained_Model', 'trained_decoder_net')",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "Linear_14": {
                "in_features": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_15": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Linear_16": {
                "in_features": {
                    "value": "512",
                    "type": "int",
                    "possible_values": []
                },
                "out_features": {
                    "value": "7 * 10 * 16",
                    "type": "BinOp",
                    "possible_values": []
                }
            },
            "ReLU_17": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ConvTranspose2d_22": {
                "in_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_23": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_24": {
                "in_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_25": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "ConvTranspose2d_26": {
                "in_channels": {
                    "value": "64",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_27": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Conv2d_28": {
                "in_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "3",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "ReLU_29": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "Dropout_30": {
                "p": {
                    "value": "0.15",
                    "type": "float",
                    "possible_values": []
                }
            },
            "ConvTranspose2d_31": {
                "in_channels": {
                    "value": "16",
                    "type": "int",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "4",
                    "type": "int",
                    "possible_values": []
                },
                "stride": {
                    "value": "2",
                    "type": "int",
                    "possible_values": []
                },
                "padding": {
                    "value": "1",
                    "type": "int",
                    "possible_values": []
                }
            },
            "Sigmoid_32": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            }
        }
    },
    "nao_simulation/catkin_ws/src/my_executables/scripts/Conv_decoder_model/eval_net.py": {
        "torch": {
            "MSELoss_28": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "no_grad_22": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "is_available_50": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_54": {
                "f": {
                    "value": "conv_decoder_sim/trained_model",
                    "type": "str",
                    "possible_values": []
                }
            },
            "from_numpy_23": {
                "ndarray": {
                    "value": "np.float32(input_data)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_24": {
                "ndarray": {
                    "value": "np.float32(target_data)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "nao_simulation/catkin_ws/src/my_executables/scripts/Conv_decoder_model/train_net.py": {
        "torch": {
            "Adam_46": {
                "variable": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "net.parameters()",
                    "type": "Call",
                    "possible_values": []
                },
                "lr": {
                    "value": "0.0001",
                    "type": "float",
                    "possible_values": []
                }
            },
            "StepLR_47": {
                "variable": {
                    "value": "scheduler",
                    "type": "variable",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "type": "variable",
                    "possible_values": [
                        [
                            "optim.Adam(net.parameters(), lr=0.0001)",
                            "Call"
                        ]
                    ]
                },
                "step_size": {
                    "value": "5000",
                    "type": "int",
                    "possible_values": []
                },
                "gamma": {
                    "value": "0.95",
                    "type": "float",
                    "possible_values": []
                }
            },
            "MSELoss_48": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_108": {
                "obj": {
                    "value": "net.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "Checkpoint/net_end_of_training",
                    "type": "str",
                    "possible_values": []
                }
            },
            "load_131": {
                "variable": {
                    "value": "checkpoint",
                    "type": "variable",
                    "possible_values": []
                },
                "f": {
                    "value": "Checkpoint/checkpoint_state",
                    "type": "str",
                    "possible_values": []
                }
            },
            "is_available_37": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "MSELoss_99": {
                "variable": {
                    "value": "criterion",
                    "type": "variable",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_127": {
                "obj": {
                    "value": "net.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "Checkpoint/net_end_of_training_cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "save_136": {
                "obj": {
                    "value": "net.state_dict()",
                    "type": "Call",
                    "possible_values": []
                },
                "f": {
                    "value": "Checkpoint/checkpoint_cpu",
                    "type": "str",
                    "possible_values": []
                }
            },
            "from_numpy_58": {
                "variable": {
                    "value": "tensor_x",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.float32(x[i * batch_size:(i + 1) * batch_size])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_59": {
                "variable": {
                    "value": "tensor_y",
                    "type": "variable",
                    "possible_values": []
                },
                "ndarray": {
                    "value": "np.float32(y[i * batch_size:(i + 1) * batch_size])",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "no_grad_93": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "save_85": {
                "obj": {
                    "value": "state",
                    "type": "variable",
                    "possible_values": [
                        [
                            "{'net': net.state_dict(), 'test_error': test_loss, 'epoch': epoch}",
                            "Dict"
                        ]
                    ]
                },
                "f": {
                    "value": "Checkpoint/checkpoint_state",
                    "type": "str",
                    "possible_values": []
                }
            },
            "from_numpy_94": {
                "ndarray": {
                    "value": "np.float32(data.X_test)",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "from_numpy_95": {
                "ndarray": {
                    "value": "np.float32(data.Y_test)",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "nao_simulation/catkin_ws/src/my_executables/scripts/central_benchmark_monolithic.py": {
        "torch": {
            "zeros_375": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_387": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_400": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "load_242": {
                "f": {
                    "value": "os.path.join(self.model_path, 'trained_model')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "nao_simulation/catkin_ws/src/my_executables/scripts/pixelAI.py": {
        "torch": {
            "device_24": {
                "variable": {
                    "value": "device",
                    "type": "variable",
                    "possible_values": []
                },
                "type": {
                    "value": "cuda:0 if torch.cuda.is_available() else cpu",
                    "type": "IfExp",
                    "possible_values": []
                }
            },
            "zeros_120": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "zeros_128": {
                "variable": {
                    "value": "input.grad",
                    "type": "Attribute",
                    "possible_values": []
                },
                "*size": {
                    "value": "input.size()",
                    "type": "Call",
                    "possible_values": []
                }
            },
            "is_available_24": {
                "params": {
                    "value": "default",
                    "type": null,
                    "possible_values": []
                }
            },
            "load_100": {
                "f": {
                    "value": "os.path.join(self.model_path, 'trained_model')",
                    "type": "Call",
                    "possible_values": []
                }
            }
        }
    },
    "nao_simulation/catkin_ws/src/my_executables/scripts/pixelAI_old.py": {
        "torch": {}
    }
}