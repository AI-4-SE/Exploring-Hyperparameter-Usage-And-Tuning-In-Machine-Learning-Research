{
    "main.py": {
        "sklearn": {
            "accuracy_score_144": {
                "y_true": {
                    "value": "self.gold_labels",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "self.pred_labels",
                    "possible_values": []
                }
            },
            "f1_score_145": {
                "y_true": {
                    "value": "self.gold_labels",
                    "possible_values": []
                },
                "y_pred": {
                    "value": "self.pred_labels",
                    "possible_values": []
                },
                "average": {
                    "value": "macro",
                    "possible_values": []
                }
            }
        },
        "torch": {
            "SummaryWriter_53": {
                "variable": {
                    "value": "writer",
                    "possible_values": []
                },
                "log_dir": {
                    "value": "os.path.join(args['output_path'], 'runs')",
                    "possible_values": []
                }
            },
            "manual_seed_48": {
                "seed": {
                    "value": "args['seed']",
                    "possible_values": []
                }
            },
            "tensor_76": {
                "variable": {
                    "value": "label",
                    "possible_values": []
                },
                "data": {
                    "value": "[np.array(label[i]) / np.sum(label[i]) for i in range(len(label))]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "randperm_103": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "n": {
                    "value": "size",
                    "possible_values": [
                        [
                            "len(self.data)",
                            "Call"
                        ]
                    ]
                }
            },
            "argmax_133": {
                "variable": {
                    "value": "gold_labels",
                    "possible_values": []
                },
                "input": {
                    "value": "gold",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "argmax_135": {
                "variable": {
                    "value": "pred_labels",
                    "possible_values": []
                },
                "input": {
                    "value": "pred",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_187": {
                "variable": {
                    "value": "self.mlp",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(self.max_length * config['embedding_size'], u)",
                    "possible_values": []
                }
            },
            "stack_209": {
                "variable": {
                    "value": "data",
                    "possible_values": []
                },
                "tensors": {
                    "value": "embedding",
                    "possible_values": []
                }
            },
            "softmax_211": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "input": {
                    "value": "output",
                    "possible_values": [
                        [
                            "self.mlp(data.view(data.size(0), -1))",
                            "Call"
                        ],
                        [
                            "self.mlp(out_1.view(out_1.size(0), -1))",
                            "Call"
                        ],
                        [
                            "self.mlp(M.view(M.size(0), -1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_225": {
                "variable": {
                    "value": "self.cnn_1",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Conv1d(config['embedding_size'], opt['conv_1']['size'], opt['conv_1']['kernel_size'], padding=opt['conv_1']['kernel_size'] // 2)",
                    "possible_values": []
                }
            },
            "Sequential_243": {
                "variable": {
                    "value": "self.mlp",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(opt['conv_1']['size'] * opt['max_length'] // 2, mlp_u)",
                    "possible_values": []
                }
            },
            "stack_265": {
                "variable": {
                    "value": "data",
                    "possible_values": []
                },
                "tensors": {
                    "value": "embedding",
                    "possible_values": []
                }
            },
            "transpose_265": {
                "variable": {
                    "value": "data",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                },
                "dim0": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "softmax_270": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "input": {
                    "value": "output",
                    "possible_values": [
                        [
                            "self.mlp(data.view(data.size(0), -1))",
                            "Call"
                        ],
                        [
                            "self.mlp(out_1.view(out_1.size(0), -1))",
                            "Call"
                        ],
                        [
                            "self.mlp(M.view(M.size(0), -1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Sequential_305": {
                "variable": {
                    "value": "self.mlp",
                    "possible_values": []
                },
                "*args": {
                    "value": "nn.Linear(r * u, mlp_u)",
                    "possible_values": []
                }
            },
            "Parameter_311": {
                "variable": {
                    "value": "self.Ws1",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn(da, u)",
                    "possible_values": []
                }
            },
            "Parameter_312": {
                "variable": {
                    "value": "self.Ws2",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.randn(r, da)",
                    "possible_values": []
                }
            },
            "pad_sequence_330": {
                "variable": {
                    "value": "padded",
                    "possible_values": []
                },
                "sequences": {
                    "value": "embedding",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "softmax_332": {
                "variable": {
                    "value": "A",
                    "possible_values": []
                },
                "input": {
                    "value": "torch.matmul(self.Ws2, torch.tanh(torch.matmul(self.Ws1, H.transpose(1, 2))))",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "matmul_333": {
                "variable": {
                    "value": "M",
                    "possible_values": []
                },
                "input": {
                    "value": "A",
                    "possible_values": [
                        [
                            "F.softmax(torch.matmul(self.Ws2, torch.tanh(torch.matmul(self.Ws1, H.transpose(1, 2)))), dim=2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "H",
                    "possible_values": [
                        [
                            "self.rnn(padded)[0]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "softmax_335": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "input": {
                    "value": "output",
                    "possible_values": [
                        [
                            "self.mlp(data.view(data.size(0), -1))",
                            "Call"
                        ],
                        [
                            "self.mlp(out_1.view(out_1.size(0), -1))",
                            "Call"
                        ],
                        [
                            "self.mlp(M.view(M.size(0), -1))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "eye_338": {
                "variable": {
                    "value": "I",
                    "possible_values": []
                },
                "n": {
                    "value": "A.size(1)",
                    "possible_values": []
                }
            },
            "Adagrad_379": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "args['lr']",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                },
                "lr_decay": {
                    "value": "args['lr_decay']",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "args['weight_decay']",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                }
            },
            "is_available_38": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "tensor_83": {
                "variable": {
                    "value": "b",
                    "possible_values": []
                },
                "data": {
                    "value": "t",
                    "possible_values": [
                        [
                            "text",
                            "Name"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_84": {
                "variable": {
                    "value": "zero",
                    "possible_values": []
                },
                "*size": {
                    "value": "max_length",
                    "possible_values": []
                },
                "out": {
                    "value": "b.size(1)",
                    "possible_values": []
                }
            },
            "arange_105": {
                "variable": {
                    "value": "ids",
                    "possible_values": []
                },
                "start": {
                    "value": "size",
                    "possible_values": [
                        [
                            "len(self.data)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_109": {
                "variable": {
                    "value": "label",
                    "possible_values": []
                },
                "input": {
                    "value": "self.data.label",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "batch_idx",
                    "possible_values": [
                        [
                            "ids[self.batch_size * i:self.batch_size * (i + 1)]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "L1Loss_195": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "L1Loss_251": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "LSTM_295": {
                "variable": {
                    "value": "self.rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "d",
                    "possible_values": [
                        [
                            "config['embedding_size']",
                            "Subscript"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "u",
                    "possible_values": [
                        [
                            "opt['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['rnn_hidden_size']",
                            "Subscript"
                        ],
                        [
                            "u * 2",
                            "BinOp"
                        ]
                    ]
                },
                "num_layers": {
                    "value": "num_layers",
                    "possible_values": [
                        [
                            "opt['num_layers']",
                            "Subscript"
                        ]
                    ]
                },
                "bidirectional": {
                    "value": "bidirectional",
                    "possible_values": [
                        [
                            "opt['bidirectional']",
                            "Subscript"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "L1Loss_316": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "SGD_382": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "model.parameters()",
                    "possible_values": []
                },
                "lr": {
                    "value": "args['lr']",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                },
                "momentum": {
                    "value": "args['momentum']",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                },
                "weight_decay": {
                    "value": "args['weight_decay']",
                    "possible_values": [
                        [
                            "parser.parse_args()",
                            "Call"
                        ],
                        [
                            "json.load(f)",
                            "Call"
                        ]
                    ]
                }
            },
            "tensor_79": {
                "data": {
                    "value": "t",
                    "possible_values": [
                        [
                            "text",
                            "Name"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "Linear_188": {
                "in_features": {
                    "value": "self.max_length * config['embedding_size']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "u",
                    "possible_values": [
                        [
                            "opt['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['rnn_hidden_size']",
                            "Subscript"
                        ],
                        [
                            "u * 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "ReLU_189": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_190": {
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "opt['dropout']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "Linear_191": {
                "in_features": {
                    "value": "u",
                    "possible_values": [
                        [
                            "opt['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['rnn_hidden_size']",
                            "Subscript"
                        ],
                        [
                            "u * 2",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "config['num_labels']",
                    "possible_values": []
                }
            },
            "MSELoss_197": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Conv1d_226": {
                "in_channels": {
                    "value": "config['embedding_size']",
                    "possible_values": []
                },
                "out_channels": {
                    "value": "opt['conv_1']['size']",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "opt['conv_1']['kernel_size']",
                    "possible_values": []
                },
                "padding": {
                    "value": "opt['conv_1']['kernel_size'] // 2",
                    "possible_values": []
                }
            },
            "ReLU_229": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_230": {
                "p": {
                    "value": "opt['conv_1']['dropout']",
                    "possible_values": []
                }
            },
            "MaxPool1d_231": {
                "kernel_size": {
                    "value": "opt['max_pool_1']['kernel_size']",
                    "possible_values": []
                },
                "stride": {
                    "value": "opt['max_pool_1']['stride']",
                    "possible_values": []
                }
            },
            "Linear_244": {
                "in_features": {
                    "value": "opt['conv_1']['size'] * opt['max_length'] // 2",
                    "possible_values": []
                },
                "out_features": {
                    "value": "mlp_u",
                    "possible_values": [
                        [
                            "opt['fc']['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['mlp_hidden_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "ReLU_245": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_246": {
                "p": {
                    "value": "opt['fc']['dropout']",
                    "possible_values": []
                }
            },
            "Linear_247": {
                "in_features": {
                    "value": "mlp_u",
                    "possible_values": [
                        [
                            "opt['fc']['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['mlp_hidden_size']",
                            "Subscript"
                        ]
                    ]
                },
                "out_features": {
                    "value": "config['num_labels']",
                    "possible_values": []
                }
            },
            "MSELoss_253": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "GRU_298": {
                "variable": {
                    "value": "self.rnn",
                    "possible_values": []
                },
                "input_size": {
                    "value": "d",
                    "possible_values": [
                        [
                            "config['embedding_size']",
                            "Subscript"
                        ]
                    ]
                },
                "hidden_size": {
                    "value": "u",
                    "possible_values": [
                        [
                            "opt['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['rnn_hidden_size']",
                            "Subscript"
                        ],
                        [
                            "u * 2",
                            "BinOp"
                        ]
                    ]
                },
                "num_layers": {
                    "value": "num_layers",
                    "possible_values": [
                        [
                            "opt['num_layers']",
                            "Subscript"
                        ]
                    ]
                },
                "bidirectional": {
                    "value": "bidirectional",
                    "possible_values": [
                        [
                            "opt['bidirectional']",
                            "Subscript"
                        ]
                    ]
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Linear_306": {
                "in_features": {
                    "value": "r * u",
                    "possible_values": []
                },
                "out_features": {
                    "value": "mlp_u",
                    "possible_values": [
                        [
                            "opt['fc']['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['mlp_hidden_size']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "ReLU_307": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "Dropout_308": {
                "p": {
                    "value": "opt['dropout']",
                    "possible_values": []
                }
            },
            "Linear_309": {
                "in_features": {
                    "value": "mlp_u",
                    "possible_values": [
                        [
                            "opt['fc']['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['mlp_hidden_size']",
                            "Subscript"
                        ]
                    ]
                },
                "out_features": {
                    "value": "config['num_labels']",
                    "possible_values": []
                }
            },
            "randn_311": {
                "*size": {
                    "value": "da",
                    "possible_values": [
                        [
                            "opt['param_da']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "u",
                    "possible_values": [
                        [
                            "opt['hidden_size']",
                            "Subscript"
                        ],
                        [
                            "opt['rnn_hidden_size']",
                            "Subscript"
                        ],
                        [
                            "u * 2",
                            "BinOp"
                        ]
                    ]
                }
            },
            "randn_312": {
                "*size": {
                    "value": "r",
                    "possible_values": [
                        [
                            "opt['param_r']",
                            "Subscript"
                        ]
                    ]
                },
                "out": {
                    "value": "da",
                    "possible_values": [
                        [
                            "opt['param_da']",
                            "Subscript"
                        ]
                    ]
                }
            },
            "MSELoss_318": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "matmul_332": {
                "input": {
                    "value": "self.Ws1",
                    "possible_values": []
                },
                "other": {
                    "value": "H.transpose(1, 2)",
                    "possible_values": []
                }
            },
            "matmul_341": {
                "input": {
                    "value": "A",
                    "possible_values": [
                        [
                            "F.softmax(torch.matmul(self.Ws2, torch.tanh(torch.matmul(self.Ws1, H.transpose(1, 2)))), dim=2)",
                            "Call"
                        ]
                    ]
                },
                "other": {
                    "value": "A.transpose(1, 2)",
                    "possible_values": []
                }
            },
            "no_grad_438": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_199": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "argmax_215": {
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "torch.argmax(gold, dim=1).cpu().numpy()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_255": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "argmax_274": {
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "torch.argmax(gold, dim=1).cpu().numpy()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_320": {
                "variable": {
                    "value": "self.loss",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "tanh_332": {
                "input": {
                    "value": "torch.matmul(self.Ws1, H.transpose(1, 2))",
                    "possible_values": []
                }
            },
            "argmax_345": {
                "input": {
                    "value": "gold_labels",
                    "possible_values": [
                        [
                            "torch.argmax(gold, dim=1).cpu().numpy()",
                            "Call"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "no_grad_414": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/__main__.py": {
        "torch": {
            "set_device_161": {
                "device": {
                    "value": "args.gpu",
                    "possible_values": []
                }
            },
            "is_available_162": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/biLM.py": {
        "torch": {
            "dropout_245": {
                "variable": {
                    "value": "token_embedding",
                    "possible_values": []
                },
                "input": {
                    "value": "token_embedding",
                    "possible_values": [
                        [
                            "self.token_embedder(word_inp, chars_inp, (mask_package[0].size(0), mask_package[0].size(1)))",
                            "Call"
                        ],
                        [
                            "F.dropout(token_embedding, self.config['dropout'], self.training)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.config['dropout']",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "dropout_258": {
                "variable": {
                    "value": "encoder_output",
                    "possible_values": []
                },
                "input": {
                    "value": "encoder_output",
                    "possible_values": [
                        [
                            "self.encoder(token_embedding, mask)",
                            "Call"
                        ],
                        [
                            "encoder_output[1]",
                            "Subscript"
                        ],
                        [
                            "F.dropout(encoder_output, self.config['dropout'], self.training)",
                            "Call"
                        ],
                        [
                            "self.encoder(token_embedding)",
                            "Call"
                        ]
                    ]
                },
                "p": {
                    "value": "self.config['dropout']",
                    "possible_values": []
                },
                "training": {
                    "value": "self.training",
                    "possible_values": []
                }
            },
            "manual_seed_454": {
                "seed": {
                    "value": "opt.seed",
                    "possible_values": []
                }
            },
            "Adam_582": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "filter(need_grad, model.parameters())",
                    "possible_values": []
                },
                "lr": {
                    "value": "opt.lr",
                    "possible_values": []
                }
            },
            "save_277": {
                "obj": {
                    "value": "self.token_embedder.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(path, 'token_embedder.pkl')",
                    "possible_values": []
                }
            },
            "save_278": {
                "obj": {
                    "value": "self.encoder.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(path, 'encoder.pkl')",
                    "possible_values": []
                }
            },
            "set_device_457": {
                "device": {
                    "value": "opt.gpu",
                    "possible_values": []
                }
            },
            "is_available_461": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "SGD_584": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "filter(need_grad, model.parameters())",
                    "possible_values": []
                },
                "lr": {
                    "value": "opt.lr",
                    "possible_values": []
                }
            },
            "set_device_634": {
                "device": {
                    "value": "args.gpu",
                    "possible_values": []
                }
            },
            "is_available_635": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "save_280": {
                "obj": {
                    "value": "self.classify_layer.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "os.path.join(path, 'classifier.pkl')",
                    "possible_values": []
                }
            },
            "load_283": {
                "f": {
                    "value": "os.path.join(path, 'token_embedder.pkl')",
                    "possible_values": []
                }
            },
            "load_284": {
                "f": {
                    "value": "os.path.join(path, 'encoder.pkl')",
                    "possible_values": []
                }
            },
            "load_285": {
                "f": {
                    "value": "os.path.join(path, 'classifier.pkl')",
                    "possible_values": []
                }
            },
            "manual_seed_459": {
                "seed": {
                    "value": "opt.seed",
                    "possible_values": []
                }
            },
            "Adagrad_586": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "filter(need_grad, model.parameters())",
                    "possible_values": []
                },
                "lr": {
                    "value": "opt.lr",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/elmo.py": {
        "torch": {
            "is_available_112": {
                "variable": {
                    "value": "self.use_cuda",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/frontend.py": {
        "torch": {
            "cat_193": {
                "variable": {
                    "value": "token_embedding",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[token_embedding, token_embedding]",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_195": {
                "variable": {
                    "value": "encoder_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[token_embedding, encoder_output]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "load_205": {
                "f": {
                    "value": "os.path.join(path, 'token_embedder.pkl')",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage",
                    "possible_values": []
                }
            },
            "load_207": {
                "f": {
                    "value": "os.path.join(path, 'encoder.pkl')",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/classify_layer.py": {
        "torch": {
            "Linear_20": {
                "variable": {
                    "value": "self.hidden2tag",
                    "possible_values": []
                },
                "in_features": {
                    "value": "output_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "n_class",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_21": {
                "variable": {
                    "value": "self.criterion",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_50": {
                "variable": {
                    "value": "self.criterion",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Embedding_57": {
                "variable": {
                    "value": "self.column_emb",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_class",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "output_dim",
                    "possible_values": []
                }
            },
            "Embedding_60": {
                "variable": {
                    "value": "self.column_bias",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_class",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Parameter_63": {
                "variable": {
                    "value": "self.oov_column",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(output_dim, 1)",
                    "possible_values": []
                }
            },
            "CrossEntropyLoss_141": {
                "variable": {
                    "value": "self.criterion",
                    "possible_values": []
                },
                "size_average": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Parameter_148": {
                "variable": {
                    "value": "self.M",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(output_dim, corr_dim)",
                    "possible_values": []
                }
            },
            "Embedding_152": {
                "variable": {
                    "value": "self.corr",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "n_class",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "corr_dim",
                    "possible_values": []
                }
            },
            "Parameter_155": {
                "variable": {
                    "value": "self.oov_column",
                    "possible_values": []
                },
                "data": {
                    "value": "torch.Tensor(output_dim, 1)",
                    "possible_values": []
                }
            },
            "cat_211": {
                "variable": {
                    "value": "self.embedding_matrix",
                    "possible_values": []
                },
                "tensors": {
                    "value": "sub_matrices",
                    "possible_values": [
                        [
                            "[self.oov_column]",
                            "List"
                        ],
                        [
                            "[self.oov_column]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/elmo.py": {
        "torch": {
            "pad_packed_sequence_142": {
                "variable": {
                    "value": "(inputs, batch_lengths)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "inputs",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_78": {
                "variable": {
                    "value": "stacked_sequence_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[stacked_sequence_output, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_100": {
                "variable": {
                    "value": "stacked_sequence_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[stacked_sequence_output, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "stack_182": {
                "tensors": {
                    "value": "sequence_outputs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "cat_188": {
                "tensors": {
                    "value": "final_hidden_states",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_189": {
                "tensors": {
                    "value": "final_memory_states",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_175": {
                "tensors": {
                    "value": "[forward_output_sequence, backward_output_sequence]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_86": {
                "tensors": {
                    "value": "[state, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_179": {
                "tensors": {
                    "value": "[forward_state[0], backward_state[0]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_180": {
                "tensors": {
                    "value": "[forward_state[1], backward_state[1]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/embedding_layer.py": {
        "torch": {
            "Embedding_30": {
                "variable": {
                    "value": "self.embedding",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "self.n_V",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "n_d",
                    "possible_values": [
                        [
                            "len(embvecs[0])",
                            "Call"
                        ]
                    ]
                },
                "padding_idx": {
                    "value": "self.padid",
                    "possible_values": []
                }
            },
            "from_numpy_35": {
                "ndarray": {
                    "value": "embvecs",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/encoder_base.py": {
        "torch": {
            "sum_89": {
                "variable": {
                    "value": "num_valid",
                    "possible_values": []
                },
                "input": {
                    "value": "mask[:, 0]",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_96": {
                "variable": {
                    "value": "packed_sequence_input",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_inputs[:num_valid, :, :]",
                    "possible_values": []
                },
                "lengths": {
                    "value": "sorted_sequence_lengths[:num_valid].data.tolist()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_174": {
                "tensors": {
                    "value": "[state, zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/highway.py": {
        "torch": {
            "ModuleList_36": {
                "variable": {
                    "value": "self._layers",
                    "possible_values": []
                },
                "modules": {
                    "value": "[torch.nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]",
                    "possible_values": []
                }
            },
            "sigmoid_57": {
                "variable": {
                    "value": "gate",
                    "possible_values": []
                },
                "input": {
                    "value": "gate",
                    "possible_values": [
                        [
                            "projected_input[:, 1 * self._input_dim:2 * self._input_dim]",
                            "Subscript"
                        ],
                        [
                            "torch.sigmoid(gate)",
                            "Call"
                        ]
                    ]
                }
            },
            "Linear_36": {
                "in_features": {
                    "value": "input_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "input_dim * 2",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/lstm.py": {
        "torch": {
            "LSTM_17": {
                "variable": {
                    "value": "self.encoder",
                    "possible_values": []
                },
                "*args": {
                    "value": "self.config['encoder']['projection_dim']",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "self.config['encoder']['n_layers']",
                    "possible_values": []
                },
                "bidirectional": {
                    "value": "True",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "dropout": {
                    "value": "self.config['dropout']",
                    "possible_values": []
                }
            },
            "Linear_23": {
                "variable": {
                    "value": "self.projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.config['encoder']['dim']",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.config['encoder']['projection_dim']",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_27": {
                "tensors": {
                    "value": "[self.projection(forward), self.projection(backward)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/lstm_cell_with_projection.py": {
        "torch": {
            "Linear_73": {
                "variable": {
                    "value": "self.input_linearity",
                    "possible_values": []
                },
                "in_features": {
                    "value": "input_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "4 * cell_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_74": {
                "variable": {
                    "value": "self.state_linearity",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "4 * cell_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "Linear_77": {
                "variable": {
                    "value": "self.state_projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "cell_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_size",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "sigmoid_183": {
                "variable": {
                    "value": "input_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 0 * self.cell_size:1 * self.cell_size] + projected_state[:, 0 * self.cell_size:1 * self.cell_size]",
                    "possible_values": []
                }
            },
            "sigmoid_185": {
                "variable": {
                    "value": "forget_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 1 * self.cell_size:2 * self.cell_size] + projected_state[:, 1 * self.cell_size:2 * self.cell_size]",
                    "possible_values": []
                }
            },
            "tanh_187": {
                "variable": {
                    "value": "memory_init",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 2 * self.cell_size:3 * self.cell_size] + projected_state[:, 2 * self.cell_size:3 * self.cell_size]",
                    "possible_values": []
                }
            },
            "sigmoid_189": {
                "variable": {
                    "value": "output_gate",
                    "possible_values": []
                },
                "input": {
                    "value": "projected_input[:, 3 * self.cell_size:4 * self.cell_size] + projected_state[:, 3 * self.cell_size:4 * self.cell_size]",
                    "possible_values": []
                }
            },
            "clamp_199": {
                "variable": {
                    "value": "memory",
                    "possible_values": []
                },
                "input": {
                    "value": "memory",
                    "possible_values": [
                        [
                            "input_gate * memory_init + forget_gate * previous_memory",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(memory, -self.memory_cell_clip_value, self.memory_cell_clip_value)",
                            "Call"
                        ]
                    ]
                },
                "min": {
                    "value": "-self.memory_cell_clip_value",
                    "possible_values": []
                },
                "max": {
                    "value": "self.memory_cell_clip_value",
                    "possible_values": []
                }
            },
            "clamp_208": {
                "variable": {
                    "value": "timestep_output",
                    "possible_values": []
                },
                "input": {
                    "value": "timestep_output",
                    "possible_values": [
                        [
                            "self.state_projection(pre_projection_timestep_output)",
                            "Call"
                        ],
                        [
                            "torch.clamp(timestep_output, -self.state_projection_clip_value, self.state_projection_clip_value)",
                            "Call"
                        ],
                        [
                            "timestep_output * dropout_mask[0:current_length_index + 1]",
                            "BinOp"
                        ]
                    ]
                },
                "min": {
                    "value": "-self.state_projection_clip_value",
                    "possible_values": []
                },
                "max": {
                    "value": "self.state_projection_clip_value",
                    "possible_values": []
                }
            },
            "tanh_202": {
                "input": {
                    "value": "memory",
                    "possible_values": [
                        [
                            "input_gate * memory_init + forget_gate * previous_memory",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(memory, -self.memory_cell_clip_value, self.memory_cell_clip_value)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "elmoformanylangs/modules/token_embedder.py": {
        "torch": {
            "Linear_29": {
                "variable": {
                    "value": "self.projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "emb_dim",
                    "possible_values": [
                        [
                            "0",
                            "Constant"
                        ],
                        [
                            "emb_dim + char_emb_layer.n_d * 2",
                            "BinOp"
                        ]
                    ]
                },
                "out_features": {
                    "value": "self.output_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_45": {
                "variable": {
                    "value": "token_embedding",
                    "possible_values": []
                },
                "tensors": {
                    "value": "embs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "Linear_87": {
                "variable": {
                    "value": "self.projection",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.emb_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.output_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "cat_124": {
                "variable": {
                    "value": "token_embedding",
                    "possible_values": []
                },
                "tensors": {
                    "value": "embs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "LSTM_26": {
                "variable": {
                    "value": "self.char_lstm",
                    "possible_values": []
                },
                "*args": {
                    "value": "char_emb_layer.n_d",
                    "possible_values": []
                },
                "num_layers": {
                    "value": "1",
                    "possible_values": []
                },
                "bidirectional": {
                    "value": "True",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                },
                "dropout": {
                    "value": "config['dropout']",
                    "possible_values": []
                }
            },
            "ModuleList_79": {
                "variable": {
                    "value": "self.convolutions",
                    "possible_values": []
                },
                "modules": {
                    "value": "self.convolutions",
                    "possible_values": []
                }
            },
            "transpose_102": {
                "variable": {
                    "value": "character_embedding",
                    "possible_values": []
                },
                "input": {
                    "value": "character_embedding",
                    "possible_values": [
                        [
                            "self.char_emb_layer(Variable(chars_inp).cuda() if self.use_cuda else Variable(chars_inp))",
                            "Call"
                        ],
                        [
                            "torch.transpose(character_embedding, 1, 2)",
                            "Call"
                        ]
                    ]
                },
                "dim0": {
                    "value": "1",
                    "possible_values": []
                },
                "dim1": {
                    "value": "2",
                    "possible_values": []
                }
            },
            "cat_119": {
                "variable": {
                    "value": "char_emb",
                    "possible_values": []
                },
                "tensors": {
                    "value": "convs",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "Conv1d_71": {
                "variable": {
                    "value": "conv",
                    "possible_values": []
                },
                "in_channels": {
                    "value": "char_embed_dim",
                    "possible_values": [
                        [
                            "cnn_config['char_dim']",
                            "Subscript"
                        ]
                    ]
                },
                "out_channels": {
                    "value": "num",
                    "possible_values": []
                },
                "kernel_size": {
                    "value": "width",
                    "possible_values": []
                },
                "bias": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "max_116": {
                "variable": {
                    "value": "(convolved, _)",
                    "possible_values": []
                },
                "input": {
                    "value": "convolved",
                    "possible_values": [
                        [
                            "self.convolutions[i](character_embedding)",
                            "Call"
                        ],
                        [
                            "activation(convolved)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "elmoformanylangs/modules/util.py": {
        "torch": {
            "cat_100": {
                "variable": {
                    "value": "final_encoder_output",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[final_forward_output, final_backward_output]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "arange_63": {
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "len(sequence_lengths)",
                    "possible_values": []
                }
            },
            "rand_122": {
                "*size": {
                    "value": "tensor_for_masking.size()",
                    "possible_values": []
                }
            }
        }
    }
}