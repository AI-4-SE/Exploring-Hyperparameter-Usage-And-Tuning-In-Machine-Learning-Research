{
    "models/_utils.py": {
        "torch": {
            "cat_118": {
                "variable": {
                    "value": "targets",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(targets_dx, targets_dy, targets_dw, targets_dh)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_139": {
                "variable": {
                    "value": "reference_boxes",
                    "possible_values": []
                },
                "tensors": {
                    "value": "reference_boxes",
                    "possible_values": [
                        [
                            "torch.cat(reference_boxes, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_140": {
                "variable": {
                    "value": "proposals",
                    "possible_values": []
                },
                "tensors": {
                    "value": "proposals",
                    "possible_values": [
                        [
                            "torch.cat(proposals, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "as_tensor_155": {
                "variable": {
                    "value": "weights",
                    "possible_values": []
                },
                "data": {
                    "value": "self.weights",
                    "possible_values": []
                },
                "dtype": {
                    "value": "dtype",
                    "possible_values": [
                        [
                            "reference_boxes.dtype",
                            "Attribute"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "reference_boxes.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "cat_166": {
                "variable": {
                    "value": "concat_boxes",
                    "possible_values": []
                },
                "tensors": {
                    "value": "boxes",
                    "possible_values": [
                        [
                            "boxes.to(rel_codes.dtype)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "clamp_196": {
                "variable": {
                    "value": "dw",
                    "possible_values": []
                },
                "input": {
                    "value": "dw",
                    "possible_values": [
                        [
                            "rel_codes[:, 2::4] / ww",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(dw, max=self.bbox_xform_clip)",
                            "Call"
                        ]
                    ]
                },
                "max": {
                    "value": "self.bbox_xform_clip",
                    "possible_values": []
                }
            },
            "clamp_197": {
                "variable": {
                    "value": "dh",
                    "possible_values": []
                },
                "input": {
                    "value": "dh",
                    "possible_values": [
                        [
                            "rel_codes[:, 3::4] / wh",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(dh, max=self.bbox_xform_clip)",
                            "Call"
                        ]
                    ]
                },
                "max": {
                    "value": "self.bbox_xform_clip",
                    "possible_values": []
                }
            },
            "zeros_like_204": {
                "variable": {
                    "value": "pred_boxes",
                    "possible_values": []
                },
                "input": {
                    "value": "rel_codes",
                    "possible_values": [
                        [
                            "torch.cat(rel_codes, dim=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "nonzero_306": {
                "variable": {
                    "value": "gt_pred_pairs_of_highest_quality",
                    "possible_values": []
                },
                "input": {
                    "value": "match_quality_matrix == highest_quality_foreach_gt[:, None]",
                    "possible_values": []
                }
            },
            "nonzero_41": {
                "variable": {
                    "value": "positive",
                    "possible_values": []
                },
                "input": {
                    "value": "matched_idxs_per_image >= 1",
                    "possible_values": []
                }
            },
            "squeeze_41": {
                "variable": {
                    "value": "positive",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "nonzero_42": {
                "variable": {
                    "value": "negative",
                    "possible_values": []
                },
                "input": {
                    "value": "matched_idxs_per_image == 0",
                    "possible_values": []
                }
            },
            "squeeze_42": {
                "variable": {
                    "value": "negative",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_59": {
                "variable": {
                    "value": "pos_idx_per_image_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "matched_idxs_per_image",
                    "possible_values": [
                        [
                            "matched_idxs",
                            "Name"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                }
            },
            "zeros_like_62": {
                "variable": {
                    "value": "neg_idx_per_image_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "matched_idxs_per_image",
                    "possible_values": [
                        [
                            "matched_idxs",
                            "Name"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                }
            },
            "log_115": {
                "input": {
                    "value": "gt_widths / ex_widths",
                    "possible_values": []
                }
            },
            "log_116": {
                "input": {
                    "value": "gt_heights / ex_heights",
                    "possible_values": []
                }
            },
            "cat_163": {
                "variable": {
                    "value": "rel_codes",
                    "possible_values": []
                },
                "tensors": {
                    "value": "rel_codes",
                    "possible_values": [
                        [
                            "torch.cat(rel_codes, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "exp_201": {
                "input": {
                    "value": "dw",
                    "possible_values": [
                        [
                            "rel_codes[:, 2::4] / ww",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(dw, max=self.bbox_xform_clip)",
                            "Call"
                        ]
                    ]
                }
            },
            "exp_202": {
                "input": {
                    "value": "dh",
                    "possible_values": [
                        [
                            "rel_codes[:, 3::4] / wh",
                            "BinOp"
                        ],
                        [
                            "torch.clamp(dh, max=self.bbox_xform_clip)",
                            "Call"
                        ]
                    ]
                }
            },
            "randperm_52": {
                "n": {
                    "value": "positive.numel()",
                    "possible_values": []
                },
                "device": {
                    "value": "positive.device",
                    "possible_values": []
                }
            },
            "randperm_53": {
                "n": {
                    "value": "negative.numel()",
                    "possible_values": []
                },
                "device": {
                    "value": "negative.device",
                    "possible_values": []
                }
            }
        }
    },
    "models/coco_eval.py": {
        "torch": {
            "stack_161": {
                "tensors": {
                    "value": "(xmin, ymin, xmax - xmin, ymax - ymin)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "models/coco_utils.py": {
        "torch": {
            "Subset_157": {
                "variable": {
                    "value": "dataset",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "possible_values": [
                        [
                            "torch.utils.data.Subset(dataset, ids)",
                            "Call"
                        ],
                        [
                            "{'images': [], 'categories': [], 'annotations': []}",
                            "Dict"
                        ],
                        [
                            "dataset.dataset",
                            "Attribute"
                        ],
                        [
                            "CocoDetection(img_folder, ann_file, transforms=transforms)",
                            "Call"
                        ],
                        [
                            "_coco_remove_images_without_annotations(dataset)",
                            "Call"
                        ],
                        [
                            "CocoDetection(img_folder, ann_file, transforms=transforms)",
                            "Call"
                        ],
                        [
                            "_coco_remove_images_without_annotations(dataset)",
                            "Call"
                        ]
                    ]
                },
                "indices": {
                    "value": "ids",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ]
                    ]
                }
            },
            "stack_50": {
                "variable": {
                    "value": "masks",
                    "possible_values": []
                },
                "tensors": {
                    "value": "masks",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(masks, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.zeros((0, height, width), dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "targets['masks']",
                            "Subscript"
                        ],
                        [
                            "masks.permute(0, 2, 1).contiguous().permute(0, 2, 1)",
                            "Call"
                        ],
                        [
                            "convert_coco_poly_to_mask(segmentations, h, w)",
                            "Call"
                        ],
                        [
                            "masks[keep]",
                            "Subscript"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_52": {
                "variable": {
                    "value": "masks",
                    "possible_values": []
                },
                "*size": {
                    "value": "(0, height, width)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                }
            },
            "tensor_61": {
                "variable": {
                    "value": "image_id",
                    "possible_values": []
                },
                "data": {
                    "value": "[image_id]",
                    "possible_values": []
                }
            },
            "as_tensor_69": {
                "variable": {
                    "value": "boxes",
                    "possible_values": []
                },
                "data": {
                    "value": "boxes",
                    "possible_values": [
                        [
                            "[obj['bbox'] for obj in anno]",
                            "ListComp"
                        ],
                        [
                            "torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)",
                            "Call"
                        ],
                        [
                            "boxes[keep]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "possible_values": []
                }
            },
            "reshape_69": {
                "variable": {
                    "value": "boxes",
                    "possible_values": []
                },
                "input": {
                    "value": "-1",
                    "possible_values": []
                },
                "shape": {
                    "value": "4",
                    "possible_values": []
                }
            },
            "tensor_75": {
                "variable": {
                    "value": "classes",
                    "possible_values": []
                },
                "data": {
                    "value": "classes",
                    "possible_values": [
                        [
                            "[obj['category_id'] for obj in anno]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(classes, dtype=torch.int64)",
                            "Call"
                        ],
                        [
                            "classes[keep]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int64",
                    "possible_values": []
                }
            },
            "tensor_79": {
                "variable": {
                    "value": "states",
                    "possible_values": []
                },
                "data": {
                    "value": "states",
                    "possible_values": [
                        [
                            "[obj['states'] for obj in anno]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(states, dtype=torch.int64)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.int64",
                    "possible_values": []
                }
            },
            "tensor_113": {
                "variable": {
                    "value": "area",
                    "possible_values": []
                },
                "data": {
                    "value": "[obj['area'] for obj in anno]",
                    "possible_values": []
                }
            },
            "tensor_114": {
                "variable": {
                    "value": "iscrowd",
                    "possible_values": []
                },
                "data": {
                    "value": "[obj['iscrowd'] for obj in anno]",
                    "possible_values": []
                }
            },
            "zeros_37": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "(height, width)",
                    "possible_values": []
                }
            },
            "as_tensor_38": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "data": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "torch.zeros((height, width))",
                            "Call"
                        ],
                        [
                            "torch.as_tensor(mask, dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "coco_mask.decode(rles)",
                            "Call"
                        ],
                        [
                            "mask[..., None]",
                            "Subscript"
                        ],
                        [
                            "torch.as_tensor(mask, dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "mask.any(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                }
            },
            "as_tensor_45": {
                "variable": {
                    "value": "mask",
                    "possible_values": []
                },
                "data": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "torch.zeros((height, width))",
                            "Call"
                        ],
                        [
                            "torch.as_tensor(mask, dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "coco_mask.decode(rles)",
                            "Call"
                        ],
                        [
                            "mask[..., None]",
                            "Subscript"
                        ],
                        [
                            "torch.as_tensor(mask, dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "mask.any(dim=2)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                }
            },
            "as_tensor_90": {
                "variable": {
                    "value": "keypoints",
                    "possible_values": []
                },
                "data": {
                    "value": "keypoints",
                    "possible_values": [
                        [
                            "targets['keypoints']",
                            "Subscript"
                        ],
                        [
                            "keypoints.reshape(keypoints.shape[0], -1).tolist()",
                            "Call"
                        ],
                        [
                            "None",
                            "Constant"
                        ],
                        [
                            "[obj['keypoints'] for obj in anno]",
                            "ListComp"
                        ],
                        [
                            "torch.as_tensor(keypoints, dtype=torch.float32)",
                            "Call"
                        ],
                        [
                            "keypoints.view(num_keypoints, -1, 3)",
                            "Call"
                        ],
                        [
                            "keypoints[keep]",
                            "Subscript"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float32",
                    "possible_values": []
                }
            }
        }
    },
    "models/engine.py": {
        "torch": {
            "get_num_threads_71": {
                "variable": {
                    "value": "n_threads",
                    "possible_values": []
                },
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "device_74": {
                "variable": {
                    "value": "cpu_device",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "no_grad_69": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "set_num_threads_73": {
                "int": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "set_num_threads_112": {
                "int": {
                    "value": "n_threads",
                    "possible_values": [
                        [
                            "torch.get_num_threads()",
                            "Call"
                        ]
                    ]
                }
            },
            "synchronize_88": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "models/faster_rcnn.py": {
        "torch": {
            "Linear_264": {
                "variable": {
                    "value": "self.fc6",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_features": {
                    "value": "representation_size",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1024",
                            "Constant"
                        ]
                    ]
                }
            },
            "Linear_265": {
                "variable": {
                    "value": "self.fc7",
                    "possible_values": []
                },
                "in_features": {
                    "value": "representation_size",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1024",
                            "Constant"
                        ]
                    ]
                },
                "out_features": {
                    "value": "representation_size",
                    "possible_values": [
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1024",
                            "Constant"
                        ],
                        [
                            "1024",
                            "Constant"
                        ]
                    ]
                }
            },
            "relu_270": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc6(x)",
                    "possible_values": []
                }
            },
            "relu_271": {
                "variable": {
                    "value": "x",
                    "possible_values": []
                },
                "input": {
                    "value": "self.fc7(x)",
                    "possible_values": []
                }
            },
            "Linear_288": {
                "variable": {
                    "value": "self.cls_score",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "91",
                            "MethodArgument"
                        ],
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_289": {
                "variable": {
                    "value": "self.bbox_pred",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_classes * 4",
                    "possible_values": []
                }
            },
            "Linear_303": {
                "variable": {
                    "value": "self.states_vector",
                    "possible_values": []
                },
                "in_features": {
                    "value": "in_channels",
                    "possible_values": []
                },
                "out_features": {
                    "value": "num_states",
                    "possible_values": [
                        [
                            "6",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "models/generalized_rcnn.py": {
        "torch": {
            "cat_62": {
                "tensors": {
                    "value": "[features, features2]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_64": {
                "tensors": {
                    "value": "[features[0], features2[0]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_65": {
                "tensors": {
                    "value": "[features[1], features2[1]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_66": {
                "tensors": {
                    "value": "[features[2], features2[2]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_67": {
                "tensors": {
                    "value": "[features[3], features2[3]]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_68": {
                "tensors": {
                    "value": "[features['pool'], features2['pool']]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "models/group_by_aspect_ratio.py": {
        "torch": {
            "DataLoader_98": {
                "variable": {
                    "value": "data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "possible_values": []
                },
                "batch_size": {
                    "value": "1",
                    "possible_values": []
                },
                "sampler": {
                    "value": "sampler",
                    "possible_values": [
                        [
                            "SubsetSampler(indices)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "14",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "lambda x: x[0]",
                    "possible_values": []
                }
            }
        }
    },
    "models/mask_rcnn.py": {
        "torch": {
            "load_190": {
                "variable": {
                    "value": "state_dict_backbone",
                    "possible_values": []
                },
                "f": {
                    "value": "main_backbone_pretrained_path",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "load_196": {
                "variable": {
                    "value": "state_dict_backbone2",
                    "possible_values": []
                },
                "f": {
                    "value": "aux_backbone_pretrained_path",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "ReLU_106": {
                "variable": {
                    "value": "d[relu{}.format(layer_idx)]",
                    "possible_values": []
                },
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "ReLU_121": {
                "inplace": {
                    "value": "True",
                    "possible_values": []
                }
            }
        }
    },
    "models/partrcnn_transform.py": {
        "torch": {
            "tensor_18": {
                "variable": {
                    "value": "im_shape",
                    "possible_values": []
                },
                "data": {
                    "value": "image.shape[-2:]",
                    "possible_values": []
                }
            },
            "stack_95": {
                "tensors": {
                    "value": "(xmin, ymin, xmax, ymax)",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "min_19": {
                "input": {
                    "value": "im_shape",
                    "possible_values": [
                        [
                            "torch.tensor(image.shape[-2:])",
                            "Call"
                        ]
                    ]
                }
            },
            "max_20": {
                "input": {
                    "value": "im_shape",
                    "possible_values": [
                        [
                            "torch.tensor(image.shape[-2:])",
                            "Call"
                        ]
                    ]
                }
            },
            "interpolate_29": {
                "input": {
                    "value": "image[None]",
                    "possible_values": []
                },
                "scale_factor": {
                    "value": "scale_factor",
                    "possible_values": [
                        [
                            "size / min_size",
                            "BinOp"
                        ],
                        [
                            "self.max_size / max_size",
                            "BinOp"
                        ]
                    ]
                },
                "mode": {
                    "value": "bilinear",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "False",
                    "possible_values": []
                }
            }
        }
    },
    "models/roi_heads.py": {
        "torch": {
            "cat_29": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(labels)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "[r['labels'] for r in result]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_30": {
                "variable": {
                    "value": "regression_targets",
                    "possible_values": []
                },
                "tensors": {
                    "value": "regression_targets",
                    "possible_values": [
                        [
                            "torch.cat(regression_targets, dim=0)",
                            "Call"
                        ],
                        [
                            "self.box_coder.encode(matched_gt_boxes, proposals)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cross_entropy_33": {
                "variable": {
                    "value": "classification_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "class_logits",
                    "possible_values": []
                },
                "target": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(labels)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "[r['labels'] for r in result]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "nonzero_38": {
                "variable": {
                    "value": "sampled_pos_inds_subset",
                    "possible_values": []
                },
                "input": {
                    "value": "labels > 0",
                    "possible_values": []
                }
            },
            "squeeze_38": {
                "variable": {
                    "value": "sampled_pos_inds_subset",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "smooth_l1_loss_43": {
                "variable": {
                    "value": "box_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "box_regression[sampled_pos_inds_subset, labels_pos]",
                    "possible_values": []
                },
                "target": {
                    "value": "regression_targets[sampled_pos_inds_subset]",
                    "possible_values": []
                },
                "reduction": {
                    "value": "sum",
                    "possible_values": []
                }
            },
            "cat_74": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(labels)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "[r['labels'] for r in result]",
                            "ListComp"
                        ]
                    ]
                }
            },
            "arange_75": {
                "variable": {
                    "value": "index",
                    "possible_values": []
                },
                "start": {
                    "value": "num_masks",
                    "possible_values": [
                        [
                            "x.shape[0]",
                            "Subscript"
                        ]
                    ]
                },
                "device": {
                    "value": "labels.device",
                    "possible_values": []
                }
            },
            "cat_94": {
                "variable": {
                    "value": "rois",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[matched_idxs[:, None], boxes]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_102": {
                "variable": {
                    "value": "states",
                    "possible_values": []
                },
                "tensors": {
                    "value": "states",
                    "possible_values": [
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_states, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(states, dim=0)",
                            "Call"
                        ],
                        [
                            "states.view(-1, 1)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "states.flatten()",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_106": {
                "variable": {
                    "value": "states_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "states_logits.to(torch.float32)",
                    "possible_values": []
                },
                "target": {
                    "value": "states.to(torch.float32)",
                    "possible_values": []
                }
            },
            "cat_128": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(labels)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "[r['labels'] for r in result]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_129": {
                "variable": {
                    "value": "mask_targets",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mask_targets",
                    "possible_values": [
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ],
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_135": {
                "variable": {
                    "value": "mask_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_logits[torch.arange(labels.shape[0], device=labels.device), labels]",
                    "possible_values": []
                },
                "target": {
                    "value": "mask_targets",
                    "possible_values": [
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ],
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "cat_163": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "tensors": {
                    "value": "labels",
                    "possible_values": [
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "torch.cat(labels)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[l[idxs] for (l, idxs) in zip(gt_labels, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(labels, dim=0)",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "torch.arange(num_classes, device=device)",
                            "Call"
                        ],
                        [
                            "labels.view(1, -1).expand_as(scores)",
                            "Call"
                        ],
                        [
                            "labels[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "labels.flatten()",
                            "Call"
                        ],
                        [
                            "[r['labels'] for r in result]",
                            "ListComp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_164": {
                "variable": {
                    "value": "mask_targets",
                    "possible_values": []
                },
                "tensors": {
                    "value": "mask_targets",
                    "possible_values": [
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ],
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_165": {
                "variable": {
                    "value": "partmask_targets",
                    "possible_values": []
                },
                "tensors": {
                    "value": "partmask_targets",
                    "possible_values": [
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_partmasks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(partmask_targets, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_171": {
                "variable": {
                    "value": "mask_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_logits[torch.arange(labels.shape[0], device=labels.device), labels]",
                    "possible_values": []
                },
                "target": {
                    "value": "mask_targets",
                    "possible_values": [
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ],
                        [
                            "[project_masks_on_boxes(m, p, i, discretization_size) for (m, p, i) in zip(gt_masks, proposals, mask_matched_idxs)]",
                            "ListComp"
                        ],
                        [
                            "torch.cat(mask_targets, dim=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_242": {
                "variable": {
                    "value": "xy_preds",
                    "possible_values": []
                },
                "*size": {
                    "value": "(len(rois), 3, num_keypoints)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "possible_values": []
                },
                "device": {
                    "value": "maps.device",
                    "possible_values": []
                }
            },
            "zeros_243": {
                "variable": {
                    "value": "end_scores",
                    "possible_values": []
                },
                "*size": {
                    "value": "(len(rois), num_keypoints)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "possible_values": []
                },
                "device": {
                    "value": "maps.device",
                    "possible_values": []
                }
            },
            "cat_282": {
                "variable": {
                    "value": "keypoint_targets",
                    "possible_values": []
                },
                "tensors": {
                    "value": "heatmaps",
                    "possible_values": [
                        [
                            "lin_ind * valid",
                            "BinOp"
                        ],
                        [
                            "[]",
                            "List"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_283": {
                "variable": {
                    "value": "valid",
                    "possible_values": []
                },
                "tensors": {
                    "value": "valid",
                    "possible_values": [
                        [
                            "(valid_loc & vis).long()",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(valid, dim=0).to(dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "torch.nonzero(valid).squeeze(1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "nonzero_284": {
                "variable": {
                    "value": "valid",
                    "possible_values": []
                },
                "input": {
                    "value": "valid",
                    "possible_values": [
                        [
                            "(valid_loc & vis).long()",
                            "Call"
                        ],
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(valid, dim=0).to(dtype=torch.uint8)",
                            "Call"
                        ],
                        [
                            "torch.nonzero(valid).squeeze(1)",
                            "Call"
                        ]
                    ]
                }
            },
            "squeeze_284": {
                "variable": {
                    "value": "valid",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cross_entropy_293": {
                "variable": {
                    "value": "keypoint_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "keypoint_logits[valid]",
                    "possible_values": []
                },
                "target": {
                    "value": "keypoint_targets[valid]",
                    "possible_values": []
                }
            },
            "zeros_like_324": {
                "variable": {
                    "value": "boxes_exp",
                    "possible_values": []
                },
                "input": {
                    "value": "boxes",
                    "possible_values": [
                        [
                            "expand_boxes(boxes, scale).to(dtype=torch.int64).tolist()",
                            "Call"
                        ],
                        [
                            "box_ops.clip_boxes_to_image(boxes, image_shape)",
                            "Call"
                        ],
                        [
                            "boxes[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "boxes.reshape(-1, 4)",
                            "Call"
                        ],
                        [
                            "box_ops.clip_boxes_to_image(boxes, image_shape)",
                            "Call"
                        ],
                        [
                            "boxes[:, 1:]",
                            "Subscript"
                        ],
                        [
                            "boxes.reshape(-1, 4)",
                            "Call"
                        ]
                    ]
                }
            },
            "pad_335": {
                "variable": {
                    "value": "padded_mask",
                    "possible_values": []
                },
                "input": {
                    "value": "mask",
                    "possible_values": [
                        [
                            "mask.expand((1, 1, -1, -1))",
                            "Call"
                        ],
                        [
                            "misc_nn_ops.interpolate(mask, size=(h, w), mode='bilinear', align_corners=False)",
                            "Call"
                        ],
                        [
                            "mask[0][0]",
                            "Subscript"
                        ]
                    ]
                },
                "pad": {
                    "value": "(padding,) * 4",
                    "possible_values": []
                }
            },
            "zeros_353": {
                "variable": {
                    "value": "im_mask",
                    "possible_values": []
                },
                "*size": {
                    "value": "(im_h, im_w)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "mask.dtype",
                    "possible_values": []
                },
                "device": {
                    "value": "mask.device",
                    "possible_values": []
                }
            },
            "full_179": {
                "variable": {
                    "value": "pos_weight",
                    "possible_values": []
                },
                "size": {
                    "value": "[28, 28]",
                    "possible_values": []
                },
                "fill_value": {
                    "value": "10",
                    "possible_values": []
                }
            },
            "binary_cross_entropy_with_logits_180": {
                "variable": {
                    "value": "partmask_loss",
                    "possible_values": []
                },
                "input": {
                    "value": "mask_logits[labels == 2, [3 for i in range(summ)]]",
                    "possible_values": []
                },
                "target": {
                    "value": "partmask_targets[labels == 2]",
                    "possible_values": []
                },
                "pos_weight": {
                    "value": "pos_weight",
                    "possible_values": [
                        [
                            "torch.full([28, 28], 10).to('cuda')",
                            "Call"
                        ]
                    ]
                }
            },
            "softmax_553": {
                "variable": {
                    "value": "pred_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "class_logits",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "softmax_606": {
                "variable": {
                    "value": "pred_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "class_logits",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "nonzero_503": {
                "variable": {
                    "value": "img_sampled_inds",
                    "possible_values": []
                },
                "input": {
                    "value": "pos_inds_img | neg_inds_img",
                    "possible_values": []
                }
            },
            "squeeze_503": {
                "variable": {
                    "value": "img_sampled_inds",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "arange_566": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "start": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "class_logits.shape[-1]",
                            "Subscript"
                        ],
                        [
                            "class_logits.shape[-1]",
                            "Subscript"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "class_logits.device",
                            "Attribute"
                        ],
                        [
                            "class_logits.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "nonzero_580": {
                "variable": {
                    "value": "inds",
                    "possible_values": []
                },
                "input": {
                    "value": "scores > self.score_thresh",
                    "possible_values": []
                }
            },
            "squeeze_580": {
                "variable": {
                    "value": "inds",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "arange_621": {
                "variable": {
                    "value": "labels",
                    "possible_values": []
                },
                "start": {
                    "value": "num_classes",
                    "possible_values": [
                        [
                            "class_logits.shape[-1]",
                            "Subscript"
                        ],
                        [
                            "class_logits.shape[-1]",
                            "Subscript"
                        ]
                    ]
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "class_logits.device",
                            "Attribute"
                        ],
                        [
                            "class_logits.device",
                            "Attribute"
                        ]
                    ]
                }
            },
            "nonzero_635": {
                "variable": {
                    "value": "inds",
                    "possible_values": []
                },
                "input": {
                    "value": "scores > self.score_thresh",
                    "possible_values": []
                }
            },
            "squeeze_635": {
                "variable": {
                    "value": "inds",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "interpolate_249": {
                "input": {
                    "value": "maps[i][None]",
                    "possible_values": []
                },
                "size": {
                    "value": "(roi_map_height, roi_map_width)",
                    "possible_values": []
                },
                "mode": {
                    "value": "bicubic",
                    "possible_values": []
                },
                "align_corners": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "stack_375": {
                "tensors": {
                    "value": "res",
                    "possible_values": [
                        [
                            "[paste_mask_in_image(m[0], b, im_h, im_w) for (m, b) in zip(masks, boxes)]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(res, dim=0)[:, None]",
                            "Subscript"
                        ],
                        [
                            "masks.new_empty((0, 1, im_h, im_w))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_509": {
                "tensors": {
                    "value": "(proposal, gt_box)",
                    "possible_values": []
                }
            },
            "arange_136": {
                "start": {
                    "value": "labels.shape[0]",
                    "possible_values": []
                },
                "device": {
                    "value": "labels.device",
                    "possible_values": []
                }
            },
            "arange_172": {
                "start": {
                    "value": "labels.shape[0]",
                    "possible_values": []
                },
                "device": {
                    "value": "labels.device",
                    "possible_values": []
                }
            },
            "arange_263": {
                "start": {
                    "value": "num_keypoints",
                    "possible_values": [
                        [
                            "maps.shape[1]",
                            "Subscript"
                        ]
                    ]
                }
            },
            "nonzero_703": {
                "variable": {
                    "value": "pos",
                    "possible_values": []
                },
                "input": {
                    "value": "labels[img_id] > 0",
                    "possible_values": []
                }
            },
            "squeeze_703": {
                "variable": {
                    "value": "pos",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "nonzero_731": {
                "variable": {
                    "value": "pos",
                    "possible_values": []
                },
                "input": {
                    "value": "labels[img_id] > 0",
                    "possible_values": []
                }
            },
            "squeeze_731": {
                "variable": {
                    "value": "pos",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "nonzero_764": {
                "variable": {
                    "value": "pos",
                    "possible_values": []
                },
                "input": {
                    "value": "labels[img_id] > 0",
                    "possible_values": []
                }
            },
            "squeeze_764": {
                "variable": {
                    "value": "pos",
                    "possible_values": []
                },
                "input": {
                    "value": "1",
                    "possible_values": []
                }
            }
        }
    },
    "models/transforms.py": {
        "torch": {}
    },
    "models/utils.py": {
        "torch": {
            "tensor_95": {
                "variable": {
                    "value": "local_size",
                    "possible_values": []
                },
                "data": {
                    "value": "[tensor.numel()]",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "possible_values": []
                }
            },
            "tensor_39": {
                "variable": {
                    "value": "t",
                    "possible_values": []
                },
                "data": {
                    "value": "[self.count, self.total]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float64",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "possible_values": []
                }
            },
            "tensor_48": {
                "variable": {
                    "value": "d",
                    "possible_values": []
                },
                "data": {
                    "value": "list(self.deque)",
                    "possible_values": []
                }
            },
            "tensor_53": {
                "variable": {
                    "value": "d",
                    "possible_values": []
                },
                "data": {
                    "value": "list(self.deque)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float32",
                    "possible_values": []
                }
            },
            "empty_108": {
                "variable": {
                    "value": "padding",
                    "possible_values": []
                },
                "size": {
                    "value": "(max_size - local_size,)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "possible_values": []
                }
            },
            "cat_109": {
                "variable": {
                    "value": "tensor",
                    "possible_values": []
                },
                "tensors": {
                    "value": "(tensor, padding)",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_139": {
                "variable": {
                    "value": "values",
                    "possible_values": []
                },
                "tensors": {
                    "value": "values",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.stack(values, dim=0)",
                            "Call"
                        ],
                        [
                            "values / world_size",
                            "BinOp"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "LambdaLR_249": {
                "optimizer": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "lr_lambda": {
                    "value": "f",
                    "possible_values": []
                }
            },
            "set_device_319": {
                "device": {
                    "value": "args.gpu",
                    "possible_values": []
                }
            },
            "tensor_96": {
                "data": {
                    "value": "[0]",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "possible_values": []
                }
            },
            "no_grad_132": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_191": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_available_276": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "is_initialized_278": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "save_301": {
                "obj": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "empty_106": {
                "*size": {
                    "value": "(max_size,)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                },
                "device": {
                    "value": "cuda",
                    "possible_values": []
                }
            },
            "is_available_218": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "device_count_311": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "max_memory_allocated_223": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "tool/infer.py": {
        "torch": {
            "load_179": {
                "variable": {
                    "value": "state_dict",
                    "possible_values": []
                },
                "f": {
                    "value": "args.pretrained_model",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            }
        }
    },
    "tool/train.py": {
        "torch": {
            "device_53": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "args.device",
                    "possible_values": []
                }
            },
            "DataLoader_74": {
                "variable": {
                    "value": "data_loader",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "possible_values": [
                        [
                            "get_coco_for_apollo(os.path.join(args.data_path, 'images'), os.path.join(args.data_path, 'cus_editing_data.json'), get_transform(train=True))",
                            "Call"
                        ]
                    ]
                },
                "batch_sampler": {
                    "value": "train_batch_sampler",
                    "possible_values": [
                        [
                            "GroupedBatchSampler(train_sampler, group_ids, args.batch_size)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.BatchSampler(train_sampler, args.batch_size, drop_last=True)",
                            "Call"
                        ]
                    ]
                },
                "num_workers": {
                    "value": "args.workers",
                    "possible_values": []
                },
                "collate_fn": {
                    "value": "utils.collate_fn",
                    "possible_values": []
                }
            },
            "SGD_93": {
                "variable": {
                    "value": "optimizer",
                    "possible_values": []
                },
                "params": {
                    "value": "params",
                    "possible_values": [
                        [
                            "[p for p in model.parameters() if p.requires_grad]",
                            "ListComp"
                        ]
                    ]
                },
                "lr": {
                    "value": "args.lr",
                    "possible_values": []
                },
                "momentum": {
                    "value": "args.momentum",
                    "possible_values": []
                },
                "weight_decay": {
                    "value": "args.weight_decay",
                    "possible_values": []
                }
            },
            "MultiStepLR_96": {
                "variable": {
                    "value": "lr_scheduler",
                    "possible_values": []
                },
                "optimizer": {
                    "value": "optimizer",
                    "possible_values": [
                        [
                            "torch.optim.SGD(params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)",
                            "Call"
                        ]
                    ]
                },
                "milestones": {
                    "value": "args.lr_steps",
                    "possible_values": []
                },
                "gamma": {
                    "value": "args.lr_gamma",
                    "possible_values": []
                }
            },
            "DistributedSampler_63": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "dataset": {
                    "value": "dataset",
                    "possible_values": [
                        [
                            "get_coco_for_apollo(os.path.join(args.data_path, 'images'), os.path.join(args.data_path, 'cus_editing_data.json'), get_transform(train=True))",
                            "Call"
                        ]
                    ]
                }
            },
            "RandomSampler_65": {
                "variable": {
                    "value": "train_sampler",
                    "possible_values": []
                },
                "data_source": {
                    "value": "dataset",
                    "possible_values": [
                        [
                            "get_coco_for_apollo(os.path.join(args.data_path, 'images'), os.path.join(args.data_path, 'cus_editing_data.json'), get_transform(train=True))",
                            "Call"
                        ]
                    ]
                }
            },
            "BatchSampler_71": {
                "variable": {
                    "value": "train_batch_sampler",
                    "possible_values": []
                },
                "sampler": {
                    "value": "train_sampler",
                    "possible_values": [
                        [
                            "torch.utils.data.distributed.DistributedSampler(dataset)",
                            "Call"
                        ],
                        [
                            "torch.utils.data.RandomSampler(dataset)",
                            "Call"
                        ]
                    ]
                },
                "batch_size": {
                    "value": "args.batch_size",
                    "possible_values": []
                },
                "drop_last": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "DistributedDataParallel_88": {
                "variable": {
                    "value": "model",
                    "possible_values": []
                },
                "module": {
                    "value": "model",
                    "possible_values": [
                        [
                            "torchvision.models.detection.maskrcnn_resnet50_fpn(num_classes=3)",
                            "Call"
                        ],
                        [
                            "mask_rcnn.maskrcnn_resnet50_fpn(pretrained=True, num_classes=3, main_backbone_pretrained_path=args.main_backbone_path, aux_backbone_pretrained_path=args.aux_backbone_path)",
                            "Call"
                        ],
                        [
                            "get_double_backbone_model(args)",
                            "Call"
                        ],
                        [
                            "torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])",
                            "Call"
                        ]
                    ]
                },
                "device_ids": {
                    "value": "[args.gpu]",
                    "possible_values": []
                }
            },
            "load_99": {
                "variable": {
                    "value": "checkpoint",
                    "possible_values": []
                },
                "f": {
                    "value": "args.resume",
                    "possible_values": []
                },
                "map_location": {
                    "value": "cpu",
                    "possible_values": []
                }
            }
        }
    }
}