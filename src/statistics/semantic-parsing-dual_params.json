{
    "models/Beam.py": {
        "torch": {
            "zeros_24": {
                "variable": {
                    "value": "self.scores",
                    "possible_values": []
                },
                "*size": {
                    "value": "size",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "possible_values": []
                }
            },
            "zeros_71": {
                "variable": {
                    "value": "masks",
                    "possible_values": []
                },
                "*size": {
                    "value": "word_probs.size()",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "False",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "possible_values": []
                }
            },
            "zeros_82": {
                "variable": {
                    "value": "masks",
                    "possible_values": []
                },
                "*size": {
                    "value": "beam_scores.size()",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "False",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "possible_values": []
                }
            },
            "sort_119": {
                "input": {
                    "value": "self.scores",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "stack_144": {
                "tensors": {
                    "value": "hyp[::-1]",
                    "possible_values": []
                }
            },
            "stack_157": {
                "tensors": {
                    "value": "hyp[::-1]",
                    "possible_values": []
                }
            },
            "zeros_30": {
                "*size": {
                    "value": "size",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "self.device",
                    "possible_values": []
                }
            }
        }
    },
    "models/attention/attention_rnn.py": {
        "torch": {
            "softmax_38": {
                "variable": {
                    "value": "a",
                    "possible_values": []
                },
                "input": {
                    "value": "e",
                    "possible_values": [
                        [
                            "torch.bmm(m, decoder_state.unsqueeze(-1)).squeeze(dim=-1)",
                            "Call"
                        ],
                        [
                            "self.Wa(torch.cat([d, hiddens], dim=-1))",
                            "Call"
                        ],
                        [
                            "self.Va(torch.tanh(e)).squeeze(dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "bmm_39": {
                "variable": {
                    "value": "context",
                    "possible_values": []
                },
                "input": {
                    "value": "a.unsqueeze(1)",
                    "possible_values": []
                },
                "mat2": {
                    "value": "hiddens",
                    "possible_values": []
                }
            },
            "Linear_16": {
                "variable": {
                    "value": "self.Wa",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.enc_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.dec_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_18": {
                "variable": {
                    "value": "self.Wa",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.enc_dim + self.dec_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.dec_dim",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "Linear_19": {
                "variable": {
                    "value": "self.Va",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.dec_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                },
                "bias": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "bmm_32": {
                "variable": {
                    "value": "e",
                    "possible_values": []
                },
                "input": {
                    "value": "m",
                    "possible_values": [
                        [
                            "self.Wa(hiddens)",
                            "Call"
                        ]
                    ]
                },
                "mat2": {
                    "value": "decoder_state.unsqueeze(-1)",
                    "possible_values": []
                }
            },
            "squeeze_32": {
                "variable": {
                    "value": "e",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_35": {
                "tensors": {
                    "value": "[d, hiddens]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "tanh_36": {
                "input": {
                    "value": "e",
                    "possible_values": [
                        [
                            "torch.bmm(m, decoder_state.unsqueeze(-1)).squeeze(dim=-1)",
                            "Call"
                        ],
                        [
                            "self.Wa(torch.cat([d, hiddens], dim=-1))",
                            "Call"
                        ],
                        [
                            "self.Va(torch.tanh(e)).squeeze(dim=-1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models/construct_models.py": {
        "torch": {}
    },
    "models/decoder/decoder_rnn.py": {
        "torch": {
            "Linear_19": {
                "variable": {
                    "value": "self.affine",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.hidden_dim + self.attn.enc_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.tgt_emb_size",
                    "possible_values": []
                }
            },
            "Dropout_20": {
                "variable": {
                    "value": "self.dropout_layer",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_35": {
                "variable": {
                    "value": "context",
                    "possible_values": []
                },
                "tensors": {
                    "value": "context",
                    "possible_values": [
                        [
                            "[]",
                            "List"
                        ],
                        [
                            "torch.cat(context, dim=1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_36": {
                "variable": {
                    "value": "feats",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[out, context]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/decoder/decoder_rnn_pointer.py": {
        "torch": {
            "Linear_19": {
                "variable": {
                    "value": "self.gate",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.hidden_dim + self.attn.enc_dim + self.tgt_emb_size",
                    "possible_values": []
                },
                "out_features": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "Linear_20": {
                "variable": {
                    "value": "self.affine",
                    "possible_values": []
                },
                "in_features": {
                    "value": "self.hidden_dim + self.attn.enc_dim",
                    "possible_values": []
                },
                "out_features": {
                    "value": "self.tgt_emb_size",
                    "possible_values": []
                }
            },
            "Dropout_21": {
                "variable": {
                    "value": "self.dropout_layer",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "sigmoid_43": {
                "variable": {
                    "value": "gate_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "self.gate(torch.cat([feats, x], dim=-1))",
                    "possible_values": []
                }
            },
            "bmm_45": {
                "variable": {
                    "value": "copy_distribution",
                    "possible_values": []
                },
                "input": {
                    "value": "pointer",
                    "possible_values": []
                },
                "mat2": {
                    "value": "copy_tokens",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "cat_41": {
                "tensors": {
                    "value": "pointer",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "cat_42": {
                "tensors": {
                    "value": "[out, context]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "cat_43": {
                "tensors": {
                    "value": "[feats, x]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/dual_learning.py": {
        "torch": {
            "mean_69": {
                "input": {
                    "value": "total_reward.to(self.sp_device) * sp_scores",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_70": {
                "input": {
                    "value": "sp_loss",
                    "possible_values": [
                        [
                            "-torch.mean(total_reward.to(self.sp_device) * sp_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean((1 - self.beta) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_70": {
                "input": {
                    "value": "sp_loss",
                    "possible_values": [
                        [
                            "-torch.mean(total_reward.to(self.sp_device) * sp_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean((1 - self.beta) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_71": {
                "input": {
                    "value": "(1 - self.alpha) * rec_reward",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_72": {
                "input": {
                    "value": "qg_loss",
                    "possible_values": [
                        [
                            "-torch.mean((1 - self.alpha) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean(total_reward.to(self.qg_device) * qg_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_72": {
                "input": {
                    "value": "qg_loss",
                    "possible_values": [
                        [
                            "-torch.mean((1 - self.alpha) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean(total_reward.to(self.qg_device) * qg_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_107": {
                "input": {
                    "value": "total_reward.to(self.qg_device) * qg_scores",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_108": {
                "input": {
                    "value": "qg_loss",
                    "possible_values": [
                        [
                            "-torch.mean((1 - self.alpha) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean(total_reward.to(self.qg_device) * qg_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_108": {
                "input": {
                    "value": "qg_loss",
                    "possible_values": [
                        [
                            "-torch.mean((1 - self.alpha) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean(total_reward.to(self.qg_device) * qg_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(qg_loss) if self.reduction == 'sum' else torch.mean(qg_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_109": {
                "input": {
                    "value": "(1 - self.beta) * rec_reward",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "sum_110": {
                "input": {
                    "value": "sp_loss",
                    "possible_values": [
                        [
                            "-torch.mean(total_reward.to(self.sp_device) * sp_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean((1 - self.beta) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ]
                    ]
                }
            },
            "mean_110": {
                "input": {
                    "value": "sp_loss",
                    "possible_values": [
                        [
                            "-torch.mean(total_reward.to(self.sp_device) * sp_scores, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ],
                        [
                            "-torch.mean((1 - self.beta) * rec_reward, dim=1)",
                            "UnaryOp"
                        ],
                        [
                            "torch.sum(sp_loss) if self.reduction == 'sum' else torch.mean(sp_loss)",
                            "IfExp"
                        ]
                    ]
                }
            }
        }
    },
    "models/embedding/embedding_rnn.py": {
        "torch": {
            "Embedding_8": {
                "variable": {
                    "value": "self.embed",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab",
                    "possible_values": []
                },
                "embedding_dim": {
                    "value": "emb_size",
                    "possible_values": []
                }
            },
            "Dropout_11": {
                "variable": {
                    "value": "self.dropout_layer",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "models/enc2dec/state_transition.py": {
        "torch": {
            "Linear_21": {
                "variable": {
                    "value": "self.h_affine",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_dim * self.num_directions",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_dim",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_23": {
                "variable": {
                    "value": "self.c_affine",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_dim * self.num_directions",
                    "possible_values": []
                },
                "out_features": {
                    "value": "hidden_dim",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_39": {
                "variable": {
                    "value": "index_slices",
                    "possible_values": []
                },
                "data": {
                    "value": "index_slices",
                    "possible_values": [
                        [
                            "[2 * i + 1 for i in range(self.num_layers)]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(index_slices, dtype=torch.long, device=hidden_states[0].device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "hidden_states[0].device",
                    "possible_values": []
                }
            },
            "index_select_42": {
                "variable": {
                    "value": "dec_h",
                    "possible_values": []
                },
                "input": {
                    "value": "enc_h",
                    "possible_values": [
                        [
                            "hidden_states",
                            "Name"
                        ],
                        [
                            "hidden_states",
                            "Name"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "index_slices",
                    "possible_values": [
                        [
                            "[2 * i + 1 for i in range(self.num_layers)]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(index_slices, dtype=torch.long, device=hidden_states[0].device)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_43": {
                "variable": {
                    "value": "dec_c",
                    "possible_values": []
                },
                "input": {
                    "value": "enc_c",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "index_slices",
                    "possible_values": [
                        [
                            "[2 * i + 1 for i in range(self.num_layers)]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(index_slices, dtype=torch.long, device=hidden_states[0].device)",
                            "Call"
                        ]
                    ]
                }
            },
            "index_select_47": {
                "variable": {
                    "value": "dec_h",
                    "possible_values": []
                },
                "input": {
                    "value": "enc_h",
                    "possible_values": [
                        [
                            "hidden_states",
                            "Name"
                        ],
                        [
                            "hidden_states",
                            "Name"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "index_slices",
                    "possible_values": [
                        [
                            "[2 * i + 1 for i in range(self.num_layers)]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(index_slices, dtype=torch.long, device=hidden_states[0].device)",
                            "Call"
                        ]
                    ]
                }
            },
            "tanh_66": {
                "variable": {
                    "value": "dec_h",
                    "possible_values": []
                },
                "input": {
                    "value": "dec_h",
                    "possible_values": [
                        [
                            "enc_h.new_zeros(self.num_layers, enc_h.size(1), enc_h.size(2))",
                            "Call"
                        ],
                        [
                            "enc_h.new_zeros(self.num_layers, enc_h.size(1), enc_h.size(2))",
                            "Call"
                        ],
                        [
                            "self.h_affine(enc_h.transpose(0, 1).contiguous().view(batches * self.num_layers, -1))",
                            "Call"
                        ],
                        [
                            "self.h_affine(enc_h.transpose(0, 1).contiguous().view(batches * self.num_layers, -1))",
                            "Call"
                        ],
                        [
                            "torch.index_select(enc_h, 0, index_slices)",
                            "Call"
                        ],
                        [
                            "torch.index_select(enc_h, 0, index_slices)",
                            "Call"
                        ],
                        [
                            "dec_h.contiguous().view(batches, self.num_layers, -1).transpose(0, 1).contiguous()",
                            "Call"
                        ],
                        [
                            "torch.tanh(dec_h)",
                            "Call"
                        ],
                        [
                            "dec_h.contiguous().view(batches, self.num_layers, -1).transpose(0, 1).contiguous()",
                            "Call"
                        ]
                    ]
                }
            },
            "tanh_58": {
                "input": {
                    "value": "dec_c",
                    "possible_values": [
                        [
                            "enc_c.new_zeros(self.num_layers, enc_c.size(1), enc_c.size(2))",
                            "Call"
                        ],
                        [
                            "self.c_affine(enc_c.transpose(0, 1).contiguous().view(batches * self.num_layers, -1))",
                            "Call"
                        ],
                        [
                            "torch.index_select(enc_c, 0, index_slices)",
                            "Call"
                        ],
                        [
                            "dec_c.contiguous().view(batches, self.num_layers, -1).transpose(0, 1).contiguous()",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models/encoder/encoder_rnn.py": {
        "torch": {}
    },
    "models/encoder_decoder.py": {
        "torch": {
            "save_42": {
                "obj": {
                    "value": "self.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "open(save_dir, 'wb')",
                    "possible_values": []
                }
            },
            "load_39": {
                "f": {
                    "value": "open(load_dir, 'rb')",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage",
                    "possible_values": []
                }
            }
        }
    },
    "models/generator/generator_naive.py": {
        "torch": {
            "Linear_12": {
                "variable": {
                    "value": "self.proj",
                    "possible_values": []
                },
                "in_features": {
                    "value": "feats",
                    "possible_values": []
                },
                "out_features": {
                    "value": "vocab",
                    "possible_values": []
                }
            },
            "Dropout_13": {
                "variable": {
                    "value": "self.dropout_layer",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "log_softmax_16": {
                "input": {
                    "value": "self.proj(self.dropout_layer(x))",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "models/generator/generator_pointer.py": {
        "torch": {
            "Linear_13": {
                "variable": {
                    "value": "self.proj",
                    "possible_values": []
                },
                "in_features": {
                    "value": "feats",
                    "possible_values": []
                },
                "out_features": {
                    "value": "vocab",
                    "possible_values": []
                }
            },
            "Dropout_14": {
                "variable": {
                    "value": "self.dropout_layer",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "softmax_22": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "self.proj(self.dropout_layer(x))",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "zeros_23": {
                "variable": {
                    "value": "extra_zeros",
                    "possible_values": []
                },
                "*size": {
                    "value": "x.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "x.size(1)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "x.device",
                    "possible_values": []
                }
            },
            "cat_24": {
                "variable": {
                    "value": "generate_distribution",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[out, extra_zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "log_25": {
                "variable": {
                    "value": "final_scores",
                    "possible_values": []
                },
                "input": {
                    "value": "gate_scores * generate_distribution + (1 - gate_scores) * copy_distribution + 1e-20",
                    "possible_values": []
                }
            }
        }
    },
    "models/language_model.py": {
        "torch": {
            "Dropout_18": {
                "variable": {
                    "value": "self.dropout_layer",
                    "possible_values": []
                },
                "p": {
                    "value": "dropout",
                    "possible_values": [
                        [
                            "0.5",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Embedding_19": {
                "variable": {
                    "value": "self.encoder",
                    "possible_values": []
                },
                "num_embeddings": {
                    "value": "vocab_size",
                    "possible_values": [
                        [
                            "950",
                            "MethodArgument"
                        ]
                    ]
                },
                "embedding_dim": {
                    "value": "emb_size",
                    "possible_values": [
                        [
                            "1024",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_25": {
                "variable": {
                    "value": "self.affine",
                    "possible_values": []
                },
                "in_features": {
                    "value": "hidden_dim",
                    "possible_values": [
                        [
                            "256",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "emb_size",
                    "possible_values": [
                        [
                            "1024",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "Linear_26": {
                "variable": {
                    "value": "self.decoder",
                    "possible_values": []
                },
                "in_features": {
                    "value": "emb_size",
                    "possible_values": [
                        [
                            "1024",
                            "MethodArgument"
                        ]
                    ]
                },
                "out_features": {
                    "value": "vocab_size",
                    "possible_values": [
                        [
                            "950",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "log_softmax_50": {
                "variable": {
                    "value": "scores",
                    "possible_values": []
                },
                "input": {
                    "value": "decoded",
                    "possible_values": [
                        [
                            "self.decoder(self.affine(self.dropout_layer(output)))",
                            "Call"
                        ],
                        [
                            "self.decoder(self.affine(self.dropout_layer(output)))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "log_softmax_64": {
                "variable": {
                    "value": "scores",
                    "possible_values": []
                },
                "input": {
                    "value": "decoded",
                    "possible_values": [
                        [
                            "self.decoder(self.affine(self.dropout_layer(output)))",
                            "Call"
                        ],
                        [
                            "self.decoder(self.affine(self.dropout_layer(output)))",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "gather_65": {
                "variable": {
                    "value": "log_prob",
                    "possible_values": []
                },
                "input": {
                    "value": "scores",
                    "possible_values": [
                        [
                            "F.log_softmax(decoded, dim=-1)",
                            "Call"
                        ],
                        [
                            "F.log_softmax(decoded, dim=-1)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "2",
                    "possible_values": []
                },
                "index": {
                    "value": "output_feats.unsqueeze(-1)",
                    "possible_values": []
                }
            },
            "sum_66": {
                "variable": {
                    "value": "sent_log_prob",
                    "possible_values": []
                },
                "input": {
                    "value": "log_prob * lens2mask(lens).float()",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "save_73": {
                "obj": {
                    "value": "self.state_dict()",
                    "possible_values": []
                },
                "f": {
                    "value": "open(save_dir, 'wb')",
                    "possible_values": []
                }
            },
            "load_70": {
                "f": {
                    "value": "open(load_dir, 'rb')",
                    "possible_values": []
                },
                "map_location": {
                    "value": "lambda storage, loc: storage",
                    "possible_values": []
                }
            }
        }
    },
    "models/model_attn.py": {
        "torch": {
            "ones_51": {
                "variable": {
                    "value": "ys",
                    "possible_values": []
                },
                "*size": {
                    "value": "batches",
                    "possible_values": [
                        [
                            "memory.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "1",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "tensor_53": {
                "variable": {
                    "value": "all_done",
                    "possible_values": []
                },
                "data": {
                    "value": "[False] * batches",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.uint8",
                    "possible_values": []
                },
                "device": {
                    "value": "memory.device",
                    "possible_values": []
                }
            },
            "zeros_54": {
                "variable": {
                    "value": "scores",
                    "possible_values": []
                },
                "*size": {
                    "value": "batches",
                    "possible_values": [
                        [
                            "memory.size(0)",
                            "Call"
                        ]
                    ]
                },
                "out": {
                    "value": "1",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "memory.device",
                    "possible_values": []
                }
            },
            "stack_157": {
                "variable": {
                    "value": "results[scores]",
                    "possible_values": []
                },
                "tensors": {
                    "value": "results['scores']",
                    "possible_values": []
                }
            },
            "max_59": {
                "variable": {
                    "value": "(maxprob, ys)",
                    "possible_values": []
                },
                "input": {
                    "value": "logprob",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                },
                "keepdim": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "stack_100": {
                "variable": {
                    "value": "ys",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[b.get_current_state() for b in beam if not b.done()]",
                    "possible_values": []
                }
            },
            "cat_117": {
                "variable": {
                    "value": "select_indices_array",
                    "possible_values": []
                },
                "tensors": {
                    "value": "select_indices_array",
                    "possible_values": [
                        [
                            "torch.cat(select_indices_array, dim=0)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "tensor_127": {
                "variable": {
                    "value": "active_idx",
                    "possible_values": []
                },
                "data": {
                    "value": "[item[1] for item in active]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "memory.device",
                    "possible_values": []
                }
            },
            "cat_68": {
                "tensors": {
                    "value": "pred",
                    "possible_values": []
                }
            },
            "stack_156": {
                "tensors": {
                    "value": "scores",
                    "possible_values": [
                        [
                            "torch.zeros(batches, 1, dtype=torch.float, device=memory.device)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models/model_utils.py": {
        "torch": {
            "arange_38": {
                "variable": {
                    "value": "masks",
                    "possible_values": []
                },
                "start": {
                    "value": "0",
                    "possible_values": []
                },
                "end": {
                    "value": "max_len",
                    "possible_values": [
                        [
                            "lens.max()",
                            "Call"
                        ]
                    ]
                }
            },
            "lt_38": {
                "variable": {
                    "value": "masks",
                    "possible_values": []
                },
                "input": {
                    "value": "lens.unsqueeze(1)",
                    "possible_values": []
                }
            },
            "sort_53": {
                "variable": {
                    "value": "(sorted_lens, sort_key)",
                    "possible_values": []
                },
                "input": {
                    "value": "lens",
                    "possible_values": []
                },
                "descending": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "sum_54": {
                "variable": {
                    "value": "nonzero_index",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_lens > 0",
                    "possible_values": []
                }
            },
            "index_select_55": {
                "variable": {
                    "value": "sorted_inputs",
                    "possible_values": []
                },
                "input": {
                    "value": "inputs",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                },
                "index": {
                    "value": "sort_key[:nonzero_index]",
                    "possible_values": []
                }
            },
            "pack_padded_sequence_57": {
                "variable": {
                    "value": "packed_inputs",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_inputs",
                    "possible_values": [
                        [
                            "torch.index_select(inputs, dim=0, index=sort_key[:nonzero_index])",
                            "Call"
                        ]
                    ]
                },
                "lengths": {
                    "value": "sorted_lens[:nonzero_index].tolist()",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "pad_packed_sequence_59": {
                "variable": {
                    "value": "(out, _)",
                    "possible_values": []
                },
                "sequence": {
                    "value": "packed_out",
                    "possible_values": []
                },
                "batch_first": {
                    "value": "True",
                    "possible_values": []
                }
            },
            "zeros_63": {
                "variable": {
                    "value": "pad_zeros",
                    "possible_values": []
                },
                "*size": {
                    "value": "sorted_lens.size(0) - out.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "out.size(1)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "out.size(2)",
                    "possible_values": []
                }
            },
            "cat_64": {
                "variable": {
                    "value": "sorted_out",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[out, pad_zeros]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_65": {
                "variable": {
                    "value": "pad_hiddens",
                    "possible_values": []
                },
                "*size": {
                    "value": "h.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "sorted_lens.size(0) - h.size(1)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "h.size(2)",
                    "possible_values": []
                }
            },
            "cat_66": {
                "variable": {
                    "value": "sorted_hiddens",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[h, pad_hiddens]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_72": {
                "variable": {
                    "value": "out",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_out",
                    "possible_values": [
                        [
                            "torch.cat([out, pad_zeros], dim=0)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_like_74": {
                "variable": {
                    "value": "hiddens",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_hiddens",
                    "possible_values": [
                        [
                            "torch.cat([h, pad_hiddens], dim=1)",
                            "Call"
                        ]
                    ]
                }
            },
            "zeros_68": {
                "variable": {
                    "value": "pad_cells",
                    "possible_values": []
                },
                "*size": {
                    "value": "c.size(0)",
                    "possible_values": []
                },
                "out": {
                    "value": "sorted_lens.size(0) - c.size(1)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "c.size(2)",
                    "possible_values": []
                }
            },
            "cat_69": {
                "variable": {
                    "value": "sorted_cells",
                    "possible_values": []
                },
                "tensors": {
                    "value": "[c, pad_cells]",
                    "possible_values": []
                },
                "dim": {
                    "value": "1",
                    "possible_values": []
                }
            },
            "zeros_like_76": {
                "variable": {
                    "value": "cells",
                    "possible_values": []
                },
                "input": {
                    "value": "sorted_cells",
                    "possible_values": [
                        [
                            "torch.cat([c, pad_cells], dim=1)",
                            "Call"
                        ]
                    ]
                }
            }
        }
    },
    "models/penalties.py": {
        "torch": {}
    },
    "models/reward.py": {
        "torch": {
            "tensor_35": {
                "variable": {
                    "value": "input_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "input_idxs",
                    "possible_values": [
                        [
                            "[[self.vocab.lf2id[BOS]] + [self.vocab.lf2id[word] if word in self.vocab.lf2id else self.vocab.lf2id[UNK] for word in sent] + [self.vocab.word2id[EOS]] for sent in lf_list]",
                            "ListComp"
                        ],
                        [
                            "[sent + [self.vocab.lf2id[PAD]] * (max_len - len(sent)) for sent in input_idxs]",
                            "ListComp"
                        ],
                        [
                            "[[self.vocab.word2id[BOS]] + [self.vocab.word2id[word] if word in self.vocab.word2id else self.vocab.word2id[UNK] for word in sent] + [self.vocab.word2id[EOS]] for sent in utterances]",
                            "ListComp"
                        ],
                        [
                            "[sent + [self.vocab.word2id[PAD]] * (max_len - len(sent)) for sent in input_idxs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "self.qg_device",
                    "possible_values": []
                }
            },
            "tensor_36": {
                "variable": {
                    "value": "lens",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(each) for each in input_idxs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=self.qg_device)",
                            "Call"
                        ],
                        [
                            "[len(each) for each in input_idxs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=self.sp_device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "self.qg_device",
                    "possible_values": []
                }
            },
            "tensor_43": {
                "variable": {
                    "value": "grammar",
                    "possible_values": []
                },
                "data": {
                    "value": "ans",
                    "possible_values": [
                        [
                            "domain.is_valid(domain.obtain_denotations(domain.normalize(lf_list)))",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "requires_grad": {
                    "value": "False",
                    "possible_values": []
                }
            },
            "tensor_53": {
                "variable": {
                    "value": "input_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "input_idxs",
                    "possible_values": [
                        [
                            "[[self.vocab.lf2id[BOS]] + [self.vocab.lf2id[word] if word in self.vocab.lf2id else self.vocab.lf2id[UNK] for word in sent] + [self.vocab.word2id[EOS]] for sent in lf_list]",
                            "ListComp"
                        ],
                        [
                            "[sent + [self.vocab.lf2id[PAD]] * (max_len - len(sent)) for sent in input_idxs]",
                            "ListComp"
                        ],
                        [
                            "[[self.vocab.word2id[BOS]] + [self.vocab.word2id[word] if word in self.vocab.word2id else self.vocab.word2id[UNK] for word in sent] + [self.vocab.word2id[EOS]] for sent in utterances]",
                            "ListComp"
                        ],
                        [
                            "[sent + [self.vocab.word2id[PAD]] * (max_len - len(sent)) for sent in input_idxs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "self.sp_device",
                    "possible_values": []
                }
            },
            "tensor_54": {
                "variable": {
                    "value": "lens",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(each) for each in input_idxs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=self.qg_device)",
                            "Call"
                        ],
                        [
                            "[len(each) for each in input_idxs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=self.sp_device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "self.sp_device",
                    "possible_values": []
                }
            },
            "gather_67": {
                "variable": {
                    "value": "pick_score",
                    "possible_values": []
                },
                "input": {
                    "value": "logscores",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                },
                "index": {
                    "value": "references.unsqueeze(dim=-1)",
                    "possible_values": []
                }
            },
            "squeeze_67": {
                "variable": {
                    "value": "pick_score",
                    "possible_values": []
                },
                "dim": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "no_grad_38": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_56": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/batch.py": {
        "torch": {
            "tensor_14": {
                "variable": {
                    "value": "lens_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_19": {
                "variable": {
                    "value": "inputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "inputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[word2id[w] if w in word2id else word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_27": {
                "variable": {
                    "value": "outputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "outputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_outputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_outputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_28": {
                "variable": {
                    "value": "out_lens_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "out_lens",
                    "possible_values": [
                        [
                            "[len(each) for each in bos_eos_outputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_outputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_77": {
                "variable": {
                    "value": "lens_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_82": {
                "variable": {
                    "value": "inputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "inputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[word2id[w] if w in word2id else word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_90": {
                "variable": {
                    "value": "outputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "outputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_outputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_outputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_91": {
                "variable": {
                    "value": "out_lens_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "out_lens",
                    "possible_values": [
                        [
                            "[len(each) for each in bos_eos_outputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_outputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_138": {
                "variable": {
                    "value": "lens_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_143": {
                "variable": {
                    "value": "inputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "inputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[word2id[w] if w in word2id else word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_181": {
                "variable": {
                    "value": "lens_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_186": {
                "variable": {
                    "value": "inputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "inputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[word2id[w] if w in word2id else word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_221": {
                "variable": {
                    "value": "conf",
                    "possible_values": []
                },
                "data": {
                    "value": "[ex.conf for ex in ex_list]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_226": {
                "variable": {
                    "value": "conf",
                    "possible_values": []
                },
                "data": {
                    "value": "[ex.conf for ex in ex_list]",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_241": {
                "variable": {
                    "value": "inputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "inputs_idx",
                    "possible_values": [
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.word2id[w] if w in vocab.word2id else vocab.word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[vocab.lf2id[w] if w in vocab.lf2id else vocab.lf2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ],
                        [
                            "[[word2id[w] if w in word2id else word2id[UNK] for w in sent] for sent in padded_inputs]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "tensor_242": {
                "variable": {
                    "value": "lens",
                    "possible_values": []
                },
                "data": {
                    "value": "lens",
                    "possible_values": [
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(ex) for ex in inputs]",
                            "ListComp"
                        ],
                        [
                            "[len(each) for each in bos_eos_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.tensor(lens, dtype=torch.long, device=device)",
                            "Call"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "stack_56": {
                "variable": {
                    "value": "copy_tokens",
                    "possible_values": []
                },
                "tensors": {
                    "value": "copy_tokens",
                    "possible_values": [
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "tensor_67": {
                "variable": {
                    "value": "dec_outputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "dec_outputs",
                    "possible_values": [
                        [
                            "[[len(vocab.lf2id) + oov_list[idx].index(tok) if tok not in vocab.lf2id and tok in oov_list[idx] else vocab.lf2id.get(tok, vocab.lf2id[UNK]) for tok in sent] + [vocab.lf2id[PAD]] * (max_out_len - len(sent)) for (idx, sent) in enumerate(bos_eos_outputs)]",
                            "ListComp"
                        ],
                        [
                            "[[len(vocab.word2id) + oov_list[idx].index(tok) if tok not in vocab.word2id and tok in oov_list[idx] else vocab.word2id.get(tok, vocab.word2id[UNK]) for tok in sent] + [vocab.word2id[PAD]] * (max_out_len - len(sent)) for (idx, sent) in enumerate(bos_eos_outputs)]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "stack_118": {
                "variable": {
                    "value": "copy_tokens",
                    "possible_values": []
                },
                "tensors": {
                    "value": "copy_tokens",
                    "possible_values": [
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "tensor_129": {
                "variable": {
                    "value": "dec_outputs_tensor",
                    "possible_values": []
                },
                "data": {
                    "value": "dec_outputs",
                    "possible_values": [
                        [
                            "[[len(vocab.lf2id) + oov_list[idx].index(tok) if tok not in vocab.lf2id and tok in oov_list[idx] else vocab.lf2id.get(tok, vocab.lf2id[UNK]) for tok in sent] + [vocab.lf2id[PAD]] * (max_out_len - len(sent)) for (idx, sent) in enumerate(bos_eos_outputs)]",
                            "ListComp"
                        ],
                        [
                            "[[len(vocab.word2id) + oov_list[idx].index(tok) if tok not in vocab.word2id and tok in oov_list[idx] else vocab.word2id.get(tok, vocab.word2id[UNK]) for tok in sent] + [vocab.word2id[PAD]] * (max_out_len - len(sent)) for (idx, sent) in enumerate(bos_eos_outputs)]",
                            "ListComp"
                        ]
                    ]
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "stack_171": {
                "variable": {
                    "value": "copy_tokens",
                    "possible_values": []
                },
                "tensors": {
                    "value": "copy_tokens",
                    "possible_values": [
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "stack_213": {
                "variable": {
                    "value": "copy_tokens",
                    "possible_values": []
                },
                "tensors": {
                    "value": "copy_tokens",
                    "possible_values": [
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ],
                        [
                            "[torch.cat([torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)], dim=0) for each in copy_inputs]",
                            "ListComp"
                        ],
                        [
                            "torch.stack(copy_tokens, dim=0).to(device)",
                            "Call"
                        ]
                    ]
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_49": {
                "tensors": {
                    "value": "[torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_111": {
                "tensors": {
                    "value": "[torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_164": {
                "tensors": {
                    "value": "[torch.zeros(len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.lf2id) + MAX_OOV_NUM, dtype=torch.float)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "cat_206": {
                "tensors": {
                    "value": "[torch.zeros(len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float).scatter_(-1, torch.tensor(each, dtype=torch.long).unsqueeze(-1), 1.0), torch.zeros(max_len - len(each), len(vocab.word2id) + MAX_OOV_NUM, dtype=torch.float)]",
                    "possible_values": []
                },
                "dim": {
                    "value": "0",
                    "possible_values": []
                }
            },
            "zeros_50": {
                "*size": {
                    "value": "len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.lf2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_52": {
                "*size": {
                    "value": "max_len - len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.lf2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_112": {
                "*size": {
                    "value": "len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.word2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_114": {
                "*size": {
                    "value": "max_len - len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.word2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_165": {
                "*size": {
                    "value": "len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.lf2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_167": {
                "*size": {
                    "value": "max_len - len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.lf2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_207": {
                "*size": {
                    "value": "len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.word2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "zeros_209": {
                "*size": {
                    "value": "max_len - len(each)",
                    "possible_values": []
                },
                "out": {
                    "value": "len(vocab.word2id) + MAX_OOV_NUM",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            },
            "tensor_51": {
                "data": {
                    "value": "each",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "unsqueeze_51": {
                "input": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "tensor_113": {
                "data": {
                    "value": "each",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "unsqueeze_113": {
                "input": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "tensor_166": {
                "data": {
                    "value": "each",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "unsqueeze_166": {
                "input": {
                    "value": "-1",
                    "possible_values": []
                }
            },
            "tensor_208": {
                "data": {
                    "value": "each",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.long",
                    "possible_values": []
                }
            },
            "unsqueeze_208": {
                "input": {
                    "value": "-1",
                    "possible_values": []
                }
            }
        }
    },
    "utils/gpu.py": {
        "torch": {
            "device_13": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "cpu",
                    "possible_values": []
                }
            },
            "device_17": {
                "variable": {
                    "value": "device",
                    "possible_values": []
                },
                "type": {
                    "value": "'cuda:%d' % deviceId",
                    "possible_values": []
                }
            },
            "device_count_16": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/loss.py": {
        "torch": {
            "NLLLoss_18": {
                "variable": {
                    "value": "self.loss_function",
                    "possible_values": []
                },
                "weight": {
                    "value": "*args",
                    "possible_values": []
                }
            },
            "ones_22": {
                "variable": {
                    "value": "conf",
                    "possible_values": []
                },
                "*size": {
                    "value": "inputs.size(0)",
                    "possible_values": []
                },
                "dtype": {
                    "value": "torch.float",
                    "possible_values": []
                }
            }
        }
    },
    "utils/optimizer.py": {
        "torch": {
            "clip_grad_norm__31": {
                "parameters": {
                    "value": "group['params']",
                    "possible_values": []
                },
                "max_norm": {
                    "value": "self.max_norm",
                    "possible_values": []
                }
            }
        }
    },
    "utils/seed.py": {
        "torch": {
            "manual_seed_7": {
                "seed": {
                    "value": "random_seed",
                    "possible_values": [
                        [
                            "999",
                            "MethodArgument"
                        ]
                    ]
                }
            },
            "is_available_8": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "manual_seed_12": {
                "seed": {
                    "value": "random_seed",
                    "possible_values": [
                        [
                            "999",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    },
    "utils/solver/solver_dual_learning.py": {
        "torch": {
            "empty_cache_178": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "empty_cache_145": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_36": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_59": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/solver/solver_language_model.py": {
        "torch": {
            "empty_cache_79": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_29": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/solver/solver_pseduo_method.py": {
        "torch": {
            "empty_cache_170": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "empty_cache_196": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_38": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_62": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_93": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_109": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/solver/solver_question_generation.py": {
        "torch": {
            "empty_cache_78": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_28": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/solver/solver_semantic_parsing.py": {
        "torch": {
            "empty_cache_77": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            },
            "no_grad_27": {
                "params": {
                    "value": "default",
                    "possible_values": []
                }
            }
        }
    },
    "utils/word2vec.py": {
        "torch": {
            "tensor_22": {
                "variable": {
                    "value": "word2vec[word]",
                    "possible_values": []
                },
                "data": {
                    "value": "np.fromstring(values, sep=' ', dtype=np.float)",
                    "possible_values": []
                },
                "device": {
                    "value": "device",
                    "possible_values": [
                        [
                            "None",
                            "MethodArgument"
                        ]
                    ]
                }
            }
        }
    }
}